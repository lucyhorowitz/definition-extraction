{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DgtCoi70b7wv",
        "outputId": "9b7d0632-f543-44a6-cb53-9cdd95d5c33d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4XBZk5bUaw-K"
      },
      "outputs": [],
      "source": [
        "\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "from transformers import Trainer, TrainingArguments\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "df = pd.read_csv('/content/drive/My Drive/Project/Anno_Chicago.csv')\n",
        "#smalltest\n",
        "\n",
        "small_test = df.sample(n=100)\n",
        "\n",
        "# Define your sentences and labels\n",
        "sentences = small_test['Sentence'].tolist()\n",
        "\n",
        "\n",
        "\n",
        "labels = small_test['Definition?'].tolist()  #  # Labels (1 for definition , 0 for negative)\n",
        "\n",
        "\n",
        "# Load pre-trained Sentence-BERT model and tokenizer\n",
        "model_name = \"sentence-transformers/paraphrase-mpnet-base-v2\"  # Optimal model for long English sentences\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "USmI8BjQghkB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Path to the directory containing the downloaded model files\n",
        "model_directory = \"/content/drive/My Drive/Project/Pre-trainedSbert\"\n",
        "\n",
        "# Load tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_directory)\n",
        "\n",
        "# Load model\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_directory, num_labels=2)  # 2 for binary classification\n",
        "\n",
        "tokenized_input = tokenizer(sentences, padding=True, truncation=True, return_tensors=\"pt\")\n",
        "\n",
        "# Extract input_ids and attention_mask from the tokenized inputs\n",
        "input_ids = tokenized_input['input_ids']\n",
        "attention_mask = tokenized_input['attention_mask']\n",
        "\n",
        "# Split data into training and validation sets\n",
        "train_inputs, val_inputs, train_labels, val_labels, train_mask, val_mask = train_test_split(\n",
        "    input_ids, labels, attention_mask, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PdpDz1SRgq8A",
        "outputId": "bbcf2eb1-1c28-4968-9c10-7b9818f95c28"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of MPNetForSequenceClassification were not initialized from the model checkpoint at /content/drive/My Drive/Project/Pre-trainedSbert and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='/content/drive/My Drive/Project/Trained_models/Chicago_Trained/output',  # Specify the directory where checkpoints and logs will be saved\n",
        "    per_device_train_batch_size=3,\n",
        "    per_device_eval_batch_size=3,\n",
        "    num_train_epochs=4,\n",
        "   logging_dir= '/content/drive/My Drive/Project/Trained_models/Chicago_Trained/logs',\n",
        "    evaluation_strategy=\"epoch\",\n",
        "\n",
        ")\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, input_ids, attention_mask, labels):\n",
        "        self.input_ids = input_ids\n",
        "        self.attention_mask = attention_mask\n",
        "        self.labels = labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.input_ids)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        input_id = self.input_ids[idx]\n",
        "        attention_mask = self.attention_mask[idx]\n",
        "        label = self.labels[idx]\n",
        "        return {\n",
        "            'input_ids': input_id,\n",
        "            'attention_mask': attention_mask,\n",
        "            'labels': label\n",
        "        }\n",
        "\n",
        "train_dataset = CustomDataset(train_inputs, train_mask, train_labels)\n",
        "val_dataset = CustomDataset(val_inputs, val_mask, val_labels)\n"
      ],
      "metadata": {
        "id": "fWxDsBIUgymG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the compute_metrics function to include accuracy, precision, recall, and F1-score\n",
        "def compute_metrics(pred):\n",
        "    labels = val_labels\n",
        "    preds = np.argmax(pred.predictions, axis=1)\n",
        "    accuracy = np.mean(preds == labels)\n",
        "    precision = precision_score(labels, preds)\n",
        "    recall = recall_score(labels, preds)\n",
        "    f1 = f1_score(labels, preds)\n",
        "    return {\n",
        "        'accuracy': accuracy,\n",
        "        'precision': precision,\n",
        "        'recall': recall,\n",
        "        'f1': f1,\n",
        "\n",
        "    }\n",
        "\n"
      ],
      "metadata": {
        "id": "p6GijQECg3CM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define Trainer with updated compute_metrics function\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    compute_metrics=compute_metrics\n",
        ")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "5KzrMf2fg67J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "print(\"Training started...\")\n",
        "trainer.train()\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "id": "u9wmW4rXg9qs",
        "outputId": "a485f388-ad06-4c50-a211-c8c3999ab7cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training started...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='108' max='108' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [108/108 09:29, Epoch 4/4]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.516369</td>\n",
              "      <td>0.900000</td>\n",
              "      <td>0.857143</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.923077</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.522317</td>\n",
              "      <td>0.700000</td>\n",
              "      <td>0.875000</td>\n",
              "      <td>0.583333</td>\n",
              "      <td>0.700000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.548830</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.583333</td>\n",
              "      <td>0.736842</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.570991</td>\n",
              "      <td>0.700000</td>\n",
              "      <td>0.875000</td>\n",
              "      <td>0.583333</td>\n",
              "      <td>0.700000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=108, training_loss=0.43135914979157625, metrics={'train_runtime': 577.8978, 'train_samples_per_second': 0.554, 'train_steps_per_second': 0.187, 'total_flos': 17924440646400.0, 'train_loss': 0.43135914979157625, 'epoch': 4.0})"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on the validation dataset\n",
        "print(\"Evaluation started...\")\n",
        "results = trainer.evaluate(eval_dataset=val_dataset)\n",
        "print(\"Evaluation completed!\")\n",
        "\n",
        "print(\"Evaluation results:\", results)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        },
        "id": "h7beUHHihAVP",
        "outputId": "d726a901-53f2-4b37-eadd-18e4d03995ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation started...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='14' max='7' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [7/7 01:20]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation completed!\n",
            "Evaluation results: {'eval_loss': 0.5709911584854126, 'eval_accuracy': 0.7, 'eval_precision': 0.875, 'eval_recall': 0.5833333333333334, 'eval_f1': 0.7000000000000001, 'eval_runtime': 16.9091, 'eval_samples_per_second': 1.183, 'eval_steps_per_second': 0.414, 'epoch': 4.0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "FileName = 'sbert_classification_model'\n",
        "model_save_path = '/content/drive/My Drive/Project/' + FileName\n",
        "# Save the model\n",
        "trainer.save_model(model_save_path)"
      ],
      "metadata": {
        "id": "WWxOMvTNhJfb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}