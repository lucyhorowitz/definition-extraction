For $ k $ a field or a division ring, a vector space over $ k $ (or a $ k $ - vector space) is a module over the ring $ k $ .
When the vector space is fixed, its elements are called vectors, the field $ k $ is referred to as the base field of the ground field of the vector space, and the elements of $ k $ are called scalars.
Sometimes a vector space over $ k $ is called a $ k $ - linear space.
(Compare ' $ k $ - linear map'.)
If $ k $ is only a division ring then we carefully distinguish the left $ k $ - vector spaces and right $ k $ - vector spaces.
The category of vector spaces is typically denoted Vect, or $ Vectk $ if we wish to make the field $ k $ (the ground field) explicit.
So $ Vectk coloneqq k Mod , $ .
This category has vector spaces over $ k $ as objects, and $ k $ - linear maps between these as morphisms.
Alternatively, one sometimes defines "vector space" as a two - sorted notion; taking the field $ k $ as one of the sorts and a module over $ k $ as the other.
More generally, the notion of "module" can also be considered as two - sorted, involving a ring and a module over that ring.
This is occasionally convenient; for example, one may define the notion of topological vector space or topological module as an internalization in $ Top $ of the multisorted notion.
This procedure is entirely straightforward for topological modules, as the notion of module can be given by a two - sorted Lawvere theory $ T $ , whence a topological module (for instance) is just a product - preserving functor $ T to Top $ .
One may then define a topological vector space as a topological module whose underlying (discretized) ring sort is a field.
Every free vector space admits a basis.
The basis theorem, which is equivalent to the axiom of choice, states that every vector space is a free vector space.
The concept of vector spaces seem to have been first introduced in: > (referring to Hermann Grassmann's Ausdehnungslehre)
An early expository account is in §14 of The literature on vector spaces is now extremely large, including lots of elementary linear algebra textbooks.
Classics include: Affine spaces are sets which are torsors over the abelian group of vectors of a vector space.
Thus vector spaces may serve as a basis for the affine and for the Euclidean geometry.
This approach has been invented by Hermann Weyl in 191(viii) Dieudonné wrote an influential book on such an approach to 2d and 3d Euclidian geometry, in which the basics of vector spaces in low dimension is introduced along the way (the book is intended for high school teachers): Discussion of vector space in univalent foundations of mathematics (homotopy type theory) is announced to appear in: Various more or less geometrical concepts are called spaces, to name a few vector spaces, topological spaces, algebraic spaces, ....
If such objects form a category, it is natural to look for the subobjects and to call them subspaces.
However, often the natural subspaces in the field are the regular subobjects; conversely, it is also often the case that variants which are not subobjects in the categorical sense are allowed, such as an immersed submanifold.
(These may have self - intersections, and then the immersion map is not monic, nor can this map be replaced by the inclusion of the image, since this image is usually not a manifold.)
These are very well behaved; as a vector space $ X $ is simply a module over a field, so a subspace of $ X $ is simply a submodule.
More generally, this is a special case of a subalgebra.
Vector subspaces are precisely the subobjects in Vect.
Given a topological space $ X $ (in the sense of Bourbaki, that is: a set $ X $ and a topology $ tauX $ ) and a subset $ Y $ of $ X $ , a topology $ tauY $ on a set $ Y $ is said to be the topology induced by the set inclusion $ Ysubset X $ if $ tauY = tauX cap{pw} {Y } = { U cap Y | UintauX } $ .
The pair $ (Y, tauY) $ is then said to be a (topological) subspace of $ (X, tauX) $ .
If a continuous map $ f:Zto X $ is a homeomorphism onto its image $ f(Z) $ in the induced topology on $ f(Z) $ , this inclusion map is sometimes called an embedding; $ Z $ is thus isomorphic in Top to a subspace of $ X $ .
See at topological subspace.
A 'subspace' of a topological vector space usually means simply a linear subspace, that is a subspace of the underlying discrete vector space.
However, the subspaces that we really want in categories such as Ban are the closed linear subspaces.
(Essentially, this is because we want our subspaces to be complete whenever our objects are complete.)
Given a locale $ L $ , which can also be thought of as a frame, a sublocale of $ L $ is given by a nucleus on the frame $ L $ .
Even if $ L $ is topological, so that $ L $ can be identified with a sober topological space, still there are generally many more sublocales of $ L $ than the topological ones. ...
submanifold ...
For Grothendieck topologies, one instead of a subspace has a concept of a subsite.
>
This entry is about the concept in topology.
For quotient vector spaces in linear algebras see there.
A quotient space is a quotient object in some category of spaces, such as Top (of topological spaces), or Loc (of locales), etc.
Often the construction is used for the quotient $ X/A $ by a subspace $ A subset X $ (example below).
Beware that quotient objects in the category Vect of vector spaces also traditionally called 'quotient space', but they are really just a special case of quotient modules, very different from the other kinds of quotient space.
However in topological vector spaces both concepts come together.
Let $ (X, tauX) $ be a topological space and let $ Rsim subset X times X $ be an equivalence relation on its underlying set.
Then the quotient topological space has and $ pi ;colon; X to X/sim $ is open in $ X $ .
To see that this indeed does define a topology on $ X/sim $ it is sufficient to observe that taking pre - images commutes with taking unions and with taking intersections.
Often one considers this with input datum not the equivalence relation, but any surjection $ pi ;colon; X longrightarrow Y $ of sets.
Of course this identifies $ Y = X/sim $ with $ (x1 sim x2) Leftrightarrow (pi(x1) = pi(x2)) $ .
Hence the quotient topology on the codomain set of a function out of any topological space has as open subsets those whose pre - images are open.
Equivalently this is the final topology or strong topology induced on $ Y $ by the function $ X to Y $ , see at Top - - Universal constructions.
For this construction the function $ X to Y $ need not even be surjective, and we could generalize to a sink instead of a single map; in such a case one generally says final topology or strong topology.
See also at topological concrete category.
A quotient space in $ Loc $ is given by a regular subobject in Frm.
(More details needed.)
The trigonometric function $ (cos( - ), sin( - )) ;colon; 0, 2pi longrightarrow S^1 subset mathbb{R}^2 $ from the closed interval with its Euclidean metric topology to the unit circle equipped with the subspace topology of the Euclidean plane descends to a homeomorphism on the quotient space $ 0, 2 pi/(0 sim 2 pi) $ by the equivalence relation which identifies the two endpoints of the open interval $ . array{ 0, 2pi &overset{(cos( - ), sin( - ))}{longrightarrow}& S^1 downarrow & nearrow{mathrlap{simeq}} 0, 2pi/simeq } , $ .
By the universal property of the quotient it follows that $ 0, 2pi/(0 sim 2pi) to S^1 $ is a continuous function.
Moreover, it is a bijection on the underlying sets by the $ 2pi $ - periodicity of sine and coside.
Hence it is sufficient to see that it is an open map (by this prop.).
Since the open subsets of $ 0, 2pi $ are unions of (i) the open intervals $ (a, b) $ with $ 0 lt a lt b lt 2pi $ , (i) the half - open intervals $ 0, b) $ and $ (a, 2pi $ with $ 0 lt a, b lt 2pi $ and since the projection map $ pi colon 0, 2pi to 0, 2pi/(0 sim 2pi) $ is injective on $ (0, 2pi) $ , the open subsets of $ 0, 2pi/(0 sim 2pi) $ are unions of (i) the open intervals $ (a, b) $ with $ 0 lt a lt b lt 2pi $ , (i) the glued half - open intervals $ (b, 2pi/(0sim 2pi) cup 0, a)/(0 sim 2pi) $ for $ 0 lt a, b lt 2pi $ .
By the $ 2pi $ - periodicity of $ (cos( - ), sin( - )) $ , the image of the latter under $ (cos( - ), sin( - )) $ is the same as the image of $ (b, 2pi + a) $ .
Since the function $ (cos( - ), sin( - )) colon mathbb{R} to S^1 $ is clearly an open map, it follows that the images of these open subsets in $ S^1 $ are open.
Let $ X $ be a topological space and $ A subset X $ a non - empty subset.
Consider the equivalence relation on $ X $ which identifies all points in $ A $ with each other.
The resulting quotient space (def. ) is often simply denoted $ X/A $ .
Notice that $ X/A $ is canonically a pointed topological space, with base point the equivalence class $ A/A subset X/A $ of $ A $ .
If $ A = emptyset $ is the empty space, then one defines $ X/emptyset coloneqq X+ coloneqq X sqcup ast $ to be the disjoint union space of $ X $ with the point space.
This is no longer a quotient space, but both constructions are unified by the pushout $ i colon A to X $ along the map $ A to ast $ , equivalently the cokernel of the inclusion: $ array{ A &overset{i}{hookrightarrow}& X downarrow &(po)& downarrow ast &longrightarrow& X/A } , $ .
This kind of quotient space plays a central role in the discussion of long exact sequences in cohomology, see at generalized (Eilenberg - Steenrod) cohomology.
Consider the real numbers $ mathbb{R} $ equipped with their Euclidean metric topology.
Consider on $ mathbb{R} $ the equivalence relation which identifies all real numbers that differ by a rational number: $ (x1 sim{mathbb{Q}} x2) Leftrightarrow left( x2 - x1 in mathbb{Q} subset mathbb{Q} right) , $ .
Then the quotient space $ mathbb{R}/sim{mathbb{Q}} $ is a codiscrete topological space.
We need to check that the only open subsets of $ X/sim{mathbb{Q}} $ are the empty set and the entire set $ X/sim{mathbb{Q}} $ .
So let $ U subset mathbb{R}/sim $ be a non - empty subset.
Write $ pi colon mathbb{R} to mathbb{R}/sim{mathbb{Q}} $ for the quotient projection.
By definition $ U $ is open precisely if its pre - image $ pi^{ - 1}(U) subset mathbb{R} $ is open.
By the Euclidean topology, this is the case precissely if $ pi^{ - 1}(U) $ is a union of open intervals.
Since by assumption $ pi^{ - 1}(U) $ is non - empty, it contains at least one open interval $ (a, b) subset mathbb{R} $ , with $ a lt b $ .
By the density of the rational numbers, there exists a rational number $ q in mathbb{Q} subset mathbb{R} $ with $ 0 lt q lt b - a , $ .
By definition of $ sim{mathbb{Q}} $ we have for all $ n in mathbb{Z} $ that all elements in $ (a + n q, b + n q) subset mathbb{R} $ are $ sim{mathbb{Q}} $ - equivalent to elements in $ (a, b) $ , hence that also $ (a+q, b+q) subset pi^{ - 1}(U) $ .
But the union of these open intervals is all of $ mathbb{R} $ $ underset{n in mathbb{Z}}{cup} (q + n q, b + n q) ;=; mathbb{R} $ and so $ pi^{ - 1}(U) = mathbb{R} $ .
(i) Recall that a map $ q colon X to Y $ is open if $ q(U) $ is open in $ Y $ whenever $ U $ is open in $ X $ .
It is not the case that a quotient map $ q colon X to Y $ is necessarily open.
Indeed, the identification map $ q colon I sqcup {ast } to S^1 $ , where the endpoints of $ I $ are identified with $ ast $ , takes the open point $ ast $ of the domain to a non - open point in $ S^1 $ .
(i)
Nor is it the case that a quotient map is necessarily a closed map; the classic example is the projection map $ pi1 colon mathbb{R}^2 to mathbb{R} $ , which projects the closed locus $ x y = 1 $ onto a non - closed subset of $ mathbb{R} $ .
(This is a quotient map, by the next remark.)
(i) It is easy to prove that a continuous open surjection $ p colon X to Y $ is a quotient map.
For instance, projection maps $ pi colon X times Y to Y $ are quotient maps, provided that $ X $ is inhabited.
Likewise, a continuous closed surjection $ p: X to Y $ is a quotient map: $ p^{ - 1}(U) $ is open $ Rightarrow $ $ p^{ - 1}(neg U) $ is closed $ Rightarrow $ $ p(p^{ - 1}(neg U)) = neg U $ is closed $ Rightarrow $ $ U $ is open.
For example, a continuous surjection from a compact space to a Hausdorff space is a quotient map.
A continuous function $ f ;colon; (X, tauX) longrightarrow (Y, tauY) $ whose underlying function $ f colon X longrightarrow Y $ is surjective exhibits $ tauY $ as the corresponding quotient topology precisely if $ f $ sends open and $ f $ - saturated subsets in $ X $ to open subsets of $ Y $ .
By this lemma this is the case precisely if it sends closed and $ f $ - saturated subsets to closed subsets.
>
This entry is about the concept in topology.
For quotient vector spaces in linear algebras see there.
A quotient space is a quotient object in some category of spaces, such as Top (of topological spaces), or Loc (of locales), etc.
Often the construction is used for the quotient $ X/A $ by a subspace $ A subset X $ (example below).
Beware that quotient objects in the category Vect of vector spaces also traditionally called 'quotient space', but they are really just a special case of quotient modules, very different from the other kinds of quotient space.
However in topological vector spaces both concepts come together.
Let $ (X, tauX) $ be a topological space and let $ Rsim subset X times X $ be an equivalence relation on its underlying set.
Then the quotient topological space has and $ pi ;colon; X to X/sim $ is open in $ X $ .
To see that this indeed does define a topology on $ X/sim $ it is sufficient to observe that taking pre - images commutes with taking unions and with taking intersections.
Often one considers this with input datum not the equivalence relation, but any surjection $ pi ;colon; X longrightarrow Y $ of sets.
Of course this identifies $ Y = X/sim $ with $ (x1 sim x2) Leftrightarrow (pi(x1) = pi(x2)) $ .
Hence the quotient topology on the codomain set of a function out of any topological space has as open subsets those whose pre - images are open.
Equivalently this is the final topology or strong topology induced on $ Y $ by the function $ X to Y $ , see at Top - - Universal constructions.
For this construction the function $ X to Y $ need not even be surjective, and we could generalize to a sink instead of a single map; in such a case one generally says final topology or strong topology.
See also at topological concrete category.
A quotient space in $ Loc $ is given by a regular subobject in Frm.
(More details needed.)
The trigonometric function $ (cos( - ), sin( - )) ;colon; 0, 2pi longrightarrow S^1 subset mathbb{R}^2 $ from the closed interval with its Euclidean metric topology to the unit circle equipped with the subspace topology of the Euclidean plane descends to a homeomorphism on the quotient space $ 0, 2 pi/(0 sim 2 pi) $ by the equivalence relation which identifies the two endpoints of the open interval $ . array{ 0, 2pi &overset{(cos( - ), sin( - ))}{longrightarrow}& S^1 downarrow & nearrow{mathrlap{simeq}} 0, 2pi/simeq } , $ .
By the universal property of the quotient it follows that $ 0, 2pi/(0 sim 2pi) to S^1 $ is a continuous function.
Moreover, it is a bijection on the underlying sets by the $ 2pi $ - periodicity of sine and coside.
Hence it is sufficient to see that it is an open map (by this prop.).
Since the open subsets of $ 0, 2pi $ are unions of (i) the open intervals $ (a, b) $ with $ 0 lt a lt b lt 2pi $ , (i) the half - open intervals $ 0, b) $ and $ (a, 2pi $ with $ 0 lt a, b lt 2pi $ and since the projection map $ pi colon 0, 2pi to 0, 2pi/(0 sim 2pi) $ is injective on $ (0, 2pi) $ , the open subsets of $ 0, 2pi/(0 sim 2pi) $ are unions of (i) the open intervals $ (a, b) $ with $ 0 lt a lt b lt 2pi $ , (i) the glued half - open intervals $ (b, 2pi/(0sim 2pi) cup 0, a)/(0 sim 2pi) $ for $ 0 lt a, b lt 2pi $ .
By the $ 2pi $ - periodicity of $ (cos( - ), sin( - )) $ , the image of the latter under $ (cos( - ), sin( - )) $ is the same as the image of $ (b, 2pi + a) $ .
Since the function $ (cos( - ), sin( - )) colon mathbb{R} to S^1 $ is clearly an open map, it follows that the images of these open subsets in $ S^1 $ are open.
Let $ X $ be a topological space and $ A subset X $ a non - empty subset.
Consider the equivalence relation on $ X $ which identifies all points in $ A $ with each other.
The resulting quotient space (def. ) is often simply denoted $ X/A $ .
Notice that $ X/A $ is canonically a pointed topological space, with base point the equivalence class $ A/A subset X/A $ of $ A $ .
If $ A = emptyset $ is the empty space, then one defines $ X/emptyset coloneqq X+ coloneqq X sqcup ast $ to be the disjoint union space of $ X $ with the point space.
This is no longer a quotient space, but both constructions are unified by the pushout $ i colon A to X $ along the map $ A to ast $ , equivalently the cokernel of the inclusion: $ array{ A &overset{i}{hookrightarrow}& X downarrow &(po)& downarrow ast &longrightarrow& X/A } , $ .
This kind of quotient space plays a central role in the discussion of long exact sequences in cohomology, see at generalized (Eilenberg - Steenrod) cohomology.
Consider the real numbers $ mathbb{R} $ equipped with their Euclidean metric topology.
Consider on $ mathbb{R} $ the equivalence relation which identifies all real numbers that differ by a rational number: $ (x1 sim{mathbb{Q}} x2) Leftrightarrow left( x2 - x1 in mathbb{Q} subset mathbb{Q} right) , $ .
Then the quotient space $ mathbb{R}/sim{mathbb{Q}} $ is a codiscrete topological space.
We need to check that the only open subsets of $ X/sim{mathbb{Q}} $ are the empty set and the entire set $ X/sim{mathbb{Q}} $ .
So let $ U subset mathbb{R}/sim $ be a non - empty subset.
Write $ pi colon mathbb{R} to mathbb{R}/sim{mathbb{Q}} $ for the quotient projection.
By definition $ U $ is open precisely if its pre - image $ pi^{ - 1}(U) subset mathbb{R} $ is open.
By the Euclidean topology, this is the case precissely if $ pi^{ - 1}(U) $ is a union of open intervals.
Since by assumption $ pi^{ - 1}(U) $ is non - empty, it contains at least one open interval $ (a, b) subset mathbb{R} $ , with $ a lt b $ .
By the density of the rational numbers, there exists a rational number $ q in mathbb{Q} subset mathbb{R} $ with $ 0 lt q lt b - a , $ .
By definition of $ sim{mathbb{Q}} $ we have for all $ n in mathbb{Z} $ that all elements in $ (a + n q, b + n q) subset mathbb{R} $ are $ sim{mathbb{Q}} $ - equivalent to elements in $ (a, b) $ , hence that also $ (a+q, b+q) subset pi^{ - 1}(U) $ .
But the union of these open intervals is all of $ mathbb{R} $ $ underset{n in mathbb{Z}}{cup} (q + n q, b + n q) ;=; mathbb{R} $ and so $ pi^{ - 1}(U) = mathbb{R} $ .
(i) Recall that a map $ q colon X to Y $ is open if $ q(U) $ is open in $ Y $ whenever $ U $ is open in $ X $ .
It is not the case that a quotient map $ q colon X to Y $ is necessarily open.
Indeed, the identification map $ q colon I sqcup {ast } to S^1 $ , where the endpoints of $ I $ are identified with $ ast $ , takes the open point $ ast $ of the domain to a non - open point in $ S^1 $ .
(i)
Nor is it the case that a quotient map is necessarily a closed map; the classic example is the projection map $ pi1 colon mathbb{R}^2 to mathbb{R} $ , which projects the closed locus $ x y = 1 $ onto a non - closed subset of $ mathbb{R} $ .
(This is a quotient map, by the next remark.)
(i) It is easy to prove that a continuous open surjection $ p colon X to Y $ is a quotient map.
For instance, projection maps $ pi colon X times Y to Y $ are quotient maps, provided that $ X $ is inhabited.
Likewise, a continuous closed surjection $ p: X to Y $ is a quotient map: $ p^{ - 1}(U) $ is open $ Rightarrow $ $ p^{ - 1}(neg U) $ is closed $ Rightarrow $ $ p(p^{ - 1}(neg U)) = neg U $ is closed $ Rightarrow $ $ U $ is open.
For example, a continuous surjection from a compact space to a Hausdorff space is a quotient map.
A continuous function $ f ;colon; (X, tauX) longrightarrow (Y, tauY) $ whose underlying function $ f colon X longrightarrow Y $ is surjective exhibits $ tauY $ as the corresponding quotient topology precisely if $ f $ sends open and $ f $ - saturated subsets in $ X $ to open subsets of $ Y $ .
By this lemma this is the case precisely if it sends closed and $ f $ - saturated subsets to closed subsets.
The disjoint union is a coproduct in Set, the category of sets.
In a general category coproducts need not have the expected disjointness property of those in Set.
If they do they are called disjoint coproducts.
Given any family $ (Ai){i:I} $ of sets, the (external) disjoint union $ biguplusi Ai $ (also written $ sumi Ai $ , $ coprodi Ai $ , etc) of the family is the set of all (ordered) pairs $ (i, a) $ with $ i $ in the index set $ I $ and $ a $ in $ Ai $ .
As stated, the type of the second element of such a pair depends on the first element, which is natural in dependent type theory (see at dependent sum type) and no problem for material set theory, but it may be ill formed in a structural set theory or in some forms of type theory, especially those based on the internal language of topos theory.
Alternatively, one may define $ biguplusi Ai $ to be the set of those elements $ x $ of the cartesian product $ prodi mathcal{P}Ai $ of the power sets such that there is exactly one index $ j $ such that $ xj $ is inhabited and that $ xj $ is a singleton.
If you're trying to be predicative too, then you may need to simply adopt the existence of disjoint unions as an axiom (the axiom of disjoint unions) in your foundations, stating the following facts about it.
There is a natural injection $ Aj to biguplusi Ai $ (mapping $ a $ to $ (j, a) $ , or mapping $ a $ to $ (i mapsto {a ;|; i = j } ) $ ) for each index $ j $ .
Conversely, for each element $ x $ of $ biguplusi Ai $ , there is a unique index $ j $ and such that $ x $ is in the image of the injection from $ Aj $ .
It is common to treat $ Aj $ as a subset of $ biguplusi Ai $ ; so if no confusion can result (in particular, when the notation for an element of $ Aj $ always makes the ambient set clear), one often suppresses the index in the notation for an element of the disjoint union.
Given sets $ A $ and $ B $ , the disjoint union of the binary family $ (A, B) $ is written $ A uplus B $ (also $ A + B $ , $ A amalg B $ , etc); its elements may be written (if care is needed) as $ (0, a) $ and $ (1, b) $ , $ (1, a) $ and $ (2, b) $ , $ iota{a} $ and $ kappa{b} $ , and in many other styles.
Given sets $ A1 $ through $ An $ , the disjoint union of the $ n $ - ary family $ (A1, ldots, An) $ is written $ biguplus{i=1}^n Ai $ (or similarly); its elements may be written (if care is needed) as $ (i, a) $ for $ 1 leq i leq n $ and $ a in Ai $ .
Given sets $ A1 $ , $ A2 $ , etc, the disjoint union of the countably infinitary family $ (A1, A2, ldots) $ is written $ biguplus{i=1}^infty Ai $ (or similarly); its elements may be written (if care is needed) as $ (i, a) $ for $ i $ a natural number and $ a in Ai $ .
Given a set $ A $ , the disjoint union of the unary family $ (A) $ may be identified with $ A $ itself; that is, we identify $ (i, a) $ for the unique index $ i $ with $ a $ .
The disjoint union of the empty family $ () $ is empty; it has no elements.
(This is internal in the sense of 'internal direct sum', not internalization.
For that, just see coproduct.)
If a family $ (Ai){i: I} $ of subsets of a given set $ X $ are all pairwise disjoint (that is, $ Ai cap Aj $ has an element only if $ i = j $ , for any indices $ i $ and $ j $ ), then the union $ bigcupi Ai $ is naturally bijective with the (external) disjoint union defined above.
Conversely, given an external disjoint union $ biguplusi Ai $ , each $ Aj $ may be identified with a subset of $ biguplusi Ai $ (as explained above); these subsets are all pairwise disjoint, and their union is the entire disjoint union.
Accordingly, a union of pairwise disjoint subsets may be called an internal disjoint union.
(Compare the internal vs external notions of direct sum.) category:
foundational axiom
A $ K $ - linear map (also $ K $ - linear function, $ K $ - linear operator, or $ K $ - linear transformation) is a morphism in $ K $ - Vect (or $ K $ - Mod), that is a homomorphism of vector spaces (or modules).
Often one suppresses mention of the field (or commutative ring or rig) $ K $ .
In elementary terms, a $ K $ - linear map between $ K $ - linear spaces $ V $ and $ W $ is a function $ Tcolon V to W $ such that $ T(r x + y) = r T(x) + T(y) , $ for $ x $ and
$ y $ elements of $ V $ and $ r $ an element of $ K $ .
(It is an easy exercise that this one identity is enough to ensure that $ T $ preserves all linear combinations.)
The morphisms between topological vector spaces are of course the continuous linear maps.
Between Banach spaces (including of course Hilbert spaces), these are the same as the bounded linear maps, so they're often called bounded operators (with linearity tacitly assumed).
In this context, linear operators are more general; they are (in general) only partial functions.
However, we still require the domain of the partial function to be a linear subspace, after which the definition above applies.
Because one typically restricts attention to complete spaces, the densely - defined operators (where the domain is a dense subspace) are the most general needed.
To specify that the domain of a linear operator $ Tcolon V to W $ is all of $ V $ , one may use a non - 'operator' term, such as linear mapping.
Notice that we do not require partially - defined linear operators to be continuous; see unbounded operator.
However, we have the theorem that any densely - defined, continuous, linear map $ Tcolon V to W $ , with $ W $ complete and Hausdorff, extends uniquely to all of $ V $ .
Thus one typically assumes that a continuous (or bounded) linear operator $ T $ is defined on all of $ V $ while an arbitrary linear operator $ T $ is defined only on a dense subspace of $ V $ .
In elementary mathematics (at least as taught in the United States, perhaps elsewhere?), the term 'linear function' is usually used more generally, for an affine map (but still between vector spaces); in this same context, the term 'linear transformation' is often used instead for specifically linear maps.
(Another difference at this level is that 'linear functions' are usually scalar - valued, while 'linear transformations' are usually vector - valued.)
In operator theory, one sometimes distinguishes 'linear maps' (defined everywhere, but not necessarily continuous in general) from 'linear operators' (partially defined in general, but assumed to be defined everywhere if continuous between complete Hausdorff spaces).
There is also a tendency for 'operator' to be used only for (possibly partial) endomorphisms, that is $ Tcolon V to V $ ; then operators may be composed, giving rise to an operator algebra.
If $ V $ is a function space, then an endomorphism of $ V $ is an operator in the sense of higher - order logic; the more general meaning of 'linear operator' is abstracted from this.
Let $ R $ be an associative ring with (i) As usual $ GLn(R) $ will denote the general linear group of $ ntimes n $ non - singular matrices over $ R $ .
There is an embedding of $ GLn(R) $ into $ GL{n+1}(R) $ sending a matrix $ M = (m{i, j}) $ to the matrix $ M^prime $ obtained from $ M $ by adding an extra row and column of zeros except that $ m^prime{n+1, n+1} = 1 $ .
This gives a nested sequence of groups $ GL1(R)subset GL2(R)subset ldots subset GLn(R)subset GL{n+1}(R)subset ldots $
and we write $ GL(R) $ for the colimit (union in this case) of these.
It will be called the stable general linear group over $ R $ .
Instances of "dualities" relating two different, maybe opposing, but to some extent equivalent concepts or phenomena are ubiquitous in mathematics (and in mathematical physics, see at dualities in physics).
The term "duality" is widespread and doesn't have a single crisp meaning, but a rough guiding intuition is of pairs of concepts that are mirror images of one another.
In terms of general abstract concepts in logic and category theory, instances of dualities might be (and have been) organized as follows.
Instances here include projective duality, duality in lattice theory, and duality in category theory.
In each case, one has a theory whose signature admits a nontrivial involution, in such a way that "dualizing" or applying the involution to any axiom of the theory (but otherwise preserving the logical structure of formulae) results in another theorem of the theory.
For example, for the theory of projective planes, the involution swaps points and lines, meets and joins, etc., and for each theorem there is a dual theorem.
Similarly, in category theory, the involution swaps the domain and codomain and order of composition, etc., and for any theorem of formal category theory, the corresponding dual statement is also a theorem (because the set of axioms of category theory are closed under taking formal duals).
Such formal duality can also be expressed at the level of models of the theory $ T $ : for each model $ M $ there is a "dual" or "opposite" model $ M^{op} $ obtained by re - interpreting each formal sort/function/relation of the theory as the dual sort/function/relation.
This further induces an involution $ Mod(T) to Mod(T) $ on the category of models.
For example, in the case of category theory, this operation $ C mapsto C^{op} $ , mapping a category $ C $ to its opposite category, gives an involution $ ( - )^{op}: Cat to Cat $ on the category Cat of (small) categories, viewing $ Cat $ here as a 1 - category.
In fact this is the only non - trivial automorphism of Cat, see here).
This involution $ ( - )^{op}: Cat to Cat $ is also known as abstract duality.
While the construction is a priori tautologous, any given opposite category often is equivalent to a category known by other means, which makes abstract duality interesting (particularly so in cases of concrete duality, which we discuss next).
Instances here include linear duality, Stone duality, Pontryagin duality, and projective inversions with respect to a conic hypersurface.
In each such case there is some contravariant process of "homming into" a suitable structure $ V $ called a dualizing object, which in the classical cases of what we will call "perfect duality", induces an equivalence of categories $ C^{op} stackrel{sim}{to} D $ where typically $ C $ is the category of models of one type of concrete structure, and the equivalence maps the formal categorical dual $ C^{op} $ to a category of models $ D $ consisting of "dual" concrete structures.
In other cases one might not obtain an equivalence or perfect duality, but in any case a contravariant adjoint pair of functors $ S: C to D $ , $ T: D to C $ between categories which can be termed a duality of sorts, in that concepts developed in $ C $ are mapped to dual concepts in $ D $ and vice - versa.
Quoting (Lawvere - Rosebrugh, chapter 7): >
Not every statement will be taken into its formal dual by the process of dualizing with respect to $ V $ , and indeed a large part of the study of mathematics >>space vs. quantity > and of logic >>theory vs. example >may be considered as the detailed study of the extent to which formal duality and concrete duality into a favorite $ V $ correspond or fail to correspond.
(p. 122)
Some examples follow $ . 1{W^ast} = (W^ast stackrel{delta{W^ast}}{to} W^{astastast} stackrel{(deltaW)^ast}{to} W^ast) $ .
This becomes a perfect duality if we restrict to finite - dimensional vector spaces, i.e., the contravariant functor $ ( - )^ast: Vect{fd} to Vect{fd} $ is adjoint - equivalent to itself (i.e., the covariant functor $ (( - )^ast)^{op}: Vect{fd} to Vect{fd}^{op} $ is left adjoint to $ ( - )^ast: Vect{fd}^{op} to Vect{fd} $ and the adjunction is an adjoint equivalence) $ . C to C, D, C otimes C, D to C, D, C, D otimes C to C, D, D $ where the first arrow uses the unit of an adjunction $ ( - otimes B) dashv B, - $ where $ B = C, D $ , the second uses a symmetry isomorphism $ C otimes B cong B otimes C $ , and the third uses the counit of an adjunction $ ( - otimes C) dashv C, - $ , aka an evaluation map.
It may be shown that the contravariant functor $ ( - )^ast coloneqq - , D: mathcal{C} to mathcal{C} $ is again dual to itself, exactly as in the case of linear duality above, where we have a triangular equation $ 1{C^ast} = (deltaC)^ast circ delta{C^ast} $ for an adjunction $ - , D^{op} dashv - , D $ .
Under certain circumstances, we have perfect duality, i.e., double dualization $ - , D, D: mathcal{C} to mathcal{C} $ is an equivalence; see dualizing object in a closed category and star - autonomous category.
Particular special cases of this may obtain when $ D = I $ , the monoidal unit, or even more particularly when every object has a dual object in the sense of monoidal categories; see also compact closed category.
On the other hand, there is also a mild generalization of this type of example where we deal with a biclosed monoidal category; here the double dualization will involve both the left and right internal hom $ . U: mathcal{C} to Set, qquad V: mathcal{D} to Set $ (and often when one says "concrete", one intends that these functors be faithful as well, so that $ mathcal{C}, mathcal{D} $ can be viewed as "sets with structure"; see stuff, structure, property).
The concrete duality consists of a pair of objects $ C in mathcal{C}, D in mathcal{D} $ together with an isomorphism $ omega: U C cong V D $ , such that the contravariant homs $ hom( - , C): C^{op} to Set $ and $ hom( - , D): D^{op} to Set $ lift to a contravariant adjunction between $ C $ and $ D $ , in the sense described here.
Frequently in practice, such concrete dualities are "naturally represented" in the sense described here, involving certain lifts adapted from the theory of topological concrete categories.
Again, in all of these examples, one can consider the further condition of "perfect duality" where the units and counits of the (lifted) adjunctions are isomorphisms.
{Adjunctions} Perhaps the loosest general notion of "duality" is that of adjunction, as in pairs of adjoint functors (Lambek 81).
Here one may omit any concretizations via functors to $ Set $ , or even for that matter any explicit mention of opposite categories, and just work at the level of abstract categories themselves.
Nevertheless, many adjunctions come packaged in "dual pairs".
A famous slogan from Categories for the Working Mathematician is that "all concepts are Kan extensions", and in that light the dual pairs are instances of the general dual pair "(right Kan extension, left Kan extension)" which are formal duals in the axiomatic sense described earlier.
Via the many incarnations of universal constructions in category theory, we have for example When the adjoint functors are monads and hence modalities, then adjointness between them has been argued to specifically express the concept of duality of opposites.
Again, adjunctions and specifically dual adjunctions ("Galois connections") may be thought of as generalized dualities, more general than "perfect duality" which involves equivalences between categories ("Galois correspondences").
However, it should also be noted that any such adjunction (or dual adjunction) restricts to a maximal (dual) equivalence between subcategories, by considering objects where the appropriate units and counits are isomorphisms.
This generalizes the manner by which any Galois connection induces a Galois correspondence (where in this special case, one need only take the images of the poset maps which constitute the connection).
Of particular interest are concrete dualities between concrete categories $ C, D $ , i.e. categories equipped with faithful functors $ f : C to Set $ , $ hat f : D to Set $ to Set, which are represented by objects $ a in C $ , $ hat a in D $ with the same underlying set $ f(a) = hat f(hat a) $ .
Such objects are known as dualizing objects.
Discussion of duality specifically in homological algebra and stable homotopy theory with emphasis on the concept of dualizing object in a closed category (and the induced Umkehr maps etc.) is in See also The concept of a dual basis is a way of characterizing projective modules, alternative to their characterization as direct summands of free modules.
The terminology derives from a similarity with a situation involving dual vector spaces, see below.
Let $ R $ be a ring or, more generally, an associative algebra over a unital commutative ring $ k $ .
Assuming the axiom of choice, one of the standard characterizations of the projective modules $ N $ (say left) over $ R $ is that there is an epimorphism $ Fto N $ from a free module over $ R $ which is split (" $ N $ is a direct summand of a free module", this prop.).
Equivalently, an $ R $ - module $ M $ is projective iff
it has a dual basis $ {(xi, xi^)in Mtimes Homk(M, R) } {iin I} $ in the following sense.
There is a free $ R $ - module $ F = oplus{iin I} R $ , an epimorphism of $ R $ - modules $ Fto M $ , $ F=oplusi R ni sumi rimapsto sumi ri xi $ which is split, i.e. has a right inverse, where this inverse, by the universal property of the direct sum, must be of the form $ xmapsto sumi xi^(x)in oplusi R $ where $ xi^in Homk(M, R) $ .
The right inverse condition translates to $ forall x in M : x=sumi xi^(x)xi $ .
In particular for every $ xin M $ $ xi^*(x)neq 0 $ for only finitely many $ iin I $ . {RelationToDualVectorSpaces} This terminology is related to but a bit different than in the case of $ k $ - vector spaces (cf.
at dual vector space)
.
If $ V $ has a vector space basis $ (xj){jin I} $ is a linear basis of $ V $ then $ xi^* $ defined by $ xi^(xj) = deltai^j $ is not necessarily a basis of $ V^ = Homk(V, k) $ ; it is if $ V $ is finite dimensional.
In the case of projective module $ M $ , $ xi $ do not form a basis in a free sense, but only a set of generators and with the property that there exist another set $ xi^ $ in $ M^ $ such that they together form a "dual basis".
(Still, one sometimes says that $ xi^ $ form a basis dual to $ xi $ .) category: algebra
The basic concept is for vector spaces, and the remainder are defined in terms of that.
Given an ordered field $ K $ and a vector space $ V $ over $ K $ of dimension $ n $ (a natural number), an orientation of $ V $ is a choice of one of the two equivalence classes of ordered bases of $ V $ , where two bases are considered equivalent if the transformation matrix from one to the other has positive determinant.
In the case $ n = 0 $ , the only ordered basis is the empty list, but we still declare there to be two orientations by fiat, usually called positive and negative.
We can make the definition seamless by taking the elements of the equivalence class to be pairs consisting of an ordered basis and a nonzero sign (positive or negative), with $ (B1, s1) sim (B2, s2) $ iff $ sgn det I^{B1}{B2} = s1/s_2 $ .
This is redundant except in dimension $ 0 $ , where now each equivalence class has a single element, $ (, +) $ for the positive orientation and $ (, - ) $ for the negative orientation (where $ $ is the empty list).
In any case, this ensures that if $ omega $ is an orientation, then there is also an opposite orientation $ - omega $ .
A fancier way to say the same is For $ V $ a vector space of dimension $ n $ , an orientation of $ V $ is an equivalence class of nonzero elements of the line $ bigwedge^n V $ , the $ n $ th alternating power of $ V $ , where two such elements are considered equivalent when either (hence each) is a positive multiple of the other.
Note that by both definitions, an orientation of a line (with $ n = 1 $ ) is an equivalence class of nonzero elements.
Assuming that $ K $ is the field of real numbers or something like it, we can generalize from vector spaces to vector bundles: For $ X $ a manifold and $ V to X $ a vector bundle of rank $ n $ , an orientation on $ V $ is an equivalence class of trivializations of the line bundle $ bigwedge^k V $ that is obtained by associating to each fiber of $ V $ its $ k $ th alternating power.
Equivalently for a smooth manifold this is an equivalence class of an everywhere non - vanishing element of $ bigwedge^k{C^infty(X)} Gamma(V) $ , which may be considered the sign of the element.
For $ X $ a manifold of dimension $ n $ , an orientation of $ X $ is an orientation of the tangent bundle $ T X $ (or cotangent bundle $ T^* X $ ).
This is equivalently a choice of everywhere non - vanishing differential form on $ X $ of degree $ n $ ; the orientation may be considered the sign of the $ n $ - form (and the $ n $ - form's absolute value is a pseudo - $ n $ - form).
A vector space always has an orientation, but a manifold or bundle may not.
If an orientation exists, $ V $ (or $ X $ ) is called orientable.
If $ X $ is connected space and $ V $ (or $ X $ ) is orientable, then there are exactly $ 2 $ orientations; more generally, the entire bundle is orientable iff
the restriction to each connected component is orientable, and then the number of orientations is $ 2^k $ , where $ k $ is the number of orientable components.
(Or we can always say that the number of orientations is $ 2^k 0^m $ , where now $ m $ is also the number of nonorientable components.
An orientation on a Riemannian manifold $ X $ is equivalently a lift $ hat g $ of the classifying map $ g : X to mathcal{B}O(n) $ of its tangent bundle through the fist step $ S O(n) to O(n) $ in the Whitehead tower of $ X $ : $ array{ && mathcal{B}S O(n) & {}^{hat g}nearrow & downarrow X &stackrel{g}{to}& mathcal{B} O(n) } , $ .
From this perspective a choice of orientation is the first in a series of special structures on $ X $ that continue with For $ R $ an E - ∞ ring spectrum, there is a general notion of $ R $ - orientation of vector bundles.
This is described at For $ R = H(mathbb{R}) $ be the Eilenberg - MacLane spectrum for the discrete abelian group $ mathbb{R} $ of real numbers, orientation in $ R $ - cohomology is equivalent to the ordinary notion of orientation described above.
The term 'rank' is used in many contexts to number levels within a hierarchy.
Let $ A $ be a ring and $ N $ a module over $ A $ .
If $ A $ is a field, then $ N $ is a vector space and we speak of the dimension of $ N $ ; in the general case, we may speak of the rank: A collection of elements $ (wi){i in I} $ of $ N $ is called a basis of $ N $ (over $ A $ ) if for every $ x in N $ there is a unique collection $ (ai){i in I} $ of elements of $ A $ such that $ ai = 0 $ for all but finitely many $ i in I $ and $ x = sum{i in I} ai wi $ .
If $ N $ has a basis it is called a nLab:free module (over $ A $ ).
For many examples of $ A $ (the invariant basis number rings), the cardinality $ I $ only depends on $ N $ and not on the choice of basis.
It is called the rank of $ N $ over $ A $ , notation: $ rankA(M) $ .
In any case, $ N $ is called the free module of rank $ I $ .
If $ N $ is a finitely generated free module then the rank is a finite number.
All of the following are invariant basis rings (source: Wikipedia): Besides the trivial ring (over which any module is free with any set as basis), an example of a ring without invariant basis number is the ring of $ aleph0 $ - dimensional square matrices (over any ring) in which each column has only finitely many nonzero entries (which allows multiplication to be defined).
As a module over itself, this ring is free on any inhabited finite set, as may be shown by using the equation $ aleph0 = n aleph0 $ (applied to the columns).
Let $ (X, mathcal{O}) $ be a locally ringed space and $ mathcal{E} $ a $ mathcal{O} $ - module.
Then its rank at a point $ x in X $ is the vector space dimension of the fiber $ mathcal{E}(x) coloneqq mathcal{E}x otimes{mathcal{O}x} k(x) $ over the residue field $ k(x) $ .
If $ mathcal{E} $ is of finite type, then the rank at $ x $ can equivalently be defined as the minimal number of elements needed to generate the stalk $ mathcal{E}x $ as a $ mathcal{O}x $ - module (by Nakayama's lemma).
In this case, the rank is a upper semicontinuous function $ X to mathbb{N} $ .
In the internal language of the sheaf topos $ mathrm{Sh}(X) $ , the rank of $ mathcal{E} $ can internally quite simply be defined as the minimal number of elements needed to generate $ mathcal{E} $ (taken as an element of the suitably completed natural numbers, i.e. the poset of inhabited upper sets).
Under the correspondence of internal inhabited upper sets in $ mathrm{Sh}(X) $ and upper semicontinuous functions $ X to mathbb{N} $ (details at one - sided real number), this definition coincides with the usual one if $ mathcal{E} $ is of finite type; see this MathOverflow question.
See also rank of a coherent sheaf.
As a simple special case of the above, a vector bundle is said to have rank $ n $ if each fiber is a vector space of dimension $ n $ .
Every pure set within the von Neumann hierarchy appears first at some level given by an ordinal number; this number is its hereditary rank.
We may define this rank explicitly (and recursively) as follows: $ rank S = bigcup{x in S} (rank x)^+ , $ where $ bigcup $ is the supremum operation on ordinals (literally the union for von Neumann ordinals) and $ ( - )^+ $ is the successor operation (which is $ a mapsto a cup {a } $ for von Neumann ordinals).
Recall that a cardinal number $ alpha $ is said to be regular if $ |bigcup{iin I} Xi | $ &lt; $ alpha $ whenever $ |I| $ &lt; $ alpha $ and $ |Xi| $ &lt; $ alpha $ for all $ iin I $ .
A functor $ F:mathcal{A}to mathcal{B} $ has rank $ alpha $ for some regular cardinal $ alpha $ if $ F $ preserves $ alpha $ - filtered colimits $ . F $ has rank when it has rank $ alpha $ for some regular cardinal $ alpha $ .
A monad has rank ( $ alpha $ ) when its underlying endofunctor does.
The properties of functors with rank are discussed in section (v)5 of Borceux (1994).
degree of a coherent sheaf slope of a coherent sheaf
The determinant is the (essentially unique) universal alternating multilinear map.
Let Vect $ {}k $ be the category of vector spaces over a field $ k $ , and assume for the moment that the characteristic $ char(k) neq 2 $ .
For each $ j geq 0 $ , let $ sgnj colon Sj to hom(k, k) $ be the 1 - dimensional sign representation on the symmetric group $ Sj $ , taking each transposition $ (i j) $ to $ - 1 in k^ast $ .
We may linearly extend the sign action of $ Sj $ , so that $ sgn $ names a (right) $ k Sj $ - module with underlying vector space $ k $ .
At the same time, $ Sj $ acts on the $ j^{th} $ tensor product of a vector space $ V $ by permuting tensor factors, giving a left $ k Sj $ - module structure on $ V^{otimes j} $ .
We define the Schur functor $ Lambda^j colon Vectk to Vectk $ by the formula $ Lambda^j(V) = sgnj otimes{k Sj} V^{otimes j} $ .
It is called the $ j^{th} $ alternating power (of $ V $ ).
Another point of view on the alternating power is via superalgebra.
For any cosmos $ mathbf{V} $ let $ CMon(mathbf{V}) $ be the category of commutative monoid objects in $ mathbf{V} $ .
The forgetful functor $ CMon(mathbf{V}) to mathbf{V} $ has a left adjoint $ exp(V) = sum{n geq 0} V^{otimes n}/Sn $ whose values are naturally regarded as graded by degree $ n $ .
This applies in particular to $ mathbf{V} $ the category of supervector spaces; if $ V $ is a supervector space concentrated in odd degree, say with component $ V{odd} $ , then each symmetry $ sigma: V otimes V to V otimes V $ maps $ v otimes w mapsto - w otimes v $ for elements $ v, w in V{odd} $ .
It follows that the graded component $ exp(V)n $ is concentrated in $ parity(n) $ degree, with component $ Lambda^n(V{odd}) $ .
There is a canonical natural isomorphism $ Lambda^n(V oplus W) cong sum{j + k = n} Lambda^j(V) otimes Lambda^k(W) $ .
Again take $ mathbf{V} $ to be the category of supervector spaces.
Since the left adjoint $ exp: mathbf{V} to CMon(mathbf{V}) $ preserves coproducts and since the tensor product $ otimes $ of $ mathbf{V} $ provides the coproduct for commutative monoid objects, we have a natural isomorphism $ exp(V oplus W) cong exp(V) otimes exp(W) $ .
Examining the grade $ n $ component $ exp(V oplus W)n $ , this leads to an identification $ exp(V oplus W)n = sum{j + k = n} exp(V)j otimes exp(W)k $ .
and now the result follows by considering the case where $ V, W $ are concentrated in odd degree.
If $ V $ is $ n $ - dimensional, then $ Lambda^j(V) $ has dimension $ binom{n}{j} $ .
In particular, $ Lambda^n(V) $ is 1 - dimensional.
By induction on dimension.
If $ dim(V) = 1 $ , we have that $ Lambda^0(V) $ and $ Lambda^1(V) $ are $ 1 $ - dimensional, and
clearly $ Lambda^n(V) = 0 $ for $ n geq 2 $ , at least when $ char(k) neq 2 $ .
We then infer $ array{ Lambda^j(V oplus k) & cong & sum{p + q = j} Lambda^p(V) otimes Lambda^q(k) & cong & Lambda^j(V) oplus Lambda^{j - 1}(V) } $ where the dimensions satisfy the same recurrence relation as for binomial coefficients: $ binom{n+1}{j} = binom{n}{j} + binom{n}{j - 1} $ .
More concretely: if $ e1, ldots, en $ is a basis for $ V $ , then expressions of the form $ e{n1} otimes ldots otimes e{nj} $ form a basis for $ V^{otimes j} $ .
Let $ e{n1} wedge ldots wedge e{nj} $ denote the image of this element under the quotient map $ V^{otimes j} to Lambda^j(V) $ .
We have $ e{n1} wedge ldots wedge e{ni} wedge e{n{i+1}} wedge ldots wedge e{nj} = - e{n1} wedge ldots wedge e{n{i+1}} wedge e{ni} wedge ldots wedge e{nj} $ (consider the transposition in $ Sj $ which swaps $ i $ and $ i+1 $ ) and so we may take only such expressions on the left where $ n1 lt ldots lt nj $ as forming a spanning set for $ Lambda^j(V) $ , and indeed these form a basis.
The number of such expressions is $ binom{n}{j} $ .
In the case where $ char(k) = 2 $ , the same development may be carried out by simply decreeing that $ e{n1} wedge ldots wedge e{nj} = 0 $ whenever $ ni = n{i'} $ for some pair of distinct indices $ i $ , $ i' $ .
Now let $ V $ be an $ n $ - dimensional space, and let $ f colon V to V $ be a linear map.
By the corollary, the map $ Lambda^n(f) colon Lambda^n(V) to Lambda^n(V), $ being an endomorphism on a 1 - dimensional space, is given by multiplying by a scalar $ D(f) in k $ .
It is manifestly functorial since $ Lambda^n $ is, i.e., $ D(f g) = D(f) D(g) $ .
The quantity $ D(f) $ is called the determinant of $ f $ .
We see then that if $ V $ is of dimension $ n $ , $ det colon End(V) to k $ is a homomorphism of multiplicative monoids; by commutativity of multiplication in $ k $ , we infer that $ det(U A U^{ - 1}) = det(A) $ for each invertible linear map $ U in GL(V) $ .
If we choose a basis of $ V $ so that we have an identification $ GL(V) cong Matn(k) $ , then the determinant gives a function $ det colon Matn(k) to k $ that takes products of $ n times n $ matrices to products in $ k $ .
The determinant however is of course independent of choice of basis, since any two choices are related by a change - of - basis matrix $ U $ , where $ A $ and its transform $ U A U^{ - 1} $ have the same determinant.
By following the definitions above, we can give an explicit formula: $ det(A) ;=; sum{sigma in Sn} sgn(sigma) prod{i = 1}^n a{i sigma(i)} ; $ This may equivalently be written using the Levi - Civita symbol $ epsilon $ and the Einstein summation convention as det(A) ;=; a{1 j1} a{2 j2} cdots a{n jn} , epsilon^{j1 j2 cdots jn} which in turn may be re - written more symmetrically as det(A) ;=; frac{1}{n!} epsilon^{ i1 i2 cdots in } , a{i1 j1} a{i2 j2} cdots a{in jn} , epsilon^{j1 j2 cdots jn} We work over fields of arbitrary characteristic.
The determinant satisfies the following properties, which taken together uniquely characterize the determinant.
Write a square matrix $ A $ as a row of column vectors $ (v1, ldots, vn) $ .
(i) $ det $ is separately linear in each column vector: $ det(v1, ldots, a v + b w, ldots, vn) = adet(v1, ldots, v, ldots, vn) + bdet(v1, ldots, w, ldots, vn) $ (i) $ det(v1, ldots, vn) = 0 $ whenever $ vi = vj $ for distinct $ i, j $ .
(i) $ det(I) = 1 $ , where $ I $ is the identity matrix.
Other properties may be worked out, starting from the explicit formula or otherwise: A simple observation which flows from these basic properties is Let $ v1, ldots, vn $ be column vectors of dimension $ n $ , and suppose $ w = sumj aj vj $ .
Then for each $ i $ we have $ aj det(v1, ldots, vi, ldots, vn) = det(v1, ldots, w, ldots, vn) $ where $ w $ occurs as the $ i^{th} $ column vector on the right.
This follows straightforwardly from properties 1 and 2 above.
For instance, given a square matrix $ A $ such that $ det(A) neq 0 $ , and writing $ A = (v1, ldots, vn) $ , this allows us to solve for a vector $ a $ in an equation $ A cdot a = w $
and we easily conclude that $ A $ is invertible if $ det(A) neq 0 $ .
This holds true even if we replace the field $ k $ by an arbitrary commutative ring $ R $ , and we replace the condition $ det(A) neq 0 $ by the condition that $ det(A) $ is a unit.
(The entire development given above goes through, mutatis mutandis.)
Given a linear endomorphism $ f: Mto M $ of a finite rank free unital module over a commutative unital ring, one can consider the zeros of the characteristic polynomial $ det(t cdot 1V - f) $ .
The coefficients of the polynomial are the concern of the Cayley - Hamilton theorem.
A useful intuition to have for determinants of real matrices is that they measure change of volume.
That is, an $ n times n $ matrix with real entries will map a standard unit cube in $ mathbb{R}^n $ to a parallelpiped in $ mathbb{R}^n $ (quashed to lie in a hyperplane if the matrix is singular), and the determinant is, up to sign, the volume of the parallelpiped.
It is easy to convince oneself of this in the planar case by a simple dissection of a parallelogram, rearranging the dissected pieces in the style of Euclid to form a rectangle.
In algebraic terms, the dissection and rearrangement amount to applying shearing or elementary column operations to the matrix which, by the properties discussed earlier, leave the determinant unchanged.
These operations transform the matrix into a diagonal matrix whose determinant is the area of the corresponding rectangle.
This procedure easily generalizes to $ n $ dimensions.
The sign itself is a matter of interest.
An invertible transformation $ f colon V to V $ is said to be orientation - preserving if $ det(f) $ is positive, and orientation - reversing if $ det(f) $ is negative.
Orientations play an important role throughout geometry and algebraic topology, for example in the study of orientable manifolds (where the tangent bundle as $ GL(n) $ - bundle can be lifted to a $ GL+(n) $ - bundle structure, $ GL+(n) hookrightarrow GL(n) $ being the subgroup of matrices of positive determinant).
See also KO - theory.
Finally, we include one more property of determinants which pertains to matrices with real coefficients (which works slightly more generally for matrices with coefficients in a local field): {AsAPolynomialInTracesofPowers} On the relation between determinant and trace: If $ A $ is an $ n times n $ matrix, the determinant of its exponential equals the exponential of its trace $ det(exp(A)) = exp(tr(A)) , $ .
More generally, the determinant of $ A $ is a polynomial in the traces of the powers of $ A $ : For $ 2 times 2 $ - matrices: $ det(A) ;=; tfrac{1}{2}left( tr(A)^2 - tr(A^2) right) $ For $ 3 times 3 $ - matrices: $ det(A) ;=; tfrac{1}{6} left( (tr(A))^3 - 3 tr(A^2) tr(A) + tr(A^3) right) $ For $ 4 times 4 $ - matrices: $ det(A) ;=; tfrac{1}{24} left( (tr(A))^4 - 6 tr(A^2)(tr(A))^2 + 3 (tr(A^2))^2 + 8 tr(A^3) tr(A) - 6 tr(A^4) right) $ Generally for $ n times n $ - matrices (Kondratyuk - Krivoruchenko 92, appendix B): det(A) ;=; underset{ { k1, cdots, kn in mathbb{N} } atop { underoverset{ell = 1}{n}{sum} ell kell = n } }{sum} underoverset{ l = 1 }{ n }{prod} frac{ ( - 1)^{kl
+ 1} }{ l^{kl} kl ! }
left(tr(A^l)right)^{kl} It is enough to prove this for semisimple matrices $ A $ (matrices that are diagonalizable upon passing to the algebraic closure of the ground field) because this subset of matrices is Zariski dense (using for example the nonvanishing of the discriminant of the characteristic polynomial) and the set of $ A $ for which the equation holds is Zariski closed.
Thus, without loss of generality we may suppose that $ A $ is diagonal with $ n $ eigenvalues $ lambda1, ldots, lambdan $ along the diagonal, where the statement can be rewritten as follows.
Letting $ pk = tr(A^k) = lambda1^k + ldots + lambdan^k $ , the following identity holds: prod{i=1}^n lambdai = underset{ { k1, cdots, kn in mathbb{N} } atop { underoverset{ell = 1}{n}{sum} ell kell = n } }{sum} underoverset{ l = 1 }{ n }{prod} frac{ ( - 1)^{kl + 1} }{ l^{kl} kl ! }
pl^{kl} This of course is just a polynomial identity, one closely related to various of the Newton identities that concern symmetric polynomials in indeterminates $ x1, ldots, xn $ .
Thus we again let $ pk = x1^k + ldots + xn^k $ , and define the elementary symmetric polynomials $ sigmak = sigmak(x1, ldots, xn) $ via the generating function identity sum{k geq 0} sigmak t^k
= prod{i=1}^n (1 + xi t).
Then we compute array{ sum{k geq 0} sigmak t^k & = & prod{i=1}^n (1 + xi t) & = & expleft(sum{i=1}^n log(1 + xi t)right) & = & expleft(sum{i=1}^n sum{k geq 1} ( - 1)^{k+1} frac{xi^k}{k} t^k right) & = & expleft( sum{k geq 1} ( - 1)^{k+1} frac{pk}{k} t^kright) } and simply match coefficients of $ t^n $ in the initial and final series expansions, where we easily compute x1 x2 ldots xn
= sum{n = k1 + 2k2
+ ldots + n kn} prod{l=1}^n frac1{(kl)!} left(frac{pl}{l}right)^{kl}
( - 1)^{kl+1} This completes the proof.
see Pfaffian for the moment See also One derivation of the formula (eq:DeterminantAsPolynomialInTracesOfPowers) for the determinant as a polynomial in traces of powers is spelled out in appendix B of For $ n in mathbb{N} $ and $ A in Mat{n times n}(k) $ a square matrix, the following are equivalent: (i) $ A $ is an invertible matrix; (i) $ A $ is the matrix product of elementary matrices.
See also determinant.
Let $ R $ be a commutative ring, and let $ A $ be an $ n times n $ matrix with entries in $ R $ .
Then there exists an $ n times n $ matrix $ tilde{A} $ with entries in $ R $ such that $ A tilde{A} = tilde{A} A = det(A) cdot In $ .
We may as well take $ R $ to be the polynomial ring $ mathbb{Z}a{i j}{1 leq i, j leq n} $ , since we are then free to interpret the indeterminates $ a{i j} $ however we like along a ring map $ mathbb{Z}a{i j} to R $ .
Let $ A $ denote the corresponding generic matrix.
Guided by Cramer's rule (see determinant), put $ tilde{A}{j i} = det(a1, ldots, ei, ldots an), $ the $ ai $ being columns of $ A $ and $ ei $ , the column vector with $ 1 $ in the $ i^{th} $ row and $ 0 $ 's elsewhere, appearing as the $ j^{th} $ column.
If we pretend $ A $ is invertible, then we know $ A tilde{A} = det(A) cdot In = tilde{A} A $ by Cramer's rule.
We claim this holds for general $ A $ .
Indeed, we can interpret this as a polynomial equation in $ mathbb{C}a{i j} $ and check it there.
As an equation between polynomial functions on the space of matrices $ A in Matn(mathbb{C}) = Spec(mathbb{C}a{i j}) $ , it holds on the dense subset $ GLn(mathbb{C}) hookrightarrow Matn(mathbb{C}) $ .
Therefore, by continuity, it holds on all of $ Matn(mathbb{C}) $ .
But a polynomial function equation with coefficients in $ mathbb{C} $ implies the corresponding polynomial identity, and the proof is complete.
(Cayley - Hamilton) Let $ V $ be a finitely generated free module over a commutative ring $ R $ , and let $ f colon V to V $ be an $ R $ - module map.
Let $ p(t) in Rt $ be the characteristic polynomial $ det(t cdot 1V - f) $ of $ f $ , and let $ phif colon Rt to ModR(V, V) $ be the unique $ R $ - algebra map sending $ t $ to $ f $ .
Then $ p(f) coloneqq phif(p) $ is the zero map $ 0 colon V to V $ .
Via $ phif $ , regard $ V $ as an $ Rt $ - module, and with regard to some $ R $ - basis $ {vi } {1 leq i leq n} $ of $ V $ , represent $ f $ by a matrix $ A $ .
Now consider $ t cdot In - A $ as an $ n times n $ matrix $ B(t) $ with entries in $ Rt $ .
By definition of the module structure, this matrix $ B(t) $ , seen as acting on $ V^n $ , annihilates the length $ n $ column vector $ c $ whose $ i^{th} $ row entry is $ vi $ .
By the previous lemma, there is $ tilde{B}(t) $ such that $ tilde{B}(t) B(t) $ is $ det(t cdot In - A) $ times the identity matrix.
It follows that $ det(t cdot In - A) c = tilde{B}(t) B(t) c = tilde{B}(t) 0 = 0 $ i.e., $ det(t cdot In - A) cdot vi = 0 $ for each $ i $ .
Since the $ vi $ form an $ R $ - basis, the $ Rt $ - scalar $ det(t cdot In - A) $ annihilates the $ Rt $ - module $ V $ , as was to be shown.
The Cayley - Hamilton theorem easily generalizes to finitely generated $ R $ - modules (not necessarily free) as follows.
Let $ f colon V to V $ be a module endomorphism, and suppose $ pi colon R^n to V $ is an epimorphism.
Since $ R^n $ is projective, the map $ f circ pi $ can be lifted through $ pi $ to a map $ A colon R^n to R^n $ .
Let $ P(t) $ be the characteristic polynomial of $ A $ $ . P(f) = 0 $ .
Write $ P(t) = sumi ai t^i $ .
We already know $ P(A) = 0 $ .
From $ f circ pi = pi circ A $ , it follows that $ f^i circ pi = pi circ A^i $ for any $ i geq 0 $ .
Hence $ P(f) circ pi = pi circ P(A) = 0 $ .
Since $ pi $ is epic, $ P(f) = 0 $ follows.
We give an interesting and perhaps surprising consequence of the Cayley - Hamilton theorem below, after establishing a lemma close in spirit to Nakayama's lemma.
Suppose $ V $ is a finitely generated $ R $ - module, and $ g colon V to V $ is a module map such that $ g(V) subseteq I V $ for some ideal $ I $ of $ R $ .
Then there is a polynomial $ p(t) = t^n + a1 t^{n - 1} + ldots + an $ , with all $ ai in I $ , such that $ p(g) = 0 $ .
For some finite $ n geq 0 $ , we have a surjective map $ p: R^n to V $ .
Tensoring $ p $ with $ I $ , we obtain a surjective map $ I^n cong I otimesR R^n stackrel{I otimesR p}{twoheadrightarrow} I otimesR V stackrel{mult}{twoheadrightarrow} I V $ , fitting in a commutative diagram $ array{ & & & & & & I^n & hookrightarrow & R^n & & & & & & downarrow & & downarrow mathrlap{p} R^n & stackrel{p}{to} & V & stackrel{g}{to} & im(g) & stackrel{i}{hookrightarrow} & I V & hookrightarrow & V } $ By projectivity of $ R^n $ , we can lift $ i g p: R^n to I V $ to a map $ h: R^n to I^n $ making the diagram commute.
Let $ A $ be the $ R $ - module map $ R^n stackrel{h}{to} I^n hookrightarrow R^n $ , regarded as a matrix.
Then the characteristic polynomial of $ A $ satisfies the conclusion, by the Cayley - Hamilton theorem and Proposition .
Let $ V $ be a finitely generated module over a commutative ring $ R $ , and let $ f colon V to V $ be a surjective module map.
Then $ f $ is an isomorphism.
Regard $ V $ as a finitely generated $ Rt $ - module via $ phif colon Rt to ModR(V, V) $ .
Since $ f $ is assumed surjective, we have $ I V = V $ for the ideal $ I = (t) $ of $ Rt $ .
Now take $ g = 1V $ as in the preceding lemma, a module map over the ring $ R' = Rt $ .
By the lemma, we see that $ g^n + a1 g^{n - 1} + ldots + an = 0 $ where $ ai in (t) $ , in other words the $ Rt $ - scalar $ (1 + a1 + ldots + an)1V = 0 $ as an operator on $ V $ .
Write $ ai = bi(t) t $ for polynomials $ bi(t) in Rt $ .
Now we may rewrite the previous displayed equation as $ 1V(v) = - (sumi bi(t)) t cdot v $ for all $ v in V $ , which translates into saying that $ 1V = - sumi bi(f) f $ , i.e., that $ - sumi bi(f) $ is a retraction of $ f $ .
Since $ f $ is epic, we now see $ f $ is an isomorphism.
The proof of the Cayley - Hamilton theorem follows the treatment in The proof of Proposition on surjective endomorphisms of finitely generated modules was extracted from Given a linear endomorphism, an eigenvector of it is a vector which is taken by the linear map to a multiple of itself.
This multiple is called the eigenvalue of the eigenvector.
If the linear map acts as a differential operator on a space of functions, its eigenvectors are sometimes called eigenfunctions.
Classically, a group is a monoid in which every element has an inverse (necessarily unique).
When written with a view toward group objects (see Internalization below), one should rather say that a group is a monoid together with an inversion operation.
An abelian group is a group in which moreover the order in which two elements are multiplied is irrelevant.
To some extent, a group "is" a groupoid with a single object, or more precisely a pointed groupoid with a single object.
The delooping of a group $ G $ is a groupoid $ mathbf{B} G $ with Since for $ G, H $ two groups, functors $ mathbf{B}G to mathbf{B}H $ are canonically in bijection with group homomorphisms $ G to H $ , this gives rise to the following statement: Let Grpd be the 1 - category whose objects are groupoids and whose morphisms are functors (discarding the natural transformations).
Let Grp be the category of groups.
Then the delooping functor $ mathbf{B} : Grp to Grpd $ is a full and faithful functor.
In terms of this functor we may regard groups as the full subcategory of groupoids on groupoids with a single object.
It is in this sense that a group really is a groupoid with a single object.
But notice that it is unnatural to think of Grpd as a 1 - category.
It is really a 2 - category, namely the sub - 2 - category of Cat on groupoids.
And the category of groups is not equivalent to the full sub - 2 - category of the 2 - category of groupoids on one - object groupoids.
The reason is that two functors: $ mathbf{B}f1, mathbf{B}f2 : mathbf{B}G to mathbf{B}H $ coming from two group homomorphisms $ f1, f2 : G to H $ are related by a natural transformation $ etah : mathbf{B}f1 to mathbf{B}f2 $ with single component $ etah : bullet mapsto h in Mor(mathbf{B} H) $ for each element $ h in H $ such that the homomorphisms $ f1 $ and $ f2 $ differ by the inner automorphism $ Adh : H to H $ $ (etah : mathbf{B}f1 to mathbf{B}f2) Leftrightarrow (f2 = Adh circ f1) , $ .
To fix this, look at the category of pointed groupoids with pointed functors and pointed natural transformations.
Between group homomorphisms as above, only identity transformations are pointed, so $ Grp $ becomes a full sub - $ 2 $ - category of $ Grpd $ (one that happens to be a $ 1 $ - category).
(Details may be found in the appendix to Lectures on n - Categories and Cohomology and should probably be added to pointed functor and maybe also k - tuply monoidal n - category.)
A group object internal to a category $ C $ with finite products is an object $ G $ together with maps $ mult:Gtimes Gto G $ , $ id:1to G $ , and $ inv:Gto G $ such that various diagrams expressing associativity, unitality, and inverses commute.
Equivalently, it is a functor $ C^{op}to Grp $ whose underlying functor $ C^{op} to Set $ is representable.
For example, a group object in Diff is a Lie group.
A group object in Top is a topological group.
A group object in Sch/S (the category or relative schemes) is an $ S $ - group scheme.
And a group object in $ CAlg^{op} $ , where CAlg is the category of commutative algebras, is a (commutative) Hopf algebra.
A group object in Grp is the same thing as an abelian group (see Eckmann - Hilton argument), and a group object in Cat is the same thing as an internal category in Grp, both being equivalent to the notion of crossed module.
Internalizing the notion of group in higher categorical and homotopical contexts yields various generalized notions.
For instance And the notion of loop space object and delooping makes sense (at least) in any (infinity, 1) - category.
Notice that the relation between group objects and deloopable objects becomes more subtle as one generalizes this way.
For instance not every group object in an (infinity, 1) - category is deloopable.
But every group object in an (infinity, 1) - topos is.
Following the practice of centipede mathematics, we can remove certain properties from the definition of group and see what we get: Standard examples of finite groups include Standard examples of non - finite groups include Standard examples of Lie groups include Standard examples of topological groups include For more see counterexamples in algebra.
(i) A non - abelian group, all of whose subgroups are normal: $ Q coloneqq langle a, b | a^4 = 1, a^2 = b^2, a b = b a^3 rangle $ (i) A finitely presented, infinite, simple group Thomson's group T. (i) A group that is not the fundamental group of any 3 - manifold $ . mathbb{Z}^4 $ (i) Two finite non - isomorphic groups with the same order profile $ . C4 times C4, qquad C_2 times langle a, b, | a^4 = 1, a^2 = b^2, a b = b a^3 rangle $ (i) A counterexample to the converse of Lagrange's theorem.
The alternating group $ A_4 $ has order $ 12 $ but no subgroup of order $ 6 $ .
(i) A finite group in which the product of two commutators is not a commutator $ . G = langle (a c)(b d), (e g)(f h), (i k)(j l), (m o)(n p), (a c)(e g)(i k), (a b)(c d)(m o), (e f)(g h)(m n)(o p), (i j)(k l)rangle subseteq S_{16} $ For more see also the references at group theory.
The terminology "group" was introduced (for what today would more specifically be called permutation groups) in The original article that gives a definition equivalent to the modern definition of a group: Textbook account in relation to applications in physics: See also: {TTFormalizations} Formalization of group structure in dependent type theory: in Coq: and with the univalence axiom in Agda: in cubical Agda: in Lean: Exposition in a context of homotopy type theory: Alternative discussion (under looping and delooping) of groups in homotopy type theory as pointed connected homotopy 1 - types: category: group theory In universal algebra, a direct product is simply a product in a concrete category that is created by the forgetful functor.
Compare the direct sum, a more complicated concept.
Trivially, a cartesian product of sets is a direct product in Set.
One of the requirements of a topological category is that any family of objects must have a direct product, although the term 'direct product' is not used in topology.
Many algebraic categories, such as Grp, Ab, Ring, etc, also have all direct products; this is where the term 'direct product' originated.
The category of ( $ Set $ - valued) models of any Lawvere theory has all direct products; this includes the examples from algebra above.
A subgroup of a group $ G $ is a "smaller" group $ K $ sitting inside $ G $ .
A subgroup is a subobject in the category Grp of groups: a monomorphism of groups $ K hookrightarrow G , $ .
Here $ K $ is a subgroup of $ G $ .
Every subgroup of a free group is itself free.
This is the statement of the Nielsen - Schreier theorem.
For $ H hookrightarrow G $ a sub - Lie group inclusion write $ mathbf{B}H to mathbf{B}G $ for the induced map on delooping Lie groupoids.
The homotopy fiber of this map (in Smooth∞Grpd) is the coset space $ G/H $ : there is a homotopy fiber sequence $ G/H to mathbf{B}H to mathbf{B}G , $ .
Now let $ H hookrightarrow K hookrightarrow G $ be a sequence of two subgroup inclusions.
By the above this yields the diagram $ array{ K/H &to& G/H &to& G/K downarrow && downarrow && downarrow mathbf{B}H &to& mathbf{B}H &to& mathbf{B}K downarrow && downarrow && downarrow mathbf{B}K &to& mathbf{B}G &to& mathbf{B}G } $ Discussion in univalent foundations of mathematics (homotopy type theory with the univalence axiom, but for 1 - groups): > (in Agda) See also A subgroup $ N $ of a group $ G $ is normal if the conjugation $ nmapsto g^{ - 1}n g $ by any element $ gin G $ leaves $ N $ invariant, i.e $ . g^{ - 1}N g coloneqq {g^{ - 1}n g, |, nin N } = N $ .
A subgroup $ N $ is normal iff
the partition of the group into left cosets of the subgroup $ N $ , that is the sets $ g N = { g n, |, nin N } $ , is stable in the sense that the left coset $ g1 g2 N $ of the product $ g1 g2 $ of any two elements $ g1, g2in G $ depends only on the coset $ g1 N $ , $ g2 N $ .
Thus there is well defined product on the set of cosets making the set of left cosets $ Nbackslash G $ a group.
By $ g N = g N g^{ - 1}g = N g $ the set of left cosets and the set of right cosets of a normal subgroup coincide; thus the induced group structure on the right coset set $ G/N $ is the same and called the quotient group (see quotient object).
Thus normal subgroups may also be defined as kernels $ f^{ - 1}(e) $ of group homomorphisms $ G to H $ ( $ e in H $ is the identity), and this is largely the point of normal subgroups: they are equivalent to congruence relations in the category of groups.
A normal subgroup is a normal subobject of a group in the category of groups: the more general notion of 'normal subobject' makes sense in semiabelian categories and some other setups.
If we consider a group as a special case of an $ Omega $ - group, then a normal subgroup corresponds to an ideal.
{NormalMorphismOfInfinityGroups} The notion of normal subgroups generalizes from groups to ∞ - groups.
We may take as the characteristic propery of normal subgroup inclusions $ K hookrightarrow G $ that the quotient $ G/K $ inherits a group structure.
This quotient may be identified with the homotopy fiber of the induced morphism of delooping groupoids $ mathbf{B}K to mathbf{B}G $ (see example below).
The following definition takes this as the defining property of "normality" of morphisms.
Let $ mathbf{H} $ be an (∞, 1) - topos of homotopy dimension 0 (for instance a cohesive (∞, 1) - topos) and let $ K, G $ be ∞ - group objects in $ mathbf{H} $ .
A morphism $ f : K to G $ of ∞ - groups in $ mathbf{H} $ is normal if its delooping is the homotopy fiber of a morphism to a 0 - connected object, hence if it fits into a fiber sequence of the form $ mathbf{B}K stackrel{mathbf{B}f}{to} mathbf{B}G to mathbf{B}(Gsslash K) , $ .
Here the object on the right is any 0 - connected ∞ - groupoid.
By the assumption of homotopy dimension 0 and by the discussion at looping and delooping this is necessarily the delooping of some ∞ - group, to be denoted $ Gsslash K $ .
By the discussion at fiber sequence it follows that $ Gsslash K simeq Omega mathbf{B}(G sslash K) $ is the homotopy fiber of $ mathbf{B}f $ , hence that we have a long fiber sequence $ Gsslash K to mathbf{B}K stackrel{mathbf{B}f}{to}mathbf{B}G to mathbf{B}(Gsslash K) , $ .
Therefore equivalently this says that $ f : K to G $ is normal precisely if $ mathbf{B}f : mathbf{B}K to mathbf{B}G $ is a principal ∞ - bundle.
The above fiber sequence says that this principal $ infty $ - bundle has typical fiber $ Gsslash K $ and is classified by the cocycle $ mathbf{B}G to mathbf{B}(Gsslash K) $ .
For the case $ mathbf{H} = $ ∞Grpd - - hence for discrete ∞ - groups - - and with ∞Grpd presented by the standard model structure on topological spaces, this notion is discussed in (Prezma).
The further special where $ f $ is a morphism of discrete 1 - groups, such that $ Gsslash K $ is a 2 - group (example below) is discussed in (Farjoun - Segev).
Such a normal morphism equivalently exhibits an ∞ - group extension $ G $ of $ G sslash K $ by $ K $ .
See there for more details.
Every ordinary normal subgroup inclusion $ K hookrightarrow G $ is also a normal morphism of ∞ - groups, but there are more morphisms of 1 - groups that are normal as morphisms of $ infty $ - groups.
See example below.
{Recognition} A recognition principle for normality of morphisms of ∞ - groups is (Prezma, theorem (vi)2).
Every subgroup of an abelian group is normal, trivially.
For $ G $ a group equipped with an action on another group $ N $ by group automorphisms $ rho : G to Aut(N) $ , the canonical inclusion $ N hookrightarrow G ltimes N $ exhibits $ N $ as a normal subgroup of the semidirect product group $ G ltimes N $ .
If $ N $ is a normal subgroup of $ H $ and $ phi: G to H $ is a group homomorphism, then the inverse image $ phi^{ - 1}(N) $ is normal in $ G $ and $ phi $ induces a group homomorphism $ G/f^{ - 1}(N) to H/N $ .
The proof is entirely straightforward and will be omitted.
Let $ f : K to G $ be a morphism of discrete groups (not necessarily a monomorphism) regarded as a morphisms of 0 - truncated discrete ∞ - groups.
Then the homotopy fiber of its delooping is the action groupoid $ Gsslash K = left( G times K stackrel{overset{( - )cdot f( - )}{to}}{underset{p_1} {to}} G right) , $ .
(This follows for instance by computing the homotopy pullback via the factorization lemma.)
Since $ Gsslash K $ is a 1 - type, this being an ∞ - group means that it is a 2 - group, hence (see the discussion there) that $ f : K to G $ makes a crossed module of groups.
So normal morphisms of 0 - truncated discrete ∞ - groups are equivalently morphisms underlying crossed modules of discrete groups.
This observation apparently goes back to Whitehead.
Normal morphisms of discrete ∞ - groups are discussed in {Prezma} The special case of this for morphisms of 1 - groups is discussed in {FarjounSegev} A quotient group is a quotient object in the category Grp of groups.
For $ G $ a group and $ H hookrightarrow G $ a normal subgroup, the quotient group $ G/H $ is the set of cosets, equipped with a group structure induced from $ G $ .
An action $ ( - )cdot( - ) ;colon; G times X to X $ of a group $ G $ on a set $ X $ is called transitive if it has a single orbit, i.e. for any two elements, $ x, y in X $ , there exists $ gin G $ such that $ y = g cdot x $ .
This is equivalent to saying that the shear map $ array{ G times X & overset { (pr_2, cdot) } {longrightarrow}& X times X (g, x) & mapsto & big( x, g cdot x big) , . } $ is in epimorphism.
In this form the definition makes sense for action objects internal to any ambient category with finite products.
Beware that often it is assumed that the underlying object $ X $ of a transitive action is inhabited (but not always, see at pseudo - torsor).
For $ kge 0 $ , an action $ G times X to X $ is said to be $ k $ - transitive if the componentwise - action $ G times X^{underline{k}} to X^{underline{k}} $ is transitive, where $ X^{underline{k}} $ denotes the set of tuples of $ k $ distinct points (i.e., injective functions from $ {1, dots, k } $ to $ X $ ).
For instance, an action of $ G $ on $ X $ is 3 - transitive if any pair of triples $ (a1, a2, a3) $ and $ (b1, b2, b3) $ of points in $ X $ , where $ ai ne aj $ and $ bi ne bj $ for $ ine j $ , there exists $ g in G $ such that $ (b1, b2, b3) = (g a1, g a2, g a3) $ .
A transitive action that is also free is called regular action.
See also at torsor.
A set equipped with a transitive action of $ G $ (and which is inhabited) is the same thing as a connected object in the category of G - sets.
A $ G $ - set may be decomposed uniquely as a coproduct of transitive $ G $ - sets.
Let $ : G times X to X $ be a transitive action and suppose that $ X $ is inhabited.
Then $ $ is equivalent to the action of $ G $ by multiplication on a coset space $ G/H $ , where the subgroup $ H $ is taken as the stabilizer subgroup $ H = Gx = { g in G mid g * x = x } $ of some arbitrary element $ x in X $ .
In particular, the transitivity of $ $ guarantees that the $ G $ - equivariant map $ G/H to X $ defined by $ g H mapsto g x $ is a bijection.
(Note that although the subgroup $ H = Gx $ depends on the choice of $ x $ , it is determined up to conjugacy, and so the coset space $ G/H $ is independent of the choice of element.)
Given an action $ Gtimes Xto X $ of a (discrete) group $ G $ on a set $ X $ , any set of the form $ G x = {g x|gin G } $ for a fixed $ xin X $ is called an orbit of the action, or the $ G $ - orbit through the point $ x $ .
The set $ X $ is a disjoint union of its orbits.
The category of orbits of a group $ G $ is the full subcategory of the category of sets with an action of $ G $ .
Since any orbit of $ G $ is isomorphic to the orbit $ G/H $ for some group $ H $ , the category of $ G $ - orbits admits the following alternative description: its objects are subgroups $ H $ of $ G $ and morphisms $ H1to H2 $ are elements $ gin G/H2 $ such that $ H1subset g H2g^{ - 1} $ .
In particular, the group of automorphisms of a $ G $ - orbit $ G/H $ is $ NG(H)/H $ , where $ NG(H) $ is the normalizer of $ H $ in $ G $ .
If $ G $ is a topological group, $ X $ a topological space and the action continuous, then one can distinguish closed orbits from those which are not.
Even when one starts with $ G, X $ Hausdorff, the space of orbits is typically non - Hausdorff.
(This problem is one of the motivations of the noncommutative geometry of Connes' school.)
If the original space is paracompact Hausdorff, then every orbit $ G x $ as a topological $ G $ - space is isomorphic to $ G/H $ , where $ H $ is the stabilizer subgroup of $ x $ .
Textbook accounts: For $ G $ a group and $ H1, H2 hookrightarrow $ two subgroups, one says that they are conjugate subgroups if there exists an element $ g in G $ such that the conjugation action by $ g $ takes $ H1 to H1 $ : $ H1 sim{conj} H2 ;;; coloneqq ;;; H2 = Adg(H1) = g H1 g^{ - 1} , $ .
The equivalence classes under this relation are hence called the conjugacy classes of subgroups of $ G $ .
These play a key role in much of group theory and representation theory, for instance as parameters for group characters.
See also A cyclic group is a quotient group of the free group on the singleton.
Generally, we consider a cyclic group as a group, that is without specifying which element comprises the generating singleton.
But see Ring structure below.
There is (up to isomorphism) one cyclic group for every natural number $ n $ , denoted $ mathbb{Z}n coloneqq mathbb{Z}/nmathbb{Z} , $ .
For $ n gt 0 $ , the order (cardinality) of $ mathbb{Z}n $ is $ n $ (so finite); for $ n = 0 $ , which is the group of integers $ mathbb{Z}0 coloneqq mathbb{Z} $ the order is countable but infinite.
If we identify the free group on the singleton with the additive group $ mathbb{Z} $ of integers, then the infinite cyclic group is $ mathbb{Z} $ itself, while the finite cyclic group of order $ n $ is $ mathbb{Z}/n $ , that is $ mathbb{Z} $ modulo (the normal subgroup generated by) the integer $ n $ .
Of course, $ mathbb{Z} $ itself is also $ mathbb{Z}/0 $ .
One could also consider $ mathbb{Z}/n $ for negative $ n $ , but this is the same as $ mathbb{Z}/{|n|} $ .
The cyclic group of order $ n $ may also be identified with a subgroup of the multiplicative group of complex numbers (or algebraic numbers): the group of $ n $ th roots of $ 1 $ .
For $ n = 0 $ , we may pick any non - zero complex number (or even something else) that is not a root of $ 1 $ (but there is no standard choice) and take the subgroup generated by it.
Dedicated entries exist for: Besides ' $ mathbb{Z}/n $ ', the cyclic group of order $ n $ may also be denoted in other ways: some more complicated variation of ' $ mathbb{Z}/n $ ' (to put 'the normal subgroup generated by' explicitly in the notation), or else the simplified form ' $ mathbb{Z}n $ ' (which however conflicts with notation for the $ n $ - adic integers).
When written multiplicatively, it may be denoted ' $ Zn $ ' (note the font change) or ' $ Cn $ '; either letter here stands for 'cyclic' in one language or another.
(It is a coincidence that the German words 'Zahl', which gives us ' $ mathbb{Z} $ ', and 'zyklisch', which gives us ' $ Z $ ', begin with the same letter.)
Besides ' $ mathbb{Z} $ ', the infinite cyclic group may also be denoted in other ways: some variation of ' $ (mathbb{Z}, +) $ ' to indicate that we are using addition of integers, or any of the above notations with either ' $ 0 $ ' or ' $ infty $ ' in place of ' $ n $ ' (depending on whether we think of it as $ mathbb{Z} $ modulo $ 0 $ or the cyclic group with order $ infty $ ).
When written additively, the notation for the elements of a cyclic group are usually just the notation for integers; for the finite cyclic group of order $ n $ , we use the natural number less than $ n $ .
In the finite case, we may also use brackets or some other notation to indicate equivalence classes.
When written multiplicatively, any letter (' $ e $ ', ' $ x $ ', ' $ a $ ', ' $ xi $ ', etc) may be taken to stand for the generating element; then any other element is a power of this generator.
When thought of as a multiplicative group of complex numbers, one generator is $ mathrm{e}^{2mathrm{i}pi/n} $ , and the notation may reflect that.
{Ring} Let $ A $ be a cyclic group, and let $ x $ be a generator of $ A $ .
Then there is a unique ring structure on $ A $ (making the original group the additive group of the ring) such that $ x $ is the multiplicative identity $ 1 $ .
If we identify $ A $ with the additive group $ mathbb{Z}/n $ and pick (the equivalence class of) the integer $ 1 $ for $ x $ , then the resulting ring is precisely the quotient ring $ mathbb{Z}/n $ .
In this way, a cyclic group equipped with the extra structure of a generator is the same thing (in the sense that their groupoids are equivalent) as a ring with the extra property that the underlying additive group is cyclic.
For $ n gt 0 $ , the number of ring structures on the cyclic group $ mathbb{Z}/n $ , which is the same as the number of generators, is $ phi(n) $ , the Euler totient of $ n $ ; the generators are those $ i $ that are relatively prime to $ n $ .
While $ phi(1) = 1 $ , otherwise $ phi(n) gt 1 $ (another way to see that we have a structure and not just a property).
For $ mathbb{Z} $ itself, there are two ring structures, since $ 1 $ and $ - 1 $ are the generators (and these are relatively prime to $ 0 $ ).
lineabreak {FundamentalTheoremOfCyclicGroups} For $ n in mathbb{N} $ , there is precisely one subgroup of the cyclic group $ mathbb{Z}/nmathbb{N} $ of order $ d in mathbb{N} $ for each factor of $ d $ in $ n $ , and this is the subgroup generated by $ n/d in mathbb{Z} to mathbb{Z}/nmathbb{Z} $ .
Moreover, the lattice of subgroups of $ mathbb{Z}/nmathbb{Z} $ is equivalently the dual of the lattice of natural numbers $ leq n $ ordered by divisibility.
(e.g Aluffi 09, pages 83 - 84)
This is a special case of the fundamental theorem of finitely generated abelian groups.
See there for more.
Every finite abelian group is a direct sum of abelian groups over cyclic groups.
See at finite abelian group for details.
For discussion of the group cohomology of cyclic groups see For example, relevant for Dijkgraaf - Witten theory is the fact: $ H^3{grp}big(mathbb{Z}/nmathbb{Z}, U(1)big) ;simeq; mathbb{Z}/nmathbb{Z} , $ .
We discuss some of the representation theory of cyclic groups.
For $ n in mathbb{N} $ , $ n geq 2 $ , the isomorphism classes of irreducible real linear representations of the cyclic group $ mathbb{Z}/n $ are given by precisely the following: (i) the 1 - dimensional trivial representation $ mathbf{1} $ ; (i) the 1 - dimensional sign representation $ mathbf{1}{sgn} $ ; (i) the 2 - dimensional standard representations $ mathbf{2}k $ of rotations in the Euclidean plane by angles that are integer multiples of $ 2 pi k/n $ , for $ k in mathbb{N} $ , $ 0 lt k lt n/2 $ ; hence the restricted representations of the defining real rep of SO(2) under the subgroup inclusions $ mathbb{Z}/n hookrightarrow SO(2) $ , hence the representations generated by real $ 2 times 2 $ trigonometric matrices of the form $ rho{mathbf{2}k}(1) ;=; left( array{ cos(theta) & - sin(theta) sin(theta) & phantom{ - }cos(theta) } right) phantom{AA} text{with} ; theta = 2 pi tfrac{k}{n} , , $ (For $ k = n/2 $ the corresponding 2d representation is the direct sum of two copies of the sign representation: $ mathbf{2}{n/2} simeq mathbf{1}{sgn} oplus mathbf{1}{sgn} $ , and hence not irreducible.
Moreover, for $ k gt n/2 $ we have that $ mathbf{2}{k} $ is irreducible, but isomorphic to $ mathbf{2}{n - k} simeq mathbf{2}{ - k} $ ).
In summary: $ Rep^{irr}{mathbb{R}} big( mathbb{Z}/n big){/sim} ;=; big{ mathbf{1}, mathbf{1}{sgn}, mathbf{2}k ;vert; 0 lt k lt n/2 big } $ (e.g. tom Dieck 09 ((i)(i)6), ((i)(i)8))
Historical discussion of the cyclic group in the context of the classification of finite rotation groups: Textbook accounts:
Further review: On the fundamental theorem of cyclic groups: On the group cohomology of cyclic groups with coefficients in cyclic groups: The term signature refers to a number of quite different notions in mathematics, including but not limited to: category: disambiguation The term signature refers to a number of quite different notions in mathematics, including but not limited to: category: disambiguation An alternating group $ An $ is a subgroup of a symmetric group $ Sn $ consisting of the even permutations.
The alternating group $ An $ is to the symmetric group $ Sn $ as the special orthogonal group $ SO(n) $ is to the orthogonal group $ O(n) $ .
See also at symmetric group - - Whitehead tower Given a field $ k $ and a natural number $ n in mathbb{N} $ , the special linear group $ SL(n, k) $ (or $ SLn(k) $ ) is the subgroup of the general linear group $ SL(n, k) subset GL(n, k) $ consisting of those linear transformations that preserve the volume form on the vector space $ k^n $ .
It can be canonically identified with the group of $ ntimes n $ matrices with entries in $ k $ having determinant $ 1 $ .
This group can be considered as a subvariety of the affine space $ M{ntimes n}(k) $ of square matrices of size $ n $ carved out by the equations saying that the determinant of a matrix is (i)
This variety is an algebraic group over $ k $ , and if $ k $ is the field of real or complex numbers then it is a Lie group over $ k $ .
The special linear group $ SLn(mathbb{F}) $ is a perfect group for any field $ mathbb{F} $ and any $ n geq 1 $ , except for the cases of the prime fields $ mathbb{F}2 $ and $ mathbb{F}3 $ .
See for example here, or Lang 02, theorems XIII (viii)3 and (ix)(ii) The first case admitted by Prop. is the binary icosahedral group (this Prop.): $ SL(2, mathbb{F}5) ;simeq; 2I $ The special orthogonal group or rotation group, denoted $ SO(n) $ , is the group of rotations in a Cartesian space of dimension $ n $ .
This is one of the classical Lie groups.
It is the connected component of the neutral element in the orthogonal group $ O(n) $ .
For instance for $ n=2 $ we have $ SO(2) $ the circle group.
It is the first step in the Whitehead tower of $ O(n) $ $ cdots to Fivebrane(n) to String(n) to Spin(n) to SO(n) to mathrm{O}(n) , , $ the next step of which is the spin group.
In physics the rotation group is related to angular momentum.
ordinary cohomology of the classifying spaces $ B O(n) $ and $ B SO(n) $ : (Brown 82, Feshbach 83, Pittie 91, Rudolph - Schmidt 17, Theorem (iv)(ii)23) For $ X $ an $ n $ - dimensional manifold a lift of the classifying map $ X to mathcal{B}O(n) $ of the $ O(n) $ - principal bundle to which the tangent bundle $ T X $ is associated is the same as a choice of orientation of $ X $ $ . SO(2) simeq U(1) simeq Spin(2) $ with the circle group and spin group in dimension (ii) linebreak linebreak $ cdots to $ Fivebrane group $ to $ string group $ to $ spin group $ to $ special orthogonal group $ to $ orthogonal group.
{References} For general references see also at orthogonal group.
ordinary cohomology of the classifying spaces: See also For a natural number $ n in mathbb{N} $ , the unitary group $ U(n) $ is the group of isometries of the $ n $ - dimensional complex Hilbert space $ mathbb{C}^n $ .
This is canonically identified with the group of $ n times n $ unitary matrices.
More generally, for a Hilbert space $ mathcal{H} $ , $ U(mathcal{H}) $ is the group of unitary operators on that Hilbert space.
For the purposes of studying unitary representations of Lie groups, the topology is chosen to be the strong operator topology, although other topologies on $ U(mathcal{H}) $ are frequently considered for other purposes.
The unitary groups are naturally topological groups and Lie groups (infinite dimensional if $ mathcal{H} $ is infinite dimensional).
The unitary group $ U(n) $ is compact topological space, hence in particular a compact Lie group.
{HomotopyGroups} For $ n, N in mathbb{N} $ , $ n leq N $ , then the canonical inclusion of unitary groups
$ U(n) hookrightarrow U(N) $ is a 2n - equivalence, hence induces an isomorphism on homotopy groups in degrees $ lt 2n $ and a surjection in degree $ 2n $ .
Consider the coset quotient projection $ U(n) longrightarrow U(n+1) longrightarrow U(n+1)/U(n) , $ .
By prop.
and by this corollary, the projection $ U(n+1)to U(n+1)/U(n) $ is a Serre fibration.
Furthermore, example identifies the coset with the (2n+1) - sphere $ S^{2n+1}simeq U(n+1)/U(n) , $ .
Therefore the long exact sequence of homotopy groups of the fiber sequence $ U(n)to U(n+1) to S^{2n+1} $ is of the form $ cdots to pi{bullet+1}(S^{2n+1}) longrightarrow pibullet(U(n)) longrightarrow pibullet(U(n+1)) longrightarrow pibullet(S^{2n+1}) to cdots $ Since $ pi{leq 2n}(S^{2n+1}) = 0 $ , this implies that $ pi{lt 2n}(U(n)) overset{simeq}{longrightarrow} pi{lt 2n}(U(n+1)) $ is an isomorphism and that $ pi{2n}(U(n)) longrightarrow pi{2n}(U(n+1)) $ is surjective.
Hence now the statement follows by induction over $ N - n $ .
It follows that the homotopy groups $ pik(U(n)) $ are independent of $ n $ for $ n gt frac{k}{2} $ (the "stable range").
So if $ U = underset{longrightarrow}{lim}n U(n) $ , then $ pik(U(n)) = pik(U) $ .
By Bott periodicity we have
$ array{ pi{2k+0}(U) &= 0 pi{2k+1}(U) &= mathbb{Z}. } $ In the unstable range for low $ n $ they instead start out as follows | $ G $ | $ pi1 $ | $ pi2 $ | $ pi3 $ | $ pi4 $ | $ pi5 $ | $ pi6 $ | $ pi7 $ | $ pi8 $ | $ pi9 $ | $ pi10 $ | $ pi11 $ | $ pi12 $ | $ pi13 $ | $ pi14 $ | $ pi15 $ | | - - | - - | - - | - - | - - | - - | - - | - - | - - | - - | - - | - - | - - | - - | - - | - - | | $ U(1) $ | $ mathbb{Z} $ | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0
| | $ U(2) $ | " | 0
| $ mathbb{Z} $ | $ mathbb{Z}2 $ | $ mathbb{Z}2 $ | $ mathbb{Z}{12} $ | $ mathbb{Z}2 $ | $ mathbb{Z}2 $ | $ mathbb{Z}3 $ | $ mathbb{Z}{15} $ | $ mathbb{Z}2 $ | $ mathbb{Z}2^{oplus 2} $ | $ mathbb{Z}3oplusmathbb{Z}{12} $ | $ mathbb{Z}2^{oplus 2}oplusmathbb{Z}{84} $ | $ mathbb{Z}2oplusmathbb{Z}2 $ | | $ U(3) $ | " | " | " | 0 | $ mathbb{Z} $ | $ mathbb{Z}6 $ | 0 | $ mathbb{Z}{12} $ | $ mathbb{Z}3 $ | $ mathbb{Z}{30} $ | $ mathbb{Z}4 $ | $ mathbb{Z}{60} $ | $ mathbb{Z}6 $ | $ mathbb{Z}2oplusmathbb{Z}{84} $ | $ mathbb{Z}{36} $ | | $ U(4) $ | " | " | " | " | " | 0 | $ mathbb{Z} $ | $ mathbb{Z}{24} $ | $ mathbb{Z}2 $ | $ mathbb{Z}2oplusmathbb{Z}{120} $ | $ mathbb{Z}4 $ | $ mathbb{Z}{60} $ | $ mathbb{Z}4 $ | $ mathbb{Z}2oplusmathbb{Z}{1680} $ | $ mathbb{Z}2oplusmathbb{Z}{72} $ | | $ U(5) $ | " | " | " | " | " | " | " | 0 | $ mathbb{Z} $ | $ mathbb{Z}{120} $ | 0 | $ mathbb{Z}{360} $ | $ mathbb{Z}4 $ | $ mathbb{Z}{1680} $ | $ mathbb{Z}6 $ | | $ U(6) $ | " | " | " | " | " | " | " | " | " | 0 | $ mathbb{Z} $ | $ mathbb{Z}{720} $ | $ mathbb{Z}2 $ | $ mathbb{Z}2oplusmathbb{Z}{5040} $ | $ mathbb{Z}6 $ | | $ U(7) $ | " | " | " | " | " | " | " | " | " | " | " | 0 | $ mathbb{Z} $ | $ mathbb{Z}{5040} $ | 0 | | $ U(8) $ | " | " | " | " | " | " | " | " | " | " | " | " | " | 0 | $ mathbb{Z} $ | Due to the relation to the special unitary group, the higher homotopy groups of $ U(n) $ and
$ SU(n) $ agree.
The $ U(2) $ row can be found using the fact that $ SU(2) $ is diffeomorphic to the 3 - sphere $ S^3 $ .
The $ U(3) $ row can be found using Mimura - Toda 6(iii)
Otherwise the table is given in columns $ pik $ , $ k= 6, ldots, 15 $ , and in rows $ U(n) $ , $ n=4, ldots, 8 $ , by the Encyclopedic Dictionary of Mathematics, Table (vi)VII in Appendix
A. A good discussion about the various topologies one might place on $ U(mathcal{H}) $ and how they all agree and make $ U(mathcal{H}) $ a Polish group is in (Espinoza - Uribe).
For $ mathcal{H} $ a Hilbert space, which can be either finite or infinite dimensional, the unitary group $ U(mathcal{H}) $ and the general linear group $ GL(mathcal{H}) $ , regarded as topological groups, have the same homotopy type.
Additionally, $ U(mathcal{H}) $ is a maximal compact subgroup of $ GL(mathcal{H}) $ for finite - dimensional $ mathcal{H} $ .
By the Gram - Schmidt process.
For a separable infinite - dimensional complex Hilbert space $ mathcal{H} $ , the unitary group $ U(mathcal{H}) $ is contractible in the norm topology.
See also Kuiper's theorem.
Note that $ U(mathcal{H}) $ is also contractible in the strong operator topology (due to Dixmier and Douady).
This in contrast to the finite dimensional situation.
For $ n in mathbb{N} $ ( $ n ge 1 $ ), $ U(n) $ is not contractible.
Write $ B U(n) $ for the classifying space of the topological group $ U(n) $ .
Inclusion of matrices into larger matrices gives a canonical sequence of inclusions $ cdots to B U(n) hookrightarrow B U(n+1) hookrightarrow B U(n+2) to cdots , $ .
The homotopy direct limit over this is written $ B U := {limto}n B U(n) $ or sometimes $ B U(infty) $ .
Notice that this is very different from $ B U(mathcal{H}) $ for $ mathcal{H} $ an infinite - dimensional Hilbert space.
See topological K - theory for more on this.
For all $ n in mathbb{N} $ , the unitary group $ U(n) $ is a split group extension of the circle group $ U(1) $ by the special unitary group $ SU(n) $ $ SU(n) to U(n) to U(1) , $ .
Hence it is a semidirect product group $ U(n) simeq SU(n) rtimes U(1) , $ . {RelationToOrthogonalSymplecticAndGeneralLinearGroup} The unitary group $ U(n) $ is equivalently the intersection of the orthogonal group $ O(2n) $ , the symplectic group $ Sp(2n, mathbb{R}) $ and the complex general linear group $ GL(n, mathbb{C}) $ inside the real general linear group $ GL(2n, mathbb{R}) $ .
Actually it is already the intersection of any two of these three, a fact also known as the "2 out of 3 - property" of the unitary group.
This intersection property makes a G - structure for $ G = U(n) $ (an almost Hermitian structure) precisely a joint orthogonal structure, almost symplectic structure and almost complex structure.
In the first - order integrable case this is precisely a joint orthogonal structure (Riemannian manifold structure), symplectic structure and complex structure $ . U(1) $ is the circle group.
The (2n+1) - spheres are coset spaces of unitary groups $ S^{2n+1} simeq U(n+1)/U(n) , $ .
For $ n leq k $ , the coset $ Vn(mathbb{C}^k) coloneqq U(k)/U(k - n) $ is called the $ n $ th complex Stiefel manifold of $ mathbb{C}^k $ .
The complex Stiefel manifold $ Vn(mathbb{C}^k) $ (example ) is 2(k - n) - connected.
Consider the coset quotient projection $ U(k - n) longrightarrow U(k) longrightarrow U(k)/U(k - n) = Vn(mathbb{C}^k) , $ .
By prop.
and by this corollary the projection $ U(k)to U(k)/U(k - n) $ is a Serre fibration.
Therefore there is induced the long exact sequence of homotopy groups of this fiber sequence, and by prop.
it has the following form in degrees bounded by $ n $ : $ cdots to pi{bullet leq 2(k - n)}(U(k - n)) overset{epi}{longrightarrow} pi{bullet leq 2(k - n)}(U(k)) overset{0}{longrightarrow} pi{bullet leq 2(k - n)}(Vn(mathbb{C}^k)) overset{0}{longrightarrow} pi{bullet - 1 lt 2(k - n)}(U(k)) overset{simeq}{longrightarrow} pi{bullet - 1 lt 2(k - n)}(U(k - n)) to cdots , $ .
This implies the claim.
(...) For U(ℋ): {Idea} For $ C $ a cartesian monoidal category (a category with finite products), an internal ring or a ring object in $ C $ is an internalization to the category $ C $ of the notion of a ring.
Under some reasonable assumptions on $ C $ that allow one to construct a (symmetric) monoidal tensor product on the category of abelian group objects $ Ab(C) $ internal to $ C $ , a ring object can also be defined as a monoid object internal to that monoidal category $ Ab(C) $ .
Sometimes one might take this last point of view a little further, especially in certain contexts of stable homotopy theory where a stable (∞, 1) - category of spectra is already something like an (∞, 1) - category - analogue of a category of abelian groups.
With the understanding that a symmetric smash product of spectra plays a role analogous to tensor products of abelian groups, monoids with respect to the smash product are often referred to as " $ xyz $ - rings" of one sort or another (as mentioned at "ring operad").
Thus we have carry - over phrases from the early days of stable homotopy theory, such as "A - ∞ rings" (for monoids) and "E - ∞ rings" (commutative monoids).
Here it is understood that the monoid multiplication on spectra is an $ (infty, 1) $ - refinement of a multiplicative structure on a corresponding cohomology theory, with various forms of K - theory providing archetypal examples.
{Definition} The traditional definition, based on a traditional presentation of the equational theory of rings, is that a ring object consists of an object $ R $ in a cartesian monoidal category $ C $ together with morphisms $ a: R times R to R $ (addition), $ m: R times R to R $ (multiplication), $ 0: 1 to R $ (zero), $ e: 1 to R $ (multiplicative identity), $ - : R to R $ (additive inversion), subject to commutative diagrams in $ C $ that express the usual ring axioms.
{AsAModelOfALawvereTheory} Let $ T $ be the Lawvere theory for rings, viz.
the category opposite to the category of finitely generated free rings (which are non - commutative polynomial rings $ mathbb{Z}langle X1, ldots, Xnrangle $ ) and ring maps between them.
Then for $ C $ a category with finite products, a ring object in $ C $ may be identified with a product - preserving functor $ T to C $ .
{ViaTheMicrocosmPrinciple} Alternatively, one may define ring objects following the Baez–Dolan microcosm principle.
Indeed, similarly to how it is possible to define monoids in a monoidal category (a pseudomonoid in $ (mathsf{Cat}, times, mathsf{pt}) $ ), it is possible to speak of semiring objects internal to any bimonoidal category (a pseudomonoid in $ (mathsf{SymMonCats}, otimes{mathbb{F}}, mathbb{F}) $ ).
Namely, a semiring in a bimonoidal category $ (mathcal{C}, otimes{mathcal{C}}, oplus{mathcal{C}}, mathbf{0}{mathcal{C}}, mathbf{1}{mathcal{C}}) $ is given by a quintuple $ (R, mu^{+}{R}, eta^{+}{R}, mu^{times}{R}, eta^{times}{R}) $ consisting of - An object $ R $ of $ mathcal{C} $ , called the underlying object of the semiring; - A morphism $ mu^{+}{R}colon Roplus{mathcal{C}}Rlongrightarrow R $ of $ mathcal{C} $ , called the addition morphism of $ R $ ; - A morphism $ mu^{times}{R}colon Rotimes{mathcal{C}}Rlongrightarrow R $ of $ mathcal{C} $ , called the multiplication morphism of $ R $ ; - A morphism $ eta^{+}{R}colonmathbf{0}{mathcal{C}}longrightarrow R $ of $ mathcal{C} $ , called the additive unit morphism of $ R $ ; - A morphism $ eta^{times}{R}colonmathbf{1}{mathcal{C}}longrightarrow R $ of $ mathcal{C} $ , called the multiplicative unit morphism of $ R $ ; satisfying the following conditions: (i) The triple $ (R, mu^{+}R, eta^{+}R) $ is a commutative monoid in $ mathcal{C} $ ; (ii) The triple $ (R, mu^{times}R, eta^{times}R) $ is a monoid in $ mathcal{C} $ ; (iii) The diagrams "filename": "semiringinbimonoidalbilinearity(i)png", "width": 800 corresponding to the semiring axioms $ a(b+c)=a b+a c $ and $ (a+b)c=a c+b c $ commute; (iv) The diagrams "filename": "semiringinbimonoidalbilinearity2corr.png", "width": 500 corresponding to the semiring axioms $ 0a=0 $ and $ a0=0 $ commute; Moreover, for $ mathcal{C} $ a braided bimonoidal category, one defines a commutative semiring in $ mathcal{C} $ to be a semiring in $ mathcal{C} $ whose multiplicative monoid structure is commutative.
A partial version of this definition first appeared in (Brun 2006, Definition (v)1).
For the notion of a semiring in a bimonoidal category defined via the microcosm principle, we have the following examples.
In universal algebra, a direct product is simply a product in a concrete category that is created by the forgetful functor.
Compare the direct sum, a more complicated concept.
Trivially, a cartesian product of sets is a direct product in Set.
One of the requirements of a topological category is that any family of objects must have a direct product, although the term 'direct product' is not used in topology.
Many algebraic categories, such as Grp, Ab, Ring, etc, also have all direct products; this is where the term 'direct product' originated.
The category of ( $ Set $ - valued) models of any Lawvere theory has all direct products; this includes the examples from algebra above.
Prime ideals are supposed to be a generalization of prime numbers from elements of the ring of integers to ideals in the sense of 'ideal elements' of an arbitrary ring (usually commutative, but also possibly something more general than a ring).
It's not clear that they do so; maximal ideals may do a better job.
(In particular, zero is not a prime number, and the zero ideal of $ mathbb{Z} $ is not a maximal ideal either; however, it is a prime ideal.)
Nevertheless, they have assumed an importance that dwarfs any question of original motivation; indeed, the general definition of prime element follows prime ideals rather than prime numbers.
(An element of a ring is prime iff its principal ideal is prime; $ 0 $ is a prime element of $ mathbb{Z} $ but not a prime number.)
Let $ R $ be a rig (assumed unital and associative as usual), and let $ P $ be a two - sided ideal in $ R $ .
Then $ P $ is prime if $ P $ is proper and $ x $ or $ y $ belongs to $ P $ whenever $ x a y $ does for all $ a $ : $ forall, x in R, ; forall, y in R, ; (forall, a in R, ; x a y in P) ;Rightarrow; x in P ;vee; y in P $ .
Also, $ P $ is completely prime if $ P $ is proper and $ x $ or $ y $ belongs to $ P $ whenever $ x y $ does: $ forall, x in R, ; forall, y in R, ; x y in P ;Rightarrow; x in P ;vee; y in P $ .
Note that every completely prime ideal is prime (using that $ R $ is unital).
The converse holds if the rig is commutative (using that $ P $ is an ideal).
So in commutative algebra one usually uses the (simpler) definition of completely prime ideal as the definition of prime ideal: Let $ R $ be a commutative rig, and let $ P $ be an ideal in $ R $ .
Then $ P $ is prime if $ P $ is proper and $ x $ or $ y $ belongs to $ P $ whenever $ x y $ does: $ forall, x in R, ; forall, y in R, ; x y in P ;Rightarrow; x in P ;vee; y in P $ .
Essentially the same definition applies in order theory, using the analogy (which is more than an analogy in the case of a distributive lattice) between multiplication in a rig and the meet in an order: Let $ R $ be a lattice, and let $ P $ be an ideal in $ R $ .
Then $ P $ is prime if $ P $ is proper and $ x $ or $ y $ belongs to $ P $ whenever their meet does: $ forall, x in R, ; forall, y in R, ; x wedge y in P ;Rightarrow; x in P ;vee; y in P $ .
There is an infinitary version of this that is called 'complete' but is not equivalent to the notion in Definition of a completely prime ideal from the noncommutative theory: Let $ R $ be a complete lattice, and let $ P $ be an ideal in $ R $ .
Then $ P $ is completely prime if some element belongs to $ P $ whenever the meet of a subset of $ R $ does: $ forall, X subseteq R, ; bigwedge X in P ;Rightarrow; exists, x in R, ; x in X ;wedge; x in P $ .
With a little sublety, this makes sense even when meets (and joins) don't always exist: Let $ R $ be a preorder, and let $ P $ be an ideal in $ R $ .
Then $ P $ is prime if $ P $ is proper and $ x $ or $ y $ belongs to $ P $ whenever every $ z $ that precedes both $ x $ and $ y $ does: $ forall, x in R, ; forall, y in R, ; (forall, z in R, ; z leq x ;Rightarrow; z in P) ;Rightarrow; (forall, z in R, ; z leq y ;Rightarrow; z in P) ;Rightarrow; x in P ;vee; y in P $ .
Also, $ P $ is completely prime if $ P $ if some element belongs to $ P $ whenever every $ z $ that precedes every element of a subset of $ R $ does: $ forall, X subseteq R, ; (forall, z in R, ; (forall, x in R, ; x in X ;Rightarrow; z leq x) ;Rightarrow; z in P) ;Rightarrow; exists, x in R, ; x in X ;wedge; x in P $ .
Note that a prime filter in a proset $ R $ is a prime ideal in the opposite order $ R^op $ , and a completely prime filter in $ R $ is a completely prime ideal in $ R^op $ .
Again, the meaning of 'completely prime' here is unrelated to its meaning in Definition .
All of these definitions may be justified by looking at the quantale of ideals.
As discussed at ideals in a monoid, there is for two - sided ideals an operation of ideal multiplication, making the ideal lattice $ Idl(R) $ a quantale (cf. Day convolution).
Namely, if $ I, J $ are ideals, then their product $ I J $ is the ideal generated by all products $ x y $ with $ x in I, y in J $ in the case of rigs, or generated by all meets $ x wedge y $ in the case of lattices, or generated by all $ z $ satisfying $ z leq x $ and $ z leq y $ in the case of general prosets.
(Note that for a lattice or other proset, $ I J $ is equal to the intersection $ I cap J $ .)
With $ I J $ suitably defined, every definition above (except the 'complete' ones) can be subsumed below: Let $ R $ be a rig or a proset, and let $ P $ be an ideal in $ R $ .
Then $ P $ is prime if $ P $ is proper and $ I $ or $ J $ is contained in $ P $ whenever $ I J $ is: $ forall, I in Idl(R), ; forall, J in Idl(R), ; I J subseteq P ;Rightarrow; I subseteq P ;vee; J subseteq P $ .
Because $ I J = I cap J $ in order theory, prime ideals there are the same as strongly irreducible ideals, so the completely prime ideals of that theory are really just completely strongly irreducible ideals (generalizing from a pair of ideals to an arbitrary set of ideals).
In contrast, the completely prime ideals of noncommutative ring theory are not of much interest; they are a naïve definition that works in the commutative case but not so well in the noncommutative case.
Finally, note that most of these definitions have an extra clause that a prime ideal must be proper.
This can be justified by removing bias.
We state here the unbiased version of : Let $ R $ be a rig or a proset, and let $ P $ be an ideal in $ R $ .
Then $ P $ is prime if some ideal in the list is contained in $ P $ whenever a product of a finite list of ideals is contained in $ P $ : $ forall, n in mathbb{N}, ; forall, I in Idl(R)^n, ; prod{kinn} Ik subseteq P ;Rightarrow; exists, k in n, ; Ik subseteq P $ .
As is typical, $ n = 1 $ is trivial, $ n gt 2 $ can be proved from $ n = 2 $ by induction, and $ n = 0 $ is the mysterious preliminary clause, in this case that $ P $ is proper.
Note that completely prime ideals in a proset arise by generalizing from finite $ n $ to arbitrary cardinality.
Unbiased versions of the other definitions are fairly straightforward.
(For prime ideals in a noncommutative rig, the unbiased definition involves a product of the form $ a0 x0 a1 x1 cdots x{n - 2} a{n - 1} x{n - 1} an $ ; $ a0 $ and $ an $ can be ignored when $ n gt 0 $ , which is why only $ a1 $ appears in the biased definition.
The definition of completely prime ideals in order theory is already unbiased, since $ X $ could always be the empty set.)
Sometimes it's more fruitful to consider the complement of a prime ideal.
This is known in constructive mathematics as an anti - ideal, and this becomes a necessary perspective there, as many common examples fail to satisfy the above definitions constructively.
(To support anti - ideals, a rig must be equipped with a tight apartness relation, which is vacuous in classical mathematics.)
However, the concept is useful even classically.
Let $ R $ be a rig with apartness, and let $ M $ be a two - sided anti - ideal in $ R $ .
Then $ M $ is prime if $ M $ is proper (that is inhabited) and $ x a y $ belongs to $ M $ for some $ a $ whenever $ x $ and $ y $ do: $ forall, x in R, ; forall, y in R, ; x in M ;Rightarrow; y in M ;Rightarrow; exists, a in R, ; x a y in M $ .
Also, $ M $ is completely prime if $ M $ is proper and $ x y $ belongs to $ M $ whenever $ x $ and $ y $ do: $ forall, x in R, ; forall, y in R, ; x in M ;Rightarrow; y in M ;Rightarrow; x y in M $ .
If we ignore the requirement that $ M $ be an anti - ideal, then we say that $ M $ is an m - system if it is inhabited and satisfies the binary condition of a prime ideal and multiplicatively closed if it owns $ 1 $ and satisfies the binary condition of a completely prime ideal.
(A proper anti - ideal necessarily owns $ 1 $ , but an m - system might not, even though by definition it must be inhabited.)
Thus, an ideal in a commutative ring is (classically) prime iff
its complement is multiplicatively closed (and analogously for noncommutative rings).
In a matrix ring $ Mn(k) $ over a field $ k $ , the zero ideal is prime (really because a matrix ring is a simple ring, where the zero ideal is a maximal ideal), but (for $ n gt 1 $ ) not completely prime.
In the ring of integers (or the rig of natural numbers), the prime ideals are precisely the principal ideals of the prime numbers together with the zero ideal.
(This is the motivating example, despite not lining up perfectly.)
The natural numbers $ 0, 1, 2, ldots $ are partially ordered by the divisibility relation: $ a|b $ if $ b = a k $ for some natural number $ k $ .
This poset is in fact a lattice.
The greatest common divisor of $ a, b $ is their meet in this lattice.
Spelled out, this means that the greatest common divisor of $ a, b in mathbb{N} $ , denoted $ gcd(a, b) $ , is the element $ d in mathbb{N} $ uniquely characterized by the following two conditions: One could equivalently equip the natural numbers with a function $ gcd:mathbb{N} times mathbb{N} to mathbb{N} $ which satisfies the two conditions: It is almost but not quite true that "greatest" means greatest with respect to the usual ordering $ leq $ .
In particular, $ 0 $ is the maximal element with respect to the divisibility ordering, and $ gcd(0, 0) = 0 $ according to the definition above.
However, there is no "greatest" common divisor of $ 0 $ with itself if we construe "greatest" in the sense of $ leq $ : every natural number is a common divisor of $ 0 $ with itself, and there is no $ leq $ - greatest natural number!
Thus, the convention often seen in textbooks, which replaces the second condition above with or is slightly more awkward, and certainly less "pure" (mixing two relations $ | $ and $ leq $ ).
It is also less robust, because the notion of $ gcd $ is at bottom an ideal - theoretic notion: the divisibility order on elements of a principal ideal domain is a preorder whose posetal collapse is the collection of ideals, ordered oppositely to inclusion.
Thus, in ring - theoretic contexts where there is no sensible notion of $ leq $ , for example in the ring of Gaussian integers, the notion of $ gcd $ still makes perfectly good sense if we use the first formulation above, expressed purely in terms of divisibility.
From the point of view of principal ideals in a pid or Bézout domain $ R $ , the gcd corresponds to taking their join: $ (gcd(a, b)) = (a) + (b) $ .
Thus the Euclidean algorithm, which applies generally to Euclidean domains $ R $ , is a way of calculating a generator of $ (a) + (b) $ which consists of $ R $ - linear combinations of $ a $ and $ b $ .
In the set of integers, the greatest common divisor only results in a prelattice rather than a lattice, because the divisibility relation is only a preorder rather than a partial order, due to the fact that there is more than one element of the group of units of the integers.
For $ a, b in mathbb{N} $ two positive natural numbers, their least common multiple $ LCM(a, b) in mathbb{N} $ is the smallest natural number that is divisible by both $ a $ and $ b $ , i.e. such that there exist $ na, nn in mathbb{N} $ with $ na cdot a = nb cdot b = LCM(a, b) $ .
Spelled out, this means that the least common multiple of $ a, b in mathbb{N} $ , denoted $ mathrm{lcm}(a, b) $ , is the element $ d in mathbb{N} $ uniquely characterized by the following two conditions: One could equivalently equip the natural numbers with a function $ mathrm{lcm}:mathbb{N} times mathbb{N} to mathbb{N} $ which satisfies the two conditions: It is not true that "least" means least with respect to the usual ordering $ leq $ .
In particular, $ 1 $ is the minimal element with respect to the divisibility ordering, and $ mathrm{lcm}(1, 1) = 1 $ according to the definition above.
However, if we construe "least" in the sense of $ leq $ , since every natural number is a common multiple of $ 1 $ with itself, then $ 0 $ is the $ leq $ - least natural number!
Furthermore, it is also less robust, because the notion of $ lcm $ is at bottom an ideal - theoretic notion: the divisibility order on elements of a principal ideal domain is a preorder whose posetal collapse is the collection of ideals, ordered oppositely to inclusion.
Thus, in ring - theoretic contexts where there is no sensible notion of $ leq $ , for example in the ring of Gaussian integers, the notion of $ mathrm{lcm} $ still makes perfectly good sense if we use the first formulation above, expressed purely in terms of divisibility.
From the point of view of principal ideals in a pid or Bézout domain $ R $ , the lcm corresponds to taking their meet: $ (mathrm{lcm}(a, b)) = (a) cap (b) $ .
In an arbitrary Bézout unique factorization domain $ R $ , the least common multiple function is only a prelattice, because the minimum elements with respect to the least common multiple are given by the group of units $ R^times $ .
One usually takes the quotient monoid of the multiplicative structure on $ R $ by the group of units $ R^times $ to get a lattice: thus, the least common multiple is a function $ mathrm{lcm}:R times R to R/R^times $ .
In particular, in a discrete field $ K $ , the quotient $ K/K^times $ is the boolean domain $ mathrm{bool} $ and the lcm is thus a function $ mathrm{lcm}:K times K to mathrm{bool} $ , and in a Heyting field $ F $ , the quotient $ F/F^times $ is the set of truth values $ Omega $ whose divisibility partial order is the opposite poset of the usual partial order via entailment, and the lcm is thus a function $ mathrm{lcm}:F times F to Omega $ , defined as
$ mathrm{lcm}(a, b) coloneqq mathrm{isInvertible}(a) wedge mathrm{isInvertible}(b) $ A ring $ R $ is a principal ideal domain if (i) it is an integral domain (hence in particular a commutative ring) (ii) every ideal in $ R $ is a principal ideal.
Often pid is used as an abbreviation of "principal ideal domain".
A pid can also be characterized as an integral domain wich possesses a Dedekind - Hasse norm, making very clear the fact that it is a generalization of an Euclidean domain.
That both the integers and the polynomial rings $ mathbb{F}qx $ over finite fields are principal integral domains with finite group of units is one aspect of the close similarity between the two that is the topic of the function field analogy.
That also the holomorphic functions on the complex plane form a Bézout domain may then be viewed as part of the further similarity that relates the previous two to topics such as geometric Langlands duality.
See at function field analogy - - table for more on this.
In a pid $ R $ , an element $ x $ is irreducible iff $ (x) $ is a maximal ideal.
Suppose $ x $ is irreducible and $ a notin (x) $ .
Then the ideal generated by $ a, x $ is principal, say $ (b) $ .
Then $ x = b y $ and since $ x $ is irreducible, one of $ b, y $ is a unit; if $ y $ is a unit then $ (x) = (b) = (a, x) $ and thus $ a in (x) $ , contradiction.
So then $ b $ must be a unit, i.e., $ (b) $ is the improper ideal.
Thus $ (x) $ has no proper extension: $ (x) $ is maximal.
For any ring $ R $ , if $ (x) $ is maximal and $ x = a b $ for a non - unit $ a $ , then the inclusion $ (x) subseteq (a) $ is an equality by maximality, so $ a = x v $ for some $ v $ .
Then $ x = x v b $ .
In an integral domain we conclude $ 1 = v b $ ; thus $ b $ is a unit.
A pid is a Noetherian ring.
The union of an ascending chain of ideals $ I1 subseteq I2 subseteq ldots $ is an ideal $ I $ ; if $ I = (x) $ , then $ x $ belongs to one of the $ In $ , whereupon $ I = In $ .
A PID is a unique factorization domain.
Working in classical logic, Proposition says that the reverse inclusion relation on the set of nonzero ideals is well - founded.
Let $ A $ be the subset of ideals $ (a) $ that are products of finitely many (maybe zero!)
maximal principal ideals.
For any proper ideal $ (x) neq (0) $ , if every $ (t) $ properly containing $ (x) $ can be factored into maximals, then so can $ (x) $ .
(Spelling this out: either $ (x) $ is maximal/irreducible, or factors as $ (s)(t) $ where both $ s $ and $ t $ are non - units; $ (s) $ and $ (t) $ factor into maximals by hypothesis, and therefore so does $ (x) $ .)
Thus $ A $ is an inductive set, so by well - foundedness it contains every ideal $ (x) neq (0) $ , i.e., $ x $ can be factored into irreducibles.
For uniqueness of the factorization, we first remark that if $ p $ is irreducible and $ p|a b $ , then $ p|a $ or $ p|b $ .
(For $ R/(p) $ is a field and thus a fortiori an integral domain, so that if $ a b equiv 0 ; mod p $ , then $ a equiv 0 ; mod p $ or $ b equiv 0 ; mod p $ .)
Thus if $ p1 p2 ldots pm = q1 q2 ldots qn $ are two factorizations into irreducibles of the same element, then $ p1 $ divides one of the irreducibles $ qi $ , in which case $ (p1) = (qi) $ and each is a unit times the other, meaning we can cancel $ p1 $ on both sides and argue by induction.
{StructureTheoryOfModules} If $ R $ is a pid, then any submodule $ M $ of a free module $ F $ over $ R $ is also free.
(For the converse statement, see here.)
By freeness of $ F $ , there exists an isomorphism $ F cong sum{j in J} Rj $ , a coproduct of copies $ Rj $ of $ R $ (as a module over the ring $ R $ ) indexed over a set $ J $ , which we assume well - ordered using the axiom of choice.
Define submodules of $ F $ : $ F{leq j} coloneqq sum{i leq j} Ri, qquad F{lt j} coloneqq sum{i lt j} Ri, $ .
Any element of $ M cap F{leq j} $ can be written uniquely as $ (x, r) $ where $ x in F{lt j} $ and $ r in Rj $ .
Define a homomorphism $ pj colon M cap F{leq j} to R $ by $ pj((x, r)) = r $ .
The kernel of $ pj $ is $ M cap F{lt j} $ , and we have an exact sequence $ 0 to M cap F{lt j} to M cap F{leq j} to im pj to 0 $ where $ im pj $ is a submodule (i.e., an ideal) of $ R $ , hence generated by a single element $ rj $ .
Let $ K subseteq J $ consist of those $ j $ such that $ rj neq 0 $ , and for $ k in K $ , choose $ mk $ such that $ pk(mk) = rk $ .
We claim that $ {mk: k in K } $ forms a basis for $ M $ .
First we prove linear independence of $ {mk } $ .
Suppose $ sum{i=1}^{n} ai m{ki} = 0 $ , with $ k1 lt k2 lt ldots lt kn $ .
Applying $ p{kn} $ , we get $ an p{kn}(m{kn}) = an r{kn} = 0 $ .
Since $ r{kn} neq 0 $ , we have $ an = 0 $ (since we are working over a domain).
The assertion now follows by induction.
Now we prove that the $ mk $ generate $ M $ .
Assume otherwise, and let $ j in J $ be the least $ j $ such that some $ m in M cap F{leq j} $ cannot be written as a linear combination of the $ mk $ , for $ k in K $ .
If $ j notin K $ , then $ m in M cap F{lt j} $ , so that $ m in M cap F{leq i} $ for some $ i lt j $ , but this contradicts minimality of $ j $ .
Therefore $ j in K $ .
Now, we have $ pj(m) = r cdot rj $ for some $ r $ ; put $ m' = m - r mj $ .
Clearly $ pj(m') = pj(m) - r cdot pj(mj) = 0 $ and so $ m' in M cap F{lt j} $ .
Thus $ m' in M cap F{leq i} $ for some $ i lt j $ .
At the same time, $ m' $ cannot be written as a linear combination of the $ mk $ ; again, this contradicts minimality of $ j $ .
Thus the $ mk $ generate $ M $ , as claimed.
Since the integers $ mathbb{Z} $ form a pid, and abelian groups are the same as $ mathbb{Z} $ - modules, we have A subgroup of a free abelian group is also free abelian.
The analog of this statement for possibly non - abelian groups is the Nielsen - Schreier theorem.
Also, since projective modules are retracts of free modules, we have Projective modules over a pid are free.
In particular, submodules of projective modules are projective.
{SmithNormalForm} For $ R $ a commutative ring which is a principal ideal domain, every matrix $ A in Mat{n times m}(R) $ with entries in $ R $ is matrix equivalent to a diagonal matrix filled up with zeros: There exist invertible matrices $ P in Mat{n times n}(R) $ and $ Q in Mat{m times m}(R) $ such that the product matrix $ P A Q $ is a diagonal matrix filled up with zeros: $ P A Q ;=; $ <center> <img src="https://ncatlab.org/nlab/files/SmithNormalForm.jpg" width="300"> </center> such that, moreover, each $ ai $ divides $ a{i+1} $ .
For matrices with coefficients in the pid of integers see also A finitely generated torsionfree module $ M $ over a pid $ R $ is free.
Let $ S $ be a finite set of generators of $ M $ , and let $ T subseteq S $ be a maximal subset of linearly independent elements.
(Unless $ M = 0 $ , then $ T $ has at least one element, because $ M $ is torsionfree.)
We claim that $ M $ can be embedded as a submodule of the free module $ F $ generated by $ T $ (which in turn is the span of $ T $ as a submodule $ F subseteq M $ ).
By Theorem , it follows that $ M $ is free.
Let $ x1, ldots, xn $ be the elements of $ T $ .
It follows from maximality of $ T $ that for any $ m in S - T $ , there is a linear relation $ rm m + r1 x1 + ldots + rn xn = 0 $ with $ rm neq 0 $ .
For each $ m $ in the complement $ S - T $ , pick such an $ rm $ , and form $ r = prod{m in S - T} rm $ .
Then the image of the scalar multiplication $ lambdar colon M to M $ factors through $ F subseteq M $ , and $ M to lambdar(M) $ is monic because $ M $ is torsionfree.
This completes the proof.
Let $ R $ be a pid.
Then an $ R $ - module $ M $ is torsionfree if and only if it is flat.
Suppose $ M $ is flat.
Let $ K $ be the field of fractions of $ R $ ; since $ R $ is a domain, we have a monic $ R $ - module map $ R to K $ .
By flatness, we have an induced monomorphism $ M cong R otimesR M to K otimesR M $ .
For any nonzero $ r in R $ , the naturality square $ array{ M & to & K otimesR M mathllap{lambdar} downarrow & & downarrow mathrlap{1 otimes lambdar} M & to & K otimesR M } $ commutes, and since the map $ 1 otimes lambdar $ is multiplication by a non - zero scalar on a vector space, it follows that this map and therefore also $ lambdar $ is monic, i.e., $ M $ is torsionfree.
In the other direction, suppose $ M $ is torsionfree.
Any module is the filtered colimit over the system of finitely generated submodules and inclusions between them; in this case all the finitely generated submodules of $ M $ are torsion - free and hence free, by Proposition .
Thus $ M $ is a filtered colimit of free modules; it is therefore flat by a standard result proved here.
structure theorem for finitely generated modules over a principal ideal domain In constructive mathematics, many important rings may fail to be principal ideal domains in the na&239;ve sense; the notion of Bézout domain, in which only the finitely generated ideals are required to be principal, is better behaved.
For instance, the ring of integers is a principal ideal domain if and only if the law of excluded middle holds:
In one direction, the usual proofs rely on being able to decide whether any particular integer belongs to the ideal or not.
For the converse, let $ varphi $ be an arbitrary proposition.
Consider the ideal $ { x in mathbb{Z} | (x = 0) vee varphi } $ .
By assumption, it is generated by some number $ n $ .
Since the integers are discrete, it holds that $ n = 0 $ or $ n neq 0 $ .
In the first case $ negvarphi $ holds, in the second $ varphi $ .
However, this ideal cannot be proved to be finitely generated either.
If an ideal is generated by $ n1, ldots, nk $ , then we may form their gcd one step at a time, which we can do algorithmically.
Therefore, $ mathbb{Z} $ remains a B&233;zout domain.
On the other hand, we could try to modify the concept of principal ideal domain to recover a concept that is identical to the usual one in classical mathematics but also includes $ mathbb{Z} $ .
For instance, we could demand that every decidable ideal is principal, or (potentially more strongly) that any ideal generated by a decidable subset is principal.
While these seem to work at first, they are too weak to prove that every PID is a B&233;zout domain, so we should try to think of something better.
Some authors have tried to define a principal ideal domain as a Noetherian Bézout domain, but it is unknown if this still coincides in constructive mathematics with the definition of principal ideal domain above.
6 (1940), 345 - 35(vi) <div style="float:right;margin:0 10px 10px 0;"> <img src="https://ncatlab.org/nlab/files/SomePrimes.jpg"
width="60"/> </div>
A prime number is a nonzero natural number that cannot be written as a product of finitely many natural numbers (all) other than itself, hence a natural number greater than 1 that is divisible only by 1 and itself.
This means that every natural number $ n in mathbb{N} $ is, up to re - ordering of factors, uniquely expressed as a product of a tuple of prime numbers: $ n ;=; 2^{n1} cdot 3^{n2} cdot 5^{n3} cdot 7^{n4} cdot 11^{ n5 } cdots $ This is called the prime factorization of $ n $ .
Notice that while the number $ 1 in mathbb{N} $ is, clearly, only divisible by one and by itself, hence might look like it deserves to be counted as a prime number, too, this would break the uniqueness of this prime factorization.
In view of the general phenomenon in classifications in mathematics of some objects being too simple to be simple one could say that 1 is "too prime to be prime".
However, historically, some authors did count 1 as a prime number, see e.g. Roegel 1(i) {RelationToIdeals} A number is prime if and only if it generates a maximal ideal in the rig $ mathbb{N} $ of natural numbers.
Prime numbers do not quite match the prime elements of $ mathbb{N} $ , since $ 0 $ generates a prime ideal but not a maximal ideal; instead they match the irreducible elements (Wikipedia).
From the Isbell - dual point of view, where a commutative ring such as the integers $ mathbb{Z} $ is regarded as the ring of functions on some variety, namely on Spec(Z), the fact that prime numbers $ p $ correspond to maximal ideals means that they correspond to the closed points in this variety (see this Example), one also writes $ (p) in Spec(mathbb{Z}) , $ .
This dual perspective on number theory as being the geometry (algebraic geometry) over Spec(Z) is called arithmetic geometry.
see at Riemann hypothesis see at Goldbach conjecture see at prime number theorem For historical discussion see See also For $ p geq 2 $ a prime number , then quotient $ mathbb{Z}/pmathbb{Z} $ of the ring of integers by $ p $ is a finite field denoted $ mathbb{F}p $ , a prime field.
Prime fields have positive characteristic.
Every prime field is a prime power local ring with trivial nilradical.
The spectra of prime fields inside Spec(Z) are analogous to knots/prime geodesics inside a (hyperbolic) 3 - dimensional space, see at Spec(Z) - -
As a 3 - dimensional space containing knots Classically, the fundamental theorem of algebra states that Since every non - zero polynomial could be made a monic polynomial by dividing by the leading coefficient, it could also be expressed as Many proofs of this theorem are known (see the references below); some use complex analysis (the reciprocal of a polynomial function cannot be bounded), some use algebraic topology (the degree of a map is invariant with respect to homotopy), and some use advanced calculus (polynomial functions on the complex numbers are open mappings).
All of these proofs involve, at some level, the fact that the real numbers are Dedekind complete, which has as a consequence the fact that the real numbers are archimedean.
Despite its name, the fundamental theorem of algebra makes reference to a concept from analysis (the field of complex numbers).
However, the analytic part may be reduced to a minimum: that the field of real numbers is real closed.
This has been known essentially forever, and is easily proved using (for example)
the intermediate value theorem.
The rest of the proof is algebraic and, unlike the other proof methods, applies to all real closed fields, which need not be archimedean.
It is due to Emil Artin, and forms a basic chapter in the Artin - - Schreier theory of real closed fields.
We recall that a real closed field is an ordered field such that every positive element has a square root, and every polynomial function of odd degree has a root.
Note that the polynomial function $ x^2 + 1 $ cannot have any root in a real closed field - - - or in fact in any ordered field, since we always have $ x^2ge 0 $ and hence $ x^2+1 ge 1 $ .
If $ F $ is real closed, then $ K = Fsqrt{ - 1} $ is algebraically closed.
We must show that any irreducible polynomial $ p $ of degree greater than $ 0 $ with coefficients in $ K $ has a root in $ K $ .
Since $ F $ has characteristic $ 0 $ , it is a perfect field.
Thus the splitting field of $ p $ is a finite Galois extension $ L $ of $ F $ , with Galois group $ G $ .
If $ G(2) $ is the Sylow 2 - group of $ G $ , then the fixed field $ E $ of $ G(2) $ is an odd degree extension of $ F $ .
Any $ alpha in E $ must then have an irreducible polynomial function $ q in Fx $ of odd degree.
But since $ F $ is real closed, $ q $ has a root in $ F $ ; by irreducibility, $ deg(q) = 1 $ and $ alpha in F $ , forcing $ E = F $ and $ G = G(2) $ .
We have $ {|G|} gt 1 $ since the splitting field contains $ K $ .
So $ G $ is a $ 2 $ - primary group.
But for any prime number $ p $ , a nontrivial finite $ p $ - group has nontrivial center (see here), and is therefore solvable by an inductive argument.
Therefore the extension $ L/F $ arises from a tower of non - trivial quadratic extensions $ F subseteq L1 subseteq ldots subseteq Ln = L $ By the quadratic formula, the first field $ L1 $ arises by adjoining roots to $ F $ of a polynomial function $ x^2 + a x + b $ , $ frac{ - a pm sqrt{a^2 - 4b}}{2}, $ where $ a^2 - 4b $ is negative.
Since $ F $ is real closed, the positive element $ 4b - a^2 $ has a square root in $ F $ , so that the roots displayed above belong to $ K = Fsqrt{ - 1} $ .
So $ L1 = K $ .
But $ K $ has no nontrivial quadratic extensions by the lemma that follows, so in fact $ L1 = Ln = K $ and the theorem is proved.
Every element of $ K = Fsqrt{ - 1} $ has a square root in $ K $ .
The proof is most easily apprehended by analogy with polar coordinate representations of complex numbers and half - angle formulas, where a square root of $ r e^{itheta} $ is given by $ r^{1/2}e^{itheta /2} $ .
Let $ i $ be a fixed square root of $ - 1 $ , and let $ a + b i $ be an arbitrary element of $ K $ , with $ a, b in F $ .
We must solve $ (x + y i)^2 = a + b i $ , i.e., find $ x, y in F $ that solve $ x^2 - y^2 = a, qquad 2x y = b $ Since $ a^2 + b^2 $ has a square root in $ F $ , we may assume by homogeneity in $ x, y $ that $ (a, b) $ is on the unit circle: $ a^2 + b^2 = 1 $ .
By interchanging $ x $ and $ y $ if need be, we may assume $ 0 leq a leq 1 $ ; replacing $ y $ by $ - y $ if need be, we may assume $ b geq 0 $ .
Taking $ x, y geq 0 $ such that $ x^2 = frac{1+a}{2}, qquad y^2 = frac{1 - a}{2}, $ we obtain a solution (since $ x^2 - y^2 = a $ and $ 4 x^2 y^2 = b^2 $ ).
As noted above, many proofs of the fundamental theorem are known.
The following proof, ultimately rooted in the fact that polynomial mappings on $ mathbb{C} $ are open mappings, has the advantage that it requires very little machinery.
From what I (Todd Trimble) understand, it is close to the method used by Argand to give his proof (1814)^(i) ^1:
Despite the credit given to Gauss for his demonstration of 1799, Argand's proof is often credited as the first one that is fully rigorous.
The proof given here also uses the Bolzano - Weierstrass theorem, first proven by Bolzano in 1817, making it somewhat contemporaneous.
Argand is also widely credited as the one who introduced the cutting - edge idea of viewing complex numbers and their operations geometrically, which the proof here also uses (the complex plane $ mathbb{C} $ being also known as the Argand plane).
Let $ fcolon mathbb{C} to mathbb{C} $ be a nonconstant polynomial mapping, and suppose $ f $ has no zero.
(i) Let $ s $ be the infimum of values $ {|f(z)|} $ ; choose a sequence $ z1, z2, z3, ldots $ such that $ {|f(zn)|} to s $ .
Since $ lim{z to infty} f(z) = infty $ , the sequence $ zn $ must be bounded; by the Bolzano - Weierstrass theorem it has a subsequence $ z{nk} $ that converges to some point $ z0 $ .
Then $ {|f(z{nk})|} $ converges to $ {|f(z0)|} $ by continuity, and converges to $ s $ as well, so $ {|f(z)|} $ attains an absolute minimum $ s $ at $ z = z0 $ .
By supposition, $ f(z0) neq 0 $ .
(ii) The polynomial function $ f $ may be uniquely written in the form $ f(z) = f(z0) + g(z)(z - z0)^n $ where $ g $ is polynomial function and $ g(z0) neq 0 $ .
Put $ F(z) = f(z0) + g(z0)(z - z0)^n $ and choose $ delta gt 0 $ small so that $ {|z - z0|} = delta Rightarrow {|g(z) - g(z0)|} lt {|g(z0)|} $ .
(iii) $ F $ maps the circle $ C = {z : {|z - z0|} = delta } $ onto a circle of radius $ r = {|g(z0)|}delta^n $ centered at $ f(z0) $ .
(This uses the fact that any complex number has an $ n^{th} $ root, which one can prove using polar coordinate representations.
We omit the details.)
Choose $ z' in C $ so that $ F(z') $ is on the line segment between the origin and $ f(z0) $ (we can always choose $ delta $ so that also $ r lt {|f(z0)|} $ ).
Then $ {|F(z')|} = {|f(z0)|} - r $ We also have $ {|f(z') - F(z')|} = {|g(z') - g(z0)|} {|z' - z0|^n} lt {|g(z0)|} delta^n = r $ according to how we chose $ delta $ in (ii) We conclude by observing the strict inequality $ {|f(z')|} leq {|F(z')|} + {|f(z') - F(z')|} lt {|f(z0)|} - r + r = {|f(z0)|}, $ which contradicts the fact that $ {|f(z)|} $ attains an absolute minimum at $ z = z0 $ .
Many proofs rely explicitly on the double negation rule by first supposing that a polynomial function $ p $ has no root and deriving a contradiction.
In constructive mathematics, integral closure and algebraic closure of a field are not the same, because not every nonconstant polynomial function has a well - defined degree.
This is still the case even if we take "nonconstant polynomial function", we mean "apart from every constant polynomial function".
In general, every nonconstant polynomial function has a well - defined degree if and only if the field is a discrete field.
Thus, the fundamental theorem of algebra is usually expressed in terms of integral closure: A fully choice - free constructive proof by Wim Ruitenberg (Ruitenberg 1991) exists for the modulated Cantor complex numbers (which agree with the Dedekind complex numbers by weak countable choice or the limited principle of omniscience).
The algebraic proof of other fields of real numbers is problematic in many ways.
First, one might wish to use the inverse function theorem to prove that the square root of every non - negative number exists; however, the inverse function theorem only proves that the square root of every positive number exists, since the inverse function theorem leads to continuous inverses, which for the square function is the continuous square root, which is only defined on the positive real numbers.
The metric square root, which is defined on the non - negative real numbers, is not continuous at $ 0 $ .
The second problem is Lemma .
This may fail in a topos (such as sheaves over $ mathbb{C} $ ), since we may not be able to find a square root of a complex number $ x $ (or element of $ Ksqrt{ - 1} $ more generally) if we do not know whether or not $ x $ is apart from zero, because there is no continuous square - root function unless one assumes weak countable choice.
Fred Richman (1998) has proposed that, in the absence of $ WCC $ , the FTA should be interpreted as a statement about sets of roots rather than about individual roots.
He constructs a complete metric space $ hat{M}n(mathbb{C}) $ which, classically, is the space of $ n $ - element multisets of complex numbers (and constructively is the completion of that space) and proves that every complex polynomial function $ p $ of degree $ n $ may be associated with a point in this space in such a way that the $ n $ elements of that point (when viewed as a multiset, if possible, and morally in any case) are the $ n $ roots of $ p $ .
Assuming classical logic, but weak foundations, it can be shown that FTA is true in the reverse mathematics system $ RCA0 $ (Tanaka - Yamazaki 2005).
{History} The proof was attempted many times before Gauss gave what is accepted as the first proof in his dissertation (Gauss 1799), although this was not without issues (Gauss 'fixed' this proof almost 50 years later, but the last gap was not filled until the 20th century).
All proofs of this fact (of which there are many) require something analytic, in the sense that ordinary algebra will not suffice: one needs to know that the real numbers (or the complex numbers) 'have no algebraic gaps'.
For instance, the rational numbers famously don't contain the square root of $ 2 $ .
The cleanest proof I know, due to Artin, that isolates this analytic germ, uses the step - ladder result that the real numbers form what is called a real closed field.
This is essentially saying that non - negative real numbers have square roots, and odd degree polynomial functions have roots (anyone who has plotted a cubic can appreciate this fact).
Alternatively, one can characterise real closed fields as those for whom the Intermediate Value Theorem (IVT) holds for polynomial functions.
Accepting this result (which does need proof), the FTA follows using pure algebra (although not of the high - school sort).
However, it is of interest, partly theoretical, partly for the sake of finding the bare minimum needed to prove the FTA, to know an elementary proof, namely one that minimises the use of analytic techniques (for instance, the IVT for polynomial functions follows from the IVT for continuous functions, but that is like killing a mosquito with a bazooka).
Gauss' second proof (Gauss 1866) is elementary (and predates Artin's by a long time).
Since Gauss lacked modern algebraic techniques, some of his proof is laborious, but (Taylor 85) gives a modern gloss.
(With some amusing side notes: as Taylor puts it - - 'Gauss takes the opportunity to be rude to his inferior contemporaries'.)
Gauss' proof, in modern language, takes up less than a page and a half, but this presupposes familiarity with some of the theory of fields (but which is pure algebra).
Artin's proof, by comparison, drawing on major theorems can be given in half a page.
It should be noted, in the context of the last statement, that proofs of the FTA can be given, relying on analytic 'bazooka' theorems, that are one sentence.
However, to spell out the proofs of the necessary theorems, one needs a course in analysis, of some variety, so one is merely sweeping a lot under a very small rug.
{References} Another new proof of the theorem that every integral rational algebraic function of one variable can be resolved into real factors of the first or second degree translated by Paul Taylor and B. Leak (1983) (web) A proof that Cauchy sequences of rational numbers satisfy the fundamental theorem of algebra: {Richman} The Reverse Mathematical treatment is given in {TK2005} A constructive algebraic proof of the fundamental theorem of algebra for the modulated Cauchy real numbers without choice princples such as weak countable choice A full formalization in the Coq proof assistant is in See also A field with finitely many elements.
Let $ F $ be a finite field.
As $ mathbb{Z} $ is the initial object in the category of rings, there is a unique ring homomorphism $ mathbb{Z} to F $ , whose regular epi - mono factorization is $ mathbb{Z} twoheadrightarrow mathbb{Z}/(p) hookrightarrow F; $ here $ p $ is prime (irreducible) since any subring of a field has no zero divisors.
Here $ mathbb{Z}/(p) $ is a prime field, usually denoted $ mathbb{F}p $ .
Thus we have an inclusion of fields $ mathbb{F}p to F $ ; in particular $ F $ is an $ mathbb{F}p $ - module or vector space, clearly of finite dimension $ n $ .
It follows that $ F $ has $ q = p^n $ elements.
In addition, since the multiplicative group $ F^times $ is cyclic (as shown for example at root of unity), of order $ q - 1 $ , it follows that $ F $ is a splitting field for the polynomial $ x^{q - 1} - 1 in mathbb{F}px $ .
As splitting fields are unique up to isomorphism, it follows that up to isomorphism there is just one field of cardinality $ q = p^n $ ; it is denoted $ mathbb{F}q $ .^fine
^fine: There is no 'canonical' choice of such a splitting field, just as there is no canonical choice of algebraic closure.
So 'morally' there is something wrong with saying 'the' finite field $ mathbb{F}q $ , although this word usage can be found in the literature.
In the special case $ n = 1 $ there is no problem: Given fields containing $ p $ elements are isomorphic in a unique way.
The Galois group $ Gal(mathbb{F}{p^n}/mathbb{F}p) $ is a cyclic group of order $ n $ , generated by the automorphism $ sigma: mathbb{F}{p^n} to mathbb{F}{p^n} $ sending $ x mapsto x^p $ .
(One way to see that $ sigma $ preserves addition is to write (binomial theorem) $ array{ (x + y)^p & = & sum{i=0}^p binom{p}{i} x^i y^{p - i} & = & x^p + y^p } $ where the second equation follows from the fact that the integer $ p $ divides the numerator of $ frac{p!}{i!(p - i)!} $ , but neither factor of the denominator, if $ 0 lt i lt p $ .
This is true for any commutative algebra over $ mathbb{F}p $ ; see freshman's dream.)
This $ sigma $ is called the Frobenius (auto)morphism or Frobenius map.
More generally, if $ m $ divides $ n $ , then $ mathbb{F}{p^m} $ is the fixed field of the automorphism $ sigma^m: x mapsto x^{p^m} $ , and $ Gal(mathbb{F}{p^n}/mathbb{F}{p^m}) $ is a cyclic group of order $ n/m $ that is generated by this automorphism, which is also called the Frobenius map (for the field extension $ mathbb{F}{p^n}/mathbb{F}{p^m} $ ), or just "the Frobenius" for short.
If $ K = widebar{mathbb{F}p} $ is an algebraic closure of $ mathbb{F}p $ , then $ K $ is the union (a filtered colimit) of the system of such finite field extensions $ mathbb{F}q $ and inclusions between them.
If $ q = p^n $ , then $ mathbb{F}q $ may be defined to be the fixed field of the automorphism $ sigma^n: K to K $ .
The Galois group $ Gal(K/mathbb{F}p) $ is the inverse limit of the system of finite cyclic groups and projections between them; it is isomorphic to the profinite completion $ widehat{mathbb{Z}} = hom(mathbb{Q}/mathbb{Z}, mathbb{Q}/mathbb{Z}) cong prod{primes; p} mathbb{Z}p $ where $ mathbb{Z}p $ is the group of $ p $ - adic integers.
category: algebra <div style="float:right;margin:0 10px 10px 0;"> <img src="https://ncatlab.org/nlab/files/ChartsOfAManifold.png" width="400"> </div>
A topological manifold $ X $ of dimension $ n in mathbb{N} $ is by definition a topological space that is locally homeomorphic to a Cartesian space $ mathbb{R}^n $ .
A choice of such morphism $ phi : mathbb{R}^n stackrel{simeq}{to} X|{im(phi)} hookrightarrow X $ is a coordinate system or coordinate chart or just chart on the image of $ phi $ .
This generalises to other sorts of manifolds.
An atlas is the collection of coordinate charts defining a manifold structure.
> graphics grabbed from Frankel For $ V $ a vector space or more generally a $ k $ - module, then a quadratic form on $ V $ is a function $ qcolon V to k $ which is homogeneous of degree 2 in that for all $ v in V $ , $ t in k $ $ q(t v) = t^2 q(v) $ and such that the polarization of $ q $ $ (v, w) mapsto q(v+w) - q(v) - q(w) $ is a bilinear form.
Written entirely in terms of $ q $ , the axioms for a quadratic form are: (Besides the homogeneity, these come from two requirements of a bilinear form to preserve scalar multiplication and addition, respectively.)
So we may alternatively define a quadratic form to be a map $ qcolon V to k $ satisfying these three axioms.
A more general quadratic map (or homogeneous quadratic map to be specific) between vector spaces $ V $ and $ W $ is a map $ qcolon V to W $ that satisfies the above three conditions.
(Then an affine quadratic map is the sum of a homogeneous quadratic map, a linear map, and a constant, just as an affine linear map is the sum of a linear map and a constant.)
From the converse point of view, $ q $ is a quadratic refinement of the bilinear form $ ( - , - ) $ .
(This always exists uniquely if $ 2 in k $ is invertible, but in general the question involves the characteristic elements of $ ( - u, - ) $ .
See there for more.)
Quadratic forms with values in the real numbers $ k = mathbb{R} $ are called positive definite or negative definite if $ q(v) gt 0 $ or $ q(v) lt 0 $ , respectively, for all $ v neq 0 $ .
See definiteness for more options.
{References} The theory of quadratic forms emerged as a part of (elementary) number theory, dealing with quadratic diophantine equations, initially over the rational integers The terminology "form" possibly originated with (which is cited as such in Gauss 1798, paragraph 151).
First classification results for forms over the integers were due to (which speaks of formas secundi gradus)
See also Course notes include for instance Quadratic refinements of intersection pairing in cohomology is a powerful tool in algebraic topology and differential topology.
See See also Every Lie group $ G $ has a canonical representation on the vector space underlying its Lie algebra $ mathfrak{g} $ , given by the derivative of its adjoint action at the neutral element.
This is called the adjoint representation.
The associated bundles via the adjoint representation are called adjoint bundles.
For $ (G, +) $ an abelian group, then a norm on the group is a function $ {vert - vert} ;colon; G longrightarrow mathbb{R} $ to the real numbers, such that (i) (positivity) $ (g neq 0) Rightarrow (vert gvert gt 0) $ (i) (triangle inequality) $ {vert g + hvert}leq {vert gvert} + {vert hvert} $ (i) (linearity) $ {vert k gvert} = {vert kvert} {vert gvert} $ for all $ k in mathbb{Z} $ .
Here $ {vert kvert} in mathbb{N} $ denotes the absolute value.
A group with a norm is a normed group, see there for more.
In constructive mathematics, it is common to replace the denial inequality with a tight apartness relation in the positivity condition.
For $ k $ a field equipped with a valuation (most usually, a local field such as $ mathbb{R} $ , $ mathbb{C} $ , or a p - adic completion of a number field), a norm on a $ k $ - vector space $ V $ is a function $ {vert - vert} colon V to mathbb{R} $ such that for all $ lambda in k $ , $ v, w in V $ we have (i) $ {vert lambda v vert} = {vert lambdavert} {vert v vert} $ (where $ vert lambda vert $ denotes the valuation) (i) $ {vert v + wvert } leq {vert v vert } + {vert w vert} $ ("triangle inequality") (i) if $ {vert vvert} = 0 $ then $ v = 0 $ .
If the third property is not required, one speaks of a seminorm.
If the triangle identity is strengthened to one speaks of a non - archimedean seminorm, otherwise of an archimedean one.
A vector space equipped with a norm is a normed vector space.
A vector of norm 1 is a unit vector.
Each seminorm determines a topology, which is Hausdorff precisely if it is a norm.
A topological vector space is called (semi - )normed if its topology can be induced by a (semi - )norm.
Two seminorms $ {vert - vert}1 $ and $ {vert - vert}2 $ are called equivalent if there are $ 0 lt C, C' in mathbb{R} $ such that for all $ v $ we have $ C {vert v vert}1 leq {vert v vert}2 leq C' {vert v vert}1 , $ .
Equivalent seminorms determine the same topology.
The collection of (bounded) multiplicative seminorms on a (Banach) ring is called its analytic spectrum (see there for details) $ . vert vec xvert ;coloneqq; sqrt{ underoverset{i = 1}{n}{sum} (xi)^2 } , $ .
(i) more generally, for $ n in mathbb{N} $ , and $ p in mathbb{N} $ , $ p geq 1 $ , then the Cartesian space $ mathbb{R}^n $ carries the p - norm $ {vert vec x vert}p coloneqq root p {sumi {|xi|^p}} $ (i) The p - norm generalizes to sequence spaces and Lebesgue spaces.
Let $ V $ be a vector space and $ B subseteq V $ an absorbing absolutely convex subset.
The Minkowski functional of $ B $ is the function $ muB colon V to mathbb{R} $ defined by: $ muB(v) = inf{t gt 0 : v in t B } $ This is a semi - norm on $ V $ .
The (open or closed) unit ball of a seminormed vector space is a convex set, a balanced set and an absorbing set.
The first two of these properties make the unit ball (or even any ball of positive radius) an absolutely convex set.
In dream mathematics, a given real vector space (with no topological structure) can have at most one complete norm, up to topological equivalence (homeomorphism of the identity function).
It can have multiple inequivalent complete seminorms and incomplete norms, but their Hausdorff quotients and completions must be different.
For example, the various Lebesgue norms on a Cartesian space $ mathbb{R}^n $ for finite $ n $ are complete and equivalent; on $ mathbb{R}^infty $ , they are inequivalent but incomplete.
As dream mathematics includes excluded middle and dependent choice, the existence of inequivalent complete norms on a given vector space cannot be proved without a stronger form of the axiom of choice, enough to disprove the Baire property (which is the only classically false axiom needed in the proof of uniqueness).
In HAF, it is argued that this explains why, in applied mathematics, there tends to be only one norm considered on any particular vector space (after Hausdorff completion).
This theorem applies more generally to F - norms but not to G - norms (even on a real vector space).
In constructive mathematics, the notion of "real numbers" bifurcates: the Dedekind real numbers are different from the modulated Cauchy real numbers, which are different from the HoTT book real numbers, which are different from the localic real numbers, and so on.
As a result, there are multiple sets of real numbers in which a metric could be valued in.
In predicative mathematics, the issue becomes even worse: there is no longer one set of Dedekind real numbers, but a whole hierarchy of Dedekind real numbers, one set for every universe in the foundations.
As a result, one cannot resort to merely using the Dedekind real numbers for defining the norm as in impredicative mathematics, one has to define norms and normed spaces more generally.
Thus, given an Archimedean integral domain $ R $ , for $ k $ a field equipped with a valuation, an $ R $ - norm on a $ k $ - vector space $ V $ is a function $ {vert - vert} colon V to R $ such that for all $ lambda in k $ , $ v, w in V $ we have (i) $ {vert lambda v vert} = {vert lambdavert} {vert v vert} $ (where $ vert lambda vert $ denotes the valuation) (i) $ {vert v + wvert } leq {vert v vert } + {vert w vert} $ ("triangle inequality") (i) if $ {vert vvert} = 0 $ then $ v = 0 $ .
One could define $ R $ - seminorms, non - archimedean $ R $ - norms, and $ R $ - normed vector spaces in the same way as above.
In general, the term 'cross product' is used for any operation denoted by the symbol ' $ times $ ', such as cartesian product, direct product, Tychonoff product, or (subsuming all of these) product in a category.
However, there is another completely different context, used in the elementary analysis of vector spaces, and that is what we discuss here.
Originally isolated from the multiplication operation in quaternions as a binary operation on $ mathbb{R}^3 simeq Im(mathbb{H}) $ , the cross product now has generalisations to other arities, other dimensions, and other ground fields.
The classical cross product on the Cartesian space $ mathbb{R}^3 $ is the bilinear function $ ( - ) times ( - )colon mathbb{R}^3 times mathbb{R}^3 to mathbb{R}^3 $ given by $ (a, b, c) times (d, e, f) = (b e - c f, c d - a f, a e - b d) $ .
This operation is invariant under orthogonal transformations and there is nothing special here about the real numbers, so given any $ 3 $ - dimensional oriented inner product space $ V $ over any field, we have a bilinear cross product $ ( - ) times ( - )colon V times V to V $ given, upon choosing any oriented orthonormal basis for $ V $ , by the formula above.
We can even do this over any free module of rank $ 3 $ over any commutative ring (or arguably a non - commutative ring, but not a rig) equipped (as may always be done) with an inner product that admits an orthonormal basis.
We have already, trivially, generalized the cross product to other ground fields.
One way to generalise it to other dimensions is to identify characteristic features as a bilinear operation and see what operations in other dimensions have these.
In this vein, a binary cross product on any inner product space $ V $ is a bilinear function $ ( - ) times ( - )colon V times V to V $ such that for all $ x, yin V $ we have (i) Alternation: $ x times x = 0 $ .
(ii) Orthgonality: $ x times y $ is orthogonal to both $ x $ and $ y $ ; that is, $ x cdot (x times y) = (x times y) cdot y = 0 $ .
(iii) Area: $ {|x times y|} = {|x|} {|y|} $ if $ x, y $ are orthogonal.
From these, we can prove a more general formula for $ {|x times y|} $ : $ {|x times y|}^2 = {|x|}^2 {|y|}^2 - (x cdot y)^2 , $ or equivalently $ {|x times y|} = {|x|} {|y|} {|sinangle(x, y)|} $ .
(Using the polarization identity to express $ x cdot y $ in terms of $ |x| $ , $ |y| $ , and either $ |x + y| $ or $ |x - y| $ , this is the double of Hero's Formula for the area of a triangle.)
Conversely, using this more general area formula, we can prove both the restricted area formula and alternation, so that only orthogonality is needed as a separate axiom.
We then have over the real numbers: These cross products exist over any base field, but as far as I know there may be additional cross products over some fields in dimensions greater than $ 1 $ .
(The claim that there are uncountably many cross products in $ 7 $ dimensions becomes the claim that the algebraic variety of these inner products has dimension greater than $ 0 $ ; even in the real case, it would be worthwhile to describe this variety in more detail.)
If we pick an orthonormal basis and demand compatibility with it, then the classification above is complete over any field (as the problem becomes essentially combinatorial), except that some of these cross products will be identified in characteristic $ 2 $ .
Binary cross products are closely related to normed division algebras (NDAs).
Given a normed division algebra $ A $ , the imaginary hyperplane $ Im(A) $ inherits an inner product from $ A $ and gains a cross product as $ x times y coloneqq Im(x y) = frac{1}{2}x, y = x y + x cdot y $ .
Conversely, given an inner product space $ V $ with a binary cross product, the orthogonal direct sum $ K oplus V $ becomes a NDA as $ (a, x) (b, y) = (a b - x cdot y, a y + b x + x times y) , $ where $ K $ is the ground field.
(Compare the relationship between complex $ $ - algebras and Jordan - - Lie algebras, where $ A $ is $ V oplus V $ instead of $ K oplus V $ , which we again think of as consisting of real and imaginary parts and where we again have two multiplication operations on $ V $ .)
By Hurwitz's theorem, the only finite - dimensional NDAs over $ mathbb{R} $ are $ mathbb{R} $ itself (the real numbers), $ mathbb{C} $ (the complex numbers), $ mathbb{H} $ (the quaternions), and $ mathbb{O} $ (the octonions).
Thus the limited possibilities for binary cross products are determined by the limited possibilities for NDA structures.
By one of the deeper strands of mathematics, this classification of something as innocent - looking as cross - products is closely related not just to the existence of normed division algebras over the real numbers, but also to all of the following: parallelizable n - spheres, the existence of real spin representations (see also at supersymmetry and division algebras), and the homotopy groups of spheres of Hopf invariant one; see there.
Given an oriented inner product space $ V $ of finite dimension $ n $ , we can define the signed volume of an $ n $ - tuple of vectors.
(See also volume form.)
This allows us to characterise an $ (n - 1) $ - ary or co - unary cross product of $ n - 1 $ vectors as a multilinear operation $ &10761;colon V^{n - 1} to V $ such that $ v0 cdot &10761;(v1, ldots, v{n - 1}) = vol(v0, v1, ldots, v{n - 1}) $ always.
There is exactly one such cross product on any such $ V $ (so two if we start with an unoriented inner product space).
In $ 3 $ dimensions, this also recovers the classical cross product.
In $ 2 $ dimensions, this produces a unary cross product given by $ {times}(a, b) = (b, - a) $ ; in a counterclockwise - oriented plane, it rotates a vector clockwise through a right angle.
In $ 1 $ dimension, this is a nullary operation (a constant) whose value is the positive normal vector $ 1 $ .
Generalizing all of the above, let a vector - valued cross product on any inner product space $ V $ be a multilinear function $ &10761;colon V^k to V $ for some natural number $ k $ (called the arity) such that: (i) Alternation: $ &10761;(v1, ldots, vk) = 0 $ if $ vi = vj $ for some $ i ne j $ .
(ii) Orthgonality: $ &10761;(v1, ldots, vk) $ is orthogonal to each $ v_i $ .
(iii) Area: $ {|&10761;(v1, ldots, vk)|} = prodi {|vi|} $ if the $ v_i $ are mutually orthogonal.
We can again extend (3) to get the magnitude of the cross product of any $ k $ vectors; its square is the determinant of the matrix whose $ (i, j) $ th entry is $ vi cdot vj $ (the Gram determinant), and then (1) again follows.
Then for an inner product space $ V $ over $ mathbb{R} $ of finite dimension $ n $ , we have: Or organized by dimension ( $ n $ ) rather than arity ( $ k $ ): Fixing a field $ K $ , let Vect be $ VectK $ , the symmetric monoidal category of vector spaces over $ K $ (with the usual tensor product), and let $ T $ be any symmetric monoidal functor from $ Vect $ to itself.
Note that any inner product $ gcolon V otimes V to K $ extends to a (possibly degenerate) inner product $ T(g)colon T(V) otimes T(V) to K $ ; similarly, any element $ x $ of $ V $ , thought of as a linear map $ xcolon K to V $ , gives rise to an element $ T(x) $ of $ T(V) $ .
The vector - valued cross products above use the identity functor for $ T $ , but other possible choices for $ T $ are $ V mapsto V otimes V $ , $ V mapsto Lambda^2 V $ , and the constant functor $ V mapsto K $ .
We could also take $ Vect $ to be a full subcategory of $ VectK $ closed under the tensor product, such as $ Fin Vect_K $ ; this may allow more possibilities for $ T $ in exchange for fewer possibilities for $ V $ .
Given an inner - product space $ V $ and a symmetric monoidal functor $ T $ , a $ T $ - valued cross product on $ V $ is a multilinear function $ &10761;colon V^k to T(V) $ for some natural arity $ k $ such that: (i) Alternation: $ &10761;(v1, ldots, vk) = 0 $ if $ vi = vj $ for some $ i ne j $ .
(ii) Orthogonality: $ &10761;(v1, ldots, vk) $ is orthogonal (in $ T(V) $ ) to each $ T(v_i) $ .
(iii) Area: $ {|&10761;(v1, ldots, vk)|} = prodi {|vi|} $ if the $ v_i $ are mutually orthogonal (in $ V $ ).
Again it follows that in any case $ {|&10761;(v1, ldots, vk)|} $ is a square root of the Gram determinant, and again this implies both (1) and (3).
I do not know a full list of these, but one important example is the scalar - valued binary cross product in $ 2 $ dimensions: $ (a, b) times (c, d) = a d - b c $ .
Actually, this scalar - valued cross product $ x times y $ is simply the dot product $ x cdot {times}y $ , where $ {times}y $ is the unary cross product in $ 2 $ dimensions.
More generally, in any number $ n geq 2 $ of dimensions, there is a multivector - valued binary cross product (actually one for each orientation) whose values are $ (n - 2) $ - vectors; this includes the scalar - valued cross product when $ n = 2 $ and the classical cross product when $ n = 3 $ , but gets more complicated for larger values of $ n $ .
In particular, for $ n = 4 $ , we have a bivector - valued cross product, which is the Hodge dual of the exterior product.
Or generalizing the scalar - valued binary cross product in a different way, the volume form on an $ n $ - dimensional inner - product space is a scalar - valued co - nullary cross product (so $ n $ - ary).
Notice that there are two of these, one for each orientation, and each of these is the dot product with one of the vector - valued $ (n - 1) $ - ary cross products.
There are no other scalar - valued cross products, except for the identically zero products of arity $ k gt n $ and the two nullary products given by the unit - norm scalars (so just $ 1 $ and $ - 1 $ over the real numbers) for arbitrary $ n $ .
The cross product is also called 'outer product', and both of these terms are sometimes also used for the exterior product.
In its most basic form, the exterior product of two vectors $ u, v $ is a bivector $ u wedge v $ .
But note that this is not a bivector - valued cross product by the definition above, since it lacks orthogonality (and indeed has nothing to do with the inner product).
In $ 3 $ dimensions, given an inner product and an orientation, we can use the Hodge dual to turn the exterior product into a vector, and this is the classical cross product once more.
In $ 2 $ dimensions, using the same structure, we can turn the bivector into a scalar; this recovers the scalar - valued binary cross product above.
In general, this produces the binary $ (n - 2) $ - vector - valued cross product.
Using only the inner product but not the orientation, we get (respectively) a pseudovector (sometimes called an axial vector) or more generally a pseudoscalar or other pseudotensor; this perspective is common in geometric algebra.
In general in dimension $ n $ , a bivector becomes an $ (n - 2) $ - pseudovector, but this is not usually a simplification.
In classical applications of the cross product, often not all of the structure is needed, and the exterior product is really the fundamental concept.
If $ M $ is a Riemannian manifold, then the tangent space at each point is an inner product space, so it may be possible to smoothly assign a $ k $ - ary cross product to these spaces.
If this is done, then we can take the curl of a $ (k - 1) $ - vector field as follows: This vector field is the curl of the original $ (k - 1) $ - vector field.
This justifies the notation $ Del times X $ for the curl.
(It's important that the cross product is alternating and multilinear, so that it makes sense to apply it to a $ k $ - vector rather than to $ k $ individual vectors.)
When $ k = 2 $ and $ n = 3 $ , there is one smooth choice of cross product for each orientation of $ M $ , and we recover the classical notion of curl.
When $ k = 1 $ and $ n = 2 $ , we may also consider the scalar - valued curl, using the scalar - valued binary cross product described above.
The scalar - valued curl of a vector field $ X $ is the same as the divergence of the rotated vector field $ {times}X $ (using the unary cross product in $ 2 $ dimensions); that is, $ Del times X = Del cdot {times}X $ .
In modern mathematics, of course, we usually think of the exterior differential of differential forms as the fundamental concept, and only turn these forms into vector fields and the like under certain circumstances.
An affine space or affine linear space is a vector space that has forgotten its origin.
An affine linear map (a morphism of affine spaces) is a linear map (a morphism of vector spaces) that need not preserve the origin.
Note that the 'linear functions' of elementary algebra - - - the total functions whose graphs are lines - - - are in fact (precisely) affine $ mathbb{R} $ - linear maps from $ mathbb{R} $ to itself.
(Similarly, the 'linear relations' - - - the relations whose graphs are lines - - - are precisely the projective $ mathbb{R} $ - linear maps.)
Alternatively, in algebraic geometry, the terminology " $ n $ - dimensional affine space" $ mathbb{A}^n k $ (affine line, affine plane, etc.) over a field $ k $ refers to, depending on context, the set $ k^n $ , or the set of maximal ideals of the polynomial algebra $ kx1, ldots, xn $ - - these definitions coinciding if $ k $ is an algebraically closed field - - and typically considered as equipped with relevant extra structure such as a Zariski topology or, going even further, the locally ringed space structure adhering to the affine variety or affine scheme corresponding to the polynomial algebra $ kx1, ldots, xn $ .
Whatever the precise sense chosen, the idea is that an affine space $ mathbb{A}^n k $ is a setting in which the study of loci of polynomial equations, i.e. definable sets in the theory of commutative algebras over $ k $ , is carried out.
Most of this article concerns affine spaces in the sense of vector spaces that have forgotten their origins or identities; the algebraic geometry sense is very briefly touched upon in the section Affine spaces as model spaces.
The definition of affine space can be made precise in various (equivalent) ways.
We give a name to some of the definitions for later reference.
Mike Shulman: I think there should also be a definition of the form "an affine space is a projective space" with a distinguished line called "infinity", which should also be equivalent to a "synthetic" description involving points and lines and incidence axioms.
This definition would not fix the field $ k $ at the outset, but rather recover it synthetically using cross - ratios.
Accordingly, it ought to define an equivalent groupoid to the groupoid of pairs $ (k, A) $ where $ k $ is a field and $ A $ is an affine space over $ A $ .
I don't know how one could recover the non - invertible affine transformations from it directly.
There should be another characterisation, which I don't quite see how to phrase, at least when $ k = mathbb{R} $ , which is that an affine space is a manifold (perhaps Riemannian) that is sufficiently flat and unbounded in some sense.
- - - Toby Mike Shulman:
It'd have to be at least Riemannian, otherwise you don't have enough structure.
I don't suppose it's enough to say that a (finitely generated) affine space is a Riemannian manifold isometric to some $ mathbb{R}^n $ ?
Toby: I intended 'that is ... in some sense' to include the possibility of structure that should be preserved by the morphisms.
Note that a Riemannian manifold is too much structure, although it allows a definition like the first one above.
(A Riemannian manifold isometric to some $ mathbb{R}^n $ is precisely a Euclidean space.)
But really, I'm hoping for some phrasing such that &8249;isomorphic to some $ mathbb{R}^n $ &8250; actually becomes a (not too obvious) theorem.
I'll keep thinking about it.
Mike Shulman: Shouldn't a Riemannian manifold isometric to some $ mathbb{R}^n $ be a "Euclidean affine space" (a torsor over a Euclidean space)?
Seems that a Euclidean space would be a Riemannian manifold equipped with an isometry to some $ mathbb{R}^n $ .
It does seem like there should be a natural way to say this, but I don't know what it is.
Toby:
I guess that this depends on what you think 'Euclidean space' means; I've known people to define it to be $ mathbb{R}^n $ , but that seems quite ahistorical to me; I like that Urs calls such a thing Cartesian space instead.
Euclid did not have coordinates; he did not even have an origin, so a Euclidean space should be a heap rather than a group.
For my comment above, I would define a Euclidean space to be an affine inner product space; FWIW Wikipedia agrees.
(However, Wikipedia doesn't go as far as I do when I claim that the inner product should be valued in an $ mathbb{R} $ - line rather than in $ mathbb{R} $ itself; then again, I ignored that subtlety myself in my previous comment.)
Clearly every vector space has an underlying affine space (and every linear map is affine linear), giving a forgetful functor $ U:Vect to Aff $ .
Conversely, any affine space gives rise to a canonical vector space, sometimes called its space of displacements.
This is obvious from the definitions that involve a vector space as part of the structure, but a vector space can also be reconstructed from the other definitions as well, analogously to how a group can be reconstructed from a heap.
This gives a functor $ D:Affto Vect $ in the other direction.
One can verify that $ D(U(V))cong V $ and $ U(D(A))cong A $ ; the first isomorphism is natural, but the second is not (otherwise $ Vect $ and $ Aff $ would be equivalent categories, which they are not).
The category of affine spaces is almost a variety of algebras, as can be seen from the last few definitions, except for the requirement that an affine space be inhabited.
To rectify this, sometimes one allows the empty set to be an affine space, although it does not have any particular vector space of displacements.
(See heapempty for discussion.)
Note that there are a few different ways to think about the operations involved in the final three definitions (those not explicitly involving a vector space).
The operation $ mucolon x, y, z mapsto x - y + z $ is the same as the Mal'cev operation (i.e. heap structure) of the additive group of a vector space.
It can be viewed as the point completing a parallelogram with given vertices $ x, y, z $ , or equivalently as the result of adding $ x $ and $ z $ , relative to a choice of $ y $ as the origin.
The operation $ Lambda_colon r, x, y mapsto x - r x + r y $ can be viewed as either a weighted average of $ x $ and $ y $ (i.e. as $ (1 - r)x + r y $ ) or as the result of multiplying the "displacement vector" $ y - x $ by $ r $ , relative to the origin $ x $ (i.e. as $ x + r(y - x) $ ).
The first few definitions, which explicitly involve a vector space, make no especial use of the fact that the vector space is a vector space rather than merely an abelian group.
Thus, they are valid (and equivalent) in the more general context of torsors and heaps.
They are also mostly complete as stated, except for the final one.
In this definition, an affine space over a vector space $ V $ is a set $ A $ together with a "subtraction" function $ Lambdacolon Atimes Ato V $ , written $ Lambdacolon x, y mapsto x - y $ , such that: If $ y - x = v $ , then we write $ y = x + v $ , which we can regard as an operation on $ x $ and $ v $ by the third axiom.
Hence we have $ (x + v) - x = v $ and (by uniqueness) $ x + (y - x) = y $ , and also $ x + 0 = x $ and $ (x + v) + w = x + (v + w) $ by the first two axioms.
Thus, these axioms suffice to make $ A $ into a torsor over the additive group of $ V $ with the action $ + $ , which is one of the previous definitions given.
Note again that this would makes sense if $ V $ is any group, not just the additive group of a vector space.
This definition is an affine version of the usual definition of a vector space in terms of addition and scalar multiplication.
However, in each case the affine operation needs to take an extra parameter.
In reading the following axioms it helps to think of $ mu(x, y, z) $ as "the sum of $ x $ and $ z $ relative to the basepoint $ y $ " and likewise $ Lambdar(x, y) $ as "the product $ rcdot y $ relative to the basepoint $ x $ ".
Joost: Could it be that there is an axiom missing here ?
One can go from Vector spaces to the 2 ternary operations definition and back, but I can't see that by starting with the two ternary operations definition, going to vectorspaces and back, you get the same $ Lambda $ .
I guess you need an extra axiom as $ mu(x, y, Lambdar(y, z))=Lambdar(x, mu(x, y, z)) $ .
Toby:
Conceptually, there is something missing, which I've inserted as the left zero property of scalar multiplication.
(The right zero property $ Lambdar(x, x) = x $ follows from this using associativity of scalar multiplication with $ s = 0 $ , same as with vector spaces.)
But I have to leave, and I haven't yet derived your axiom, even with this aid.
This definition is an affine version of the less standard definition of a vector space in terms of a single operation $ r, x, ymapsto rcdot x + y $ .
Here an affine space over $ k $ is a set $ A $ together with a single operation $ mucolon ktimes Atimes Atimes Ato A $ , written as $ (r, x, y, z)mapsto mur(x, y, z) $ and thought of as the sum " $ rcdot x + z $ relative to the basepoint $ y $ , " such that: In the affine case (in contrast to the vector space case), it turns out that if $ 2 $ is invertible the "addition" $ (x, y, z)mapsto x - y+z $ can be recovered from the "scalar multiplication" $ (r, x, y)mapsto r x + (1 - r)y $ by $ mu(x, y, z) = Lambda2(y, Lambda{1/2}(x, z)) $ .
Thus, in this case we can define an affine space over $ k $ to be a set $ A $ together with a single operation $ Lambdacolon ktimes Atimes Ato A $ such that the axioms for the two - ternary - operations definition are satisfied with this definition of $ mu $ .
However, we can also simplify the requisite axioms in this presentation.
The following axioms are easier to state if we write $ Lambdar(x, y) $ as $ (1 - r) x + r y $ , or equivalently as $ r x + s y $ , where we require $ r+s=1 $ for the expression to be defined $ . array{ r x + (1 - r)left(frac{s}{1 - r} y + frac{t}{1 - r} zright) (1 - s)left(frac{r}{1 - s} x + frac{t}{1 - s} zright) + s y (1 - t)left(frac{r}{1 - t} x + frac{s}{1 - t} yright) + t z } $ The first is defined whenever $ rneq 1 $ , the second whenever $ sneq 1 $ , and the third whenever $ tneq 1 $ .
Since $ k $ has characteristic $ neq 2 $ , we cannot have $ r=s=t=1 $ and $ r+s+t=1 $ at the same time, so at least one of these expressions is always defined.
We write $ r x + s y + t z $ for the common value of whichever of them are defined.
Let $ Th{vect} $ denote the Lawvere theory of $ k $ - vector spaces.
For any $ n $ , its $ n $ - ary operations are $ n $ - tuples $ (r1, dots, rn)in k^n $ representing the linear combination operation $ (x1, dots, xn)mapsto r1 x1 +dots+ rn xn $ .
Composition of operations is by substitution in the obvious way, and the identity operation is $ (1) $ .
A model of this theory is simply a vector space.
With this 'unbiased' definition, a vector space comes equipped with, for every integer $ nge 0 $ and $ n $ - tuple $ (r1, dots, rn) $ of elements of $ k $ , a function $ V^nto V $ (thought of as $ (v1, dots, vn)mapsto r1 v1+dots rn vn $ ), satisfying some axioms.
Let $ Th{aff} $ denote the subtheory of $ Th{vect} $ containing only those operations $ (r1, dots, rn) $ such that $ r1+dots+rn=1 $ ; an affine space is a nonempty model of $ Th{aff} $ .
(We have to observe that these are closed under the theory operations and thus define a subtheory.
Note that this excludes all zero - ary operations, so an affine space has no distinguished constants, and it also excludes all nonidentity unary operations.)
The basic operations $ r0x0+dots+rn xn $ , when $ r0+dots+rn=1 $ , are called affine (linear) combinations of elements of $ A $ .
The axioms for the unbiased definition are most straightforward to see by writing out the operations of $ Th{aff} $ .
In particular, this includes "substitution" axioms of the form $ r0(s{00} x{00} + dots + s{0m0} x{0m0}) + dots + rn (s{n0} x{n0} + dots + s{n mn} x{n mn}) = r0 s{00} x{00} + dots + rn s{n mn} x{n mn} $ .
However, it also includes "permutation" axioms of the form $ r0 x0 + dots + rn xn = r{sigma 0} x{sigma 0} + dots + r{sigma n} x{sigma n} $ and also "duplication" and "omission" axioms.
This Lawvere theory can be defined concisely as follows.
The Lawvere theory of vector spaces is the opposite of the category of finite - dimensional vector spaces; its operations are all linear combinations.
The Lawvere theory for affine spaces is the sub - theory of this consisting of only the affine combinations.
(The Lawvere theory of vector spaces also has other interesting sub - theories, such as that consisting of convex combinations whose algebras are abstract convex spaces in one sense of the term.)
Note that the empty set is a model (algebra) of this Lawvere theory; an affine space is an inhabited model.
Given the unbiased definition in terms of a Lawvere theory, the previous three "biased" vector - space - free definitions can then be recovered by finding particular generating operations for the theory.
In particular, this Lawvere theory is generated by $ 2 $ - ary operations if $ char(k)neq 2 $ , and by $ 3 $ - ary ones if $ char(k)=2 $ .
To wit, suppose given $ (r0, dots, rn)in k^{n+1} $ with $ nge 3 $ such that $ r0+dots+rn=1 $ .
Suppose for the moment that the $ ri $ are not all $ 1 $ , and WLOG suppose that $ r0neq 1 $ .
(Note that here we use the invariance under permutations.)
Then we have $ r0 x0 + dots + rn xn = r0 x0 + (1 - r0)left(frac{1}{1 - r0} r1 x1 + dots + frac{1}{1 - r0}rn xnright) $ so we have expressed the given $ (n+1) $ - ary operation in terms of a $ 2 $ - ary one and an $ n $ - ary one.
By induction, in this way we can express any $ (n+1) $ - ary operation in terms of $ 2 $ - ary ones (note that there is only one $ 1 $ - ary operation, namely the identity, and no $ 0 $ - ary ones) - - - as long as we never hit a tuple where every $ ri=1 $ .
But since we always have the requirement $ r0+dots+rn=1 $ , this badness can only happen if the characteristic of $ k $ is $ n $ .
Moreover, we still have $ x0 + dots + xn = x0 - x1 + (2x1 + x2 + dots + xn) $ so we can still write this $ (n+1) $ - ary operation in terms of a $ 3 $ - ary one and an $ n $ - ary one.
So only if $ n+1=3 $ (i.e $ . n=char(k)=2 $ ) are we prevented from getting down to $ 2 $ - ary operations only, and in this case we can still get down to $ 3 $ - ary ones.
Finally, we observe that any $ 3 $ - ary operation can be written in terms of $ 2 $ - ary ones and the particular $ 3 $ - ary operation $ x0 - x1 + x2 $ : $ r0 x0 + r1 x1 + r2 x2 = big(r0 x0 + (1 - r0) x2big) - x2 + big(r1 x1 + (1 - r1) x2big) $ .
Given an affine space $ A $ (with any other definition), the corresponding $ pi:A'to k $ is constructed as follows.
Let $ A' = 1 sqcup A $ , where $ sqcup $ is the coproduct in affine spaces (akin to a simplicial join), $ 1 $ is the terminal affine space, and $ pi $ is the composite of $ 1 sqcup !: 1 sqcup A to 1 sqcup 1 $ with a natural identification $ mu: 1 sqcup 1 cong k $ .
Both $ 1 sqcup ! $ and $ mu $ which are morphisms of $ Aff $ may be regarded as morphisms of $ 1 downarrow Aff simeq Vect $ (pointed affine spaces are vector spaces) if we let the first inclusion $ i0: 1 to 1 sqcup 1 $ be the pointing of $ 1 sqcup 1 $ and $ 0: 1 to k $ the pointing of $ k $ and define $ mu $ by $ mu circ i0 = 0 $ , $ mu circ i1 = 1 $ (the element $ 1 in k $ ).
(So $ mu $ is like two ends of a meter stick used to set up coordinates on the line $ k $ .)
Conversely, given $ pi:A'to k $ , the fiber $ pi^{ - 1}(1) $ naturally acquires a "vector - valued difference" affine space structure by simple subtraction in the vector space $ A' $ , where the vector space of displacements is $ V = pi^{ - 1}(0) $ .
Note that this definition embeds the category $ Aff $ of (inhabited) affine spaces fully - faithfully in the slice category $ Vect/k $ .
The objects of $ Vect/k $ not in $ Aff $ are those of the form $ 0:Vto k $ , which form a category equivalent to $ Vect $ itself.
Moreover, there are no morphisms from objects of $ Aff $ to objects not in $ Aff $ ; while by the above construction, a morphism from $ 0:Vto k $ to an affine space $ pi:A'to k $ is just a map from $ V $ to the vector space of displacements of $ A $ .
Hence, $ Vect/k $ is equivalent to the (dual) cograph of $ D:Affto Vect $ .
If we allow affine spaces to be empty, then they are the models of an algebraic theory $ Th{Aff} $ .
Moreover, like $ Th{Vect} $ , the theory $ Th{Aff} $ is a commutative theory.
It follows that if $ A, B $ are affine spaces, then the set $ hom(A, B) $ is closed under all affine space operations pointwise defined on the set of all functions from $ A $ to $ B $ .
This gives $ Aff $ a closed category structure; on general grounds, it is in fact a symmetric monoidal closed category.
The unit of this structure is the terminal or one - pointed affine space $ 1 $ , via the natural isomorphism $ hom(1, B) cong B $ .
Thus $ Aff $ is a closed semicartesian monoidal category.
Analogous to the case of $ Vect $ , every affine space is a coproduct of copies of the monoidal unit: an affine space $ A $ of dimension $ n $ admits an affine basis, which amounts to an isomorphism $ 1 sqcup 1 sqcup ldots sqcup 1 cong A $ , represented by $ n+1 $ sic points of $ A $ .
Such basis representations allow one to coordinatize spaces of maps $ hom(A, B) cong B^{n+1} $ , with dimension $ (n+1)dim(B) $ .
If one uses the first of the affine basis elements to give a pointing of the affine space (equivalent to a vector space structure), then the remaining affine basis elements provide a vector space basis, and in those coordinates every element $ f in hom(A, B) $ may be written in matrix - vector form $ f(x) = M x + b $ , where again the space of such $ (M, b) $ has dimension $ m n + m $ if $ m $ is the dimension of $ B $ .
(There are also more 'unbiased' coordinate descriptions, not biased in favor of the first basis element playing the role of the origin.)
Similarly, we can coordinatize affine tensor products $ A otimes B $ : the tensor distributes over coproducts (as it does in any symmetric monoidal closed category) and so $ (bigsqcup{n+1} 1) otimes (bigsqcup{m+1} 1) cong bigsqcup{(m+1)(n+1)} 1 otimes 1 cong bigsqcup{(m+1)(n+1)} 1 $ with dimension $ m n + m + n $ .
In other words, if $ a1, ldots, a{n+1} $ is an affine basis of $ n $ - dimensional $ A $ and $ b1, ldots, b{m+1} $ a basis of $ m $ - dimensional $ B $ , then $ A otimes B $ has an affine basis consisting of the $ m n + m + n + 1 $ many elements $ ai otimes bj $ .
The embedding $ Aff to Vect/k $ described in the previous subsection, sending $ A $ to $ 1 sqcup !: 1 sqcup A to 1 sqcup 1 $ , is a strong monoidal functor (preserves the tensor product up to coherent isomorphism) if $ Vect/k $ is endowed with the obvious tensor product acquired from $ Vect $ .
Note that $ Vect/k $ is the coreflection of $ Vect $ from monoidal categories to semicartesian monoidal categories; the embedding $ Aff to Vect/k $ was in fact discovered by one of us in conjunction with this fact, and is the same as the functor induced by universality from the strong monoidal functor $ Aff to Vect $ given by $ A mapsto 1 sqcup A $ .
Every finitely - generated affine space is isomorphic to the $ n $ - fold direct sum $ k^n $ , where $ k $ is the base field and $ n $ is a natural number (possibly $ 0 $ ).
In algebraic geometry, an $ n $ - dimensional affine space is often denoted $ mathbb{A}^n $ and identified with $ k^n $ .
If one accepts the empty set as an affine space, then this is considered to have dimension $ - 1 $ by convention (so $ k^{ - 1} = empty $ ).
The notion of affine space may be generalised to affine module by replacing the vector space above by a module and the base field $ k $ by a commutative ring.
Then an affine module over the ring $ mathbb{Z} $ of integers is precisely a commutative heap, just like a module over $ mathbb{Z} $ is an abelian group.
Note that the definition involving only one "scalar multiplication" operation works if and only if $ 2 $ is invertible in $ k $ ; it's not enough that $ 2 ne 0 $ in $ k $ .
Mike Shulman: I haven't thought much about affine modules, but it seems likely to me that the "biased" module - free definitions won't be right any more, since the Lawvere theory needn't be generated by 2 - ary or 3 - ary operations (as far as I can see).
More explicitly, I don't immediately see how to write an operation like $ (x0, x1, x2, x3) mapsto 4x0 - 6x1 - 2x2 + 5x3 $ in terms of $ A^3to A $ and $ mathbb{Z}times A^2to A $ , but it seems to me that this operation should still exist in an affine $ mathbb{Z} $ - module.
Mike Shulman:
Well that's rubbish isn't it.
The operation $ A^3to A $ is enough to give you a heap, hence an additive group, and then $ mathbb{Z}times A^2to A $ gives you the scalar multiplication.
And so $ 4x0 - 6x1 - 2x2 + 5x3 = big((4x0 - 3y) - y + ( - 6x1+7y)big) - y + big(( - 2x2+3y) - y + (5x3 - 4y)big) $ for any $ y $ at all.
Toby:
Right.
But I find an affine module of a rig to be a trickier concept.
Mike Shulman: Quite so.
Perhaps first one should look for a version of a heap corresponding to a monoid?
Toby:
Yes, that would be an affine $ mathbb{N} $ - module.
Affine spaces typically serve as local models for more general kinds of spaces.
For instance a manifold is a topological space that is locally isomorphic to an affine space over the real numbers.
Similarly, in algebraic geometry a scheme is locally isomorphic to an affine scheme.
Therefore there are attempts to axiomatize properties of categories of affine spaces for the purpose of using these as model spaces for more complicated geometries.
One such axiomatization is the notion of geometry (for structured (∞, 1) - toposes).
and in particular that of pregeometry.
If $ sigma = { v0, ldots, vq } in Kq $ , the set of $ q $ - simplices of a simplicial complex, $ K $ , then its barycentre, $ b(sigma) $ , is the point $ b(sigma) = sum{0leq i leq q}frac{1}{q + 1} vi in |K| $ .
For the use of barycenters in the barycentric subdivision, see classical triangulation or A real number is a number that may be approximated by rational numbers.
Equipped with the operations of addition and multiplication induced from the rational numbers, real numbers form a field, commonly denoted $ mathbb{R} $ .
The underlying set is the completion of the ordered field $ mathbb{Q} $ of rational numbers: the result of adjoining to $ mathbb{Q} $ suprema for every inhabited bounded subset with respect to the natural ordering of rational numbers.
The set of real numbers also carries naturally the structure of a topological space and as such $ mathbb{R} $ is called the real line also known as the continuum.
Equipped with both the topology and the field structure, $ mathbb{R} $ is a topological field and as such is the uniform completion of $ mathbb{Q} $ equipped with the absolute value metric.
Together with its cartesian products - - the Cartesian spaces $ mathbb{R}^n $ for natural numbers $ n in mathbb{N} $ - - the real line $ mathbb{R} $ is a standard formalization of the idea of continuous space.
The more general concept of (smooth) manifold is modeled on these Cartesian spaces.
These, in turn are standard models for the notion of space in particular in physics (see spacetime), or at least in classical physics.
See at geometry of physics for more on this.
The original idea of a real number came from geometry; one thinks of a real number as specifying a point on a line, with line understood as the abstract idea of the object that a pencil and a ruler draw on a piece of paper.
(More precisely, given two distinct points on the line, called $ 0 $ and $ 1 $ , you get a bijection between the points and the real numbers.)
Euclid (citing Eudoxus) dealt with ratios of geometric magnitudes, which give positive real numbers; an arbitrary real number is then a difference of ratios of magnitudes.
However, the Greeks did not think of such ratios as numbers; that appears to have been an insight of the Arabs.
See more at Eudoxus real number.
A big project of the 19th century (at least in hindsight) was the 'arithmetisation of analysis': showing how real numbers could be defined completely in terms of rational numbers (and the desired classes of functions on them could be defined in terms of the general point - set notion of function).
Two successful approaches were developed in 1872, Richard Dedekind's definition of real numbers as certain sets of rational numbers (called Dedekind cuts) and Georg Cantor's definition as certain sequences of rational numbers (called Cauchy sequences).
A more modern approach is instead to characterise the properties that the set of real numbers must have and to prove that this is categorical (unique up to a unique bijection preserving those properties).
Then the important result of the 19th - century programme is simply that this is consistent (that there exists at least one such set).
One can even use Hilbert's or Tarski's axioms for geometry to do this characterisation, coming full circle back to geometry.
Exactly how to define or characterise real numbers is still important in constructive mathematics and topos theory with its internal logic.
For more on this, see real numbers object and the examples below.
There are two basic approaches possible: to define what a real number is as a mathematical object, or to define the real line as a specific object in some previously known category.
Consider two inhabited subsets, $ L $ and $ U $ , of a countable unbounded dense linear order, such as $ mathbb{Q} $ (the set of rational numbers) or $ mathbb{Z}1/10 $ (the set of decimal fractions), such that: We may define a Dedekind real number to be such a pair, which is also called a Dedekind cut.
If $ x coloneqq (L, U) $ is a Dedekind cut, then we write $ a lt x $ to mean that $ a in L $ and $ x lt b $ to mean that $ b in U $ .
We may approximate a Dedekind cut $ x $ as closely as we like by applying (*) as often as necessary.
This will be only finitely often, for any fixed positive level of approximation, given initial upper and lower bounds (which exist since $ L $ and $ U $ are inhabited).
See Dedekind completion for more.
Classically, a real number can be given by an infinite Cauchy sequence of decimal fractions $ mathbb{Z}1/10 $ , each of which is a decimal fraction that approximates the real number to a given number of decimal places.
However, many real numbers have several representations, i.e $ . 1/10 = 0.09999(ix).. = 0.10000 $ . . .
so we need to specify an equivalence relation on the Cauchy sequences.
Thus, $ mathbb{R} $ is constructed as a subquotient of the function set $ mathbb{Z}1/10^{mathbb{N}} $ .
We can generalise this to any Cauchy sequence of rational numbers, and $ mathbb{R} $ is constructed as a subquotient of the function set $ mathbb{Q}^{mathbb{N}} $ .
This construction is equivalent to the construction by Dedekind cuts, at least assuming weak countable choice (which also follows from excluded middle).
Thus it is popular in both classical mathematics and traditional constructive mathematics (which accepts countable choice).
However, in stricter forms of constructive mathematics, including those used as internal languages in topos theory, the Cauchy reals and Dedekind reals are not equivalent.
(On the other hand, by generalising to Cauchy nets, we recover the Dedekind reals again.)
See Cauchy real number and generalized Cauchy real number for more.
There is an algebraic (more or less) characterisation of the real line as the 'initial sequentially modulated Cauchy complete archimedean field'.
This can be interpreted as follows: The initial sequentially modulated Cauchy complete ordered field results in the HoTT book real numbers.
There is a well - known algebraic (more or less) characterisation of the real line as the 'Dedekind complete ordered field', or sometimes the 'Dedekind complete archimedean field'.
This can be interpreted as follows: (i) For all elements $ a in F $ , the upwards unbounded open interval $ (a, infty) $ is inhabited.
(ii) For all elements $ a in F $ , the downwards unbounded open interval $ ( - infty, a) $ is inhabited.
(iii) For all elements $ a in F $ and $ b in F $ , $ a lt b $ if and only if $ (b, infty) $ is a subinterval of $ (a, infty) $ (iv) For all elements $ a in F $ and $ b in F $ , $ b lt a $ if and only if $ ( - infty, b) $ is a subinterval of $ ( - infty, a) $ (v)
For all elements $ a in F $ and $ b in F $ , if $ a lt b $ , then $ F $ is a subinterval of the union of $ (a, infty) $ and $ ( - infty, b) $ (vi) For all elements $ a in F $ and $ b in F $ , the intersection of $ (a, infty) $ and $ ( - infty, b) $ is a subinterval of $ (a, b) $ In impredicative mathematics, we speak of the such field because it is unique up to unique isomorphism.
Assuming impredicative foundations, there is an archimedean field $ mathbb{R} $ which is Dedekind - complete, and into which every archimedean field embeds.
Furthermore, every Dedekind - complete ordered field is isomorphic to $ mathbb{R} $ , and uniquely so.
Construct $ mathbb{R} $ using, say, Dedekind cuts of rational numbers.
Then it is well known how to prove these facts about $ mathbb{R} $ , so we omit the proof for now.
However, we note that the proof is valid in weak foundations, in particular internal to any topos with a natural numbers object.
One can actually work in even weaker foundations than that; see the constructions at real numbers object.
Even weaker foundations are possible if one allows the underlying set of $ mathbb{R} $ to be large.
However, if we are working in predicative mathematics with multiple universes in the foundation, the Dedekind real numbers would no longer be unique up to unique isomorphism, but rather there would be a set of Dedekind real numbers for each universe.
There is a well - known algebraic (more or less) characterisation of the real line as the 'Cauchy complete ordered field', or sometimes the 'Cauchy complete archimedean field'.
This can be interpreted as follows: In impredicative mathematics, we speak of the such field because it is unique up to unique isomorphism.
Assuming impredicative foundations, there is an archimedean field $ mathbb{R} $ which is Cauchy - complete, and into which every archimedean field embeds.
Furthermore, every Cauchy - complete ordered field is isomorphic to $ mathbb{R} $ , and uniquely so.
Construct $ mathbb{R} $ using, say, Cauchy nets of rational numbers.
Then it is well known how to prove these facts about $ mathbb{R} $ , so we omit the proof for now.
However, we note that the proof is valid in weak foundations, in particular internal to any topos with a natural numbers object.
One can actually work in even weaker foundations than that; see the constructions at real numbers object.
Even weaker foundations are possible if one allows the underlying set of $ mathbb{R} $ to be large.
However, if we are working in predicative mathematics with multiple universes in the foundation, the Cauchy real numbers would no longer be unique up to unique isomorphism, but rather there would be a set of Cauchy real numbers for each universe.
There is a well - known algebraic (more or less) characterisation of the real line as the 'terminal archimedean field' in a universe.
This can be interpreted as follows: In impredicative mathematics, we speak of the such field because it is unique up to unique isomorphism in a universe.
However, if we are working in predicative mathematics with multiple universes in the foundation, there is only a terminal archimedean field in a universe if there is a maximal universe term inside the universe into which all the other universe terms in that universe embed into.
There is a characterisation of the real line as the 'complete archimedean Tarski group' due to Alfred Tarski.
This can be interpreted as follows: See Tarski's axiomatization of the real numbers for more information.
Consider binary relations $ sim $ on a countable inhabited dense linear order without endpoints, such as the rational numbers, satisfying these four properties: The collection of all such relations form a frame, which we may interpret (by definition) as the locale of real numbers.
It can also be defined as the localic completion of the rational numbers.
We may then define a localic real number to be a point of this locale.
This agrees with the notion of Dedekind real number, even in very weak (predicative and constructive) foundations.
See locale of real numbers for more.
The unit interval of the real numbers $ 0, 1 $ could be constructed as a terminal coalgebra of an endofunctor in the category of intervals.
Let $ (mathbb{R}, 0, +, - , 1, cdot, lt) $ be an ordered field where $ 0 lt 1 $ , with a monotone $ f:0, 1to mathbb{R} $ such that $ f(0) = 0 $ and $ f(1) = 1 $ .
The set $ mathbb{R} $ of real numbers is the initial such ordered field.
See also: dyadic interval coalgebra, decimal interval coalgebra, rational interval coalgebra.
The positive real line $ mathbb{R}^+ $ may be characterized as the terminal coalgebra for an endofunctor Let Pos be the category of posets with a forgetful functor $ Ucolon Pos to Set $ Consider the endofunctor $ F1colon Pos to Pos $ defined as the ordinal product $ F1colon X mapsto omega cdot X, $ for $ omega in Pos $ , where $ omega cdot X $ is the cartesian product $ U(omega) times U(X) $ with the lexicographic order.
The terminal coalgebra of $ F1 $ is order isomorphic to the non - negative real line $ mathbb{R}^+ $ , with its standard order.
This is theorem (v)1 in (Pavlovic–Pratt 1999).
There are many ways of setting up this description of $ mathbb{R}^+ $ , depending on the coalgebra structure $ mathbb{R}^+ to omega cdot mathbb{R}^+ $ chosen.
Here is one: there are evident poset isomorphisms $ mathbb{R}^+ cong 1, infty) $ and $ omega cong mathbb{N}{geq 2} = {n in mathbb{N}: n geq 2 } $ .
Define a map $ (alpha, beta): 1, infty) to mathbb{N}{geq 2} cdot 1, infty) $ where $ alpha(x) $ is the smallest integer strictly greater than $ x $ , and $ beta(x) = 1/(alpha(x) - x) $ .
The stream of integers $ an = alpha(beta^n(x)) $ gives a continued fraction representation of $ x $ in the form $ x = a0 - frac1{a1 - frac1{a2 - ldots}}, $ and the resulting bijection $ 1, infty) to mathbb{N}{geq 2} times mathbb{N}{geq 2} times ldots $ , sending $ x $ to $ (a0, a1, ldots) $ , is in fact a poset isomorphism if we endow the right - hand side with the lexicographic order.
Another way, which circumvents the use of isomorphisms $ mathbb{R}^+ cong 1, infty) $ and $ omega cong mathbb{N}{geq 2} $ , is to define $ (alpha, beta): mathbb{R}^+ to omega cdot mathbb{R}^+ $ where $ alpha(x) $ is the floor of $ x $ , and $ beta(x) = 1/(1 - x + alpha(x)) - 1 $ .
Then $ an = alpha(beta^n(x)) $ gives a continued fraction representation of $ x $ in the form $ x = a0 + frac1{1 + frac1{a1 + frac1{1 + frac1{a2 + ldots}}}}, $ and the resulting bijection $ mathbb{R}+ to omega times omega times ldots $ , sending $ x $ to $ (a0, a1, ldots) $ , is again a poset isomorphism if we endow the right - hand side with the lexicographic order.
There are more and similar characterizations along these lines.
The smooth real numbers (say in a smooth topos) are only an ordered local ring rather than an ordered field, because there might be non - zero non - invertible nilpotent infinitesimals in the smooth real numbers.
Nevertheless, the quotient of the smooth real numbers by the ideal of non - invertible elements is one of the ordered field of real numbers as defined above.
{Topologies} There are alternative topologies on $ mathbb{R} $ sometimes considered: Another variant of $ mathbb{R} $ as a topological space is the The term 'real number' was originally introduced to indicate that one is not considering the generalistion to complex numbers or other kinds of hypercomplex numbers.
Accordingly, that term 'real' may sometimes be used for another generalisation of real numbers to indicate again that one is not considering a complexification.
The extended real numbers include $ pminfty $ as well as the real numbers; one may speak of finite numbers or bounded numbers to indicate that one is not considering this extension.
Lower reals, upper reals, and MacNeille reals are related generalisations studied in constructive mathematics, although with excluded middle they are (at least if bounded) the same as ordinary real numbers; one may speak of located numbers to indicate that one is not considering such extensions.
Surreal numbers and the hyperreal numbers of nonstandard analysis are two ways to include infinite and infinitesimal versions of real numbers (besides the trivial case of $ pminfty $ ); one may speak of standard numbers to indicate that one is not considering such extensions (although the precise meaning of 'standard' depends on the universe that one is working in).
In descriptive set theory, one often says 'real number' for an element of Baire space $ mathbb{N}^{mathbb{N}} $ .
This is not really a generalisation; by the Schroeder - Bernstein theorem, the underlying sets of $ mathbb{R} $ and $ mathbb{N}^{mathbb{N}} $ are isomorphic.
Constructively, $ mathbb{N}^{mathbb{N}} $ can still be thought of as the set of irrational numbers, so this use of the term may actually be a restriction.
Floating - point numbers are often used in computer programming to represent real numbers, but they do not behave very well; one may speak of infinite - precision numbers to indicate that one's programming environment models 'real real numbers'.
As mentioned above, the $ p $ - adic numbers for various prime numbers $ p $ are variations on the theme of real numbers; real numbers may be thought of as $ 0 $ - adic numbers.
Similarly, the real numbers are characteristic - $ 0 $ numbers since they are based on the prime field $ mathbb{Q} $ ; one could also start the construction with a different characteristic (although it makes more sense to get analogues of complex numbers than of real numbers).
Finally, one can consider points on a noncommutative line instead of the usual commutative numbers.
So in summary, this page is about the real, finite, located, standard, analytic, infinite - precision, $ 0 $ - adic, characteristic - $ 0 $ , commutative numbers.
For more see the references at analysis.
Review and history:
As the coalgebra of the real interval: The definition of the real numbers in constructive analysis as Cauchy real numbers, namely as regular Cauchy sequences of rational numbers is due to: Direct formalization of the definition of Cauchy real numbers from Bishop (1967) in Agda: review: and closely related constructions in Coq have been implemented in following a monadic re - formulation (via the completion monad) due to Overview of implementation of real numbers in proof assistants (cf. constructive analysis):
Assistants and Libraries, Mathematical Structures in Computer Science 26 7 (2016) 1196 - 1233 &lbrack;hal:00806920, doi:(x)1017/S0960129514000437&rbrack; A novel construction principle of the type of real numbers, as a higher inductive - inductive type in univalent homotopy type theory, not reliant on representatives by sequences of rational numbers, and with provable Cauchy completeness even without extra axiom of countable choice is laid out (cf.
HoTT book real numbers) in Something like this has been implemented in Coq: >
This entry is about the concept in order theory.
See at group order for the concept of the same name in group theory.
An order on a set $ S $ is (usually) a binary relation that is, at the very least, transitive.
Actually, there are several different notions of order that are each useful in their own ways: The closely related notion of a cyclic order is not actually a binary relation but a ternary relation.
The study of orders is order theory.
A mostly unrelated notion from group theory is order of a group, meaning the cardinality $ |G| $ of the underlying set of a group $ G $ , especially when this is finite.
By extension, one speaks of the order of an element $ x in G $ , as the order of the cyclic subgroup $ langle xrangle $ generated by the element.
For example, the order of a permutation $ pi in S_n $ is the least integer $ 1 le kle n $ such that $ pi^k = id $ .
Sometimes one thinks of an infinite group as having order zero.
The orders then have the natural order relation of divisibility.
The term 'order' can also be used fairly generically as a synonym of 'degree' or 'rank', as in first - order logic, the order of a differential equation, etc.
Of course, these various orders form a well - order, so this is not entirely unrelated either.
>
This entry is about the concept in order theory.
See at group order for the concept of the same name in group theory.
An order on a set $ S $ is (usually) a binary relation that is, at the very least, transitive.
Actually, there are several different notions of order that are each useful in their own ways: The closely related notion of a cyclic order is not actually a binary relation but a ternary relation.
The study of orders is order theory.
A mostly unrelated notion from group theory is order of a group, meaning the cardinality $ |G| $ of the underlying set of a group $ G $ , especially when this is finite.
By extension, one speaks of the order of an element $ x in G $ , as the order of the cyclic subgroup $ langle xrangle $ generated by the element.
For example, the order of a permutation $ pi in S_n $ is the least integer $ 1 le kle n $ such that $ pi^k = id $ .
Sometimes one thinks of an infinite group as having order zero.
The orders then have the natural order relation of divisibility.
The term 'order' can also be used fairly generically as a synonym of 'degree' or 'rank', as in first - order logic, the order of a differential equation, etc.
Of course, these various orders form a well - order, so this is not entirely unrelated either.
>
This entry is about the concept in group theory.
See at order for the concept in order theory.
{OrderOfAGroup} For $ G $ a discrete group, its order is the cardinality of the underlying set.
Hence for $ G $ a finite group, its order $ vert Gvert in mathbb{N} $ is a natural number, the number of its group elements.
{OrderOfAnElementOfAGroup} For $ G $ a group and $ g in G $ an element, the order of $ g $ is the smallest natural number $ n $ such that the $ n $ - fold group product of $ g $ with itself is the neutral element: $ order(g) coloneqq min { n in mathbb{N} | g^n = e } , $ .
The exponent of a group is the least common multiple of the order of all elements of the group.
Sometimes the term ''order'' refers to the height of a (group) scheme $ X $ over a field (of characteristic $ p $ ) which is defined to be the dimension of the associated ring of functions $ O(X) $ as a $ k $ - vector space.
Another term for this notion is ''rank''.
If this group scheme is moreover p - divisible - which means that is is in fact a codirected diagram of group schemes of order $ p^{v h} $ ; in this case $ h $ is called the order or height of $ X $ .
For $ G $ a finite group and $ g in G $ an element, there is a close relation between (i) the order $ vert Gvert $ of $ G $ in the sense above; (i) the order $ order(g) $ of $ g $ the sense above The element $ g $ generates a cyclic subgroup $ Cg subset G $ .
Evidently, the order of the element $ g $ equals the order $ vert Cg vert $ of this cyclic subgroup that it generates: order(g)
=vert C_gvert , .
By Lagrange's theorem, if $ G $ a finite group and $ H subset G $ a subgroup, then the order $ vert Gvert $ of $ G $ is divisible by the order $ vert Hvert $ of $ H $ .
The multiple is called the subgroup index $ G : H in mathbb{N} $ : $ {vert Gvert} ;=; G : H , {vert Hvert} , $ .
Hence with (eq:OrderOfElementIsOrderOfGeneratedCyclicGroup) it follows that with $ g in G $ any element, the order of $ g $ divides the order of $ G $ : $ {vert Gvert}/ order(g) ;=; G : C_g , $ .
See also >
This entry is about the concept in order theory.
See at group order for the concept of the same name in group theory.
An order on a set $ S $ is (usually) a binary relation that is, at the very least, transitive.
Actually, there are several different notions of order that are each useful in their own ways: The closely related notion of a cyclic order is not actually a binary relation but a ternary relation.
The study of orders is order theory.
A mostly unrelated notion from group theory is order of a group, meaning the cardinality $ |G| $ of the underlying set of a group $ G $ , especially when this is finite.
By extension, one speaks of the order of an element $ x in G $ , as the order of the cyclic subgroup $ langle xrangle $ generated by the element.
For example, the order of a permutation $ pi in S_n $ is the least integer $ 1 le kle n $ such that $ pi^k = id $ .
Sometimes one thinks of an infinite group as having order zero.
The orders then have the natural order relation of divisibility.
The term 'order' can also be used fairly generically as a synonym of 'degree' or 'rank', as in first - order logic, the order of a differential equation, etc.
Of course, these various orders form a well - order, so this is not entirely unrelated either.
>
This entry is about the notion of limit in analysis and topology.
For the notion of the same name in category theory see at limit.
A limit of a sequence (or net) of points $ (x_i) $ in a topological space (or other convergence space) $ X $ is a point $ x $ such that the sequence eventually gets arbitrarily close to $ x $ .
We can also speak of a limit of a filter on $ X $ .
The notion is of particular and historical importance in analysis, where it serves to define for instance the notion of derivative.
The precise definition depends on what sort of space $ X $ is.
If $ X $ a topological space and $ I $ the set of natural numbers (or more generally any directed set) and $ nu = (xi){iin I}colon I to X $ is a sequence (or a net) of points in $ X $ , one says that a point $ x in X $ is a limit of $ nu $ or that $ nu $ converges to $ x $ if for each neighbourhood $ U $ in $ X $ of $ x $ there exists an $ n in I $ such that $ x_i in U $ for each $ i geq n $ .
An important special case (the original) is: If $ X $ the real line and $ I $ the set of natural numbers (or more generally any directed set) and $ nu = (xi){iin I}colon I to X $ is a sequence (or a net) of real numbers, one says that a point $ x in X $ is a limit of $ nu $ or that $ nu $ converges to $ x $ if for each positive number $ epsilon $ there exists an $ n in I $ such that $ {|x_i - x|} lt epsilon $ for each $ i geq n $ .
An important generalization (possibly the most general) is: If $ X $ a convergence space and $ I $ the set of natural numbers (or more generally any directed set) and $ nu = (xi){iin I}colon I to X $ is a sequence (or a net) of points in $ X $ , one says that a point $ x in X $ is a limit of $ nu $ or that $ nu $ converges to $ x $ if the eventuality filter of $ nu $ converges to $ x $ (which is a primitive concept in convergence spaces).
Other types of space for which we might put in definitions (or which might have definitions on their own pages) are (extended) (quasi) - (pseudo) - metric spaces, premetric spaces, (quasi) - uniform spaces, pretopological spaces, and (quasi) - uniform convergence spaces.
When one of the conditions above holds, we may write any of the following, where ' $ to $ ' is read as 'converges to':
Or we may write any of the following, were $ lim $ is read as 'the set of limits of': Of course, the right - hand side has a meaning by itself, as the set of limits itself (a subset of the underlying set of $ X $ , or a subspace of $ X $ itself).
If $ X $ is a Hausdorff space, then there is at most one point $ x $ with the property that the sequence (or net) $ nu $ converges to $ x $ .
Then we may write any of the following, were now $ lim $ is read as 'the limit of':
Now the right - hand side by itself is the possibly undefined term for the limit itself (if it exists).
More generally than sequences, and equivalently to nets, we may speak of limits of filters on $ X $ .
This concept is axiomatized directly in the concept of convergence space.
In the case of a topological space $ X $ , a filter of subsets of $ X $ converges to a point $ x $ if every neighbourhood of $ x $ is contained in the filter.
In the definitions above, equivalent nets (those with equal eventuality filters) always converge to the same point.
As every proper filter is the eventuality filter of some net, a proper filter converges to $ x $ if any of these nets converges to $ x $ ; the improper filter converges to every point.
(In constructive mathematics, we may cover all filters by saying: $ F $ converges to $ x $ if, on the assumption that $ F $ is proper, any of its nets converges to $ x $ .)
{RelationToLimitsInCategoryTheory} The limits of category theory are a great generalization of an analogy with the limits discussed here.
It turns out, however, that limits in topological spaces (at least) can be viewed as category - theoretic limits.
For now, see this math.sx answer.
Discussion of this history of the concept, with emphasis on its roots all the way back in Zeno's paradoxes of motion is in category: analysis Given a space $ S $ , a subspace $ A $ of $ S $ , and a concrete point $ x $ in $ S $ , $ x $ is a limit point of $ A $ if $ x $ can be approximated by the contents of $ A $ .
There are several variations on this idea, and the term 'limit point' itself is ambiguous (sometimes meaning Definition , sometimes Definition .
The classical definitions apply when $ S $ is a topological space.
Then $ A $ may be thought of as a subset of (the underlying set of) $ S $ , and $ x $ as an element.
In order to apply the definitions in constructive mathematics, there needs to be an inequality relation $ ne $ on the points of $ S $ ; in classical mathematics, this is taken to be the denial inequality, as usual.
(We need not assume that $ ne $ is an apartness relation nor any compatibility between $ ne $ and the topology, at least for the definitions; although it's quite possible that some classical theorems will require such assumptions.)
For the most general definitions, let $ kappa $ be a collection of cardinal numbers.
(We might want $ kappa $ to have some closure properties akin to those of an arity class, but the definition there is not quite what we want.)
Recall that a $ kappa $ - ary indexed subset of $ S $ is a function $ Bcolon I to S $ such that the cardinality of $ I $ belongs to the class $ kappa $ ; a point $ y $ is in $ B $ (as an indexed subset) if $ y $ belongs to the range of $ B $ (as a function), and $ y $ is out of $ B $ if $ y $ is inequal ( $ ne $ ) to every point in $ B $ .
The point $ x $ is a $ kappa $ - adherent point of the subspace $ A $ if, for each neighbourhood $ U $ of $ x $ , for each $ kappa $ - ary indexed subset $ B $ of the intersection $ U cap A $ , there is an element $ y $ of $ U cap A $ that is out of $ B $ .
Slightly more strongly, $ x $ is a $ kappa $ - accumulation point (or $ kappa $ - cluster point) of $ A $ if, for each neighbourhood $ U $ of $ x $ , for each $ kappa $ - ary indexed subset $ B $ of $ U cap A $ , there is an element $ y ne x $ of $ U cap A $ that is out of $ B $ .
(Alternatively, take $ U $ to be a punctured neighborhood, but that won't work constructively in general.)
Every $ kappa $ - accumulation point is a $ kappa $ - adherent point; the converse holds if every $ k in kappa $ satisfies $ k + 1 in kappa $ (and then one usually says 'accumulation' rather than 'adherent').
Also, if $ kappa subseteq lambda $ , then every $ lambda $ - (adherent/accumulation) point is a $ kappa $ - (adherent/accumulation) point.
It immediately follows that the following classical special cases are in order of increasing strength: The point $ x $ is an adherent point of the subspace $ A $ if, for every neighbourhood $ U $ of $ x $ , the intersection $ U cap A $ is inhabited (nonempty).
The point $ x $ is an accumulation point of the subspace $ A $ if, for every punctured neighbourhood $ U $ of $ x $ , the intersection $ U cap A $ is inhabited.
The point $ x $ is an $ omega $ - accumulation point (or $ infty $ - accumulation point) of the subspace $ A $ if, for every neighbourhood $ U $ of $ x $ , the intersection $ U cap A $ is infinite.
The point $ x $ is a condensation point of the subspace $ A $ if, for every neighbourhood $ U $ of $ x $ , the intersection $ U cap A $ is uncountable.
The subspace $ A $ is closed iff
every adherent point of $ A $ belongs to $ A $ and iff every accumulation point of $ A $ belongs to $ A $ .
(Thus one may say that $ A $ is closed iff every limit point of $ A $ belongs to $ A $ without ambiguity.)
More generally, the closure of $ A $ is the set of all adherent points of $ A $ .
This justifies using 'limit point' to mean an adherent point: the adherent points of $ A $ are precisely those that are limits of nets of points in $ A $ .
Classically (using excluded middle, or more generally if $ S $ has decidable equality), the closure of $ A $ is the union of $ A $ and its set of accumulation points.
The set of accumulation points of $ A $ is also called the derived set of $ A $ , denoted $ A' $ .
The study of derived sets is of great historical importance in Georg Cantor's development of set theory, even though closure sets are more important in modern mathematics.
Note that while $ Cl(Cl(A)) = Cl(A) $ , no similar relationship holds between $ A' $ and $ A'' $ , $ A''' $ , etc; one can even continue this into transfinite ordinal numbers (possibly their earliest application).
Classically, a point in $ A $ that is not an accumulation point of $ A $ is precisely an isolated point of $ A $ .
(Constructively, each of these is stronger than the negation of the other, but the two conditions may be taken to be antitheses.)
A justification for the terminology 'limit point' for an accumulation point is that the concept of limit of a function approaching a point really only makes sense approaching an accumulation point.
(This is for essentially the same reason that every function is continuous at an isolated point.)
Indeed, every answer whatsoever satisfies the naive definition of $ lim_c f $ if $ c $ is an isolated point of $ dom f $ (because the improper filter converges everywhere).
The geometric series is the series $ sum_{n = 0}^infty r^n , $ .
For $ r in mathbb{R} $ with $ {Vert r Vert} lt 1 $ this sequence converges $ underset{n to infty}{lim} underoverset{k = 0}{n}{sum} r^k ;=; frac{1}{1 - r} , $ .
For $ r in mathbb{Z}_p $ with $ r = p $ the above sequences converges in the p - adic metric.
See also: >
This entry is about the notion of "limit" in category theory.
For the notion of the same name in analysis and topology see at limit of a sequence.
In category theory a limit of a diagram $ F : D to C $ in a category $ C $ is an object $ lim F $ of $ C $ equipped with morphisms to the objects $ F(d) $ for all $ d in D $ , such that everything in sight commutes.
Moreover, the limit $ lim F $ is the universal object with this property, i.e. the "most optimized solution" to the problem of finding such an object.
The limit construction has a wealth of applications throughout category theory and mathematics in general.
In practice, it is possibly best thought of in the context of representable functors as a classifying space for maps into a diagram.
So in some sense the limit object $ lim F $ "subsumes" the entire diagram $ F(D) $ into a single object, as far as morphisms into it are concerned.
The corresponding universal object for morphisms out of the diagram is the colimit.
An intuitive general idea is that a limit of a diagram is the locus or solution set of a bunch of equations, where each of the coordinates is parametrized by one of the objects of the diagram, and where the equations are prescribed by the morphisms of the diagram.
This idea is explained more formally here.
Often, the general theory of limits (but not colimits!) works better if the source of $ F $ is taken to be the opposite category $ D^op $ (or equivalently, if $ F $ is taken to be a contravariant functor).
This is what we do below.
In any given situation, of course, you use whatever categories and functors you're interested in.
In some cases the category - theoretic notion of limit does reproduce notions of limit as known from analysis.
See the examples below.
In correspondence to the local definition of adjoint functors (as discussed there), there is a local definition of limits (in terms of cones), that defines a limit (if it exists) for each individual diagram, and there is a global definition, which defines the limit for all diagrams (in terms of an adjoint).
If all limits over the given shape of diagrams exist in a category, then both definitions are equivalent.
See also the analogous discussion at homotopy limit.
A limit is taken over a functor $ F : D^{op} to C $ and since the functor comes equipped with the information about what its domain is, one can just write $ lim F $ for its limit.
But often it is helpful to indicate how the functor is evaluated on objects, in which case the limit is written $ lim_{d in D} F(d) $ ; this is used particularly when $ F $ is given by a formula (as with other notation with bound variables.)
In some schools of mathematics, limits are called projective limits, while colimits are called inductive limits.
Also seen are (respectively) inverse limits and direct limits.
Both these systems of terminology are alternatives to using 'co - ' when distinguishing limits and colimits.
The first system also appears in pro - object and ind - object.
Correspondingly, the symbols $ underset{leftarrow}lim $ and $ underset{rightarrow}lim $ are used instead of $ lim $ and $ colim $ .
Confusingly, many authors restrict the meanings of these alternative terms to (co)limits whose sources are directed sets; see directed limit.
In fact, this is the original meaning; projective and inductive limits in this sense were studied in algebra before the general category - theoretic notion of (co)limit.
There is a general abstract definition of limits in terms of representable functors, which we describe now.
This reproduces the more concrete and maybe more familiar description in terms of universal cones, which is described further below.
Let in the following $ D $ be a small category and Set the category of sets (possibly realized as the category $ U Set $ of $ U $ - small sets with respect to a given Grothendieck universe.)
The limit of a Set - valued functor $ F : D^{op} to Set $ is the hom - set $ lim F coloneqq Hom_{D^{op}, Set}(pt, F) in Set $ in the functor category $ D^{op}, Set $ (the presheaf category), where $ pt : D^{op} to Set $ $ pt : d mapsto { } $ is the functor constant on the point, i.e. the terminal diagram.
The set $ lim F $ is equivalently called The set $ lim F $ can be equivalently expressed as an equalizer of a product, explicitly: $ lim F simeq leftlbrace (xd){d in D} in prod{d in D} F(d) | forall (di stackrel{alpha}{to} dj) in D : F(alpha)(x{dj}) = x{di} rightrbrace $ In particular, the limit of a set - valued functor always exists.
Notice the important triviality that the covariant hom - functor commutes with set - valued limits: for every set $ S $ we have a bijection of sets $ Hom{Set}(S, lim F) simeq lim Hom{Set}(S, F( - )) , , $ where $ Hom(S, F( - )) : D^{op} to Set $ .
The above formula generalizes straightforwardly to a notion of limit for functors $ F : D^{op} to C $ for $ C $ an arbitrary category if we construct a certain presheaf on $ C $ which we will call $ hat lim F $ .
The actual limit $ lim F $ is then, if it exists, the object of $ C $ representing this presheaf.
More precisely, using the Yoneda embedding $ y: C to C^{op}, Set $ define for $ F : D^{op} to C $ the presheaf $ hat lim F in C^{op}, Set $ by $ (hat lim F)(c)coloneqq Hom{Set^{D^{op}}}(pt, HomC(c, F( - ))) $ for all $ c in C $ , or suppressing the subscripts for readability: $ (hat lim F)(c) = Hom(pt , Hom(c, F( - ))) , $ .
The presheaf - valued limit always exists; iff this presheaf is representable by an object $ lim F $ of $ C $ , then this is the limit of $ F $ : $ Hom(c, lim F) simeq Hom(pt, Hom(c, F( - ))) , $ .
In the above formulation, there is an evident generalization to weighted limits: replace in the above the constant terminal functor $ pt : D^{op} to Set $ with any functor $ W : D^{op} to Set $ - - then called the weight - - , then the $ W $ - weighted limit of $ F $ $ limW F $ often written $ {W, F } $ is, if it exists, the object representing the presheaf $ c mapsto Hom{D^{op}, Set}(W , HomC(c, F( - ))) , , $ i.e. such that $ Hom(c, limW F) simeq Hom(W, Hom(c, F( - ))) , $ naturally in $ c in C $ .
The very definition of limit as above asserts that the covariant hom - functor $ Hom(c, - ) : C to Set $ commutes with forming limits.
Indeed, the definition is equivalent to saying that the hom - functor is a continuous functor.
Unwrapping the above abstract definition of limits yields the following more hands - on description in terms of universal cones.
Let $ F : D^{op} to C $ be a functor.
Notice that for every object $ c in C $ an element $ $ is to be identified with a collection of morphisms $ c to F(d) $ for all $ d in D $ , such that all triangles $ array{ && c & swarrow && searrow F(di) && stackrel{F(f)}{to} && F(dj) } $ commute.
Such a collection of morphisms is called a cone over $ F $ , for the obvious reason.
If the limit $ lim F in C $ of $ F $ exist, then it singles out a special cone given by the composite morphism $ stackrel{* mapsto Id{lim F}}{to} HomC(lim F, lim F) stackrel{simeq}{to} Hom(pt, Hom(lim F, F( - ))) , , $ where the first morphism picks the identity morphism on $ lim F $ and the second one is the defining bijection of a limit as above.
The cone $ array{ && lim F & swarrow && searrow F(di) && stackrel{F(f)}{to} && F(dj) } $ is called the universal cone over $ F $ , because, again by the defining property of limit as above, every other cone $ {c to F(d) } {d in D} $ as above is bijectively related to a morphism $ c to lim F $ $ stackrel{{c to F(d) } {d in D}}{to} Hom(pt, Hom(c, F( - ))) stackrel{simeq}{to} Hom(c, lim F) , $ .
By inspection one finds that, indeed, the morphism $ c to lim F $ is the morphism which exhibits the factorization of the cone $ {c to F(d) } {d in D} $ through the universal limit cone $ array{ && c & swarrow && searrow F(di) && stackrel{F(f)}{to} && F(dj) } = array{ && c && downarrow && lim F & swarrow && searrow F(di) && stackrel{F(f)}{to} && F(dj) } , $ .
An illustrative example is the following: a limit of the identity functor $ Idc:Cto C $ is, if it exists, an initial object of $ C $ .
Given categories $ D $ and $ C $ , limits over functors $ D^{op} to C $ may exist for some functors, but not for all.
If it does exist for all functors, then the above local definition of limits is equivalent to the following global definition.
For $ D $ a small category and $ C $ any category, the functor category $ D^{op}, C $ is the category of $ D $ - diagrams in $ C $ .
Pullback along the functor $ D^{op} to pt $ to the terminal category $ pt = {bullet } $ induces a functor $ const : C to D^{op}, C $ which sends every object of $ C $ to the diagram functor constant on this object.
The left adjoint $ colimD : D^{op}, C to C $ of this functor is, if it exists, the functor which sends every diagram to its colimit and the right adjoint is, if it exists, the functor $ limD : D^{op}, C to C $ which sends every diagram to its limit.
The Hom - isomorphisms of these adjunctions state precisely the universal property of limit and colimit given above.
Concretely this means that for all $ c in C $ we have a bijection $ HomC(c, lim F) simeq Hom{D^{op}, C}(constc, F) , $ .
From this perspective, a limit is a special case of a Kan extension, as described there, namely a Kan extension to the point.
The notion of limit, being fundamental to category theory, generalizes to many other situations.
Examples include the following.
The central point about examples of limits is: Categorical limits are ubiquitous.
To a fair extent, category theory is all about limits and the other universal constructions: Kan extensions, adjoint functors, representable functors, which are all special cases of limits - - and limits are special cases of these.
Listing examples of limits in category theory is much like listing examples of integrals in analysis: one can and does fill books with these.
(In fact, that analogy has more to it than meets the casual eye: see coend for more).
Keeping that in mind, we do list some special cases and special classes of examples that are useful to know.
But any list is necessarily wildly incomplete.
Here are some important examples of limits, classified by the shape of the diagram: The concept of limit of a sequence in topological spaces is a special case of category theoretic limits, see there.
{ConstructionFromProductsAndEqualizers} Frequently some limits can be computed in terms of other limits.
This makes things easier since we only have to assume that categories have, or functors preserve, some easier - to - verify class of limits in order to obtain results about a larger one.
The most common example of this is the computation of limits in terms of products and equalizers.
Specifically, if the limit of $ F : D^{op} to C $ and the products $ prod{din Obj(D)} F(d) $ and $ prod{fin Mor{d}} F(s(f)) $ all exist, then $ lim F $ is a subobject of $ prod{din Obj(D)} F(d) $ , namely the equalizer of $ prod{d in Obj(D)} F(d) stackrel{prod{f in Mor(d)} (F(f) circ p{s(f)}) }{to} prod{f in Mor(D)} F(s(f)) $ and $ prod{d in Obj(D)} F(d) stackrel{prod{f in Mor(d)} (p{t(f)}) }{to} prod{f in Mor(D)} F(s(f)) , $ .
Conversely, if both of these products exist and so does the equalizer of this pair of maps, then that equalizer is a limit of $ F $ .
In particular, therefore, a category has all limits as soon as it has all products and equalizers, and a functor defined on such a category preserves all limits as soon as it preserves products and equalizers.
(More precisely, it suffices only to consider equalizers of reflexive pairs.)
Another example is that all finite limits can be computed in terms of pullbacks and a terminal object.
For $ C $ a locally small category, for $ F : D^{op} to C $ a functor and writing $ C(c, F( - )) : D^{op} to Set $ , we have $ C(c, lim F) simeq lim C(c, F( - )) , $ .
Depending on how one introduces limits this holds by definition or is an easy consequence.
For $ F : D^{op} to Set $ any functor and $ const{} : D^{op} to Set $ the functor constant on the point, the limit of $ F $ is the hom - set $ lim F simeq D^{op}, Set $ in the functor category, i.e. the set of natural transformations from the constant functor into $ F $ .
Let $ D $ be a small category and let $ D' $ be any category.
Let $ C $ be a category which admits limits of shape $ D $ .
Write $ D', C $ for the functor category.
Then {CompatibilityAmongUniversalConstructions} Let $ R ;colon; C to C' $ be a functor that is right adjoint to some functor $ L : C' to C $ .
Let $ D $ be a small category such that $ C $ admits limits of shape $ D $ .
Then $ R $ commutes with $ D $ - shaped limits in $ C $ in that for $ F : D^{op} to C $ some diagram, we have $ R(lim F) simeq lim (R circ F) , $ .
Using the adjunction isomorphism and the above fact that hom - functor preserves limits, one obtains for every $ c' in C' $ $ C'(c', R (lim F)) & simeq C(L(c'), lim F) & simeq lim C(L(c'), F) & simeq lim C'(c', Rcirc F) & simeq C'(c', lim (R circ F)) , . , $ .
Since this holds naturally for every $ c' $ , the Yoneda lemma, corollary II on uniqueness of representing objects implies that $ R (lim F) simeq lim (R circ F) $ .
Let $ D $ and $ D' $ be small categories and let $ C $ be a category which admits limits of shape $ D $ as well as limits of shape $ D' $ .
Then these limits commute with each other, in that for $ F : D^{op} times {D'}^{op} to C $ a functor , with corresponding induced functors $ FD : {D'}^{op} to D^{op}, C $ and $ F{D'} : {D}^{op} to {D'}^{op}, C $ , then the canonical comparison morphism lim F simeq lim{D} (lim{D'} F_D ) simeq lim{D'} (lim{D} F_{D'} ) is an isomorphism.
Since the limit - construction is the right adjoint functor to the constant diagram - functor, this is a special case of right adjoints preserve limits (Prop. ).
See limits and colimits by example for what formula (eq:ComparisonMorphismForCommutingLimits) says for instance for the special case $ C = $ Set.
In general limits do not commute with colimits.
But under a number of special conditions of interest they do.
Special cases and concrete examples are discussed at commutativity of limits and colimits.
Limits and colimits were defined in Daniel M. Kan in Chapter II of the paper that also defined adjoint functors and Kan extensions: This paper refers to limits as inverse limits.
The observation that limits can be constructed from products and equalisers is due to: That, more generally, it suffices to consider only equalisers of reflexive pairs is due to: Analogously to a smooth space, a continuous space is any notion of space between which the morphisms are continuous maps.
Examples include: Contrast this with, for example: The intermediate value theorem (IVT) is a fundamental principle of analysis which allows one to find a desired value by interpolation.
It says that a continuous function $ f colon 0, 1 to mathbb{R} $ from an interval to the real numbers (all with its Euclidean topology) takes all values in between $ f(0) $ and $ f(1) $ .
The IVT in its general form was not used by Euclid.
Although it is hard to doubt that Euclid believed that, for any given angle, there was an angle with one - third the measure, this angle cannot be constructed by the methods available to Euclid, so he would never refer to it (see at Euclidean geometry).
In contrast, Archimedes made general arguments in which a quantity is approached from above and below, allowing him not only to trisect the angle but also to calculate π.
As normally stated, the IVT is not valid in constructive mathematics, although there are constructively valid versions.
These versions either weaken the conclusion to an approximate zero, or to strengthen the hypothesis to require the functions satisfy additional properties or have other structures, such as locally nonconstancy and lifting to locators in functions in the given example below.
Even interpreted classically, these are prima facie weaker results.
(classical IVT, assuming excluded middle) Let $ fcolon a, b to mathbb{R} $ be a continuous function from a compact closed interval to the real line, and suppose that $ f(a) lt 0 $ while $ f(b) gt 0 $ .
Then there exists a point $ c $ in the unit interval such that $ f(c) = 0 $ .
Let $ g:mathbb{R} to mathbb{R} $ be defined as $ g(x) coloneqq (b - a) x + a $ .
Then there exists a function $ h:1, 0 to mathbb{R} $ such that $ f = g circ h $ .
By this example the interval $ 0, 1 $ is a connected topological space (this is where excluded middle is used).
By this prop.
also its image $ f(0, 1) subset mathbb{R} $ is connected.
By this example that image is itself an interval.
This implies the claim is true for $ h $ .
Since linear functions preserve the properties of an interval being compact and closed, if the claim is true for $ h $ , it is true for $ f $ .
(constructive IVT with weakened conclusion)
For real numbers $ a $ and $ b $ , let $ fcolon a, b to mathbb{R} $ be a pointwise continuous function from the closed interval $ a, b $ to the real line, and supposed that $ f(a) lt 0 $ and $ f(b) gt 0 $ .
Then for every positive number $ epsilon $ there exists a point $ cepsilon $ in the unit interval such that $ {|f(cepsilon)|} lt epsilon $ .
This proof originally appeared in Frank 2020.
Let us inductively define the following sequences: $ a_0 coloneqq a $ $ b_0 coloneqq b $ $ cn coloneqq frac{an + b_n}{2} $ $ dn coloneqq maxleft(0, minleft(frac{1}{2} + frac{f(cepsilon)}{epsilon}, 1right)right) $ $ a{n + 1} = cn - frac{d_n (b - a)}{2^{n + 1}} $ $ a{n + 1} = bn - frac{d_n (b - a)}{2^{n + 1}} $ Then $ bn - an = frac{b - a}{2^n} $ and the sequence $ c_n $ is a Cauchy sequence, because for natural numbers $ m lt n $ , $ vert cm - cn vert leq frac{b - a}{2^m} $ Lemma: For every natural number $ m $ , either (i) there exists a $ j leq m $ such that $ vert f(cj) lt epsilon $ , or (ii) $ f(am) lt 0 $ and $ f(b_m) gt 0 $ .
This could be proved by induction on natural numbers: When $ m = 0 $ , $ f(a0) = f(a) lt 0 $ and $ f(b0) = f(b) gt 0 $ .
Now, assume that the above lemma is true for a particular $ m $ .
If there exists a $ j leq m $ such that $ vert f(cj) lt epsilon $ , then there exists a $ j leq m + 1 $ such that $ vert f(cj) lt epsilon $ .
Otherwise, either $ 2 f(cm) lt - epsilon $ , $ 2 f(cm) gt epsilon $ , or $ vert f(c_m) vert gt epsilon $ $ . d_m coloneqq 1 $ $ a{m + 1} coloneqq am $ $ b{m + 1} coloneqq cm $ so that $ a{m + 1} lt 0 $ and $ b{m + 1} gt 0 $ $ . d_m coloneqq 1 $ $ a{m + 1} coloneqq cm $ $ b{m + 1} coloneqq bm $ so that $ a{m + 1} lt 0 $ and $ b{m + 1} gt 0 $ .
Thus, the above lemma is true.
Now, by pointwise continuity at $ c $ , let $ delta $ be such that $ vert x - y vert lt delta $ implies $ vert f(x) - f(y)vert lt epsilon $ .
Choose a natural number $ m $ such that $ vert c - c_m vert lt frac{delta}{2} $ $ frac{vert b - a vert}{2^{m + 1}} lt frac{delta}{2} $ If there exists a $ j leq m $ such that $ vert f(cj) lt epsilon $ , then the intermediate value is true.
Otherwise, $ f(am) lt 0 $ and $ f(b_m) gt 0 $ , and so $ vert c - cm vert lt vert c - cm vert + vert cm - am vert lt delta $ $ vert c - cm vert lt vert c - cm vert + vert cm - bm vert lt delta $ and so that means that $ vert f(c) - f(a_m) vert lt epsilon $ $ vert f(c) - f(b_m) vert lt epsilon $ which means that $ vert f(c) vert lt epsilon $ .
If excluded middle is true, then the classical IVT follows from the above theorem: By way of contradiction (applying the double negation law of classical logic), suppose that $ {|f(c)|} gt 0 $ for every $ c $ in $ 0, 1 $ .
Then the extra hypothesis of Theorem is certainly satisfied, so there exists some $ c $ such that $ f(c) = 0 $ after all.
(Constructively, this is enough to show that the classical theorem has no counterexample.)
(constructive IVT with strengthened hypothesis, assuming the interval endpoints and the zero have locators and that the function is locally nonzero)
For real numbers $ a $ and $ b $ with locators, let $ fcolon a, b to mathbb{R} $ be a pointwise continuous function from the closed interval $ a, b $ to the real line that is a locally nonzero function and that lifts to locators, and suppose that $ f(a) leq 0 $ and $ f(b) geq 0 $ .
Then, there exists a point $ c $ in $ a, b $ with a locator such that $ f(c) = 0 $ .
This proof originally appeared in Booij 2018 ... (constructive IVT with strengthened hypothesis, assuming weak countable choice and that the function is locally nonzero)
Assuming weak countable choice, for real numbers $ a $ and $ b $ , let $ fcolon a, b to mathbb{R} $ be a pointwise continuous function from the closed interval $ a, b $ to the real line that is a locally nonzero function, and suppose that $ f(a) leq 0 $ and $ f(b) geq 0 $ .
Then, there exists a point $ c $ in $ a, b $ with a locator such that $ f(c) = 0 $ .
(constructive IVT with strengthened hypothesis, assuming weak countable choice and that the function is uniformly continuous) Let $ fcolon 0, 1 to mathbb{R} $ be a uniformly continuous function from the unit interval to the real line, and suppose that $ f(0) lt 0 $ while $ f(1) gt 0 $ .
Suppose further that, for any points $ a, b $ in the unit interval with $ a lt b $ , there exists a point $ c{a, b} $ such that $ a lt c{a, b} lt b $ and $ {|f(c_{a, b})|} gt 0 $ .
(In other words, the non - zero set $ { c : {|f(c)|} gt 0 } $ is dense.)
Then there exists a point $ c $ in the unit interval such that $ f(c) = 0 $ . and countable choice; doi. >
See also differentiation and derivative.
A function (map) is differentiable at some point if it can be well approximated by a linear map near that point.
The approximating linear maps at different points together form the derivative of the map.
One may then ask whether the derivative itself is differentiable, and so on.
This leads to a hierarchy of ever more differentiable maps, starting with continuous maps and progressing through maps that are $ n $ times (continuously) differentiable to those that are infinitely differentiable, and finally to those that are analytic.
Infinitely differentiable maps are sometimes called smooth.
Differentiability is first defined directly for maps between (open subsets of) a Cartesian space.
These differentiable maps can then be used to define the notion of differentiable manifold, and then a more general notion of differentiable map between differentiable manifolds, forming a category called Diff.
We have a parallel hierarchy of ever more differentiable manifolds and ever more differentiable maps between them.
Since every more differentiable manifold has an underlying less differentiable manifold, we may always consider maps that are less differentiable than the manifolds between which they run.
In all of the following $ mathbb{R} $ denotes the real numbers and $ mathbb{R}^n $ for $ n in mathbb{N} $ their $ n $ - fold Cartesian product.
For $ i in {1, cdots, n } $ we write $ array{ mathbb{R}^n &overset{pr_i}{longrightarrow}& mathbb{R} vec v = (v1, cdots, vn) &mapsto& v_i } $ for the projection map onto the $ i $ th factor.
When considering convergence of sequences of elements of these sets we regard them as Euclidean metric spaces with the Euclidean norm $ {Vert - Vert} ;colon; mathbb{R}^n longrightarrow 0, infty) subset mathbb{R} , $ .
The open subsets of the corresponding metric topology are the unions of open balls in $ mathbb{R}^n $ .
A function $ f:mathbb{R} to mathbb{R} $ is differentiable if it comes with a function $ frac{d f}{d x}:mathbb{R} to mathbb{R} $ and a function $ Mf:mathbb{Q}+ to mathbb{Q}_+ $ in the positive rational numbers, such that $ left|f(x + h) - frac{d f}{d x}(x)right| lt epsilon |h| $ Given a predicate $ P $ on the real numbers $ mathbb{R} $ , let $ I $ denote the set of all elements in $ mathbb{R} $ for which $ P $ holds.
A partial function $ f:mathbb{R} to mathbb{R} $ is equivalently a function $ f:I to mathbb{R} $ for any such predicate $ P $ and set $ I $ .
A function $ f:I to mathbb{R} $ is differentiable at a subset $ S subseteq I $ with injection $ j:S hookrightarrow mathbb{R} $ if it has a function $ frac{d f}{d x}:S to mathbb{R} $ such that for all Archimedean ordered Artinian local $ K $ - algebras $ A $ with ring homomorphism
$ h:K to A $ and nilradical $ D $ such that for all $ epsilon in D $ , $ epsilon^2 = 0 $ , for all nilpotent elements $ epsilon in D $ , $ f_A(h(j(a)) + epsilon) = h(j(a)) + hleft(frac{d f}{d x}(a)right) epsilon $ A function $ f:I to mathbb{R} $ is differentiable at an element $ a in I $ if it is differentiable at the singleton subset $ {a } $ , and a function $ f:I to mathbb{R} $ is differentiable if it is differentiable at the improper subset of $ I $ .
Let $ n in mathbb{N} $ and let $ U subset mathbb{R}^n $ be an open subset.
Then a function $ f ;colon; U longrightarrow mathbb{R} $ is called differentiable at $ xin U $ if there exists a linear map $ d f_x : mathbb{R}^n to mathbb{R} $ such that the following limit exists as $ h $ approaches zero "from all directions at once": $ lim{hto 0} frac{f(x+h) - f(x) - d fx(h)}{Vert hVert} = 0 $ .
This means that for all $ epsilon in (0, infty) $ there exists an open subset $ Vsubseteq U $ containing $ x $ such that whenever $ x+hin V $ we have $ frac{f(x+h) - f(x) - d f_x(h)}{Vert hVert} lt epsilon $ .
We say that $ f $ is differentiable on a subset $ I $ of $ U $ if $ f $ is differentiable at every $ xin I $ , and differentiable (tout court) if $ f $ is differentiable on all of $ U $ .
We say that $ f $ is continuously differentiable if it is differentiable and $ d f $ is a continuous function.
The map $ d f_x $ is called the derivative or differential of $ f $ at $ x $ .
If $ n=1 $ , as in classical one - variable calculus, then $ d f_x $ in def. may be identified with a real number, and that number is also called the derivative of $ f $ at $ x $ and often written $ f'(x) $ .
(In that case, the notation $ d f $ is generally still reserved for the corresponding linear map, with its input denoted by $ d x $ , so that we have $ d f = f'(x) d x $ .)
An equivalent way to state def. is to say that $ f(x+h) = f(x) + d f_x(h) + E(h){Vert hVert} $ where $ E $ is a function such that $ lim{hto 0}E(h) = 0 $ .
This is easy to see; just let $ E(h) = frac{f(x+h) - f(x) - d fx(h)}{Vert hVert} $ .
Another equivalent way to say it is that $ f(x+h) = f(x) + d fx(h) + E1(h) h1 + cdots + En(h) h_n $ where $ Ei $ are functions such that $ lim{hto 0}Ei(h) = 0 $ .
For if this is true, then $ E(h) = frac{1}{Vert hVert}(E1(h) h1 + cdots + En(h) hn) $ satisfies the previous definition.
Conversely, if the previous definition holds, then defining $ Ei(h) = frac{h_i}{Vert h Vert} E(h) $ satisfies this definition.
A weaker notion of differentiability is the following: Let $ n in mathbb{N} $ and $ U subset mathbb{R}^n $ an open subset.
Then a function $ f colon U longrightarrow mathbb{R} $ is said to have directional derivative in the direction of $ v in mathbb{R}^n $ at $ xin U $ if the limit $ lim_{hto 0} frac{f(x+h v) - f(x)}{h} $ exists.
Here $ h $ is just a real number.
Historically, the term 'directional derivative' was reserved for when $ v $ is a unit vector (or divide the derivative above by $ |v| $ ), but the general concept involves less structure and is more important but has no other established name.
If $ v $ is a standard basis vector $ ei $ , then the directional derivative is called a partial derivative* with respect to the corresponding coordinate, and often written $ frac{partial f}{partial xi} $ or $ f{xi} $ .
If $ f $ is differentiable at $ x $ in the sense of def. , then $ d fx(v) $ is its directional derivative along $ v $ .
In particular, the coordinates of $ d fx $ are the partial derivatives of $ f $ .
In general, $ f $ may have all partial derivatives, and even all directional derivatives, without being differentiable; see the examples below.
However, if $ f $ has all partial derivatives and they are continuous as functions of $ x $ , then in fact $ f $ is differentiable (and indeed continuously differentiable).
Let $ n1, n2 in mathbb{N} $ and let $ Usubseteq mathbb{R}^{n1} $ be an open subset.
Then a function $ f ;colon; U longrightarrow mathbb{R}^{n2} $ is differentiable if for all $ i in {1, cdots, n2 } $ the component function $ fi ;colon; U overset{f}{longrightarrow} mathbb{R}^{n2} overset{pru}{longrightarrow} mathbb{R} $ is differentiable in the sense of def. .
In this case, the derivatives $ d fi colon mathbb{R}^n to mathbb{R} $ of the $ fi $ assemble into a linear map of the form $ d fx ;colon; mathbb{R}^{n1} to mathbb{R}^{n2} , $ .
For $ X $ and $ Y $ differentiable manifolds, then a function $ f colon X longrightarrow Y $ is called differentiable if for $ left{ mathbb{R}^{n} underoverset{simeq}{phii}{to} Ui subset Xright } $ an atlas for $ X $ and $ left{ mathbb{R}^{n'} underoverset{simeq}{psij}{to} Vj subset X2right } $ and atlas for $ Y $ then for all $ i in I $ and $ j in J $ the function $ mathbb{R}^n supset phantom{AA} (fcirc phii)^{ - 1}(Vj) overset{phii}{longrightarrow} f^{ - 1}(Vj) overset{f}{longrightarrow} Vj overset{psij^{ - 1}}{longrightarrow} mathbb{R}^{n'} $ is differentiable in the sense of def. .
For $ U subset mathbb{R}^n $ an open subset and $ f ;colon; Uto mathbb{R}^m $ a differentiable function (def. ), we may regard its differential $ d f $ as a function from a subset of $ U $ (the points where $ f $ is differentiable) to the space $ L(mathbb{R}^n, mathbb{R}^m) $ of linear maps.
Since $ L(mathbb{R}^n, mathbb{R}^m) cong mathbb{R}^{n m} $ is again a Cartesian space, we may then ask whether $ d f $ is differentiable.
We can then iterate, obtaining the following hierarchy of differentiability.
Because iterated differentiability by itself is not very useful, and a differentiable map is necessarily continuous, one generally includes continuity of the last assumed derivatives.
Note that $ f $ is differentiable on a set $ U $ iff there is a function $ f' $ on $ U $ (necessarily unique, assuming that $ U $ has no isolated points) such that $ forall, epsilon gt 0, ; forall, x in U, ; exists, delta gt 0, ; forall, y in U, ; {|{y - x}|} lt delta ;Rightarrow; {|{f(y) - f(x) - f'(x)(y - x)}|} lt epsilon , {|{y - x}|} $ .
Reverse quantifiers, and $ f $ is uniformly differentiable on $ U $ iff there is a function $ f' $ on $ U $ such that $ forall, epsilon gt 0, ; exists, delta gt 0, ; forall, x in U, ; forall, y in U, ; {|{y - x}|} lt delta ;Rightarrow; {|{f(y) - f(x) - f'(x)(y - x)}|} lt epsilon , {|{y - x}|} $ .
In classical mathematics, $ f $ is uniformly differentiable if and only if $ f $ is differentiable and its derivative $ f' $ is uniformly continuous; in other words, $ f $ is uniformly differentiable iff $ f $ is uniformly - continuously differentiable.
The same is true in constructive mathematics as long as one assumes dependent choice.
In the absence of dependent choice, however, the argument only goes one way, and uniform differentiability is stronger.
Furthermore, just as pointwise continuity is not as well behaved constructively as uniform continuity, so pointwise differentiability is not as well behaved constructively as uniform differentiability.
For this reason, uniform differentiability is particularly important in constructive mathematics.
In addition, one could talk about locally uniform differentiablilty, which is a continuously differentiable function on a set $ U $ which is uniformly differentiable on every closed and bounded subset $ V subseteq U $ .
If $ f:Uto mathbb{R}^m $ is twice differentiable with $ Usubseteq mathbb{R}^n $ , its second derivative $ d(d f) : U to L(mathbb{R}^n, L(mathbb{R}^n, mathbb{R}^m)) cong Bilin(mathbb{R}^n, mathbb{R}^n;mathbb{R}^m) $ is a function from $ U $ into the space of bilinear maps from $ mathbb{R}^ntimes mathbb{R}^n $ to $ mathbb{R}^m $ .
If $ f:Uto mathbb{R}^m $ is twice differentiable, then its second derivative $ d(d f) $ lands in the space of symmetric bilinear maps, i.e. for any $ xin U $ and $ v, win mathbb{R}^n $ we have $ d(d f)x(v, w) = d(d f)x(w, v) $ .
It suffices to assume $ m=1 $ ; otherwise we just consider it componentwise.
Define a function $ g:mathbb{R}to mathbb{R} $ by $ g(xi) = f(x+xi v+w) - f(x+xi v) $ .
Then by the chain rule, $ g $ is differentiable and $ g'(xi) &= d f{x+xi v+w}(v) - d f{x+xi v}(v) &= Big(d f{x+xi v+w}(v) - d f{x}(v)Big) - Big(d f{x+xi v}(v) - d fx(v)Big) &= d(d f){x}(v, xi v + w) + E1 |v|, |xi v + w| - d(d f)x(v, xi v) - E2 |v|, |xi v| &= d(d f)x(v, w) + E |v|, (|v|+|w|) $ where $ E1, E2, E to 0 $ as $ (v, w)to 0 $ .
Now the mean value theorem tells us that for some $ xiin(0, 1) $ we have $ f(x+v+w) - f(x+v) - f(x+w) + f(x) &= g(1) - g(0) &= g'(xi) &= d(d f)x(v, w) + E (|v|+|w|)^(ii) $ But the "second - order difference" $ f(x+v+w) - f(x+v) - f(x+w) + f(x) $ is manifestly symmetric in $ v $ and $ w $ , so we have $ d(d f)x(v, w) - d(d f)x(w, v) = E (|v|+|w|)^2 $ where $ lim{(v, w)to 0} E = 0 $ .
But bilinearity of the LHS then implies that it is identically zero.
The components of the bilinear map $ d(d f) $ are the second - order partial derivatives $ frac{partial^2 f}{partial xi partial xj} $ of $ f $ .
Thus, this theorem says that if $ f $ is twice differentiable, then the mixed partials are equal, $ frac{partial^2 f}{partial xi partial xj} = frac{partial^2 f}{partial xj partial xi} $ .
The second - order partial derivatives may exist without the mixed partials being equal; see below for a counterexample.
However, the theorem shows that if we require $ f $ to actually be twice differentiable rather than merely having second - order partial derivatives, then this cannot happen.
In particular, we have the following corollary, which is more commonly found in textbooks.
If $ f $ has first and second - order partial derivatives, and the latter are continuous in a neighborhood of $ x $ , then the mixed partial derivatives are equal, $ frac{partial^2 f}{partial xi partial xj} = frac{partial^2 f}{partial xj partial xi} $ .
Continuity of the second - order partials implies that the first - order partials are differentiable, and hence so is the differential $ d f $ .
Note that the proof of the theorem implies that if $ f $ is twice differentiable at $ x $ , then there exists a bilinear map $ partial^2 fx : mathbb{R}^n times mathbb{R}^n to mathbb{R}^m $ such that $ f(x+v+w) - f(x+v) - f(x+w) + f(x) = partial^2 fx(v, w) + E(v, w) ({|v|+|w|})^2 $ where $ lim{v, wto 0} E(v, w) = 0 $ .
This is a condition that makes sense as a condition on an arbitrary $ f $ without assuming differentiability.
and if it holds, then the bilinear map $ partial^2 fx $ must be symmetric.
Moreover, as explained here, if $ f $ is differentiable in a neighborhood of $ x $ and satisfies this condition at $ x $ , then it is in fact twice differentiable at $ x $ .
To see this, it suffices to show that each coordinate of $ d f $ is differentiable, so let $ w=delta ei $ , with $ ei $ a unit basis vector and $ delta $ a real number $ neq 0 $ .
Then we have $ E(v, delta ei) = frac{f(x+v+delta ei) - f(x+v) - f(x+delta ei) + f(x) - partial^2 fx(v, delta w)}{{|v|}{delta}} $ Taking the limit as $ deltato 0 $ and using differentiability of $ f $ at $ x $ and $ x+v $ (for sufficiently small $ v $ ), we get $ lim{delta to 0} E(v, delta ei) = frac{d f{x+v}(ei) - d fx(ei) - partial^2 fx(v, ei)}{{|v|}} $ .
Now take the limit as $ vto 0 $ ; on the left we get $ 0 $ by assumption, so the function $ ymapsto d fy(ei) $ is differentiable at $ x $ with derivative $ partial^2 fx( - , ei) $ .
Thus, $ d f $ is differentiable at $ x $ .
On the other hand, this condition by itself does not even imply that $ f $ is continuous.
For instance, if $ f $ is a $ mathbb{Q} $ - linear map $ mathbb{R}to mathbb{R} $ , then the second - order difference $ f(x+v+w) - f(x+v) - f(x+w) + f(x) $ is identically zero.
Let $ f:mathbb{R}^nto mathbb{R} $ be differentiable.
Instead of asking whether $ d f : U to L(mathbb{R}^n, mathbb{R}) $ is differentiable, we can ask whether its exponential transpose $ d f : Utimes mathbb{R}^n to mathbb{R} $ is differentiable.
(Note that $ Utimes mathbb{R}^n $ is the tangent bundle of $ Usubseteq mathbb{R}^n $ .)
This amounts to asking that for $ xin U $ and $ vin mathbb{R}^n $ , we have $ d f{x+w}(v+h) - d fx(v) = d^2 f{(x, v)}(w, h) + E(|w|+|h|) $ for a linear map $ d^2 f{(x, v)}:mathbb{R}^{2n} to mathbb{R} $ , where $ lim{(w, h)to 0} E = 0 $ .
Setting $ h=0 $ , we see that this implies that $ d f : U to L(mathbb{R}^n, mathbb{R}) $ is differentiable, with differential $ d(d f)x = d^2 f{(x, v)}(w, 0) $ for any $ v $ .
And setting $ w=0 $ , we obtain $ d fx(h) = d^2 f{(x, v)}(0, h) $ for any $ v $ .
Thus, we can write $ d^2 f{(x, v)}(w, h) = partial^2 fx(v, w) + d fx(h) $ where $ partial^2 fx $ is the symmetric bilinear map from the previous section.
Conversely, if $ f $ is twice differentiable, then using linearity and continuity of $ d f $ it is easy to see that the above condition holds.
Therefore, these two kinds of twice - differentiability of $ f $ are equivalent as conditions on $ f $ , but the resulting second differential is different.
In the second case, we get $ d^2f = partial^2 f + d f = sum{i, j} frac{partial^2f}{partial xi partial xj} d xi , d xj + sumi frac{partial f}{partial xi} d^2 xi $ .
rather than merely the first term $ sum{i, j} frac{partial^2f}{partial xi partial xj} d xi , d xj $ .
There are two advantages to the second approach (asking that $ d f : Utimes mathbb{R}^n to mathbb{R} $ be differentiable).
Firstly, we can reformulate it in terms of $ f $ by asking that there exists a linear map $ d fx : mathbb{R}^n to mathbb{R}^m $ and a bilinear map $ partial^2 fx : mathbb{R}^n times mathbb{R}^n to mathbb{R}^m $ such that $ f(x+v+w+h) - f(x+v) - f(x+w) + f(x) = partial^2 fx(v, w) + d fx(h) + E(v, w, h) sqrt{{|v|}^2{|w|}^2 + {|h|}^2} $ . where $ lim{v, w, h to 0} E(v, w, h) = 0 $ .
This holds if $ f $ is twice differentiable, for then we can write $ f(x+v+w+h) &= f(x+v+w) + d f_{x+v+w}(h) + E {|h|} &= f(x+v+w) + d fx(h) + d(d f)x(v+w, h) + E {|v+w|}{|h|} + E{|h|} $ and $ d(d f)x(v+w, h) $ can also be incorporated into the error term.
Of course, setting $ h=0 $ we obtain the characterization of twice - differentiability from the previous section.
But setting $ v=w=0 $ , we find that $ f $ is differentiable at $ x $ with derivative $ d fx $ .
So here we have a direct characterization of the second derivative which also implies that the first derivative exists (although it seems that it doesn't imply differentiability in a neighborhood of $ x $ , so that the resulting "second derivative" may not actually be the derivative of the first derivative).
Secondly, the virtue of a second differential incorporating the first derivatives is that like the first differential $ d f $ , but unlike the bilinear map $ partial^2 f $ , it satisfies Cauchy's invariant rule.
This means that we can express the chain rule for second differentials of composite maps simply by substitution: if $ y = f(u) $ and $ u = g(x) $ , then finding $ d^2 y $ in terms of $ d u $ and $ d^2 u $ , and $ d u $ and $ d^2 u $ in terms of $ d x $ and $ d^2 x $ , and substituting, gives the correct expression for $ d^2 y $ in terms of $ d x $ and $ d^2 x $ .
In fact, this can be proven using the above direct characterization of the second differential, in essentially exactly the same way that we prove the ordinary chain rule for first derivatives.
We sketch the proof, omitting the explicit error terms.
We can write $ g(f(x+v+w+h)) - g(f(x+v)) - g(f(x+w)) + g(f(x)) $ as $ g(f(x) + v' + w' + h') - g(f(x) + v') - g(f(x) + w') + g(f(x)) $ where $ v' = f(x+v) - f(x) $ and $ w' = f(x+w) - f(x) $ and $ h' = f(x+v+w+h) - f(x+v) - f(x+w) + f(x) $ .
Now by extra - strong twice differentiability of $ g $ , this is approximately equal to $ partial^2 g{f(x)}(v', w') + d g{f(x)}(h') $ .
But by differentiability of $ f $ , we have $ v' approx d fx(v) $ and $ w' approx d fx(w) $ , while by extra - strong twice differentiability of $ f $ we have $ h' approx partial^2 fx(v, w) + d fx(h) $ .
Thus, we obtain approximately $ partial^2 g{f(x)}(d fx(v), d fx(w)) + d g{f(x)}(partial^2 fx(v, w) + d fx(h)) $ which is exactly what we would get by substitution.
If $ X $ and $ Y $ are $ C^k $ - differentiable manifolds, then we may define what it means for a map $ f:Xto Y $ to be $ n $ times differentiable, or $ C^n $ , for any $ nle k $ , by asking that it yield such a map when restricted to any charts.
The most common case is when $ X $ and $ Y $ are smooth (infinitely differentiable) manifolds, so that we can define $ C^n $ functions between them for all $ nle infty $ .
(Analytic manifolds, which are necessary in order to define analyticity of $ f $ , are somewhat rarer.)
A differentiable map between manifolds induces a map between their tangent bundles $ d f : T X to T Y $ ; this operation extends to a functor from $ C^{k+1} $ manifolds and $ C^{k+1} $ maps to $ C^k $ manifolds and $ C^k $ maps.
See differentiation for more.
{DifferentiabilityOpposedToPartialDifferentiability} The function $ f:mathbb{R}^2 to mathbb{R} $ defined by $ f(x, y) = frac{y^3}{x^2+y^2} &quad (x, y) neq (0, 0) 0 &quad (x, y) = (0, 0) $ is continuous everywhere, and has directional derivatives (def. ) at $ (0, 0) $ in all directions, but is not differentiable at $ (0, 0) $ in the sense of def. .
Note that the (unnormalized) directional derivative along the vector $ (a, b) $ is $ frac{b^3}{a^2+b^2} $ , which is not linear.
One may wonder whether existence of a linear map $ d fx $ is enough, but this is also not the case.
The function $ f:mathbb{R}^2 to mathbb{R} $ defined by $ f(x, y) = frac{y^3}{x} &quad xneq 0 0 &quad x=0 $ has all directional derivatives at $ (0, 0) $ equaling $ 0 $ , so that in particular there is a linear map $ d f{(0, 0)} $ whose values are the directional derivatives.
But it is not differentiable at $ (0, 0) $ ; in fact, it is not even continuous at $ (0, 0) $ .
(Thus it also provides an example of a discontinuous function which has all directional derivatives.)
The discontinuity kind of gives this last one away; maybe a continuous function with all directional derivatives must be differentiable?
But no, because if $ W $ is a Weierstrass function (continuous everywhere but differentiable nowhere) from $ mathbb{R} $ to $ mathbb{R} $ with period $ 2pi $ , and $ operatorname{atan2} $ is a $ 2 $ - argument arctangent function from $ mathbb{R}^2 $ to $ mathbb{R} $ (so that $ sqrt{x^2+y^2} , sin, operatorname{atan2}(y, x) = y $ and $ sqrt{x^2+y^2} , cos, operatorname{atan2}(y, x) = x $ for all $ x $ and $ y $ ), then set $ f(x, y) = (x^2 + y^2) W(operatorname{atan2}(y, x)) $ .
Then $ f $ is, like $ W $ , continuous everywhere and differentiable nowhere, yet the directional derivatives through the origin are all $ 0 $ .
There are further examples (including one that is analytic except at the origin) at Math StackExchange question 149704(iii) Let $ k $ be a natural number, and consider the function $ fk(x) coloneqq x^k sin(1/x) $ from the real line to itself, with $ f(0) coloneqq 0 $ .
Away from $ 0 $ , $ fk $ is smooth (even analytic); but at $ 0 $ , $ f0 $ is not continuous, $ f1 $ is continuous but not differentiable, $ f2 $ is differentiable but not continuously differentiable, and so on: Similarly, in two dimensions we can consider functions such as $ f(x, y) = (x^2+y^2)sin(frac{1}{sqrt{x^2+y^2}}) $ .
together with $ f(0, 0) = 0 $ .
This is smooth away from $ 0 $ , and once differentiable at $ 0 $ , even in the strong sense that it is well - approximated by a linear function near $ 0 $ .
However, its derivative is not continuous at $ 0 $ .
In particular, this shows that the converse of the theorem "if the partial derivatives exist and are continuous at a point, then the function is differentiable there" fails, even in higher dimensions.
Uniform differentiability is stronger than continuous differentiability but independent of twice differentiability.
For an example that is uniformly differentiable but not twice differentiable, use $ f3 $ again.
For an example that that is twice differentiable (and hence continuously differentiable) but not uniformly differentiable, use $ x mapsto x^3 $ .
However, on a compact domain, any continuously differentiable function (and a fortiori any twice differentiable function) must be uniformly continuous (at least in classical and intuitionistic mathematics).
The function $ f:mathbb{R}^2 to mathbb{R} $ defined by $ f(x, y) = frac{x y (x^2 - y^2)}{x^2+y^2} $ plus $ f(0, 0) = 0 $ , has partial derivatives $ frac{partial^2f}{partial x partial y} $ and $ frac{partial^2f}{partial y partial x} $ that both exist but are not equal at $ (0, 0) $ (nor are they continuous at $ (0, 0) $ ).
Therefore, by the theorem proven above, it is not twice differentiable at $ (0, 0) $ .
While differentiability means approximability by a linear function, twice differentiability does not mean approximability by a quadratic function.
For example, the function $ f(x) = x^3 sin(1/x) $ (with $ f(0) =0 $ , to make it continuous there) is not twice differentiable at $ x=0 $ , but it is well - approximated by the quadratic polynomial $ p(x) = 0 $ in the sense that their difference is $ o(x^2) $ as $ xto 0 $ .
Even worse, the function $ f(x) = e^{ - 1/x^2} sin(e^{1/x^2}) $ is not twice differentiable at $ x=0 $ , but it is well - approximated by a polynomial of any finite degree $ n $ (namely, the zero polynomial), in the sense that their difference is $ o(x^n) $ as $ xto 0 $ .
In some contexts, it is useful to say that functions such as these have "pointwise second derivatives".
More precisely, we say that a function $ f $ has a pointwise $ k^{th} $ derivative at $ a $ if it is continuous at $ a $ and there exists a polynomial $ p $ of degree $ k $ such that $ lim{xto a} frac{f(x) - p(x)}{(x - a)^k} = 0 $ .
(We have to state continuity explicitly in order to match the usual notion of differentiability when $ k = 1 $ , since nothing in this limit constrains the value of $ f(a) $ .)
In this case, the pointwise $ k^{th} $ derivative is $ f^{(k)}{pt}(a) = p^{(k)}(a) $ (and it follows that all lower - order pointwise derivatives match as well).
Thus we would say that while $ f(x) = x^3 sin(1/x) $ does not have a second derivative at $ 0 $ , it does have a *pointwise* second derivative at $ 0 $ , and $ f{pt}''(0) = 0 $ .
Similarly, $ e^{ - 1/x^2} sin(e^{1/x^2}) $ is pointwise smooth.
See e.g. this MSE answer.
The polynomial $ p $ may be thought of as the $ k $ th - order Taylor polynomial of $ f $ at $ a $ , and the limit above is Taylor's theorem with the Peano remainder.
(Thus the subscript $ pt $ can be thought of as standing for &8216;Peano - - Taylor&8217; as well as for &8216;pointwise&8217;.)
Note that while $ k $ - times pointwise differentiability is weaker than $ k $ - times differentiability for $ k gt 1 $ and equivalent for $ k = 1 $ , it is stronger for $ k = 0 $ (since even $ 0 $ - times pointwise differentiability requires continuity).
In the definition of strong twice - differentiability, we cannot replace the symmetric bilinear map $ partial^2 fx(v, w) $ by the corresponding quadratic form $ Qx(v) = partial^2fx(v, v) $ .
In other words, if we suppose that $ f(x+2v) - 2 f(x+v) + f(x) = Qx(v) + E(v) {|v|}^2 $ where $ lim{vto 0} E(v) = 0 $ , for some quadratic form $ Qx $ , it does not follow that $ f $ is twice differentiable at $ x $ , even in one dimension.
The same old counterexample $ f(x) = x^3 sin(1/x) $ (with $ f(0)=0 $ ) works: we have $ f(0+2v) - 2 f(0+v) + f(0)= 2v^3(4sin(frac{1}{2v}) - sin(frac{1}{v})) $ so $ E(v) = v (4sin(frac{1}{2v}) - sin(frac{1}{v})) to 0 $ .
Early account, in the context of Cohomotopy, cobordism theory and the Pontryagin - Thom construction: The motivating idea of the derivative in differential calculus is that it is approximated by a ratio of differences.
We may also say that an instantaneous rate of change is approximated by an average rate of change.
The Mean Value Theorem (MVT) reverses this, and says that any average rate of change is equal to some instantaneous rate of change, if certain differentiability conditions are met.
The name comes from the fact that, due to the fundamental theorem of calculus, an average rate of change over an interval may be viewed as an average (or mean) of the instantaneous rates of change along the interval.
Thus, the theorem states that the mean value of the derivative on an interval is attained somewhere in that interval.
There are traditionally three versions of increasing generality, although even the most general version is implicit in the most specific version (requiring only a linear coordinate transformation).
Suppose that $ a lt b $ are real numbers and $ f $ is a continuous real - valued function on $ a, b $ .
If $ f $ is differentiable on the interior $ {a, b} $ , and if $ f(a) = f(b) $ , then for some $ c in {{a, b}} $ , $ f'(c) = 0 $ .
Suppose that $ a lt b $ are real numbers and $ f $ is a continuous real - valued function on $ a, b $ .
If $ f $ is differentiable on the interior $ {a, b} $ , then for some $ c in {{a, b}} $ , $ f'(c) = frac {f(b) - f(a)} {b - a} , $ or equivalently $ f'(c) (b - a) = f(b) - f(a) $ .
Suppose that $ a lt b $ are real numbers and $ f $ and $ g $ are continuous real - valued functions on $ a, b $ .
If $ f $ and $ g $ are differentiable on the interior $ {a, b} $ , then for some $ c in {{a, b}} $ , $ f'(c) (g(b) - g(a)) = g'(c) (f(b) - f(a)) ; $ assuming that $ f' $ and $ g' $ are never simultaneously zero in $ {a, b} $ and that $ (f(a), g(a)) neq (f(b), g(b)) $ , then for some $ c in {{a, b}} $ , $ frac {f'(c)} {g'(c)} = frac {f(b) - f(a)} {g(b) - g(a)} , $ where either side of this equation is allowed to be interpreted as $ infty $ in case it is division by zero (necessarily with a nonzero dividend under these conditions); or perhaps better, an equality of ratios: $ f'(c) : g'(c) :: f(b) - f(a) : g(b) - g(a) $ .
If we write $ u $ for $ f(x) $ and $ v $ for $ g(x) $ , then this last version states that $ left.{frac{mathrm{d}u}{mathrm{d}v}}right|{x=c} = left.{frac{Delta{u}}{Delta{v}}}right|{x=a}^b $ .
Compare this to the definition $ left.{frac{mathrm{d}u}{mathrm{d}v}}right|{x=a} coloneqq lim{bto{a}} left.{frac{Delta{u}}{Delta{v}}}right|{x=a}^b $ (although this is really only a definition when $ v $ is $ x $ , which reduces Cauchy's theorem to Lagrange's).
Rolle's theorem is usually called just 'Rolle's' theorem, being the only result attributed today to Michel Rolle; but Lagrange's and Cauchy's theorems must be called 'mean value' theorems, as Joseph - Louis Lagrange and Augustin - Louis Cauchy did far more.
By default, the term 'Mean Value Theorem' usually refers to Lagrange's theorem.
(But neither Rolle nor Lagrange proved their theorem in the general case; the first proofs of all of them are due to Cauchy in 1823, a decade after Lagrange's death and more than a century after Rolle's death.)
One consequence of these mean - value theorems if that if the relevant derivatives (or ratios of derivatives) are bounded, then the corresponding differences (or ratios of differences) will also be bounded.
We state this for Lagrange's theorem, although there are versions that correspond more to Rolle's or Cauchy's.
Suppose that $ a lt b $ are real numbers and $ f $ is a continuous real - valued function on $ a, b $ .
If $ f $ is differentiable on the interior $ {a, b} $ , and we have $ m leq f' leq M $ on $ {a, b} $ for some constants $ m $ and $ M $ , then $ m leq frac {f(b) - f(a)} {b - a} leq M $ .
A slightly weaker statement is $ {|{f(b) - f(a)}|} leq {|{b - a}|} , sup{{a, b}} {|{f'}|} , $ which is true even if the derivative is unbounded (in which case the right - hand side is infinite).
In constructive mathematics, the mean - value theorems generally cannot be proved, since it may be impossible to find the value $ c $ (although some variations with stronger hypotheses or weaker conclusions can often be proved, similarly to the Intermediate - Value Theorem).
However, the mean - value inequality is true in constructive mathematics, as long as $ f $ is uniformly differentiable on every closed subinterval of $ {a, b} $ (as is typical).
The second form of the mean - value inequality shows the relationship of differentiability to Lipschitz continuity: a continuous function on an interval with bounded derivative on the interior of the interval is Lipschitz continuous on that interval (and the supremum of the absolute value of the derivative is the Lipschitz constant).
If $ k $ is a field, given the polynomial ring $ kx $ , there is a canonical ring homomorphism $ j:kx to (k to k) $ which sends constant polynomials in $ kx $ to constant functions in $ k to k $ , and the generator $ x in kx $ to the identity function $ idk $ , where $ k to k $ is the function algebra on $ k $ .
There is a function $ i:k(x) to {A in Ob(Part(k)) vert Hom(A, k) } $ from the field of rational expression to the set of all partial functions in the category of partial functions $ Part(k) $ , where the function algebra $ k to k $ is the endomorphism $ k $ - algebra on the improper subset $ k $ .
The function $ i $ is defined as follows: given two polynomials $ p, q in kx $ where $ q neq 0 $ , for all $ x in {a in k | q(a) neq 0 } $ $ ileft(frac{p}{q}right)(x) coloneqq frac{j(p)(x)}{j(q)(x)} $ where for $ x in k $ and $ y in k $ $ frac{x}{y} $ is the division of $ x $ by $ y $ in $ k $ , and for $ r in k(x) $ and $ s in k(x) $ , $ frac{r}{s} $ is the division of $ r $ by $ s $ in $ k(x) $ .
A rational function $ f $ is an element of the image of $ i $ , $ f in im(i) $ .
It is perhaps more illuminating to think of this partial function (with domain $ D $ ) as coming from a (total) function $ p/q: mathbb{P}^1(k) to mathbb{P}^1(k) $ on the projective line, where we have inclusion functions $ i: k to mathbb{P}^1(k) $ and the partial function is given by the pair of projection maps in the pullback $ array{ D & to & k downarrow & & downarrowmathrlap{i} k & underset{p/q circ i}{to} & mathbb{P}^1(k) } $ It should also be noticed that such endofunctions $ p/q $ on $ mathbb{P}^1(k) $ are closed under composition (except that special provision must be made for the constant function valued at $ infty $ , which corresponds to the "fraction" $ 1/0 $ ).
This comes from the fact that the reciprocal function is not a multiplicative inverse of the identity function $ f(x) = frac{x}{x} neq 1 $ , due to the fact that $ f(x) $ is undefined at $ 0 $ , and thus has a different domain than the constant function $ 1 $ , which is the multiplicative unit.
rational functions are continuous on their domain of definition On the homotopy type of spaces of rational maps from the Riemann sphere to itself (related to the moduli space of monopoles in $ mathbb{R}^3 $ and to the configuration space of points in $ mathbb{R}^2 $ ): Classically, a logarithm is a partially - defined smooth homomorphism from a multiplicative group of numbers to an additive group of numbers.
As such, it is a local section of an exponential map.
As exponential maps can be generalised to Lie groups, so can logarithms.
Consider the field of real numbers; these numbers form a Lie group under addition (which we will call simply $ mathbb{R} $ ), while the nonzero numbers form a Lie group under multiplication (which we will call $ mathbb{R}^* $ ).
The multiplicative group has two connected components; we will focus attention on the identity component (which we will call $ mathbb{R}^+ $ ), consisting of the positive numbers.
The Lie groups $ mathbb{R} $ and $ mathbb{R}^+ $ are in fact isomorphic.
In fact, there is one isomorphism for each positive real number $ b $ other than $ 1 $ ; this number $ b $ is called the base.
Fixing a base, the map from $ mathbb{R}^+ $ to $ mathbb{R} $ is called the real logarithm with base $ b $ , written $ x mapsto logb x $ ; the map from $ mathbb{R} $ to $ mathbb{R}^+ $ is the real exponential map with base $ b $ , written $ x mapsto b^x $ .
The real logarithms are handily defined using the Riemann integral of the reciprocal as follows: array { ln x & coloneqq int1^x frac{1}{t} , mathrm{d}t ; logb x & coloneqq frac{ln x}{ln b} .
} Note that $ ln $ is itself a logarithm, the natural logarithm, whose base is $ mathrm{e} = (ii)71828182845ldots $ .
(The exponential map may similarly be defined as an infinite series, but I'll leave that for its own article.)
Now consider the field of complex numbers; these also form a Lie group under addition (which we call $ mathbb{C} $ ), while the nonzero numbers form a Lie group under multiplication (which we call $ mathbb{C}^ $ ).
Now the multiplicative group is connected, so we would like to use all of it.
However, $ mathbb{C} $ and $ mathbb{C}^ $ are not isomorphic.
Indeed, the multiplication map $ mathbb{R}^ times S^1 to mathbb{C}^ $ exhibits $ mathbb{C}^ $ as a biproduct of $ mathbb{R}^ $ and the circle group $ S^1 $ , so that homomorphisms $ mathbb{C}^ to mathbb{C} $ are given by pairs of homomorphisms $ f colon mathbb{R}^ to mathbb{C} $ , $ g colon S^1 to mathbb{C} $ .
But every homomorphisms $ g colon S^1 to mathbb{C} $ is trivial: the restriction of $ g $ to the torsion subgroup of $ S^1 $ is trivial since $ mathbb{C} $ is torsionfree, and since the torsion subgroup is dense in $ S^1 $ , any Lie group homomorphism $ S^1 to mathbb{C} $ must also be trivial.
Therefore, every homomorphism $ h colon mathbb{C}^ to mathbb{C} $ factors through the projection $ mathbb{C}^ to mathbb{R}^ $ .
It quickly follows that no such $ h $ can be injective, nor can such $ h $ be surjective.
Taking advantage of biproduct representations $ mathbb{C} cong mathbb{R} oplus mathbb{R} $ and $ mathbb{C}^ cong mathbb{R}^ oplus S^1 $ , we can classify homomorphisms from $ mathbb{C} $ to $ mathbb{C}^ $ .
Each is given by a 4 - tuple of real numbers $ (a, b, c, d) $ : $ phi{a, b, c, d}(x + i y) = e^{a x} e^{i b x} e^{c y} e^{i d y} $ .
The cases where $ a = d $ , $ b = - c $ correspond to those homomorphisms that are holomorphic functions (i.e., that satisfy the Cauchy - Riemann equations).
Putting $ w = a + b i $ , we have $ phi{a, b, - b, a}(z) = e^{w z} $ with one such homomorphism for each complex number $ w $ , and these homomorphisms are surjections whenever $ w ne 0 $ .
(N.B.: these homomorphisms are not uniquely determined by their values at $ z = 1 $ , since we have $ e^w = e^{w'} $ whenever $ w - w' $ is an integer multiple of $ 2 pi i $ , and yet the homomorphisms $ z mapsto e^{w z} $ and $ z mapsto e^{w' z} $ will be different unless $ w = w' $ .)
So we have these surjections (the complex exponential map $ z mapsto e^{w z} $ , for $ w ne 0 $ ), which are regular epimorphisms but not split epimorphisms.
However, while they have no sections (being not split), they have quite a few local sections, and the domains of the maximal local sections are precisely the connected simply connected open dense subspaces $ R $ of $ mathbb{C}^ $ .
A complex logarithm with exponential base $ w $ on $ R $ is this $ R $ - defined section of the complex exponential map $ z mapsto e^{w z} $ .
Supposing $ R $ given, we denote this by $ log{w} $ (but please note that in the context of real logarithms, this would ordinarily be denoted $ logb $ where $ b = e^w $ ).
If $ 1 in R $ , then a complex natural logarithm on $ R $ may be defined using the contour integral with the same formula (eq:integrals) as for the real natural logarithm.
We merely insist that the integral be done along a contour within the region $ R $ .
(Since $ R $ is connected, there is such a contour; since $ R $ is simply connected and $ t mapsto 1/t $ is holomorphic, the result is unique.)
Note that if $ x in mathbb{R}^+ subseteq R $ , then the real and complex natural logarithms of $ x $ will be equal.
The natural exponential map is periodic (with period $ 2 pi mathrm{i} $ ), and it is possible to add any multiple of this period to the natural logarithm of any $ x ne 1 $ by suitably changing the region $ R $ .
We then obtain the most general notion of maximally - defined complex logarithm with any base by using the formulas $ array { ln x & coloneqq C + int_{mathrm{e}^C}^x frac{1}{t} , mathrm{d}t, log_{w} x & coloneqq frac{ln x}{w} . } $ In the classical examples, the multiplicative groups $ mathbb{R}^+ $ and $ mathbb{C}^ $ both Lie groups.
The additive groups $ mathbb{R} $ and $ mathbb{C} $ are also Lie groups, but they are more than this: they are Lie algebras.
(The additive group of a Lie algebra is always a Lie group.
Actually, since these are abelian Lie algebras, their Lie - algebra structure is easy to miss, but of course they are vector spaces.)
And what's more, each additive group is the Lie algebra of the corresponding Lie group.
This generalises.
Given any Lie group $ G $ , let $ mathfrak{g} $ be its Lie algebra.
Then we have an exponential map $ expcolon mathfrak{g} to G $ , which is surjective under certain conditions (most famously when $ G $ is connected and compact, but also in the classical cases, even though $ G $ is not compact).
More generally, given any automorphism $ phi $ of $ mathfrak{g} $ , we have a map $ x mapsto exp(phi(x)) $ , which is a homomorphism of Lie groups.
Any local section of this map may be called a logarithm base $ phi $ on $ G $ (denoted $ log{phi} $ with the bracket as in the previous section); any local section of $ exp $ itself may be called a natural logarithm on $ G $ .
The Taylor series of the natural logarithm around $ 1 in mathbb{R} $ is the following series: underoverset{n = 0}{infty}{sum} tfrac{1}{n!} left( frac{d^n}{ d x^n} ln(1 + x)
right){vert x = 0} x^n & ;; = ;; underoverset{n = 1}{infty}{sum} frac {( - 1)^{n+1}} {n} x^n & ;; = ;; x - tfrac{1}{2} x^2 + tfrac{1}{3} x^3 - tfrac{1}{4} x^4 + cdots , .
For the first two terms notice that $ ln(1 + x) ;xrightarrow{x to 0}; ln(1) , =, 0 $ and that the derivative of the natural logarithm is: $ frac{d}{d x} ln(1 + x) ;=; tfrac{1}{1+x} ;xrightarrow{ x to 0 }; 1 , $ .
From here on, noticing for $ k in mathbb{N}+ $ that: $ frac{d}{d x} left( frac{1}{(1 + x)^k} right) ;=; - k frac{1}{(1 + x)^{k+1}} ;xrightarrow{x to 0}; - k $ we get, for $ n in mathbb{N}+ $ : $ frac{d^n}{d x^n} ln(1 + x) & ;=; frac{d^{n - 1}}{d x^{n - 1}} left( frac{1}{1 + x} right) & ;=; (n - 1)! cdot ( - 1)^{n - 1} frac{1}{(1 + x)^{n - 1}} & ;xrightarrow{ x to 0 }; (n - 1)! cdot ( - 1)^{n+1} , $ .
Plugging this into the defining equation on the left of (eq:MercatorTaylorSeriesForNaturalLogarithm) and using $ frac{(n - 1)!}{n!} = frac{1}{n} $ yields the claim.
Historical textbooks: (...)
The notion of power object generalizes the notion of power set from the category Set to an arbitrary category with finite limits.
Let $ C $ be a category with finite limits.
A power object of an object $ c in C $ is such that $ chir : d to Omega^c $ such that $ r $ is the pullback $ array{ r &to& inc downarrow && downarrow c times d &stackrel{Idc times chir}{to}& c times Omega^c } $ If $ C $ may lack some finite limits, then we may weaken that condition as follows: $ array { & c & leftarrow & r & rightarrow & d & Idc & downarrow & & downarrow & & downarrow & chir & c & leftarrow & inc & rightarrow & Omega^c & } $ A trigonometric function is one derived from the basic functions of trigonometry, $ cos $ , $ sin $ (cosine and sine), which themselves are the standard coordinate functions (equivalently: product projections $ pri $ ) of the Cartesian space $ mathbb{R}^2 $ , restricted to the unit circle: $ array{ & && mathbb{R} & & {}^{mathllap{cos}}nearrow & biguparrow{}^{ mathrlap{pr1} } mathbb{R} overset{exp}{longrightarrow} & S^1 &hookrightarrow& mathbb{R}^2 &simeq& mathbb{R} times mathbb{R} & & {}{mathllap{sin}}searrow & bigdownarrow{}^{ mathrlap{pr2} } & && mathbb{R} } , , $ or rather the result of composing these restrictions with an arc length parametrization $ mathbb{R} overset{exp}{to} S^1 $ .
They are also called circular functions.
In elementary mathematics, there are six traditional trigonometric functions; (i) sine $ ; $ $ sin $ (i) cosine $ ; $ $ cos $ (i) tangent $ ; $ $ tan = frac{sin}{cos} $ , (i) cotangent $ ; $ $ cot = frac{cos}{sin} $ , (i) secant $ ; $ $ sec = frac1{cos} $ , (i) cosecant $ ; $ $ csc = frac1{sin} $ .
The early view was that these functions measured the six possible ratios of side lengths of right triangles (as a basic case in terms of which other triangles can be analyzed; "trigonometry" = "triangle measure").
These six functions figure prominently in Euclidean geometry where the angles of a triangle sum to arc length $ pi $ .
There are more elaborate offshoots such as spherical trigonometry (see elliptic geometry) which was historically important for terrestrial navigation.
Moreover, there are the related hyperbolic functions (see hyperbolic geometry) which result from a projective change of conic section (from a circle to a hyperbola).
The most useful modern approach to cos and sin comes from taking Euler's formula as a working definition: Let $ exp ;colon; mathbb{C} longrightarrow mathbb{C}^ast $ be the complex exponential function, defined by the exponential power series formula $ exp(z) ;coloneqq; sum{n geq 0} frac{z^n}{n!} , $ .
These satisfy the following fundamental exponential identities: As a result, if $ z + widebar{z} = 0 $ (i.e., if $ z $ is purely imaginary: $ z = i t $ for some $ t in mathbb{R} $ ), we have $ exp(z) cdot widebar{exp(z)} = 1 $ so that $ w = exp(z) $ lies on the unit circle defined by $ wwidebar{w} = 1 $ .
The cosine function $ cos: mathbb{R} to mathbb{R} $ is defined by $ cos(t) = Re(exp(i t)) $ (real part); the sine function $ sin: mathbb{R} to mathbb{R} $ is defined by $ sin(t) = Im(exp(i t)) $ (imaginary part).
In other words: $ exp(i t) = cos(t) + isin(t) $ (Euler).
This implies that $ cos(t) = frac1{2}(exp(i t) + exp( - i t)) $ and $ sin(t) = frac1{2 i}(exp(i t) - exp( - i t)) $ ; these equations suggest the simple analytic continuation of $ cos $ and $ sin $ to functions $ mathbb{C} to mathbb{C} $ on the entire complex plane.
More or less immediate consequences of the definition include These name but a few of many trigonometric identities, facility in which can serve as a modern - day shibboleth or barrier of passage in high school or lower - level undergraduate courses in mathematics.
They seem also to be popular in mathematics education in India and appear regularly in entrance examinations there.
But the ones listed above are the most fundamental.
There is no question that the trigonometric functions are rich in significance; for example; various representations of the tangent, cotangent, secant, etc. appear in enumerative combinatorics (as in the problem of counting alternating permutations), representations of Bernoulli numbers, and so on.
An inverse trigonometric function is a right inverse to one of the six standard trigonometric functions, or more precisely a continuous right inverse to the epimorphism part of the (epi, mono) factorization of a trigonometric function.
Inverse functions are often named using the prefix "arc", so that for example "arcsine" is another name for the inverse sine.
This naming arises because the values of an inverse trigonometric function are considered as arc lengths, just as trigonometric functions themselves are defined in terms of arc length parametrizations.
Another possible reason for using the arc - prefix is to avoid a notational confusion, where for example $ cos^{ - 1} $ might easily be confused with the reciprocal of the cosine function, inasmuch as the notation $ cos^n $ is commonly used to denote an $ n^{th} $ power of the cosine.
Since many such right inverses are possible, the choice of right inverse is a matter of convention.
For the arcsine and arctangent, the choice is dictated by having $ 0 $ as a fixed point.
This leads to convenient power series representations in neighborhoods of the origin, for example $ arctan(x) = x - frac{x^3}{3} + frac{x^5}{5} - ldots $ For other inverse trigonometric functions, the choice is dictated by convenient formulas such as $ arccos(x) = frac{pi}{2} - arcsin(x), qquad arccot(x) = frac{pi}{2} - arctan(x) $ while we also have $ arcsec(x) = arccos(frac1{x}), qquad arccsc(x) = arcsin(frac1{x}) $ .
See also (...)
See also: In analysis, uniform convergence refers to a type of convergence of sequences $ (fn){n in mathbb{N}} $ of functions $ fn colon X to mathbb{R} $ into the real numbers.
In terms of epsilontic analysis such a sequence converges uniformly to some function $ f colon X to mathbb{R} $ if for each positive real number $ epsilon gt 0 $ there exists a natural number $ Nepsilon in mathbb{N} $ such that if $ n geq N(epsilon) $ then for all points $ x in X $ the difference (in absolute value) between the value of $ fn $ at that point and that of $ f $ at that point is smaller than $ epsilon $ : $ underset{epsilon gt 0}{forall} ; underset{N(epsilon) in mathbb{N}}{exists} ; underset{n geq N(epsilon)}{forall} ; underset{x in X}{forall} ; , vert fn(x) - f(x) vert lt epsilon , $ .
What us uniform about this convergence is that the bound $ N(epsilon) $ is required to work for all $ x in X $ (hence uniformly over $ x $ ).
This is in contrast to pointwise convergence where one allows a different bound $ N $ to exist for each $ epsilon $ and each point $ x in X $ separately.
Since for non - finite $ X $ the maximum of all such local choices of $ N $ in general does not exist, uniform convergence is a stronger condition than pointwise convergence.
Let (i) $ X $ be a set; (i) $ Y $ a complete metric space.
Consider the set $ F(X, Y) $ of functions $ X to Y $ as a metric space via the supremum norm.
Then this is again complete: every Cauchy sequence of functions converges uniformly.
If $ X $ is equipped with the structure of a topological space and if the Cauchy sequence of functions consist of continuous functions, then also the limit function is continuous.
(e.g. Gamelin - Greene 83, theorem I (ii)5 and II (iii)5) The radius of convergence of a power series tells how far out the series will converge.
Let $ a = (a0, a1, ldots) $ be an infinite sequence of complex numbers, let $ zeta $ be a particular complex number, and consider the power series sumn an (z - zeta)^n .
The radius of convergence is the supremum of the positive numbers $ epsilon $ such that (eq:series) converges for $ {|z - zeta|} lt epsilon $ .
(This supremum is a nonnegative lower real in $ 0, infty $ .)
The phrasing above is ambiguous.
If $ epsilon $ is less than the radius of convergence, does this mean that (eq:series) converges for every $ z $ with $ {|z - zeta|} leq epsilon $ or for some such $ z $ ?
It doesn't matter:
If (eq:series) converges for some $ z $ with $ {|z - zeta|} = epsilon $ , then (eq:series) converges for every $ z $ with $ {|z - zeta|} lt epsilon $ .
(We do not say that (eq:series) converges for $ z $ with $ {|z = zeta|} = epsilon $ , but this has no effect on the supremum.)
The radius of convergence is clearly independent of $ zeta $ .
It can be calculated quite easily from the coefficients $ ai $ : The radius of converge of (eq:series) is $ R = liminfn {|an|}^{ - 1/n} $ .
For $ {|z - zeta|} lt R $ , (eq:series) is (pretty much by definition) an analytic function of $ z $ .
There is a partial converse: If a function $ f $ is analytic at all $ z $ with $ {|z - zeta|} lt R $ , then there is a power series (eq:series) that converges to $ f(z) $ for all $ z $ with $ {|z - zeta|} lt R $ .
(Specifically, $ an = f^{(n)}(zeta)/n! $ .)
Over the real numbers, Theorem&160; fails.
I'm sure (says one of this pages authors) that there are interesting things to say about series in adic numbers, matrices, and things like that, but I don't know them.
A function $ f $ between complex manifolds is holomorphic if it is complex - differentiable, or equivalently complex - analytic.
One may also see definitions referring to the intermediate notions of continuous differentiability or infinite differentiability.
The theorem that every continuously complex - differentiable function is analytic is soft and due to Augustin Cauchy; the theorem that every complex - differentiable function is continuously differentiable is hard and due essentially to Édouard Goursat (which may be seen as filling in a gap in Cauchy's proof).
See Cauchy integral formula and Goursat theorem.
On infinite - dimensional manifolds, we have several notions of holomorphic function; see Wikipeda.
In relation to the homotopy - theoretic Oka principle: A topological space is called locally path - connected if it has a basis of path - connected neighbourhoods.
In other words, if for every point $ x $ and neighbourhood $ V ni x $ , there exists a path - connected neighbourhood $ U subset V $ that contains $ x $ .
Let $ X $ be a locally path connected space.
Then the path connected component $ Px subset X $ over any point $ x in X $ is an open set.
It is sufficient to show that every point $ y in Px $ has a neighbourhood $ Uy $ which is still contained in $ Px $ .
But by local path connectedness, $ y $ has a neighbourhood $ Vy $ which is path connected.
It follows by concatenation of paths that $ Vy subset Px $ .
A locally path - connected space is connected if and only if it is path - connected.
The connected components of a locally path - connected space are the same as its path - connected components.
A path connected component is always connected (this lemma), and in a locally path - connected space is it also open (lemma ).
This means that every path - connected component is also connected.
Conversely, it is now sufficient to see that every connected component is path - connected.
Suppose it were not, then it would be covered by more than one disjoint non - empty path - connected components.
But by lemma these would be all open.
This would be in contradiction with the assumption that $ U $ is connected.
Hence we have a proof by contradiction.
For $ n in mathbb{N} $ then Euclidean space $ mathbb{R}^n $ (with its metric topology) is locally path - connected, since each open ball is path - connected topological space.
Similarly the open intevals, closed intervals and half - open intervals, regarded as topological subspaces of the Euclidean real line, are locally path connected.
Every open subspace of a locally path connected topological space is itself locally path connected.
The Euclidean circle $ S^1 = left{ x in mathbb{R}^2 ;vert; {Vert xVert} = 1right } subset mathbb{R}^2 $ is locally path connected.
By definition of the subspace topology and the defining topological base of the Euclidean plane, a base for the topology of $ S^1 $ is given by the images of open intervals under the local homeomorphism $ (cos( - ), sin( - )) ;colon; mathbb{R}^1 to S^1 , $ .
But these open intervals are locally path connected by example , and in fact they are, evidently path - connected topological space.
The condition is a necessary assumption in the in the form of the condition for An inhabited graph has two notions of being connected: If a graph's edges are undirected these two notions coincide while if directed the stronger condition implies the weaker.
For the various categories of graphs, which of their objects are weakly connected correspond to the general notion of connected objects in these categories.
A function such that its square has a well - defined integration against a given measure.
The chain rule is the statement that differentiation $ d : Diff to Diff $ is a functor on Diff: given two smooth functions between smooth manifolds $ f : X to Y $ and $ g : Y to Z $ we have $ d(g circ f) : T X stackrel{d f}{to} T Y stackrel{d g}{to} T Z , $ .
If one thinks of a tangent vector $ v in Tx X $ to be an equivalence class of a smooth path $ gammav : - epsilon, epsilon to X $ , for some $ epsilongt 0 $ , with $ gamma(0) = x $ , then the chain rule is the associativity of the composite $ - epsilon, epsilon stackrel{gammav}{to} X stackrel{f}{to} Y stackrel{g}{to} Z , $ .
Bracketed as $ (g circ f)circ gammav $ this represents $ d(g circ f)(v) $ .
Bracketed as $ g circ (f circ gammav) $ is represents
$ d g (d f (v)) $ .
Alternatively, in a context of synthetic differential geometry where with $ D $ being the infinitesimal interval we may identify $ v $ with $ v : D to X $ , the chain rule is the associativity of $ D stackrel{v}{to} X stackrel{f}{to} Y stackrel{g}{to} Z , $ .
Let $ X = Y = Z = mathbb{R} $ the real line.
Then the tangent bundle $ T X $ is canonically identified with $ mathbb{R} times mathbb{R} $ .
Given two functions, $ f, g : mathbb{R} to mathbb{R} $ their derivatives are traditionally regarded again as functions $ f', g' : mathbb{R} to mathbb{R} $ , though strictly speaking we are to think of them as the maps $ d f, d g : mathbb{R} times mathbb{R} = T mathbb{R} to T mathbb{R} = mathbb{R} times mathbb{R} $ given by $ d f : (x, v) mapsto (f(x), v f'(x)) $ and $ d g : (x, v) mapsto (g(x), v g'(x)) , $ .
The composite $ d (g circ f) : mathbb{R} times mathbb{R} = T mathbb{R} to T mathbb{R} = mathbb{R} times mathbb{R} $ is therefore the map $ d(g circ f) : (x, v) mapsto (f(x), v f'(x)) mapsto (g(f(x)), v f'(x) g'(f(x))) , $ .
Therefore we have $ (g circ f)'(x) = f'(x) g'(f(x)) , $ .
This is the form in which the chain rule is usually introduced in elementary calculus.
While the chain rule is of great theoretical importance, it is completely unnecessary for the working out of derivatives of elementary functions in ordinary calculus (including the multivariable case).
Every result giving the derivative of an elementary function corresponds to a rule (along the lines of the product rule) for the operation of that function to any expression.
For example, instead of learning that $ frac{mathrm{d}}{mathrm{d}x} (sin x) = cos x $ and then applying both this fact and the chain rule to find the derivative of an expression of the form $ sin u $ , just learn $ frac{mathrm{d}}{mathrm{d}x} (sin u) = cos u , frac{mathrm{d}u}{mathrm{d}x} $ and apply this rule directly; the original fact is the special case in which $ u coloneqq x $ .
Even better, learn the rule as $ mathrm{d}(sin u) = cos u , mathrm{d}u ; $ then it applies without further modification to multivariable calculus (as well as implicit differentiation, related rates, integration by substitution, and other stock features of one - variable calculus).
The chain rule could still be used in the proof of this 'sine rule'.
Even so, it is quite possible to prove the sine rule directly (much as one proves the product rule directly rather than using the two - variable chain rule and the partial derivatives of the function $ x, y mapsto x y $ ).
In any case, the chain rule is not directly needed when working out specific derivatives.
As a rule of differentiation, the chain rule is needed only when an unspecified differentiable function $ f $ appears, and then may be given in the form $ frac{mathrm{d}}{mathrm{d}x} bigl(f(u)bigr) = f'(u) , frac{mathrm{d}u}{mathrm{d}x} $ or $ mathrm{d}bigl(f(u)bigr) = f'(u) , mathrm{d}u $ to match other rules.
Although the chain rule is often written as frac{mathrm{d}y}{mathrm{d}x} = frac{mathrm{d}y}{mathrm{d}u} , frac{mathrm{d}u}{mathrm{d}x} , this is an oversimplification.
Upon choosing an independent variable, it is possible (and easy) to give a rigorous definition of the differential $ mathrm{d}u $ , and then (eq:trivial) is a triviality (assuming no division by zero).
However, with such a definition of differential, (eq:trivial) is not the chain rule!
The reason is that, when (eq:trivial) is used as a mnemonic for the chain rule, $ {mathrm{d}u}/{mathrm{d}x} $ uses $ x $ as the independent variable, but $ {mathrm{d}y}/{mathrm{d}u} $ uses $ u $ .
Either may be chosen to define differentials^invertibility, but one must (a priori) be consistent.
Now, it so happens that the choice of independent variable is entirely irrelevant; differentials have the same meaning no matter which independent variable is used.
But this fact requires proof; it is the chain rule (or at least a prerequisite for using (eq:trivial) as the chain rule), and it is not a triviality.
In this form, the chain rule is also known as Cauchy's invariant rule.
^invertibility: Well, either may be chosen as long as their differentials are nowhere zero, which is exactly what must be true for (1) to make sense.
More precisely, given that $ x $ works as an independent variable, the Chain Rule tells us that $ u $ works just as well so long as $ mathrm{d}u $ (as defined using $ x $ ) is nowhere zero.
This may be related to the easy but wrong proof of the Chain Rule that founders on a division by zero in exactly the same place (where $ mathrm{d}u $ would be), although I don't see a direct connection.
The chain rule can also be discussed as a piece of formal algebra of power series (over a general commutative ring $ A $ ).
We present a conceptual proof based on considerations of SDG.
The statement is that if $ q, p in A x $ are power series, with $ 0 $ the $ 0^{th} $ (constant) coefficient of $ p $ , then $ (q circ p)'(x) = q'(p(x))p'(x) $ under standard definitions.
Let $ D = Ay/(y^2) $ be the representing object for derivations.
Let $ delta: A x to A x otimesA D cong A x y/(y^2) $ be the unique topological $ A $ - algebra map (under the $ (x) $ - adic topologies) that sends $ x $ to $ x + y $ .
(If it helps, think $ delta(q) = q(x + y) $ .)
For $ p in A x $ , define $ p' $ via the equation $ delta(p) = p(x) + p'(x)y $ .
Let $ pi: A x otimesA D to A x otimesA D $ be the unique topological algebra map taking $ x $ to $ p(x) $ and $ y $ to $ p'(x)y $ .
Let $ - circ p: A x to A x $ denote the unique topological algebra map that takes $ x $ to $ p $ .
Then the diagram $ array{ A x & stackrel{delta}{to} & A x otimesA D mathllap{ - circ p} downarrow & & downarrow mathrlap{pi} A x & underset{delta}{to} & A x otimesA D } $ commutes in the category of topological algebras, since the two legs agree when evaluated at the generator $ x $ .
But then, evaluating each leg at a power series $ q in A x $ , we have $ delta( - circ p) = delta(q circ p) = (q circ p)(x) + (q circ p)'(x)y $ and $ pi delta = pi(delta(q)) = pi(q(x) + q'(x)y) = q(p(x)) + q'(p(x))(p'(x)y) $ whence the coefficients of $ y $ agree: $ (q circ p)'(x) = q'(p(x))p'(x) $ .
A synthetic formalization of the chain rule in differential cohesive homotopy type theory is given in See also On the Goodwillie chain rule in Goodwillie calculus:
In general, a maximum is a top element, a minimum is a bottom element, and an extremum is either.
However, these terms are typically used in analysis, where the order theory is secondary.
One also usually speaks of extrema of a function, meaning a top or bottom element of the range of the function under its induced order as a subset of an ordered codomain.
In this context, one also considers local extrema of functions; a local extremum of $ f $ is an extremum of a restriction of $ f $ to an open subspace of its original domain.
In any case, the extremum is strict if the function takes the extreme value only once (in the relevant domain).
We list some sufficient and necessary conditions for a (nice) function $ f $ on a smooth manifold to have a local extremum at a point $ x $ .
As these are local conditions, we may assume $ f $ is a function $ U to mathbb{R} $ where $ U $ is an open subset in a Cartesian space $ mathbb{R}^n $ .
These conditions fall under the rubric of "second derivative test".
Assume $ f $ to be a twice - differentiable function, and let $ x $ in its domain be a critical point: a point where its derivative / Jacobian vanishes.
Let $ Hx(f) $ be the Hessian matrix of the function.
Recall that $ x $ is a **nondegenerate** critical point if the symmetric matrix $ Hx $ is nondegenerate; equivalently, if $ 0 $ is not an eigenvalue of $ Hx $ .
Let $ x $ be a nondegenerate critical point.
Then (The only other possibility left for a nondegenerate critical point is that $ Hx(f) $ be an indefinite form, having a mix of positive and negative eigenvalues.
In this case, $ x $ is a saddle point.
For more on this, see Morse theory.)
If $ x $ is a degenerate critical point (so $ 0 $ is an eigenvalue of $ Hx $ ), we have: These conditions are not sufficient.
For a simple example, the origin in $ mathbb{R}^2 $ is a critical point of $ f(x, y) = x^3 - y^3 $ , where the Hessian is the zero matrix (hence positive semidefinite and negative semidefinite), but clearly the origin is neither a local maximum nor a local minimum.
The diffeomorphism group $ Diff(X) $ of a smooth manifold $ X $ is the group of its diffeomorphisms: the automorphism group of $ X $ as an object of the category SmoothMfd.
Beware that when $ X $ is assumed orientable then sometimes, but not always, $ Diff(X) $ is implicitly taken to be the group of orientation - preserving diffeomorphisms.
For the following kinds of manifolds $ Sigma $ it is true that every homotopy equivalence $ alpha colon Pi(Sigma) stackrel{simeq}{longrightarrow} Pi(Sigma) $ (hence every equivalence of their fundamental infinity - groupoids) is homotopic to a diffeomorphism $ a colon Sigma stackrel{simeq}{longrightarrow} Sigma $ i.e. that given $ alpha $ there is $ a $ with $ alpha simeq Pi(a) , $ . {HomotopyTypeAndMappingClassGroup} The homotopy type
$ Pi(Diff(Sigma)) $ of the diffeomorphism group $ Diff(Sigma) $ is of interest (e.g. Hatcher 12).
For instance this is the automorphism ∞ - group of a manifold, regarded as a k - morphism in an (∞, n) - category of cobordisms.
Specifically, the group of connected components is the mapping class group $ pi0(Pi(Diff(Sigma))) = MCG(Sigma) , $ . $ Pi(Diff(S^1))simeq Pi(O(2)) $ $ Pi(Diff(D^1))simeq Pi(O(1)) $ {HomotopyTypeForSurfaces} For $ Sigma $ a closed orientable surface, then the bare homotopy type of its diffeomorphism group is (i) if $ Sigma $ is the sphere then
$ Pi(Diff(S^2)) & simeq Pi(O(3)) & simeq MCG(S^2)times Pi(SO(3)) & simeq mathbb{Z}2 times Pi(SO(3)) $ (i) if $ Sigma $ is the torus then $ Pi(Diff(S^1 times S^1)) & simeq MCG(S^1 times S^1)times Pi(S^1 times S^1 ) & simeq GL2(mathbb{Z}) times B(mathbb{Z} timesmathbb{Z}) $ (i) in all other cases all higher homotopy groups vanish:
$ Pi(Diff(Sigma)) simeq MCG(Sigma) $ The first statement is due to (Smale 58), see also at sphere eversion.
The second and third are due to (Earle - Eells 67, Gramain 73) $ . Pi(Diff(S^1 times S^2)) simeq Pi(O(2) times O(3)) times Omega Pi(SO(3)) , $ .
(Hatcher 81) linebreak The bare homotopy type of the diffeomorphism group of the 3 - sphere is that of the orthogonal group $ O(4) $ $ eshbig( Diff(S^3) big) ;simeq; esh , O(4)) , , $ the equivalence being exhibited by the canonical inclusion $ O(4) hookrightarrow Diff(S^3) , $ .
Also $ esh , Diff(D^3) ;simeq; esh , O(3) , $ .
After being conjectured by Smale, this was proven in (Hatcher 1983).
Generally: For every smooth 3 - manifold the canonical map $ Pi(Diff(X)) to Pi(Homeo(X)) $ sending diffeomorphisms to their underlying homeomorphisms of topological spaces is a weak homotopy equivalence.
That this follows from the Smale cojecture, theorem , was shown in (Cerf).
For discussion see (Hatcher, 1978).
If a 3 - manifold $ X $ is not a Seifert 3 - manifold via an $ S^1 $ - action then $ Pi(Diff(X)) simeq MCG(X) , $ .
If $ X $ is Seifert via an $ S^1 $ - action, then the component of $ Diff(X) $ are typically $ Pi(S^1) $ - s.
The observation that infinite - dimensional smooth groups such as diffeomorphism groups (and quantomorphism groups etc.) are naturally regarded as internal groups in diffeological spaces - - diffeological groups - - is due to Bulletin of the American Mathematical Society 73(4) 557 - - 559, 1967 Second Series, Vol.
87, No. 1 (Jan., 1968), pp. 56 - 88 (JSTOR) For 4 - manifolds the analogue of the Smale conjecture fails: > (via graph complexes)
The inverse function theorem says that given any sequentially Cauchy complete Archimedean field $ mathbb{R} $ and a continuously differentiable function $ f:I to mathbb{R} $ from an open interval $ I subseteq mathbb{R} $ such that for all points $ a in I $ , $ left| frac{d f}{d x}(a) right| gt 0 $ the inverse function $ f^{ - 1}:mathrm{im}(f) to mathbb{R} $ exists and is unique and is defined by the first - order nonlinear ordinary differential equation $ left(frac{d f}{d x} circ f^{ - 1}right) frac{d f^{ - 1}}{d x} = 1 $ with initial condition $ f^{ - 1}(f(a)) = a $ .
Classically, $ mathbb{R} $ is essentially unique, but constructively, there are multiple inequivalent sequentially Cauchy complete Archimedean fields.
To be done...
This proof is adapted from the Wikipedia article on the inverse function theorem, in the section "A proof using the contraction mapping principle", the contraction mapping principle being another name for the Banach fixed - point theorem.
Let $ ( - r, r) $ denote an open interval in $ mathbb{R} $ with radius $ r $ and centre $ 0 $ .
If $ g:( - r, r) to mathbb{R} $ is a map such that $ g(0) = 0 $ and there exists a rational constant $ 0 lt c lt 1 $ such that $ vert g(y) - g(x) vert = c vert y - x vert $ for all $ x in ( - r, r) $ and $ y in ( - r, r) $ , then $ f = mathrm{id}mathbb{R} + g $ is injective on $ ( - r, r) $ and $ ( - (1 - c)r, (1 - c)r) subset f(( - r, r)) subset ( - (1 + c)r, (1 + c)r) $ where $ mathrm{id}mathbb{R} $ is the identity map on the real numbers, restricted in the domain to $ ( - r, r) $ , and given an open interval $ I subseteq mathbb{R} $ , $ f(I) $ is the image of $ f $ under $ I $ .
First, the map $ f $ is injective on $ ( - r, r) $ , since if $ f(x) = f(y) $ , then $ g(y) - g(x) = x - y $ and so $ vert g(y) - g(x) vert = vert y - x vert $ , which is a contradiction unless $ y = x $ .
Next we show
$ ( - (1 - c)r, (1 - c)r) subset f(( - r, r)) $ The idea is to note that this is equivalent to, given a point $ y $ in $ ( - (1 - c) r, (1 - c) r) $ , find a fixed point of the map $ F : - r, r to - r', r' $ defined as $ F(x) = y - g(x) $ where $ 0 lt r' lt r $ such that $ vert y vert leq (1 - c)r' $ and the bar means a closed ball.
To find a fixed point, we use the Banach fixed - point theorem and checking that $ F $ is a well - defined strict - contraction mapping is straightforward.
Finally, we have: $ f(( - r, r)) subset ( - (1 + c)r, (1 + c)r) $ since $ vert f(x) vert = vert x + g(x) - g(0) vert le (1+c) vert x vert $ Now that we have established the lemma, we could proved the main theorem: It is enough to prove the special case when $ a = 0, b = f(a) = 0 $ and $ f'(0) = mathrm{id}mathbb{R} $ .
Let $ g = f - mathrm{id}mathbb{R} $ .
The mean value theorem applied to $ t mapsto g(x + t(y - x)) $ says: $ vert g(y) - g(x) vert leq vert y - x vert sup{0 lt t lt 1} vert g'(x + t(y - x)) vert $ Since $ g'(0) = mathrm{id}mathbb{R} - mathrm{id}mathbb{R} = 0 $ and $ g' $ is continuous, we can find an $ r gt 0 $ such that $ vert g(y) - g(x)vert leq 2^{ - 1} vert y - x vert $ for all $ x, y $ in $ ( - r, r) $ .
Then the earlier lemma says that $ f = g + mathrm{id}mathbb{R} $ is injective on $ ( - r, r) $ and $ ( - r/2, r/2) subset ( - r, r) $ .
Then $ f : ( - r, r) cap f^{ - 1}(( - r/2, r/2)) to ( - r/2, r/2) $ is bijective and thus has the inverse, where given an open interval $ I subseteq mathbb{R} $ , $ f^{ - 1}(I) $ is the inverse image of $ f $ over $ I $ .
to be continued...
The given proof of the inverse function theorem above relies on the mean value theorem, which in constructive mathematics is only true for uniformly differentiable functions.
There might be other proofs which might not rely on the mean value theorem and could prove the inverse function theorem for continuously differentiable functions.
While continuously differentiable functions and locally uniformly differentiable functions are well - defined in every Archimedean ordered field, the inverse function theorem does not hold in all Archimedean ordered fields.
One could instead consider adding the inverse function theorem as an axiom to an arbitrary Archimedean ordered field $ R $ .
There are a few axioms which could be used here $ frac{d f}{d x}left(f^{ - 1}(a)right) cdot frac{d f^{ - 1}}{d x}left(aright) = 1 $ $ frac{d f}{d x}left(f^{ - 1}(a)right) cdot frac{d f^{ - 1}}{d x}left(aright) = 1 $ The former is stronger than the latter, although they are equivalent in the presence of excluded middle.
If $ R $ satisfies the locally uniformly continuous inverse function axiom, then $ R $ is a real closed field.
There is also a third possible axiom in dependent type theory, which uses the shape modality.
Given an Archimedean ordered field $ R $ , let $ esh coloneqq LR $ be the shape modality, the localization at $ R $ .
A type $ T $ is shapewise contractible if its shape is contractible.
Given an open interval $ I subseteq R $ , a function $ f:I to R $ is shapewise continuous if the graph of $ f $ , the set of all pairs $ (x, y) $ in $ I times R $ such that $ y = f(x) $ , is shapewise contractible: $ mathrm{isShapewiseContinuous}(f) coloneqq mathrm{isContr}left(eshleft(sum{x:I} sum{y:R} y ={R} f(x)right)right) $ $ frac{d f}{d x}left(f^{ - 1}(a)right) cdot frac{d f^{ - 1}}{d x}left(aright) = 1 $ See also: Implicit function theorems give sufficient conditions for the existence of a differentiable inverse of a germ $ fp $ of a differentiable map $ fcolon M to N $ of smooth manifolds at a point $ p $ .
The invertibility is trivially equivalent to the statement that the germ is a local diffeomorphism of some neighborhood of $ p $ to some neighborhood of $ f(p) $ .
If it is invertible, then we can consider the tangent map $ Tp fcolon Tp M to T{f(p)}N $ .
If $ f $ is locally invertible with differentiable inverse, then for all $ y $ in some neighborhood of $ y $ the functoriality of $ T $ implies that $ Id{Ty} = Ty (f^{ - 1} circ f) = T{f(y)} f^{ - 1} circ Ty f $ and alike for $ f circ f^{ - 1} $ at $ f(y) $ , demonstrating that $ Ty f $ must then be invertible.
The inverse function theorem says that the invertibility of $ Tp f $ is in fact sufficient for the invertibility of the germ, which is then automatically differentiable.
Let $ U subset mathbf{R}^n $ be an open set in a cartesian space, $ ain U $ , $ fcolon U to mathbf{R}^n $ a map of class $ C^1 $ and $ detleft(frac{partial fi}{partial xj}(a)right)neq 0 $ .
Then there are open sets $ V ni a $ , $ W ni f(a) $ , $ V subset U $ such that $ f|Vcolon V to W $ is a diffeomorphism and for all $ y in W $ and $ (f^{ - 1})'(y) = (f'f^{ - 1}(y))^{ - 1} $ .
This is the theorem stated in the Idea section; the differentiable germ is assumed to be of class $ C^1 $ (continuously differentiable).
The statement is local, so one can consider it in charts, hence the proof reduces to the case of $ mathbf{R}^n $ .
Let $ fcolon M to N $ be a smooth map of smooth manifolds.
A point $ q in N $ is a regular value of $ f $ if for every point $ p in f^{ - 1}(q) $ the differential $ Tp fcolon Tp M to Tq N $ is an epimorphism.
The implicit function theorem asserts that $ Q = f^{ - 1}(p) $ is a smooth submanifold of $ M $ and the tangent bundle $ T M|N $ globally splits as $ T M|N cong T N oplus mathbf{R}^n $ where $ n = dim N $ .
More generally, if $ W subset N $ is a submanifold, we say that the map $ f $ is transversal along $ W $ if for every point $ xin f^{ - 1}(W) $ there is an equality $ T{f(x)} N = T{f(x)}W + (Tx f)(Tx X) $ .
In particular, $ f $ is transveral along every regular value $ p in N $ .
The implicit function theorem asserts that the preimage $ f^{ - 1}(W) $ is a smooth submanifold of $ M $ , the normal bundle $ nu(f^{ - 1}(W) subset M) $ is isomorphic to $ f^(nu(Wsubset N)) $ , and the differential $ T f $ exhibits the fiberwise isomorphism $ nu(f^{ - 1}(W)subset M)to nu(Wsubset N) $ .
Various applications and related theorems can be found in chapter 5: Local and tangential properties of An invariant global statement on manifolds is at page 44 of Elementary course notes of the case in $ mathbf{R}^n $ (mainly lots of examples): The concept of a $ delta $ - ring appearing in this article is distinct from that appearing in arithmetic differential geometry $ . sigma $ - algebras and their variants are collections of subsets important in classical measure theory and probability theory.
Although $ sigma $ - algebras are often introduced as a mere technicality in the definition of measurable space (to specify the measurable subsets), even once one has a fixed measurable space $ X $ , it is often useful to consider additional (typically coarser) $ sigma $ - algebras of measurable subsets of $ X $ .
We assume the law of excluded middle throughout; see Cheng measurable space for the constructive theory, and compare also measurable locale.
Given a set $ X $ , a $ sigma $ - algebra is a collection of subsets of $ X $ that is closed under complementation and under unions and intersections of countable families.
Notice that the power set $ mathcal{P} X $ of $ X $ is a Boolean algebra under the operations of complementation and of union and intersection of finite families.
Actually, it is a complete Boolean algebra, since we can also take unions and intersections of all families.
A $ sigma $ - algebra is an intermediate notion, since (in addition to being closed under complementation) we require that it be closed under unions and intersections of countable families.
Given a set $ X $ and a collection $ mathcal{M} $ of subsets $ S subseteq X $ , there are really several kinds of collections that $ mathcal{M} $ could be: (i) The empty set $ empty $ is in $ mathcal{M} $ .
(ii) If $ S $ and $ T $ are in $ mathcal{M} $ , then so is their union $ S cup T $ .
(iii) If $ S $ and $ T $ are in $ mathcal{M} $ , then so is their relative complement $ T setminus S $ .
It follows that $ mathcal{M} $ is closed under intersections of inhabited finite families and under symmetric difference of finite families: We can actually use the latter as an alternative to (2), since $ S cup T = (S uplus T) uplus (S cap T) $ .
Or we can use the pair as an alternative to (2, 3), since $ T setminus S = (S cap T) uplus T $ .
For that matter, we can weaken (1) to simply say that some set $ S $ is in $ mathcal{M} $ ; then $ empty = S setminus S $ .
While the union and symmetric difference of an empty family (both the empty set) belong to $ mathcal{M} $ , the intersection of an empty family (which is $ S $ itself) might not.
The term 'ring' dates from the days when a ring in algebra was not assumed to be unital; so a ring on $ X $ is simply a subring (in this sense) of the Boolean ring $ mathcal{P} X $ .
(i) The empty set $ empty $ is in $ mathcal{M} $ .
(ii) If $ S $ and $ T $ are in $ mathcal{M} $ , then so is their union $ S cup T $ .
(iii) If $ S $ and $ T $ are in $ mathcal{M} $ , then so is their relative complement $ T setminus S $ .
(iv) If $ S1, S2, S3, ldots $ are in $ mathcal{M} $ , then so is their intersection $ bigcapi S_i $ .
Of course, every $ delta $ - ring is a ring, but not conversely.
Actually, if you want to define the concept of $ delta $ - ring directly, it's quicker if you use the symmetric difference; then (2, 3) follow by the reasoning above and the idempotence of intersection (so that $ S cap T = S cap T cap T cap T cap cdots $ ).
The symbol ' $ delta $ ' here is from German 'Durchschnitt', meaning intersection; it may be used in many contexts to refer to intersections of countable families.
(i) The empty set $ empty $ is in $ mathcal{M} $ .
(ii) If $ S $ and $ T $ are in $ mathcal{M} $ , then so is their union $ S cup T $ .
(iii) If $ S $ and $ T $ are in $ mathcal{M} $ , then so is their relative complement $ T setminus S $ .
(iv) If $ S1, S2, S3, ldots $ are in $ mathcal{M} $ , then so is their union $ bigcupi S_i $ .
Now (2) is simply redundant; $ S cup T = S cup T cup T cup T cup cdots $ .
A $ sigma $ - ring is obviously a ring, but in fact it is also a $ delta $ - ring; $ bigcapi Si = (bigcupi Si) setminus bigcupj (bigcupi Si setminus Sj) $ .
The symbol ' $ sigma $ ' here is from German 'Summe', meaning union; it may be used in many contexts to refer to unions of countable families.
(i) The empty set $ empty $ is in $ mathcal{M} $ .
(ii) If $ S $ and $ T $ are in $ mathcal{M} $ , then so is their union $ S cup T $ .
(iii) If $ S $ and $ T $ are in $ mathcal{M} $ , then so is their relative complement $ T setminus S $ .
(iv) The improper subset $ X $ is in $ mathcal{M} $ .
Actually, (2) is now redundant again; $ S cup T = X setminus ((X setminus T) setminus S) $ .
But perhaps more importantly, $ mathcal{M} $ is closed under absolute complementation (that is, complementation relative to the entire ambient set $ X $ ); that is: In light of this, the most common definition of algebra is probably to use this fact together with (1, 2); then (3) follows because $ T setminus S = neg(S cup neg{T}) $ and (4) follows because $ X = negempty $ .
On the other hand, one could equally well use intersection instead of union; absolute complements allow the full use of de Morgan duality.
The term 'field' here is even more archaic than the term 'ring' above; indeed the only field in this sense which is a field (in the usual sense) under symmetric difference and intersection is the field $ {empty, X } $ (for an inhabited set $ X $ ).
(i) The empty set $ empty $ is in $ mathcal{M} $ .
(ii) If $ S $ and $ T $ are in $ mathcal{M} $ , then so is their union $ S cup T $ .
(iii) If $ S $ and $ T $ are in $ mathcal{M} $ , then so is their relative complement $ T setminus S $ .
(iv) The improper subset $ X $ is in $ mathcal{M} $ .
(v) If $ S1, S2, S3, ldots $ are in $ mathcal{M} $ , then so is their union $ bigcupi S_i $ .
As with $ sigma $ - rings, (2) is redundant; as with algebras, it's probably most common to use the absolute complement in place of (3, 4).
Thus the usual definition of a $ sigma $ - algebra states: (i) The empty set $ empty $ is in $ mathcal{M} $ .
(ii) If $ S $ is in $ mathcal{M} $ , then so is its complement $ neg{S} $ .
(iii) If $ S1, S2, S3, ldots $ are in $ mathcal{M} $ , then so is their union $ bigcupi S_i $ .
And again we could again just as easily use intersection as union, even in the infinitary axiom.
That is, a $ delta $ - algebra is automatically a $ sigma $ - algebra, because $ bigcupi Si = negbigcapi neg{Si} $ .
Any and all of the above notions have been used by various authors in the definition of measurable space; for example, Kolmogorov used algebras (at least at first), and Halmos used $ sigma $ - rings.
Of course, the finitary notions (ring and algebra) aren't strong enough to describe the interesting features of Lebesgue measure; they are usually used to study very different examples (finitely additive measures).
On the other hand, $ delta $ &8209; or $ sigma $ - rings may be more convenient than $ sigma $ - algebras for some purposes; for example, vector - valued measures on $ delta $ - rings make good sense even when the absolute measure of the whole space is infinite.
Note that the collection of measurable sets with finite measure (in a given measure space) is a $ delta $ - ring, while the collection of measurable sets with $ sigma $ - finite measure is a $ sigma $ - ring.
A measurable space is usually defined to be a set $ X $ with a $ sigma $ - algebra $ mathcal{M} $ on $ X $ ; sometimes one of the more general variations above is used.
In any case, an $ mathcal{M} $ - measurable subset of $ X $ , or just a measurable set, is any subset of $ X $ that belongs to $ mathcal{M} $ .
If $ mathcal{M} $ is one of the more general variations, then we also want some subsidiary notions: $ S $ is relatively measurable if $ S cap T $ belongs to $ mathcal{M} $ whenever $ T $ does, and $ S $ is $ sigma $ - measurable if it is a countable union of elements of $ mathcal{M} $ .
Notice that every relatively measurable set is measurable iff $ S $ is at least an algebra; in any case, the relatively measurable sets form a ( $ sigma $ ) - algebra if $ mathcal{M} $ is at least a ( $ delta $ ) - ring.
Similary, every $ sigma $ - measurable set is measurable iff $ S $ is at least a $ sigma $ - ring; in any case, the $ sigma $ - measurable sets form a $ sigma $ - ring if $ mathcal{M} $ is at least a $ delta $ - ring.
As a $ sigma $ - algebra is a collection of subsets, we might hope to develop a theory of bases and subbases of $ sigma $ - algebras, such as is done for topologies and uniformities.
However, things do not work out as nicely.
(It is quite easy to generate rings or algebras, but generating $ delta $ - rings and $ sigma $ - rings is just as tricky as generating $ sigma $ - algebras.)
We do get something by general abstract nonsense, of course.
It's easy to see that the intersection of any collection of $ sigma $ - algebras is itself a $ sigma $ - algebra; that is, we have a Moore closure.
So given any collection $ mathcal{B} $ of sets whatsoever, the intersection of all $ sigma $ - algebras containing $ mathcal{B} $ is a $ sigma $ - algebra, the $ sigma $ - algebra generated by $ mathcal{B} $ .
(We can similarly define the $ delta $ - ring generated by $ mathcal{B} $ and similar concepts for all of the other notions defined above.)
What is missing is a simple description of the $ sigma $ - algebra generated by $ mathcal{B} $ .
(For a mere algebra, this is easy; any $ mathcal{B} $ can be taken as a subbase of an algebra, the symmetric unions of finite families of elements of $ mathcal{B} $ form a base of the algebra, and the intersections of finite families of elements of the base form an algebra.
For a ring, the only difference is to use intersections only of inhabited families.
But for anything from a $ delta $ - ring to a $ sigma $ - algebra, nothing this simple will work.)
In fact, the question of how to generate a $ sigma $ - algebra is the beginning of an entire field of mathematics, descriptive set theory.
For our purposes, we need this much: So we need an $ aleph_1 $ steps, not just $ 2 $ .
(This is only the beginning of descriptive set theory; our $ Sigmaalpha $ are their $ Sigma^0alpha $ - - - except that for some reason they start with $ Sigma^01 $ instead of $ Sigma^00 $ - - - , and the subject continues to higher values of the superscript.)
Note that countable choice is essential here and elsewhere in measure theory, to show that a countable union of a countable union is a countable union.
But the full axiom of choice is not; in fact, much of descriptive set theory (although this is irrelevant to the small portion above) works better with the axiom of determinacy instead.
We are now learning ways to understand measure theory and probability away from the traditional reliance on sets required with $ sigma $ - algebras; see measurable space for a summary of other ways to define this concept.
We still need to know what happens to all of the other $ sigma $ - algebras of measurable sets in a measurable space.
One solution may to use quotient measurable spaces in place of sub - $ sigma $ - algebras; for example, see explicit quotient in the example of macroscopic entropy above.
Measure theory studies measurable spaces and measure spaces.
Measure theory is the field of mathematics that grew out of the Lebesgue integral and Kolmogorov's axioms for probability.
The general measure theory studies general notions and constructions in measure theory, like the connection to integration, the measure spaces, derivation by measure, Caratheodory construction and so on.
Probability theory studies special class of measures, so called probability measures which are normalized to unity.
Measure theory is very much having a central role in studying so called ergodic theory of dynamical system.
Geometric measure theory is the geometric study of measures of subsets of Euclidean space and the measure theoretic aspects of various geometric objects, like the integration of classes of currents and their extremization properties.
There is a generalization, the noncommutative measure theory, which is more or less the study of von Neumann algebra, see Connes (1995).
A comprehensive five - volume treatise (with a sixth volume forthcoming) is A more concise two - volume treatise is A classical (slightly dated) concise treatise is Other texts include {ReferencesViaToposTheory} Discussion via topos theory and particularly via Boolean toposes:
The counting measure on a measurable set (in particular on a countable set) is the measure which assigns to a subset the cardinality of this subset (hence which "counts" the number of elements of the subset).
For $ p in mathbb{R} $ , $ p geq 1 $ , the $ p $ - norm is a norm on suitable real vector spaces given by the $ p $ th root of the sum (or integral) of the $ p $ th - powers of the absolute values of the vector components.
With due care the definition makes sense for non - finite dimensional vector spaces such as sequence spaces and Lebesgue spaces, making them into normed vector spaces, hence metric spaces.
For $ p = 1 $ the $ p $ - norm is the Taxicab norm or Manhattan norm.
For $ p = 2 $ the $ p $ - norm is the standard Euclidean norm, defining Euclidean spaces and Hilbert spaces of square integrable functions.
For $ p = infty $ the $ p $ - norm (found by taking the limit $ p to infty $ ) is the supremum (or essential supremum in the continuous case) of the absolute values of the components of vectors, then called the supremum norm.
For $ 0 leq p lt 1 $ one may still make sense of the formulas that define $ p $ - norms for $ p geq 1 $ (see at Generalizations below), but the resulting concepts are no longer genuine norms.
The concept of $ p $ - norm makes sense in increasing generality, {ThePNorm} For $ n in mathbb{N} $ , $ p in mathbb{R} $ , $ p gt 0 $ , the $ p $ - norm $ Vert - Vertp $ is the norm on the real finite dimensional vector space $ mathbb{R}^n $ given by the $ p $ th root of the sum of the $ p $ - powers of the absolute value of the components of a given vector $ vec x = (x){i = 1}^n in mathbb{R}^n $ : $ {Vert vec x Vertp} coloneqq root p {sumi {vert x_ivert^p}} $ Equipping it with this norm makes $ mathbb{R}^n $ a normed vector space.
For $ p = 2 $ this is the Euclidean norm, the standard norm that defines Euclidean space.
For $ p = infty $ one takes the supremum over the absolute values of the components $ {Vert vec xVert_infty} ;coloneqq; underset{1 leq i leq n}{sup} {vert x_ivert} , $ .
<div style="float:right;margin:0 10px 10px 0;"> <img src="https://upload.wikimedia.org/wikipedia/commons/thumb/d/d4/Vector - p - Normsqtl(i)svg/220px - Vector - p - Normsqtl(i)svg.png" width="200">
</div>
The graphics on the right (grabbed from Wikipedia) shows unit circles in $ mathbb{R}^2 $ with respect to various p - norms.
{OnSequenceSpaces} For $ p in mathbb{R} $ , write $ ell^p $ for the vector space of those sequences $ (xi){i in mathbb{N}} $ in $ mathbb{R} $ for which the series $ underset{i in mathbb{N}}{sum} {vert x_ivert}^p ;lt; infty $ (the sum of the $ p $ th powers of the absolute value of the components of the sequence) converges.
For $ p geq 1 $ the the function $ {Vert - Vert_p} ;colon; ell^p longrightarrow mathbb{R} $ $ {Vert (xi){i in mathbb{N}} Vert_p} ;coloneqq; root{p}{underset{i in mathbb{N}}{sum} {vert x_ivert^p}} $ defines a norm on this real vector space.
This normed vector space is complete, hence a Banach space.
This is called the sequence space.
For $ p = infty $ one takes $ ell^infty $ to be the space of bounded sequences and $ {Vert (xi){i in mathbb{N}} Vert_infty} ;coloneqq; underset{k in mathbb{N}}{sup} {vert x_kvert } $ to be the supremum over the absolute values of the components of the sequence.
This is also called the supremum norm.
{OnLebesgueSpaces} More generally, for $ (X, mu) $ a measure space, write $ L^p(X) $ for the vector space of equivalence classes of those measurable functions $ f colon X to mathbb{R} $ , for which the integral $ int_X {vert f vert^p} dmu ;lt; infty $ exists, and where two such functions are regarded as equivalent, $ f1 sim f2 $ , if $ intX {vert f2 - f_1 vert^p} dmu ;=; 0 , $ .
On this space the function $ {Vert - Vert_p} ;colon; L^p(X) longrightarrow mathbb{R} $ $ {Vert f Vert_p} ;coloneqq; root{p}{int_X {vert fvert^p}} dmu $ defines a norm.
The triangle inequality holds due to Minkowski's inequality.
The normed vector space $ (L^p(X), {Vert - Vertp}) $ is also called a Lebesgue space_.
{Generalizations} For $ 0 leq p lt 1 $ , the above definitions for $ Vert { - }Vert_p $ still make sense in themselves, but the result is no longer a norm, as Minkowski's inequality (the triangle inequality for $ p $ - norms) fails.
A variant definition for $ 0 lt p leq 1 $ (which agrees with the usual definition for $ p = 1 $ , preserving continuity in $ p $ ) leaves out the $ p $ th root; then the result satisfies the triangle inequality (and indeed is a metric) but fails to be a norm because it is not positive - homogeneous of degree $ 1 $ (but of degree $ p $ instead).
Such a thing is called an F - norm.
For $ p = 0 $ , we might try to take the limit as $ p searrow 0 $ .
For the unmodified $ p $ - norm (with the root), this is infinite if there is more than one nonzero entry and is the absolute value of the one nonzero entry if there is only one (or 0 if there is none); for the modified $ p $ - norm (without the root), it is the (possibly infinite) number of nonzero entries.
In either case, however the triangle inequality fails.
Therefore, there is a further modified $ 0 $ - norm, given by $ {|(x1, x2, ldots)|0} = sum{n=1}^infty frac {2^{ - n} {|xn|}} {1 + {|xn|}} $ for $ l^0 $ , and this is an $ F $ - norm.
(But I don't know what is the justification for thinking of this as a $ p $ - norm for $ p = 0 $ .)
A probability density is a density on some space which under integration yields a probability measure.
Similarly, a probability density function is a measurable function on some measure space that under integration yields a probability measure.
(This entry describes two distinct notions, one in the theory of inner product spaces, and the second in a more purely category theoretic context.)
Two elements $ x, y $ in an inner product space, $ (V, langle - , - rangle) $ , are orthogonal or normal vectors, denoted $ x perp y, $ if $ langle x, yrangle = 0 $ .
Two morphisms $ e:Ato B $ and $ m:Cto D $ in a category are said to be orthogonal, written $ eperp m $ , if $ e $ has the left lifting property with respect to $ m $ , i.e. if in any commutative square $ array{ A & overset{e}{to} & B downarrow && downarrow C & underset{m}{to} & D} $ there exists a unique diagonal filler making both triangles commute: $ array{ A & overset{e}{to} & B downarrow & swarrow & downarrow C & underset{m}{to} & D} $ Given a class of maps $ E $ , the class $ {m | eperp m ;forall ein E } $ is denoted $ E^{downarrow} $ or $ E^perp $ .
Likewise, given $ M $ , the class $ {e | eperp m ;forall min M } $ is denoted $ M^{uparrow} $ or $ {}^perp M $ .
These operations form a Galois connection on the poset of classes of morphisms in the ambient category.
In particular, we have $ ({}^perp(E^perp))^perp = E^perp $ and $ {}^perp(({}^perp M)^perp) = {}^perp M $ .
A pair $ (E, M) $ such that $ E^perp = M $ and $ E = {}^perp M $ is sometimes called a prefactorization system.
If in addition every morphism factors as an $ E $ - morphism followed by an $ M $ - morphism, it is an (orthogonal) factorization system.
The orthogonal subcategory problem is related to localization.
Suppose $ Sigma^perp $ is indeed a reflective subcategory; let $ r: C to Sigma^perp $ be the reflector (the left adjoint to the inclusion $ i: Sigma^perp to C $ ).
Certainly $ r $ sends arrows in $ Sigma $ to isomorphisms in $ Sigma^perp $ .
Indeed, if $ f: A to B $ belongs to $ Sigma $ , then the inverse to $ r(f): r(A) to r(B) $ is the unique arrow extending $ 1_{r(A)} $ along $ r(f): r(A) to r(B) $ to an arrow $ g: r(B) to r(A) $ , using the fact that $ r(A) $ belongs to $ Sigma^perp $ .
A representation is reducible if it is a direct sum of irreducible representations.
>
This page is about algebra as a theory.
If you are looking for the term algebra as an object see associative algebra or algebra over an operad or the like.
See below for more.
geometry $ leftarrow $ Isbell duality $ rightarrow $ algebra
The word 'algebra' is often also used for an algebraic structure: Various fields of mathematics or mathematical concepts can be manipulated in an algebraic or symbolic way, and such approaches or formalized subfields have names like categorical algebra, homological algebra, homotopical algebra and so on.
Methods of combinatorics which involve much algebra, and manipulations with formal power series in particular, are called algebraic combinatorics.
The $ n $ lab has a number of entries on particular algebraic structures (monoid, semigroup, group, ring, noetherian ring, quasigroup, associative algebra, Lie algebra, coalgebra, dg - algebra, bialgebra, graded algebra, Hopf algebra, coring, quasitriangular bialgebra, lattice, rig, near - ring, $ Omega $ - group, field, perfect field, skewfield, free field, vector space, vertex operator algebra, crossed module, chain complex, hypermonoid, hyperring, hyperfield, truss, brace etc.), entries on their structural features, parts, "envelopes" or localizations (ideal, center, centralizer, normal subgroup, normal closure, normalizer, holomorph, Ore set, Ore localization, enveloping algebra, universal enveloping algebra) and on algebraic structures internal to other categories (topological group, Lie group, Lie groupoid, algebraic group, formal group, dg - algebra etc).
There are also few pages on various invariants of algebraic objects or operations on algebraic expressions, e.g. on resultants of polynomials, determinant of a matrix, quasideterminant of a matrix with noncommutative entries.
For many algebraic structures a notion of action is defined; they embody "symmetry algebras" of some other algebraic objects.
An action is expressed via a representation of one object as a subobject of a full object of another; or as a combination of the object which acts and which is acted upon (e.g. action groupoid).
Objects with action are modules of the appropriate kind (possibly dualized: comodule, contramodule; multiple, e.g. bimodule; or homotopized like $ A_infty $ - modules).
The possibilities for realizing a given algebra via symmetries of another object are systematically studied in a field called representation theory.
See also Introductory textbooks: See also: and see the references at ring, module, etc.
A bilinear form is simply a linear map $ langle - , - ranglecolon V otimes V to k $ out of a tensor product of $ k $ - modules into the ring $ k $ (typically taken to be a field).
It is called symmetric if $ langle x, yrangle = langle y, xrangle $ for all $ x, y in V $ .
For variants on this, such as the property of being conjugate - symmetric, see inner product space.
It is called nondegenerate if the mate $ V to V^ast = hom(V, k) $ is injective (a monomorphism).
Let $ k = mathbb{R} $ be the real numbers.
A symmetric bilinear form is called {CategorificationsAndnPOV} Concepts which relate to (non - degenerate) bilinear forms from the nPOV and/or categorifications of the concept of bilinear forms include This page is about the polar decomposition of bounded operators on Hilbert spaces.
Any complex number $ z $ has a representation as $ z = r e^{i phi} $ with $ r in mathbb{R}, r ge 0 $ being the absolute value of $ z $ and the complex number $ e^{i phi} $ of norm $ 1 $ being the modulus, or the complex sign, of $ z $ .
The polar decomposition of a bounded operator is a generalization of this representation.
Let $ mathcal{H} $ be a Hilbert space and $ S1, S2 $ be closed linear subspaces.
An unitary isomorphism $ U: S1 to S2 $ is called a partial isometry with initial space $ S1 $ and final space or range $ S2 $ Let $ T $ be a bounded operator on $ mathcal{H} $ The positive operator $ |T| := (T^T)^{frac{1}{2}} $ is called the modulus of T. For every bounded operator $ T $ on $ mathcal{H} $ there exists a unique partial isometry $ U $ such that (i) U has initial space $ overline{R(|T|)} $ and range $ overline{R(T)} $ (ii) $ T = U |T| = U (T^*T)^{frac{1}{2}} $ We have stated the theorem for the operator algebra $ mathcal{B}(mathcal{H}) $ only, for a general C - star algebra $ C $ it need not hold because the partial isometry $ U $ need not be contained in $ C $ .
This is true however for every von Neumann algebra.
Most textbooks about operators on Hilbert spaces mention the polar decomposition, for example it can be found in the beginning of In Euclidean geometry, a regular polygon is a (simple, non self - intersecting) polygon in a Euclidean space $ mathbb{R}^n $ such that every segment of the boundary of the polygon has the same length and every angle between two segments of the boundary of the polygon has the same angle measure.
(The boundary of a regular polygon is sometimes called called a regular polygonal line)
We are using the circle constant $ tau = 2 pi $ .
Every regular polygon is the union of $ n $ congruent triangles each with segments of length $ r $ and $ r $ respectively and an angle of $ frac{tau}{n} $ between the two segments of length $ r $ .
As a result, the triangles are isosceles and the altitude from the center of the regular polygon to the third segment of the triangles bisects the angle: such that the angles between the circumradius and the altitude is $ frac{tau}{2n} $ .
The length of the third segment is thus given by $ b coloneqq r sinleft(frac{tau}{2n}right) + r sinleft(frac{tau}{2n}right) = 2 r sinleft(frac{tau}{2n}right) $ The perimeter of a regular polygon $ mathcal{P}n $ (strictly speaking, a regular polygonal line) with $ n $ sides and circumradius $ r $ is given by the sequence of functions $ Pmathcal{P}:mathbb{N} to (mathbb{R} to mathbb{R}) $ $ Pmathcal{P}(n)(r) = n b = r (2 n) sinleft(frac{tau}{2n}right) $ The area of a regular polygon $ mathcal{P}n $ with $ n $ sides and circumradius $ r $ is given by the sequence of functions $ P:mathbb{N} to (mathbb{R} to mathbb{R}) $ $ Amathcal{P}(n)(r) = n left(frac{1}{2} r bright) = n frac{1}{2} r (2 r) sinleft(frac{tau}{2n}right) = frac{1}{2} r^2 (2 n) sinleft(frac{tau}{2n}right) $ half the diameter of a sphere See also: tableofcontents In real analysis, given a sequence $ a:mathbb{N} to mathbb{R} $ in the real numbers, the series $ sum{n = 0}^infty an $ is absolutely convergent if the sequence of partial sums is a Cauchy sequence, and the sequence of partial sums of the series $ sum{n = 0}^infty vert an vert $ is also a Cauchy sequence.
In functional analysis, given a sequence $ a:mathbb{N} to B $ in a Banach space $ B $ , the series $ sum{n = 0}^infty an $ is absolutely convergent if the sequence of partial sums is a Cauchy sequence in $ B $ , and the sequence of partial sums of the series $ sum{n = 0}^infty Vert an Vert $ is a Cauchy sequence in the real numbers.
The argument of an integral is called the integrand.
For instance if $ omega in Omega^p(X) $ is a differential form then it is the integral in the expression $ intX omega $ for the integration of differential forms.
A convex space (also called barycentric algebra and other terms, invented independently many times) is a set equipped with a notion of taking weighted averages, or convex - linear combinations, of its elements.
Do not confuse this with an (abstract) convex set, which a special kind of convex space, also defined below.
The category of convex spaces is the category of algebras of a Lawvere theory, being the affine part of the theory of $ K $ - (semi)modules with only the idempotent operations.
This definition is used by Meng (1989), and many basic properties of the category are detailed therein.
Equivalently, the category of convex spaces is the category of algebras of a finitary monad, as explained by Jacobs (2010) and Swirszcz.
The category of convex spaces is is complete, cocomplete, symmetric monoidal closed under the (usual) tensor product construction, and has a cogenerator B&ouml;rger and Kemper (1994).
The subcategory consisting of the single object, the unit interval, is dense (left - adequate) in the category.
This follows from Isbell's theorem on left adequate subcategories for algebraic theories, using the fact that the free convex space on 2 elements is the unit interval.
Axiomatically, a convex space can be characterized as a set $ X $ equipped with a family of functions $ cp : X times X to X $ satisfying some natural axioms (described below).
For examples all nonunital commutative rings are convex spaces, with the map $ cp(x, y) = x + p(y - x) $ .
The monad assigning to any set the free convex space on that set is a finitary commutative monad (see Jacobs (2010)).
We can thus follow Durov in thinking of it as a generalized ring.
This allows us to think of convex spaces as 'modules' of a generalized ring, very much as vector spaces are modules of a field.
This is also true of the relatives of convex spaces: affine spaces and conical spaces.
For example, all affine spaces are convex spaces as defined below.
Of particular importance are convex spaces parametrized by the interval $ P = 0, 1 $ or the Boolean algebra $ P = {0, 1 } $ .
These two algebras are dual, in a certain sense described by Jacobs (2009).
This duality is functorial, and therefore is present for convex spaces for general $ P $ .
This leads to the notion of a dual convex space.
A convex space is a set $ X $ equipped with: such that the following identities always hold: As a consequence of the first and third axioms, $ c1(x, y) = c0(y, x) = y $ .
This defines convex spaces as a variety of algebras, with one binary operation for each $ p $ .
The intended interpretation is that $ cp(x, y) = x + p(y - x) = (1 - p)x + p y $ .
i.e., $ cp(x, y) $ is the $ p $ - weighted average of $ x $ and $ y $ , where $ x $ gets weight $ 1 - p $ and $ y $ gets weight $ p $ .
By thinking of $ p $ as a continuous parameter, this interpretation has the advantage of "starting" at $ x $ , then moving toward $ y $ at "rate" $ p $ .
This interpretation is 'biased', in the sense that the centered choice $ p=0 $ favors $ x $ .
It is also possible to give an 'unbiased' definition, which characterizes to convex - linear combinations of many points.
This is an $ n $ - ary operation parametrised by a list $ p := (p1, ldots, pn) $ satisfying $ sum{i = 1}^n pi = 1 $ .
If $ x := (x^1, ldots, x^n) $ , then $ cp(x) := sumi pi x^i $ .
A homomorphism of convex spaces may be called a convex - linear map or an affine linear map (since an affine space is a convex space with extra properties, as in the examples below).
It should probably not be called a 'convex map', which (between affine spaces) is something more general.
Any real vector space is a convex space, with $ cp(x, y) = x + p(y - x) $ .
In the unbiased version, any convex - linear combination is a linear combination.
Note that a convex - linear map between vector spaces may not be a linear map, since it may not preserve the identity; thus, a vector space is a convex space with extra structure.
More generally, any real affine space is a convex space; since $ p + (1 - p) = 1 $ , the expression for $ cp $ in a vector space is valid in an affine space.
In the unbiased version, any convex - linear combination is an affine linear combination.
Now any convex - linear map between affine spaces is an affine linear map (and conversely); an affine space is a convex space with extra properties.
Still more generally, any convex subset (that is, one containing the entire line segment between two given points) of a real affine space is a convex space (again with extra properties, which are described algebraically below).
The Boolean field $ {0, 1 } $ is a convex space with $ cp(x, y) = x vee y = x + y - x y $ whenever $ 0 lt p lt 1 $ (with $ c0(x, y) = x $ and $ c1(x, y) = y $ as always); this cannot be realised as a subset of a vector space.
This can be generalised to any (possibly unbounded) semilattice.
(It would be nice to find an example like this that can be defined constructively; this one relies on excluded middle.)
There is a nice abstract converse to the example of a convex subset of an affine space.
A convex space is cancellative if $ y = z $ whenever $ cp(x, y) = cp(x, z) $ for some $ x $ and $ p ne 0 $ .
We may call a cancellative convex space an abstract convex set.
The justification for this terminology is this A convex space is cancellative if and only if it is isomorphic (as a convex space) to a convex subset of some real affine space.
Compare this with the theorem that a monoid is cancellative if and only if it is isomorphic to a submonoid of some group.
Of course, most of the examples given above are cancellative, being manifestly given as convex subsets of real affine space.
However, the last example - - - a semilattice with $ cp(x, y) = x vee y $ whenever $ 0 lt p lt 1 $ - - - is non - cancellative.
Convex spaces have been rediscovered many times under many different names.
References tend to define $ cp $ only for $ 0 lt p lt 1 $ , but it seems obvious that it's best to include the edge cases as well.
Classically, it makes no difference, but the definition above is probably better in constructive mathematics.
arXiv/090(iii)5522 Many other references, and a discussion of how convex spaces have been repeatedly rediscovered, can be found at the $ n $ - Category Caf&233; post Convex Spaces.
An indefinite integral is something less definite than a definite integral.
Whereas a definite integral is typically some kind of number or other concrete quantity, an indefinite integral is typically another variable quantity of the same type as the integrand.
The term 'indefinite integral' is itself rather indefinite, having been used for a variety of slightly different concepts.
Both semidefinite integrals and antiderivatives are more precise versions of indefinite integrals.
The fundamental theorem of calculus is basically the theorem that these different kinds of indefinite integral are essentially the same thing.
To begin with, we will discuss the integration of real - valued functions on the real line, but much of this can be generalized to other contexts.
So let $ f $ be a partial function from $ mathbb{R} $ to $ mathbb{R} $ ; typically, the domain of $ f $ will be an interval, but we do not require this.
If $ a $ is a real number (usually in the domain of $ f $ , or at least in the domain's closure), then the semidefinite integral of $ f $ from $ a $ (or with initial point $ a $ ) is the function $ x mapsto inta^x f(t) , mathrm{d}t $ .
(If $ x lt a $ , then we must define $ inta^x $ as $ - intx^a $ .)
The semidefinite integral is defined in terms of the definite integral.
We can put names such as 'Riemann' and 'Lebesgue' between 'semidefinite' and 'integral' to specify a particular kind of definite integral to be used.
Note that the domain of the semidefinite integral is an interval containing $ a $ and contained in the domain of $ f $ (or at least in its closure if we allow improper integrals or integrating almost functions).
If we start by defining $ f $ as a locally integrable function on a closed interval $ I $ containing $ a $ , then the semidefinite integral will also have $ I $ as its domain.
The value at $ x $ of the semidefinite integral from $ a $ may be denoted $ inta f(x) , mathrm{d}x $ for short.
Notice that this notation has no dummy variable; we only need to introduce the dummy variable $ t $ to unfold the definition.
(Indeed, some writers will abuse notation, writing $ inta^x f(x) , mathrm{d}x $ for the semidefinite integral.)
But as in $ mathrm{d}y/mathrm{d}x $ , the $ x $ here is not a free variable either, since we cannot freely use substitution; it has to be viewed as variable quantity instead.
Rather, if you want to evaluate $ inta f(x) , mathrm{d}x $ when $ x $ is some number $ b $ , then the notation for this is $ inta^b f(x) , mathrm{d}x $ , in which $ x $ has now become a dummy variable but has not simply been replaced with $ b $ .
If $ a $ and $ C $ are real numbers (with $ a $ in the domain of $ f $ or its closure), then the indefinite integral of $ f $ from $ a $ with initial value $ C $ is the function $ x mapsto C + inta^x f(t) , mathrm{d}t $ .
We may write this value as $ C + inta f(x) , mathrm{d}x $ for short.
This is only one of the meanings of 'indefinite integral', but it is the only one that doesn't have alternative unambiguous terminology.
Note that $ C $ is the value of the indefinite integral at $ a $ ; thus, $ C $ is the initial value if $ a $ is the initial point.
But for authors who use this concept, there is often no need to mention either $ a $ or $ C $ (and hence no terminology needed for them), because they are interested only in whether some other function $ F $ is an indefinite integral of $ f $ , where $ f $ is a locally integrable function on some closed interval.
If $ F $ is a partial function from $ mathbb{R} $ to $ mathbb{R} $ , then $ F $ is an antiderivative of $ f $ (or an antidifferential of $ f , mathrm{d}x $ ) if $ f $ is the derivative of $ F $ on its domain: $ forall, x in dom F, ; f(x) = F'(x) $ .
A posteriori, $ F $ must be differentiable.
This is the usual meaning of 'indefinite integral' in modern Calculus textbooks using the Riemann integral, especially when the domain of $ f $ is an interval.
If $ F $ is a Lebesgue - measurable partial almost function from $ mathbb{R} $ to $ mathbb{R} $ , then $ F $ is an almost antiderivative of $ f $ if $ f $ is the derivative of $ F $ almost everywhere: $ operatorname{ess}forall, x in dom F, ; f(x) = F'(x) $ .
We are especially interested in the case where $ F $ is absolutely continuous.
This is not standard terminology, but it fits in well with other 'almost' terminology in measure theory.
This is a common meaning of 'indefinite integral' when using the Lebesgue integral.
The main property linking the different kinds of indefinite integral is the fundamental theorem of calculus (FTC).
For various definitions of integral, one can prove that every semidefinite integral, or more generally any indefinite integral in the sense of Definition , is an antiderivative; and that every antiderivative, or more generally every almost antiderivative, is an indefinite integral; possibly with technical conditions (depending on the type of integral concerned) such as differentiability or absolute continuity.
See that article for details.
Indefinite integrals provide solutions to differential equations.
Of course, the definition of an antiderivative is that it is the solution to a particularly simple differential equation.
Employing the FTC, we see that the indefinite integrals are the solutions to the corresponding initial - value problems.
Specifically, the solution to $ F'(x) = f(x), ; F(a) = C $ is the indefinite integral of $ f $ with initial point $ a $ and initial value $ C $ : $ F(x) = C + inta f(x) , mathrm{d}x $ .
When $ omega $ is an exterior $ 1 $ - form on a subspace $ S $ of the cartesian space $ mathbb{R}^n $ , then we can define an antiderivative (or antidifferential) of $ omega $ to be any real - valued function $ f $ on $ S $ such that $ mathrm{d}f = omega $ .
Then when $ P $ is a point in $ S $ (or perhaps its closure), we can define the value of the semidefinite integral of $ omega $ with initial point $ P $ to be the integral of $ omega $ along a straight line segment from $ P $ ; the domain is a star - convex set radiating from $ P $ and contained in (the closure of) $ S $ .
If we define an indefinite integral as a semidefinite integral plus a constant initial value, then every antiderivative of $ omega $ on a star - convex set is an indefinite integral.
Conversely, every indefinite integral is an antiderivative if $ omega $ is closed.
If $ omega $ is not closed, then it still has indefinite integrals (as long as it's continuous or otherwise locally integrable), but these are no longer antiderivatives (which non - closed forms never have).
This can perhaps be generalized to Riemannian manifolds by considering integrals along geodesics; although the geodesic between two points is not always unique (even when it exists), it is unique on a sufficiently small (and often quite large) neighbourhood.
(For example, on a sphere, as long as $ omega $ is integrable, we can define the indefinite integral this way at every point except the one directly opposite the initial point.)
However, this straight - line definition seems rather artificial, and it might be best to use the more notion of semidefinite integral below, applicable only to closed forms but on more general manifolds.
We can generalize to exterior differential forms on differentiable manifolds, generalizing the FTC to the Stokes theorem.
It's clear what an antiderivative is in this context: $ alpha $ is an exterior antiderivative of $ omega $ iff $ omega $ is the exterior derivative of $ alpha $ .
On a smooth manifold, we know what 'almost' means and so can also define exterior almost antiderivatives.
If $ omega $ is a $ 1 $ - form on any differentiable manifold and $ P $ is a point in its domain, then the semidefinite integral of $ omega $ with initial point $ P $ is defined at another point $ Q $ iff the integral of $ omega $ is the same along any path from $ P $ to $ Q $ (and then that integral is the value).
We can define an indefinite integral by adding a constant initial value.
Then every antiderivative on a path - connected domain is an indefinite integral, and conversely every indefinite integral is an antiderivative.
By definition, $ omega $ is exact iff an antiderivative exists, and therefore iff an indefinite integral exists on each path - connected component.
Similarly, $ omega $ is closed iff
it has an indefinite integral on a neighbourhood of each point; if the domain of $ omega $ is simply connected, then the indefinite integral can be extended to the entire domain.
It remains to consider a good notion of semidefinite and indefinite integrals for higher - rank forms.
In an algebraic limit field $ F $ , the notion of a derivative is well defined and is represented by the Newton - Leibniz operator $ tilde{D} $ .
Given a subset $ S subseteq F $ , and a function $ f:S to F $ , the set of antiderivatives of $ f $ is the fiber of the Newton - Leibniz operator at $ f $ : $ {g in D^1(S, F) vert tilde{D}(g) = f } $ An antiderivative is an element of the above subset.
tableofcontents A power series in a variable $ X $ and with coefficients in a ring $ R $ is a series of the form $ sum{n = 0}^infty an X^n $ where $ an $ is in $ R $ for each $ nge 0 $ .
Given that there are no additional convergence conditions, a power series is also termed emphatically as a formal power series.
If $ R $ is commutative, then the collection of formal power series in a variable $ X $ with coefficients in $ R $ forms a commutative ring denoted by $ R X $ .
More generally, a power series in $ k $ commuting variables $ X1, ldots, Xk $ with coefficients in a ring $ R $ has the form $ sum{n1=0, n2=0, ldots, nk = 0}^infty a{n1ldots nk} X1^{n1} X2^{n2}cdots Xk^{nk} $ .
If $ R $ is commutative, then the collection of formal power series in $ k $ commuting variables $ X1, ldots, Xk $ form a formal power series ring denoted by $ R X1, ldots, Xk $ .
More generally, we can consider noncommutative (associative unital) ring $ R $ and words in noncommutative variables $ X1, ldots, Xk $ of the form $ w = X{i1}cdots X{im} $ (where $ m $ has nothing to do with $ k $ ) and with coefficient $ aw in R $ (here $ w $ is a word of any length, not a multiindex in the previous sense).
Thus the power sum is of the form $ sumw aw Xw $
and they form a formal power series ring in variables $ X1, ldots, Xk $ denoted by $ Rlangle langle X1, ldots, Xk ranglerangle $ .
Furthermore, $ R $ can be even a noncommutative semiring in which case the words belong to the free monoid on the set $ S = { X1, ldots, Xk } $ , the partial sums are then belong to a monoid semiring $ Rlangle Srangle $ .
The formal power series then also form a semiring, by the multiplication rule $ sum{r} ar Xr cdot sum bs Xs = sumw sum{u, v; w = u v} au bv Xw $ Of course, this implies that in a specialization, $ b $ - s commute with variables $ X{ik} $ ; what is usually generalized to take some endomorphisms into an account (like at noncommutative polynomial level of partial sums where we get skew - polynomial rings, i.e. iterated Ore extensions).
For a natural number $ k $ , a power series $ sum{n=0}^infty an X^n $ such that $ an = 0 $ for all $ n gt k $ is a polynomial of degree at most $ k $ .
For $ f in C^infty(mathbb{R}) $ a smooth function on the real line, and for $ f^{(n)} in C^infty(mathbb{R}) $ denoting its $ n $ th derivative its MacLaurin series (its Taylor series at $ 0 $ ) is the power series $ sum{n = 0}^infty frac{1}{n!} f^{(n)}(0) x^n , $ .
If this power series converges to $ f $ , then we say that $ f $ is analytic.
This follows easily from the observation that we can invert $ 1 + x b $ for any power series $ b $ by forming $ 1 - x b + x^2 b^2 - ldots $ and collecting only finitely many terms in each degree.
As a simple corollary, $ R x1, ldots, xn $ equipped with the ideal $ (x1, ldots, xn) $ is the free adic $ R $ - algebra on $ n $ generators, in the sense that it is the value of the left adjoint $ Pow $ to the forgetful functor $ Ideal: AdicRAlg to Set: (A, I) mapsto I $ as applied to the set $ {x1, ldots, xn } $ .
The idea is that for each adic $ R $ - algebra $ (S, I) $ and element $ (s1, ldots sn) in I^n $ , there is a unique adic algebra map $ R x1, ldots, xn to S $ that sends $ xi $ to $ si $ ; this adic algebra map sends a power series $ sum a{k1, ldots, kn} x1^{k1} xn^{kn} $ to the sequence of truncations $ left(sum{k1 + ldots + kn lt k} a{k1, ldots, kn} s1^{k1} ldots sn^{kn} mod I^kright)k $ belonging to $ underset{longleftarrow}{lim}k S/I^k cong S $ .
It follows that we may define a clone or cartesian operad as follows: the $ n^{th} $ component is the set $ In = (x1, ldots, xn) subset R x1, ldots, xn $ which is the monad value $ Ideal Pow({x1, ldots, xn } ) $ .
Letting $ M $ denote the monad $ Ideal circ Pow $ , with monad multiplication $ mu $ , and $ n $ the set $ {x1, ldots, xn } $ , the clone multiplication $ In times Ik^n to Ik $ is the composition of the maps $ M(n) times M(k)^n cong M(n) times hom(n, M(k)) stackrel{1 times func}{to} M(n) times hom(M(n), M M(k)) stackrel{eval}{to} M M(k) stackrel{mu(k)}{to} M(k) $ The clone multiplication thus defined is called substitution of power series; it takes a tuple consisting of $ p(x1, ldots, xn) in In, q1(x1, ldots xk) in Ik, ldots qn(x1, ldots, xk) in Ik) $ to a power series denoted as
$ p(q1(x1, ldots, xk), ldots qn(x1, ldots, xk)) $ .
The resulting clone or operad yields, in the particular case $ k = n = 1 $ , an associative substitution operation $ x R x times x R x stackrel{sub}{to} x R x $ with $ sub(p, q) = p circ q $ the power series $ p(q(x)) $ .
The group of invertible elements in the substitution monoid $ x R x $ consists of power series of the form $ a1 x + a2 x^2 + ldots $ where $ a1 $ is multiplicatively invertible in the ring $ R $ .
In other words, we can functionally invert a power series provided that the linear coefficient $ a1 $ is invertible in $ R $ .
Given power series $ a = a1 x + a2 x^2 + ldots $ and $ b = b1 x + b2 x^2 + ldots $ , we may read off coefficients of the composite $ a circ b $ as $ (a circ b)k = sum{n geq 1} an sum{k = k1 + ldots + kn} b{k1} b{k2} ldots b{kn} $ where in particular $ (a circ b)1 = a1 b1 $ .
Now $ a $ is the left functional inverse of $ b $ , or $ b $ is the right inverse of $ a $ , if $ (a circ b)(x) = x $ , i.e., if $ (a circ b)k = 1 $ if $ k = 1 $ and $ 0 $ otherwise.
The first equation says simply $ (a circ b)1 = a1 b1 = 1 $ which implies $ a1 $ is invertible.
Conversely, if $ a1 $ is multiplicatively invertible and $ b1 = a1^{ - 1} $ , then the equations $ array{ sum{n geq 1} an sum{k = k1 + ldots + kn} b{k1} b{k2} ldots b{kn} & = 1; if; k = 1 & = 0; if; k neq 1 } $ may be uniquely solved for the remaining $ ai $ 's given the $ bj $ 's, and uniquely solved for the remaining $ bj $ 's given the $ ai $ 's, by an inductive procedure: for $ k neq 1 $ we have $ a1 bk + ak b1^k + ; terms; an b{k1} ldots b{kn} = 0 $ and this allows us to solve for $ bk $ , $ bk = - a1^{ - 1}(ak b1^k + ; terms; an b{k1} ldots b{kn}) $ given the values $ a1, ldots, ak $ and earlier $ b $ - values $ b{kj} $ for $ kj lt k $ given by inductive hypothesis.
Similarly we can solve for $ ak $ in terms of given coefficients $ b1, ldots, bk $ and earlier $ a $ - values $ an $ , $ n lt k $ .
Thus every power series $ a $ has a right inverse if $ a1^{ - 1} $ exists, and $ b $ has a left inverse if $ b1^{ - 1} $ exists, and this completes the proof.
| ring with infinitesimals | function | - - - - - - - - - - - - - - - - - - - - - | - - - - - - - - - - - - - - - - - | | dual numbers | differentiable function
|
|
Weil ring | smooth function | | power series ring | analytic function
| Suppose that $ K $ is a Archimedean ordered field and $ Kepsilon $ is the ring of power series in $ K $ .
Since $ Kepsilon $ is a local ring, the quotient of $ Kepsilon $ by its ideal of non - invertible elements $ epsilon Kepsilon $ is the residue field $ K $ itself, and the canonical function used in defining the quotient is the function $ Re:Kepsilon to K $ which takes a number $ a in Kepsilon $ to its purely real component $ Re(a) in K $ and takes $ Re(epsilon) = 0 $ .
Since $ Kepsilon $ is an ordered $ K $ - algebra, there is a strictly monotone ring homomorphism $ h:K to Kepsilon $ .
An element $ a in Kepsilon $ is purely real if $ h(Re(a)) = a $ , and an element $ a in Kepsilon $ is purely infinitesimal if it is in the fiber of $ Re $ at $ 0 in K $ .
Zero is the only element in $ Kepsilon $ which is both purely real and purely infinitesimal.
Suppose that $ K $ is a sequentially Cauchy complete Archimedean ordered field with lattice structure, and $ Kepsilon $ is the ring of power series of $ K $ .
Then analytic functions are each definable on $ K $ using the algebraic, order, metric, and convergence structure on $ K $ .
The ring homomorphism $ h:K to Kepsilon $ preserves analytic functions: given a natural number $ n in mathbb{N} $ and a purely infinitesimal element $ eta in epsilon Kepsilon $ , then for every analytic function $ f in C^infty(K) $ , there is a function $ f{Kepsilon}:Kepsilon to Kepsilon $ such that for all elements $ x in K $ , $ f{Kepsilon}(h(x)) = h(f(x)) $ and $ f{Kepsilon}(h(x) + eta) = sum{i = 0}^{infty} frac{1}{i!} hleft(frac{d^i f}{d x^i}(x)right) eta^i $ A formalization in homotopy type theory and there in Coq is discussed in section 4 of The discussion of the differentiation of a converging power series term by term is at category: analysis, algebra A continuous function between two topological spaces that are each weakly homotopy equivalent to the circle is, up to homotopy, defined by how much it "winds" one circle around the other.
This is its winding number, an integer.
Equivalently this is the element in the fundamental group of the codomain which is represented by the map.
A special case of the degree of a continuous function.
Let $ Omega $ be a domain in a complex manifold and let $ P subset Omega $ be a (complex - ) analytic subset which is empty or of codimension one.
A holomorphic function $ f $ defined on the complement $ Omega setminus P $ is called a meromorphic function in $ Omega $ if for every point $ p in P $ one can find an arbitrarily small neighbourhood $ U $ of $ p $ in $ Omega $ and functions $ phi $ , $ psi $ holomorphic in $ U $ without common non - invertible factors in $ Int(U) $ , such that $ f = phi/psi $ in $ U setminus P $ .
In one complex dimension (one complex variable), hence on a Riemann surface, a meromorphic function is a complex - analytic function which is defined away from a set of isolated points.
Equivalently this is a holomorphic function with values in the Riemann sphere.
Compare a holomorphic function, which is valued in the complex plane (the Riemann sphere minus a point).
category: analysis A directional derivative, or G&226;teaux derivative, is a partial derivative of a function on a manifold along the direction given by a tangent vector.
Let $ F $ and $ G $ be locally convex topological vector spaces, $ U subseteq F $ an open subspace and $ Pcolon U to G $ a continuous map.
The derivative of $ P $ at the point $ f in U $ in the direction $ h in F $ is the limit $ D Pf h = lim{t to 0} frac{1}{t} (P(f + t h) - P(f)) $ .
If the limit exists for every $ f in U $ and every $ h in F $ then one can define a map $ D Pcolon U times F to G $ .
If the limit exists and $ D P $ is continuous (jointly in both variables), we say that $ P $ is continuously differentiable or $ C^1 $ .
A simple but nontrivial example is the operator $ Pcolon C^{infty}a, b to C^{infty}a, b $ given by $ P(f) coloneqq f f' $ with the derivative $ D P(f) h = f' h + f h' $ .
In the context of a Fréchet space, it may be that the directional derivative in every direction exists but the Fréchet derivative does not; however the existence of Fr&233;chet derivative implies the existence of directional derivatives in all directions.
The notion of directional derivatives extends to smooth manifolds (including infinite - dimensional ones based on Fréchet spaces) using local coordinates; the differentiability does not depend on the choice of a local chart.
In this case we have (if everything is defined) $ D Pcolon T(U) to G , $ where $ T(U) $ is the tangent space of $ U $ (an open subspace of $ T(F) $ .
An analogue of the directional derivative and Faa di Bruno formula in the Goodwillie calculus are in When a multifunction is differentiated with respect to any one of its arguments alone, holding the others fixed, then we are engaged in partial differentiation.
Very generally, let $ (Xi)i $ be a family of differentiable spaces (in some sense), let $ Y $ be another such space, and let $ f $ be a differentiable map to $ Y $ from a subspace $ U $ of the cartesian product $ prodi Xi $ .
Let $ d $ be a relevant differential or derivative operator, and let $ xi $ be the composite $ U hookrightarrow prodi Xi twoheadrightarrow Xi $ of the inclusion map of $ U $ and the $ i $ th product projection (the $ i $ th coordinate).
Then under good conditions, we have $ d{f} = sumi partiali{f} , d{xi} $ for a unique family $ (partiali{f})i $ of linear operators, the partial derivatives of $ f $ with respect to this decomposition of $ U $ .
The term $ partiali{f} , d{xi} $ , which may be denoted $ di{f} $ , is similarly a partial differential of $ f $ .
More precisely, we choose a category of differentiable spaces and differentiable maps between them, on which there is an endofunctor that takes each space $ U $ to a notion of tangent bundle $ T{U} $ , which is assumed to be a vector bundle over $ U $ , and takes a map $ fcolon U to Y $ to $ d{f}colon T{U} to T{Y} $ .
(Note that this isn't the case for generalised smooth spaces, but we could take microlinear spaces, as well as more familiar examples such as differentiable manifolds.)
Then $ d{xi}colon T{U} to T{Xi} $ , $ partiali{f}pcolon T{xi(p)}{Xi} to T{f(p)}{Y} $ is a linear operator between stalks (for $ p $ a point in $ U $ ), and the sum takes place in the vector space $ T{f(p)}{Y} $ .
We can extend this if we work in a cartesian closed category of generalised smooth spaces.
As in the above, let $ (Xi){i in I} $ be a family of smooth spaces and $ Y $ another smooth space.
For simplicity, let $ f colon prodi Xi to Y $ be a smooth map (aka morphism in the category) defined on the whole product (so we take $ U = prodi Xi $ in the above).
For $ i0 in I $ we can use the cartesian closed structure to define a morphism $ C^infty(prodi Xi, Y) xrightarrow{cong} C^infty(prod{i ne i0} Xi, C^infty(X{i0}, Y)) $ .
Thus given a morphism $ f colon prodi Xi to Y $ we get a parametrised family of morphisms $ X{i0} to Y $ which we could write (using parameters) as $ f(x{widehat{i0}})(x{i0}) $ .
As taking the derivative is a smooth functor, we can partially differentiate the morphisms by applying differentiation to the morphisms $ X{i0} to Y $ , thus yielding $ d f{i0}(x{widehat{i0}})(x{i0}, v) $ as a morphism $ prod{i ne i0} Xi to C^infty(T X{i0}, T Y) $ .
In full, $ d f{i0} $ is the image of $ f $ under the chain of morphisms:
$ C^infty(prodi Xi, Y) xrightarrow{cong} C^infty(prod{i ne i0} Xi, C^infty(X{i0}, Y)) xrightarrow{C^infty(prod{i ne i0} Xi, - )} C^infty(prod{i ne i0} Xi, C^infty(T X{i0}, T Y)) $ .
This is the partial derivative of $ f $ along $ X{i0} $ .
When the coordinates $ xi $ are given individual names $ u, v, w, ldots $ , one usually writes $ partial{f}/partial{u} $ for $ partiali{f} $ (where $ u $ replaces $ xi $ ); but $ (partial{f}/partial{u}){v, w, ldots} $ is less ambiguous.
Similarly, one can write $ (d{f}){v, w, ldots} $ for the partial differential $ (partial{f}/partial{u}){v, w, ldots} , d{u} $ , which is $ di{f} $ when $ u $ replaces $ xi $ .
(If $ d{f} $ is thought of as an infinitesimal change in $ f $ , then $ (d{f}){v, w, ldots} $ is an infinitesimal change subject to the condition that $ v, w, ldots $ are fixed.)
Then $ left(frac{partial{f}}{partial{u}}right){v, w, ldots} = frac{(d{f}){v, w, ldots}}{d{u}} = frac{(d{f}){v, w, ldots}}{(d{u}){v, w, ldots}} , $ which explains the notation and why ' $ partial $ ' looks like ' $ d $ '.
(The reason for the latter equality is that $ partiali{xj} $ is the Kronecker delta $ delta{i, j} $ .)
The Kock - Lawvere axiom for the axiomatization of differentiation in synthetic differential geometry was introduced in Let $ (X, g) $ be a Riemannian manifold and $ f in C^infty(X) $ a function.
The gradient of $ f $ is the vector field $ nabla f := g^{ - 1} d{dR} f in Gamma(T X) , , $ where $ d{dR} : C^infty(X) to Omega^1(X) $ is the de Rham differential.
This is the unique vector field $ nabla f $ such that $ d{dR} f = g( - , nabla f) $ or equivalently, if the manifold is oriented, this is the unique vector field such that $ d{dR} f = starg iota{nabla f} volg , , $ where $ volg $ is the volume form and $ starg $ is the Hodge star operator induced by $ g $ .
(The result is independent of orientation, which can be made explicit by interpreting both $ vol $ and $ star $ as valued in pseudoforms.)
Alternatively, the gradient of a scalar field $ A $ in some point $ xin M $ is calculated (or alternatively defined) by the integral formula $ grad A = lim{vol Dto 0} frac{1}{vol D} oint{partial D} vec{n} A d S $ where $ D $ runs over the domains with smooth boundary $ partial D $ containing point $ x $ and $ vec{n} $ is the unit vector of outer normal to the surface $ S $ .
The formula does not depend on the shape of boundaries taken in limiting process, so one can typically take a coordinate chart and balls with decreasing radius in this particular coordinate chart.
If $ (M, g) $ is the Cartesian space $ mathbb{R}^n $ endowed with the standard Euclidean metric, then $ nabla f= sum{i=1}^nfrac{partial f}{partial x^i}partiali $ .
This is the classical gradient from vector analysis.
In many classical applications of the gradient in vector analysis, the Riemannian structure is actually irrelevant, and the gradient can be replaced with the differential 1 - form.
A line integral is an integral along a curve.
These are sometimes called path integrals (not to be confused with the path integral in quantum physics, which is integration over a space of curves rather than along a curve in some space) and contour integrals (especially in complex analysis).
By the modern understanding of the integration of differential forms, one integrates differential 1 - forms (cotangent vector fields) along oriented curves, and so this would be the natural way to understand a line integral.
However, there are several slightly different line integrals, and not all of them are reducible to integration of $ 1 $ - forms along oriented curves.
Sometimes we have to fall back on more basic notions, ultimately the integration of pseudo - $ 1 $ - forms on a $ 1 $ - dimensional space.
Here we assume familiarity with integration of differential forms and pseudoforms, defining in terms of them the various classical notions of line integral.
In each case, the classical notation (developed before the rigorous treatment of analysis in the 19th century) is not taken literally by the classical definition (developed after the rigorous treatment and still found in calculus texts), and this definition is accompanied by a reparametrisation theorem.
We would like to make sense of the classical notation and eliminate the reparametrisation theorems (or at least make them all special cases of a general theorem to be proved once for all) using differential forms.
Often we find that we can relax some of the restrictions in the classical definition as well.
Classically, we have a Cartesian space $ X $ , a continuous map $ vec{F}colon X to X $ , and a continuously differentiable map $ Ccolon a, b to X $ ; the line integral of $ vec{F} $ along $ C $ is defined as $ intC vec{F} cdot mathrm{d}vec{r} coloneqq inta^b vec{F}(C(t)) cdot C'(t) , mathrm{d}t , $ where the integral on the right is a Riemann integral and $ C' $ is the derivative of $ C $ componentwise.
If $ phicolon e, f to a, b $ is a continuously differentiable increasing bijection, then $ int{C circ phi} vec{F} cdot mathrm{d}vec{r} = intC vec{F} cdot mathrm{d}vec{r} , $ the reparametrisation theorem.
We can start to justify the classical notation by interpreting $ vec{r} $ as the same map $ a, b to X $ as $ C $ ; then we have $ intC vec{F} cdot mathrm{d}vec{r} coloneqq inta^b vec{F}(vec{r}(t)) cdot vec{r}'(t) , mathrm{d}t , $ in which case the classical notation simply seems to be suppressing some of the notation in the formal definition on the right.
In particular, we interpret $ mathrm{d}vec{r} $ as meaning $ vec{r}'(t) , mathrm{d}t $ .
But this suggests that we should really be looking at differential forms.
Since $ X $ is a Cartesian space, we may identify it with any of its tangent spaces and so identify $ vec{F} $ with a tangent vector field on $ X $ , or equivalenty a vector - valued $ 0 $ - form.
Since $ vec{r} $ is only serving to parametrise the curve, it should be interpreted as something trivial, in this case the identity map on $ X $ , also viewed as a vector - valued $ 0 $ - form.
Then $ mathrm{d}vec{r} $ is a vector - valued $ 1 $ - form (which we can do since a Cartesian space has a trivial connection), and $ vec{F} cdot mathrm{d}vec{r} $ is an ordinary $ 1 $ - form.
Finally, since the curve $ C $ is given up to an increasing reparametrisation, it is an oriented $ 1 $ - submanifold of $ X $ .
Now we may interpret the notation $ int_C vec{F} cdot mathrm{d}vec{r} $ literally as the integral of a $ 1 $ - form.
It is now no longer necessary that $ C $ be given by a continuously differentiable parametrisation; the vector - valued $ 0 $ - form $ vec{r} $ is continuously differentiable regardless, and so we only need $ C $ to be a rectifiable curve (although it is a theorem that such a curve must have a parametrisation - - - by arclength if nothing else - - - that is continuously differentiable almost everywhere, so that the classical definition still covers this using a Riemann integral).
However, this operation from $ vec{F} $ to $ vec{F} cdot mathrm{d}vec{r} $ is something more fundamental in differential geometry; in fact, $ vec{F} cdot mathrm{d}vec{r} $ is simply $ vec{F}^flat $ , the cotangent vector field that corresponds to the tangent vector field $ vec{F} $ .
Understanding this, we wish to generalise $ X $ to any (pseudo) - Riemannian manifold.
In this case, we cannot interpret $ vec{r} $ literally, but we may still interpret $ mathrm{d}vec{r} $ as a vector - valued $ 1 $ - form, indeed as the tautological one that (viewing a $ 1 $ - form as an operation on vector fields) is the identity map on vector fields.
With this understanding, the classical notation still makes sense, although it is probably easier to write $ intC vec{F} cdot mathrm{d}vec{r} = intC vec{F}^flat $ as the most general definition of the line integral of a vector field along an oriented curve in a (pseudo) - Riemannian manifold.
Classically, we again have a Cartesian space $ X $ , now a continuous map $ f $ from $ X $ to $ mathbb{R} $ or $ mathbb{C} $ , and again a continuously differentiable map $ Ccolon a, b to X $ ; the line integral of $ f $ along $ C $ is defined as $ intC f mathrm{d}s coloneqq inta^b f(C(t)) {|C'(t)|} , mathrm{d}t , $ where again the integral on the right is a Riemann integral and $ C' $ is the derivative of $ C $ componentwise.
If $ phicolon e, f to a, b $ is a continuously differentiable bijection (whether increasing or decreasing), then $ int{C circ phi} f mathrm{d}s = intC f mathrm{d}s , $ the reparametrisation theorem.
We cannot interpret $ mathrm{d}s $ as the differential of anything; rather, $ mathrm{d}s $ is the magnitude of the line integral element $ mathrm{d}vec{r} $ from the previous section.
In particular, identifying $ vec{r} $ with $ C $ again, we have $ intC f mathrm{d}s coloneqq inta^b f(vec{r}(t)) {|vec{r}'(t)|} , mathrm{d}t , $ so $ mathrm{d}s $ seems to mean $ {|vec{r}'(t)|} , mathrm{d}t $ .
Using the standard orientation on $ a, b $ to change the $ 1 $ - form $ mathrm{d}t $ to the pseudo - $ 1 $ - form $ {|mathrm{d}t|} $ , this is consistent with $ mathrm{d}s = {|mathrm{d}vec{r}|} $ .
But for this to really make sense, we have to see what kind of object $ mathrm{d}s $ is on $ X $ .
It is neither a $ 1 $ - form (which can be integrated along an oriented curve) nor a pseudo - $ 1 $ - form (which can be integrated along a pseudo - oriented curve, that is a transversely oriented curve); it is instead an absolute $ 1 $ - form, which can be integrated along an unoriented curve.
If we interpret $ mathrm{d}vec{r} $ as the canonical vector - valued $ 1 $ - form again, then we can take its magnitude to get a positive semidefinite (nonnegative - scalar - valued, and in this case actually definite) absolute $ 1 $ - form, so $ mathrm{d}s = {|mathrm{d}vec{r}|} $ is literally true.
It would be nice to have notation without fake differentials and with the one piece of structure that actually plays a role: the metric.
If we multiply two $ 1 $ - forms using the symmetric product (instead of the exterior product as usual for differential forms), then we get a symmetric bilinear form, and in this way the (symmetric) square of the arclength element $ mathrm{d}s $ is the metric $ g $ .
Since $ mathrm{d}s $ is positive, we can reasonably call it the principal square root of $ g $ .
Thus, $ intC f mathrm{d}s = intC f sqrt{g} $ defines the line integral of a scalar field along an unoriented curve in a Riemannian manifold.
On a pseudo - Riemannian manifold, $ g $ itself may not be positive and so may not have a square root.
In that case, we can take the absolute value of $ g $ first and use $ intC f mathrm{d}s = intC f sqrt{|g|} , $ although this is most intuitive for curves that are consistently timelike or spacelike.
It's also possible to keep the previous formula and allow one of these two types of curve to have imaginary arclength; which one depends on conventions.
In any case, a line integral along a lightlike curve is zero.
Classically, we have the complex plane $ mathbb{C} $ , a continuous map $ fcolon mathbb{C} to mathbb{C} $ , and a continuously differentiable map $ Ccolon a, b to mathbb{C} $ ; the contour integral (or line integral again) of $ f $ along $ C $ is defined as $ intC f mathrm{d}z coloneqq inta^b f(C(t)) C'(t) , mathrm{d}t , $ where the integral on the right is a Riemann integral and $ C' $ is the derivative of $ C $ .
If $ phicolon e, f to a, b $ is a continuously differentiable increasing bijection, then $ int{C circ phi} f mathrm{d}z = intC f mathrm{d}z , $ the reparametrisation theorem.
We start to justify the classical notation by interpreting $ z $ as the same map $ a, b to mathbb{C} $ as $ C $ ; then we have $ intC f mathrm{d}z coloneqq inta^b f(z(t)) z'(t) , mathrm{d}t , $ in which case the classical notation seems again to be suppressing some of the notation in the formal definition.
In particular, $ mathrm{d}z $ is interpreted as $ z'(t) , mathrm{d}t $ .
But again, we should really be looking at differential forms.
We may identify the space $ mathbb{C} $ with the scalar field and so identify $ f $ with a scalar field on $ mathbb{C} $ , or equivalenty a $ 0 $ - form.
Since $ z $ is only serving to parametrise the curve, it should be interpreted as the identity map on $ mathbb{C} $ , also viewed as a $ 0 $ - form.
Then $ mathrm{d}z $ is a $ 1 $ - form, and $ f mathrm{d}z $ is a $ 1 $ - form.
Finally, since the curve $ C $ is given up to an increasing reparametrisation, it is an oriented $ 1 $ - submanifold of $ X $ .
Now we may interpet the notation $ intC f mathrm{d}z $ literally as the integral of a $ 1 $ - form.
It is now no longer necessary that $ C $ be given by a continuously differentiable parametrisation; the vector - valued $ 0 $ - form $ z $ is continuously differentiable regardless, and so we only need $ C $ to be a rectifiable curve (although it is a theorem that such a curve must have a continuously differentiable parametrisation after all).
Classically, we have the complex plane $ mathbb{C} $ , a continuous map $ fcolon mathbb{C} to mathbb{C} $ , and a continuously differentiable map $ Ccolon a, b to mathbb{C} $ ; the absolute contour integral (or whatever one calls it) of $ f $ along $ C $ is defined as $ intC f {|mathrm{d}z|} coloneqq inta^b f(C(t)) {|C'(t)|} , mathrm{d}t , $ where the integral on the right is a Riemann integral and $ C' $ is the derivative of $ C $ .
If $ phicolon e, f to a, b $ is a continuously differentiable bijection (whether increasing or decreasing), then $ int{C circ phi} f {|mathrm{d}z|} = intC f {|mathrm{d}z|} , $ the reparametrisation theorem.
As before, if $ z $ is interpreted as the same map $ a, b to mathbb{C} $ as $ C $ ; then we have $ intC f {|mathrm{d}z|} coloneqq inta^b f(z(t)) {|z'(t)|} , mathrm{d}t , $ so $ {|mathrm{d}z|} $ seems to mean $ {|z'(t)|} , mathrm{d}t $ .
As before, if we use the standard orientation on $ a, b $ to change the $ 1 $ - form $ mathrm{d}t $ to the pseudo - $ 1 $ - form $ {|mathrm{d}t|} $ , then $ {|mathrm{d}z|} $ is the absolute value of $ mathrm{d}z $ from before.
Of course, we should really be looking at differential forms.
Again, $ f $ is a scalar field on $ mathbb{C} $ , or equivalenty a $ 0 $ - form.
Again $ z $ is the identity map on $ mathbb{C} $ , viewed as a $ 0 $ - form.
Then $ mathrm{d}z $ is a $ 1 $ - form, its absolute value $ {|mathrm{d}z|} $ is a (positive definite) absolute $ 1 $ - form, and $ f {|mathrm{d}z|} $ is a (more general) absolute $ 1 $ - form.
Since $ C $ is given up to an arbitrary reparametrisation, it is an unoriented $ 1 $ - submanifold of $ X $ , which is just what we need for an absolute $ 1 $ - form.
Now we may interpet the notation $ intC f {|mathrm{d}z|} $ literally as the integral of an absolute $ 1 $ - form.
This is actually a special case of the line integral of a scalar field, since $ {|mathrm{d}z|} = {|mathrm{d}(x + mathrm{i}y)|} = {|mathrm{d}x + mathrm{i} , mathrm{d}y|} = sqrt{(mathrm{d}x)^2 + (mathrm{d}y)^2} = sqrt{g} = mathrm{d}s , $ since $ mathrm{d}x^2 + mathrm{d}y^2 $ is the standard metric on $ mathbb{C} $ .
Here are a couple of old Usenet posts that explain how line integrals of scalar fields should be viewed in terms of forms and pseudoforms.
These are obsolete with the concept of absolute forms, but they contain more explicit calculations.
See also Length is the volume of curves.
The characteristic function of a subset $ U $ of some set $ X $ is a function from $ X $ to the set $ TV $ of truth values (which classically is $ TV = {bot, top } $ ) that takes $ a $ in $ X $ to the truth value of the statement that $ a in U $ .
That is, $ chiU(a) ;Leftrightarrow; a in U , $ where $ chiU $ (also often $ 1U $ ) is the characteristic function of $ U $ .
More generally, the characteristic morphism of a subobject $ U $ of some objects $ X $ in a category with a subobject classifier $ Omega $ is the morphism from $ X $ to $ Omega $ that classifies $ U $ ; we have that $ array { U & hookrightarrow & X downarrow & & downarrow & chiU 1 & underset{top}to & Omega } $ is a pullback square.
A function which is differentiable function to arbitrary order is called a smooth function.
Let $ mathbb{R} $ be the real numbers.
A function $ f:mathbb{R} to mathbb{R} $ is smooth if it comes with a sequence of functions $ D^{( - )}f:mathbb{N} to (mathbb{R} to mathbb{R}) $ and a sequence of functions $ M^{( - )}f:mathbb{N} to (mathbb{Q}+ to mathbb{Q}+) $ in the positive rational numbers, such that $ |(D^{n}f)(x + h) - (D^{n}f)(x) - h (D^{n + 1}f)(x)| lt epsilon |h| $ Unwrapping the recursive definition above, a function $ f:mathbb{R} to mathbb{R} $ is smooth if it comes with a sequence of functions $ D^{( - )}f:mathbb{N} to (mathbb{R} to mathbb{R}) $ and a sequence of functions $ M^{( - )}f:mathbb{N} to (mathbb{Q}+ to mathbb{Q}+) $ in the positive rational numbers, such that $ left|f(x + h) - sum{i=0}^n frac{h^i (D^{i}f)(x)}{i!}right| lt epsilon |h^n| $ Given a predicate $ P $ on the real numbers $ mathbb{R} $ , let $ I $ denote the set of all elements in $ mathbb{R} $ for which $ P $ holds.
A partial function $ f:mathbb{R} to mathbb{R} $ is equivalently a function $ f:I to mathbb{R} $ for any such predicate $ P $ and set $ I $ .
A function $ f:I to mathbb{R} $ is smooth at a subset $ S subseteq I $ with injection $ j:S hookrightarrow mathbb{R} $ if it has a function $ frac{d^{ - } f}{d x^{ - }}:mathbb{N} times S to mathbb{R} $ with $ frac{d^0 f}{d x^0}left(aright) = a $ for all $ a in S $ , such that for all Archimedean ordered Artinian local $ mathbb{R} $ - algebras $ A $ with ring homomorphism $ hA:mathbb{R} to A $ and nilradical $ D $ , natural numbers $ n in mathbb{N} $ , and purely infinitesimal elements $ epsilon in D $ such that $ epsilon^{n + 1} = 0 $ $ fA(hA(j(a)) + epsilon) = sum{i = 0}^{n} frac{1}{i!} hAleft(frac{d^i f}{d x^i}left(aright)right) epsilon^i $ A function $ f:I to mathbb{R} $ is smooth at an element $ a in I $ if it is smooth at the singleton subset $ {a } $ , and a function $ f:I to mathbb{R} $ is smooth if it is smooth at the improper subset of $ I $ .
A function on (some open subset of) a cartesian space $ mathbb{R}^n $ with values in the real line $ mathbb{R} $ is smooth, or infinitely differentiable, if all its derivatives exist at all points.
More generally, if $ A subseteq mathbb{R}^n $ is any subset, a function $ f: A to mathbb{R} $ is defined to be smooth if it has a smooth extension to an open subset containing $ A $ .
By coinduction: A function $ f : mathbb{R} to mathbb{R} $ is smooth if (1) its derivative exists and (2) the derivative is itself a smooth function.
For $ A subseteq mathbb{R}^n $ , a smooth map $ phi: A to mathbb{R}^m $ is a function such that $ pi circ phi $ is a smooth function for every linear functional $ pi: mathbb{R}^m to mathbb{R} $ .
(In the case of finite - dimensional codomains as here, it suffices to take the $ pi $ to range over the $ m $ coordinate projections.)
The concept can be generalised from cartesian spaces to Banach spaces and some other infinite - dimensional spaces.
There is a locale - based analogue suitable for constructive mathematics which is not described as a function of points but as a special case of a continuous map (in the localic sense).
A topological manifold whose transition functions are smooth maps is a smooth manifold.
A smooth function between smooth manifolds is a function that (co - )restricts to a smooth function between subsets of Cartesian spaces, as above, with respect to any choice of atlases, hence which is a $ k $ - fold differentiable function (see there for more details), for all $ k $ The category Diff is the category whose objects are smooth manifolds and whose morphisms are smooth maps betweeen them.
There are various categories of generalised smooth spaces whose morphisms are generalized smooth functions.
For details see for example at smooth set.
Basic facts about smooth functions are Every analytic functions (for instance a holomorphic function) is also a smooth function.
A crucial property of smooth functions, however, is that they contain also bump functions.
An early account, in the context of Cohomotopy, cobordism theory and the Pontryagin - Thom construction: A partition of unity is a partition of the unit function on a topological space into a sum of continuous functions that are each non - zero only on small parts of the space.
Let $ X $ be a topological space.
A partition of unity on $ X $ is a collection $ {uj } {j in J} $ of continuous functions $ uj colon X to 0, 1 $ , $ jin J $ to the closed interval with its Euclidean metric topology such that $ sum{j in J} uj(x) = 1 $ for all $ xin X $ .
A partition of unity defines an open cover of $ X $ , consisting of the open sets $ uj^{ - 1}(0, 1 $ .
Call this the induced cover.
Given a cover $ mathcal{U} = {Uj } {jin J} $ of a topological space (open cover or closed or neither), the partition of unity $ {uj } J $ is subordinate to $ mathcal{U} $ if for all $ jin J $ , $ overline{uj^{ - 1}(0, 1} subset Uj $ .
What this means is that the open sets $ uj^{ - 1}(0, 1 $ form an open cover refining the cover $ mathcal{U} $ .
A partition of unity is point finite if for every $ xin X $ there is only a finite number of $ jin J $ such that $ uj(x) neq 0 $ .
A partition of unity is locally finite if for every $ xin X $ there is an open neighborhood $ U $ of $ x $ such that for only a finite number of $ jin J $ there is $ xin U $ such that $ uj(x) neq 0 $ .
{Harmless} Often, the property of local finiteness is included in the definition of a partition of unity.
This is harmless, since a result due to Michael R. Mather (Prop. below) says that for any partition of unity we can find a locally finite partition of unity with the same indexing set and whose induced cover refines the original induced cover.
Consider $ mathbb{R} $ with its Euclidean metric topology.
Let $ epsilon in (0, infty) $ and consider the open cover $ { (n - 1 - epsilon , n+1 + epsilon) subset mathbb{R} } {n in mathbb{Z} subset mathbb{R} } $ .
Then a partition of unity $ { fn colon mathbb{R} to 0, 1 } {n in mathbb{N}} $ subordinate to this cover is given by $ fn(x) coloneqq left{ array{ x - (n - 1) &vert& n - 1 leq x leq n 1 - (x - n) &vert& n leq x leq n+1 0 &vert& text{otherwise} } right } $ .
Assuming the axiom of choice then: Let $ (X, tau) $ be a topological space.
Then the following are equivalent: (i) $ (X, tau) $ is a paracompact Hausdorff space.
(i) Every open cover of $ (X, tau) $ admits a subordinate partition of unity.
Similarly normal spaces are equivalently those such that every locally finite cover has a subordinate partition of unity (reference Bourbaki, Topology Generale - find this!)
Slightly more generally, a topological space (not necessarily Hausdorff) is fully normal if and only every open cover admits a subordinate partition of unity.
A T1 - space is fully normal if and only if it is paracompact, in which case it is also Hausdorff.
For topological spaces that are not T1 - spaces, the condition of being fully normal is strictly stronger than paracompactness.
A regular locale is fully normal if and only if it is paracompact.
The usual proof of the existence of partitions of unity goes through for such locales since it does not make any use of points.
{ExistenceOnSmoothManifolds} Paracompact smooth manifolds admit locally finite smooth partitions of unity subordinate to any open cover (this follows from the existence of a smooth bump function on $ - 1, 1 $ ).
It is not true, however, that analytic manifolds have analytic partitions of unity - the aforementioned bump function is smooth but not analytic: Let $ X $ be a smooth manifold and let $ {Ui subset X } {i in I} $ be an open cover.
Then there exists cover $ left{ B0(epsilonj) underoverset{simeq}{psij}{to} Vj subset X right } {i in J} $ which is a locally finite refinement of $ {Ui subset X } {i in I} $ with each patch diffeomorphic to a closed ball in Euclidean space.
First consider the special case that $ X $ is compact topological space.
Let $ left{ mathbb{R}^n underoverset{simeq}{phij}{longrightarrow} Vj subset X right } $ be a smooth atlas representing the smooth structure on $ X $ .
The intersections $ left{ Ui cap Vj right } {i in I, j in J} $ still form an open cover of $ X $ .
Hence for each point $ x in X $ there is $ i in I $ and $ j in J $ with $ x in Ui cap Vj $ .
By the nature of the Euclidean topology, there exists a closed ball $ Bx $ around $ phij^{ - 1}(x) $ in $ phij^{ - 1}(Ui cap Vj) subset mathbb{R}^n $ .
Its image $ phij(Bx) subset X $ is a neighbourhood of $ x in X $ diffeomorphic to a closed ball.
The interiors of these balls form an open cover $ left{ Int(Bx) subset X right } {x in X} $ of $ X $ which, by construction, is a refinement of $ {Ui subset X } {i in I} $ .
By the assumption that $ X $ is compact, this has a finite subcover $ left{ Int(Bl) subset X right } {l in L} $ for $ L $ a finite set.
Hence $ left{ Bl subset X right } {l in L} $ is a finite cover by closed balls, hence in particular locally finite, and by construction it is still a refinement of the orignal cover.
This shows the statement for $ X $ compact.
Now for general $ X $ , notice that without restriction we may assume that $ X $ is connected, for if it is not, then we obtain the required refinement on all of $ X $ by finding one on each connected component.
But if a locally Euclidean paracompact Hausdorff space $ X $ is connected, then it is sigma - compact and in fact admits a countable increasing exhaustion $ V0 subset V1 subset V2 subset cdots $ by open subsets whose topological closures $ K0 subset K1 subset K2 subset cdots $ exhaust $ X $ by compact subspaces $ Kn $ (by the proof of this prop.).
For $ n in mathbb{N} $ , consider the open subspace $ V{n+2} setminus K{n - 1} ;subset; X $ which canonically inherits the structure of a smooth manifold (this prop.).
As above we find a refinement of the restriction of $ {Ui subset X } {i in I} $ to this open subset by closed balls and since the further subspace $ K{n+1}setminus Kn $ is still compact (by this lemma) there is a finite set $ Ln $ such that $ {B{ln} subset V{n+2} setminus K{n - 1} subset X } {ln in Ln} $ is a finite cover of $ K{n+1} setminus Kn $ by closed balls refining the original cover.
It follows that the union of all these $ left{ B{ln} subset X right } {n in mathbb{N}, ln in Ln} $ is a refinement by closed balls as required.
Its local finiteness follows by the fact that each $ B{ln} $ is contained in the "strip" $ V{n+2} setminus K{n - 1} $ , each strip contains only a finite set of $ B{ln} $ - s and each strip intersects only a finite number of other strips.
(Hence an open subset around a point $ x $ which intersects only a finite number of elements of the refined cover is given by any one of the balls $ B{ln} $ that contain $ x $ .)
Let $ X $ be a paracompact smooth manifold.
Then every open cover $ {Ui subset X } {i in I} $ has a subordinate partition of unity by functions $ {fi colon Ui to mathbb{R} } {i in I} $ which are smooth functions.
By lemma the given cover has a locally finite refinement by closed subsets diffeomorphic to closed balls: $ left{ B0(epsilonj) underoverset{simeq}{psij}{to} Vj subset X right } {j in J} , $ .
Given this, let $ hj ;colon; X longrightarrow mathbb{R} $ be the function which on $ Vj $ is given by a smooth bump function $ bj ;colon; mathbb{R} longrightarrow mathbb{R} $ with support $ supp(bj) = B0(epsilonj) $ : $ hj ;colon; x mapsto left{ array{ bj(psij^{ - 1}(x)) &vert& x in Vj 0 &vert& text{otherwise} } right. , $ .
By the nature of bump functions this is indeed a smooth function on all of $ X $ .
By local finiteness of the cover by closed balls, the function $ h ;colon; X longrightarrow mathbb{R} $ given by $ h(x) coloneqq underset{j in J}{sum} hj(x) $ is well defined (the sum involves only a finite number of non - vanishing contributions) and is smooth.
Therefore setting $ fj ;coloneqq; frac{hj}{h} $ then $ left{ fj right } {j in J} $ is a subordinate partition of unity by smooth functions as required.
A collection of functions $ mathcal{U} = {ui : X to 0, 1 } $ such that every $ xin X $ is in the support of some $ ui $ .
Then $ mathcal{U} $ is called locally finite if the cover $ ui^{ - 1}(0, 1 $ (i.e. the induced cover) is locally finite.
(Mather, 1965) Let $ {ui } J $ be a partition of unity.
Then there is a locally finite partition of unity $ {vi } {iin J} $ such that the induced cover of the latter is a refinement of the induced cover of the former.
The proof is Proposition A.(ii)8 in Dold 95 and Lemma (v)(i)8 on page 301 of Engelking 8(ix)
This implies that (locally finite) numerable covers are cofinal in induced covers arising from collections of functions as in the definition.
In particular, given the Milnor classifying space $ mathcal{B}^M G $ of a topological group $ G $ , which comes with a countable family of 'coordinate functions' $ mathcal{B}^M G to 0, 1 $ , has a numerable cover.
This is shown by Dold to be a trivialising cover for the universal bundle constructed by Milnor, and so the universal bundle is numerable.
Partitions of unity can be used in constructing maps from spaces to geometric realizations of simplicial spaces (incl.
simplicial sets) - for example a classifying map for a $ G $ - bundle where $ G $ is a Lie group.
Partitions of unity can be used to give explicit coboundaries for the cocycles of the complex of functions on a cover.
Let $ {Ui to X } $ be a open cover and $ {rhoi in C(X, mathbb{R}) } $ a collection of functions with Write $ C({Ui } ) : Delta^{op} to Top $ for the Cech nerve of the cover and $ C(C({Ui } ), mathbb{R}) $ for the cosimplicial ring of functions on this simplicial topological space; and $ (Cbullet(C({Ui } ), mathbb{R}), delta) $ for the corresponding (normalized) cochain complex: its differential is the alternating sum of the pullbacks of functions along the face maps, i.e. along the restriction maps $ delta = sumk ( - 1)^k delta{k}^ , $ .
For instance for $ f = {f{i1, i2, cdots, in} in C(U{i1} cap cdots cap U{i{n+1}}) } $ a collection of functions in degree $ n $ , we have $ (delta f){i0 cdots in i{n+1}} = sum{k = 0}^{n+1} ( - 1)^k f{i0 cdots i{k - 1} i{k+1} cdots i{n+1}} , $ .
This cochain complex has vanishing cochain cohomology in positive degree.
We can explicitly construct corresponding coboundaries using the partion of unity: assume that with the above notation $ f $ is a cocycle in positive degree, in that $ delta f = 0 $ .
Then define the $ (n - 1) $ - cochain $ lambda{i1 cdots i_n} := sum{i0} rho{i0} f{i0 i1 cdots in} , $ .
Here in the summands on the right the product is defined on $ U{i0} cap U{i1} cap cdots cap U{in} $ and extended as 0 to all of $ U{i1} cap cdots cap U{in} $ .
With this definition we have $ delta lambda = f , $ .
To see this we compute $ (delta lambda){i1 cdots i_{n+1}} & := sum{i0} rho{i0} sum{k=1}^n ( - 1)^k f{i0 i1 cdots i{k - 1} i{k+1} cdots i_{n+1}} & = pm sum{i0} rho{i0} f{i1 cdots i_{n+1}} & = f{i1 cdots i_{n+1}} , , $ where in the second step we used the condition $ delta f = 0 $ and in the last step we used the property of the partition of unity.
This construction is used a lot in Cech cohomology.
For instance it can be used to show in Chech cocycles that every principal bundle admits a connection on a bundle (see there for the details).
Discussion of partitions of unity in constructive mathematics is in >
This entry is about the concept of distributional densities in functional analysis.
For the concept in differential geometry and Lie theory see at distribution of subspaces.
{Idea} In functional analysis, the concept of distributional density, usually just called distribution for short, is a generalization of the concept of density, hence of something that may be integrated against a bump function to produce a number.
If a non - degenerate background density/volume form $ dvol $ is fixed, then each other density is a function relative to $ dvol $ , and hence with such an identification understood distributional densities are generalized functions, namely objects that may arise as potentially singular limits of sequences of smooth functions (i.e. of non - singular distributions).
Famous examples of such are the delta distributions and the Heaviside distribution which behave like constant functions with an infinitely sharp spike or kink, respectively.
Distributional densities appear notably as fundamental solutions to linear partial differential equations (such as for the wave equation/Klein - Gordon equation, whose fundamental solutions are the propagators of free quantum fields), which is the context in which the concept was originally introduced.
The study of their singularity structure (encoded by their singular support and their wave front set) is a fundamental tool in PDE theory (for instance in the propagation of singularities theorem), known as microlocal analysis.
Distributions are also fundamental in the rigorous construction of perturbative quantum field theory, where they appear in the variant as operator - valued distributions.
Often distributions are considered by default just on open subsets of Euclidean space with its canonical volume form tacitly understood.
But the concept of distributions makes sense more generally on general smooth manifolds (at least).
If these are equipped with the structure of a (pseudo - ) Riemannian manifold then the induced volume form again identifies distributions with generalized functions.
More in detail, given an actual density/volume form $ dvol $ on some smooth manifold $ X $ , then the operation of integration of bump functions (elements in the topological vector space $ C^infty_c(X) $ ) against $ dvol $ yields the continuous linear functional $ array{ C^infty_c(X) &longrightarrow& mathbb{R} b &mapsto& int_{x in X} b(x) dvol(x) } , $ .
However, not every continuous linear functional on $ C^inftyc(X) $ arises this way.
For example for $ x0 in X $ any point, the simple evaluation map $ delta{x0} ;colon; b mapsto b(x_0) $ is also a continuous linear functional on $ C^inftyc(X) $ (the "delta distribution").
While this is not the integral against any bump function times a fixed density, it is the limit of integrations against any sequence of bump functions (times the fixed density) whose support narrows in on $ x0 $ .
Therefore one defines a distributional density simply to be any continuous linear functional on $ C^infty_c(X) $ .
Various immediate variants of this definition may be considered.
For instance if the space of "test functions" $ C^inftyc(X) $ is generalized to that of all smooth functions, then one speaks of compactly supported distributions_, or if it is enlarged just to the Schwartz space of functions with all derivatives rapidly decreasing, then one speaks of tempered distributions.
These are important as on them there is a a good concept of Fourier transform of distributions.
Most of the usual constructions of differential calculus generalize from smooth functions to distributions, notably there is a concept of derivative of distributions (defined by generalizing the formula for integration by parts).
A key subtlety is that, however, some standard operations on functions become only partially defined on distributions, namely only when their singularity structure is compatible.
In particular there is a concept of pullback of distributions and the product of distributions compatible with that of smooth functions, but defined only whenever the wave front sets of the distributions involved satisfy suitable compatibility conditions.
Taking this subtlety into account for the operator - valued distributions appearing in perturbative quantum field theory is what leads to the concept of Wick algebras ("normal ordering"), see there for more.
Due to their potentially singular nature, there is more freedom in the extension of distributions than there is for smooth functions.
Notably for extensions from the complement of a single point to that point the freedom is in choosing a point - supported distribution, and these are precisely the derivatives of delta - distributions.
In the construction of time - ordered products of operator - valued distributions it is precisely this freedom in choosing point - extensions of distributions which in perturbative quantum field theory is known as "renormalization".
{Definitions} We first recall the Then we consider the axiomatic reformulation in terms of monads following Kock 1(i) {TraditionalDefinition} Distributions come in various flavors, depending on what spaces of functions they act on.
The functions they act on are called test functions; typically they are smooth functions on domains in Euclidean space satisfying some boundedness property.
The widest (and generally the default) notion is as follows.
For $ X subset mathbb{R}^n $ a smooth manifold given as an open subset of a Euclidean space, the topological vector space $ C^inftyc(X) $ of compactly supported test functions_ is the following (i) the underlying set is the set of bump functions, hence of smooth functions $ X to mathbb{R} $ to the real numbers with compact support; (i) equipped with evident real vector space structure given by pointwise addition and pointwise multipication of functions.
(i) equipped with the topology which is the metric topology induced from the family of seminorms $ rho{K, alpha}(f) = sup{x in K} |partial^{alpha} f| $ where $ K subseteq U $ is compact and $ alpha = (alpha1, ldots, alphan) $ is a multi - index and $ partial^{alpha} = frac{partial^{alpha1}}{partial x^{alpha1}} ldots frac{partial^{alphan}}{partial x^{alphan}} $ is the corresponding differential operator.
The topological vector space $ C^inftyc(X) $ of compactly supported test functions (def. ) is locally convex and complete with respect to its uniformity; it is in fact an LF - space: an inductive limit of Fréchet spaces $ Cc^{infty}(K) $ (each of which has empty interior as a subspace of $ Cc^{infty}(U) $ , so by the Baire category theorem, $ Cc^{infty}(U) $ is not itself a Fréchet space).
Let $ X subset mathbb{R}^n $ be a smooth manifold given as an open subset of Euclidean space.
A distribution on $ X $ is a continuous linear functional of the form $ C^infty_c(X) longrightarrow mathbb{R} $ from the locally convex topological vector space of compactly supported test functions (def. ) to the real numbers.
The space of distributions on $ X $ is denoted $ mathcal{D}'(X) $ (see also remark ).
There is an obvious bilinear pairing $ array{ mathcal{D}'(X) times C_c^{infty}(X) &longrightarrow& mathbb{R} (S, phi) &mapsto& S(phi) } $ given by evaluation.
Often one writes $ langle S, phirangle $ instead of $ S(phi) $ .
The space of distributions can be given the weak $ $ - topology, meaning the smallest topology rendering the maps $ langle - , phirangle ;colon; mathcal{D}'(U) to mathbb{R} $ continuous for all test functions $ phi $ .
As $ Cc^infty(U) $ is reflexive, this agrees with the weak topology.
See at locally convex topological vector space the section Continuous linear functionals for alternative characterizations of the continuity of distributions according to def. .
Notice that other natural topologies exist, such as uniform convergence on compact subsets of $ Cc^infty(U) $ (in this case, this agrees with uniform convergence on bounded subsets which usually goes by the name of the strong topology).
On general grounds the symbols $ D(X) $ or $ mathcal{D}(X) $ or similar would seem evident notation for the space of distributions on a smooth manifold $ X $ .
However, Laurent Schwartz in his seminal work (Schwartz 50) used $ mathcal{D}(X) $ to denote the space $ C^inftyc(X) $ of compactly supported continuous functions, and then $ mathcal{D}'(X) $ for its linear continuous dual, hence for the space of distributions (see also H&246;rmander 90, below def.
(ii)(i)1).
If $ f colon X to mathbb{R} $ is locally integrable, then for all test functions $ phi $ the Lebesgue integral $ langle f, phirangle = intX f(x)phi(x) d x $ is defined; in this way a function $ f $ locally integrable over $ X $ may be regarded as a distribution on $ X $ (explaining both the sense in which distributions are "generalized functions" and a reason for the angle - bracket notation for the evaluation pairing).
In particular, there is an obvious inclusion $ Cc^{infty}(X) hookrightarrow mathcal{D}'(X) $ and this inclusion turns out to be dense.
Other notions of spaces of distributions, each endowed with the weak $ * $ - topology, include $ rho{K, alpha, beta}(phi) = sup{x in K} |x^alpha partial^beta phi| $ where $ alpha $ , $ beta $ are multi - indices.
If $ X1, X2 subset mathbb{R}^n $ are two open subsets of Euclidean space, and if $ f ;colon; X1 overset{}{longrightarrow} X2 $ is a submersion (i.e. its differential is a surjective function $ d fx ;colon; Tx X1 to T{f(x)} X2 $ for all $ x in X1 $ ), then there is a unique continuous linear functional $ f^ast ;colon; mathcal{D}'(X2) longrightarrow mathcal{D}'(X1) $ between spaces of distributions (def. ) which extends the pullback of functions in that on a distribution represented by a bump function $ b $ it is given by precomposition $ f^ast b = b circ f , $ .
This is hence called the pullback of distributions.
(H&246;rmander 90, theorem (vi)(i)2) Let $ X $ be a smooth manifold.
Then a distribution on $ X $ is an equivalence class of (i) a choice of smooth atlas $ {mathbb{R}^n underoverset{simeq}{psii}{longrightarrow} Ui subset X } {i in I} $ ; (i) for each $ i in I $ a distribution $ phii ;colon; C^infty(mathbb{R}^n)to mathbb{R} $ on the $ i $ th chart, as above; (i) such that for all pairs $ (i, j) in I times I $ these component distributions are related on intersections of charts by pullback of distributions (def. )
along the coordinate change maps: $ phij = (psii^{ - 1} circ psij)^ast phii $ .
(H&246;rmander 90, def.
(vi)(iii)3) {CharacterizationByMonads} Since smooth functions on smooth manifolds are the subject of differential geometry, and since spaces of smooth functions are naturally themselves generalized smooth spaces, it makes sense to ask whether distribution theory is actually a native topic to differential geometry.
In particular we may ask how distributions in the functional analytic sense relate to the smooth linear functions on smooth spaces of smooth functions.
Indeed, with respect to the natural formulation of differential geometry via functorial geometry (topos theory) in terms of diffeological spaces, smooth sets etc.
it turns out that distributional densities are equivalently the smooth linear functionals on smooth spaces of smooth functions.
This is discussed at As $ mathcal{D}'(U) $ is dual to $ Cc^infty(U) $ , each continuous linear operator on $ Cc^infty(U) $ induces a corresponding linear operator on $ mathcal{D}'(U) $ in the obvious way.
Given $ Fcolon Cc^infty(U) to Cc^infty(U) $ we define $ F^*colon mathcal{D}'(U) to mathcal{D}'(U) $ according to the usual formula for dualities $ F^* S(phi) = S(F phi) $ .
However, since there is an obvious inclusion $ Cc^infty(U) to mathcal{D}'(U) $ induced by the standard inner product on $ Cc^infty(U) $ , what is more usually desired is not this dual operator but an extension operator.
That is, instead of $ F^* $ we want an operator $ F^dagger colon mathcal{D}'(U) to mathcal{D}'(U) $ with the property that for $ phi in Cc^infty(U) $ then $ F^dagger(phi) = F(phi) $ (identifying $ Cc^infty(U) $ with its image in $ mathcal{D}'(U) $ ).
Being slightly more careful, let us write $ iota colon Cc^infty(U) to mathcal{D}'(U) $ for the inclusion induced by the inner product.
Then we want $ F^dagger(iota phi) = iota (F(phi)) $ .
If the extension exists, we have $ F^dagger(iota phi)(psi) = iota(F(phi))(psi) = langle F(phi), psi rangle $ Now suppose that $ F $ has an adjoint, say $ F^+ $ , with respect to the inner product.
Note that this is not automatic since $ Cc^infty(U) $ is not a Hilbert space.
Moreover, even if $ F $ extends to the Hilbert completion the Hilbertian adjoint may not work since it may not define a continuous linear map on the subspace $ Cc^infty(U) $ .
But if $ F^+ $ does exist then we have $ F^dagger(iota phi)(psi) = langle F(phi), psi rangle = langle phi, F^+(psi) rangle $ In this case, the definition of $ F^dagger $ on the whole of $ mathcal{D}'(U) $ is obvious: simply take $ {F^+}^ $ .
That is, the dual operator to the adjoint to $ F $ .
In full, $ F^dagger colon mathcal{D}'(U) to mathcal{D}'(U) $ is defined via the formula $ langle F^dagger(S), phirangle = langle S, F^+(phi) rangle $ If the ground field is $ mathbb{C} $ then this carries through essentially unchanged except for the fact that one does not use the inner product on $ C_c^infty(U) $ but rather the associated bilinear pairing $ (phi, psi) = int_U phi psi $ This is to ensure that the inclusion $ C_c^infty(U) to mathcal{D}'(U) $ is complex linear and not conjugate linear.
Otherwise extending operators becomes complex.
Two instances are of particular importance: $ langle theta cdot phi, psi rangle = langle phi, psi cdot thetarangle $ where $ phi, psi $ are arbitrary test functions.
Thus we define $ theta cdot S $ by $ langle theta cdot S, psi rangle = langle S, theta cdot psi $ $ intU partial^i(psi)(x) phi(x); d x = - intU psi(x) partial^i(phi)(x); d x $ by simple integration by parts and the fact that $ phi $ , $ psi $ are compactly supported.
Thus differentiation is skew - adjoint and so we define the extension to distributions by $ langle partial^i(S), phirangle = - langle S, partial^i(phi) rangle $ for all test functions $ phi $ .
In general, $ langle partial^alpha S, phirangle = ( - 1)^{|alpha|}langle S, partial^alpha phi rangle $ where $ |alpha| = alpha1 + ldots + alphan $ is the total degree of the multi - index.
Thus derivatives of distributions are defined to all orders.
Some examples are given in the section "examples".
{MultiplicationsOfDistributions} See at multiplication of distributions As explained above, any locally integrable function on $ U $ defines a distribution on $ U $ .
Other examples may be produced fairly cheaply by restriction of functionals on various TVS which contain the test functions.
For instance: if $ Cc(U) $ denotes the space of real - valued continuous functions with compact support in $ U $ (topologized by uniform convergence on compacts), then a functional $ mu: Cc(U) to mathbb{R} $ is essentially the same as a signed measure on $ U $ (Riesz - Markov theorem), i.e., there is a unique signed measure $ d m $ for which $ mu(phi) = int_U phi d m $ .
Since the inclusion $ i: Cc^infty(U) hookrightarrow Cc(U) $ is continuous, it follows that a measure $ mu $ defines a distribution by simple restriction along $ i $ : $ Cc^infty(U) overset{i}{to} Cc(U) overset{mu}{to} mathbb{R} $ Specializing further, consider any function of bounded variation on $ U = mathbb{R} $ , say a bounded monotone increasing function $ alpha $ .
Then the Riemann - Stieltjes integral $ int_{mathbb{R}} f(x) dalpha(x) $ is defined for all functions $ f $ with compact support; this provides a measure $ dalpha $ and hence a distribution.
A prototypical example of this is provided by the Heaviside function: $ H(x) = 1 $ if $ x gt 0 $ , else 0.
("Heaviside": what a great pun!)
Here we have, for all $ f in C_c(mathbb{R}) $ , $ langle f, d H rangle = int_{mathbb{R}} f(x) d H(x) = f(0) $ As a distribution, the Heaviside measure is the famous Dirac distribution.
The long - standing intuitive practice among physicists and engineers is to write $ d H(x) = delta_0(x) d x $ where of course the function $ H(x) $ doesn't have a derivative in the classical sense (i.e., as a function), but as a distribution, it does.
Meanwhile, $ H(x) $ is itself the derivative of a continuous function: $ G(x) = max{x, 0 } $ .
For an example of a distribution on $ mathbb{R} $ which does not arise from a measure, consider the derivative of the Dirac distribution.
(As a functional, it maps a test function $ phi $ to $ - phi'(0) $ .)
These examples are by no means curiosities.
A fairly deep theorem is that every distribution arises as a linear combination of derivatives of continuous functions: $ S = sum{alpha in A} partial^alpha galpha $ The theory of distributions (and more generally of microlocal analysis) is central in perturbative quantum field theory in its rigorous incarnation via causal perturbation theory/perturbative algebraic quantum field theory.
For example the reason for normal ordered products in Wick algebras is given by the H&246;rmander criterion on wave front sets for the product of distributions to be well defind, and renormalization is understood to be the freedom in choosing extension of distributions of the resulting products of Feynman propagators.
See also operator - valued distribution and Wightman axioms.
A brief survey of applications of distribution theory to perturbative quantum field theory may be found here.
Within mathematics, distributions are quite commonplace; for example, de Rham appropriated them for his theory of currents.
Distribution theory has also long been used in the theory of partial differential equations.
Here is a sample theorem: A proof is given in these notes by Helgason.
The basic idea is to prove there exists a fundamental solution of $ D $ , i.e., a distribution $ T $ such that $ D T = delta_0 $ .
Then $ u = f T $ is smooth.
The existence of a fundamental solution involves a theorem of Paley - Wiener type.
There is another point of view on distributions: that they can be modeled by actual functions provided that one admits infinite and infinitesimal quantities of the type used in Robinson nonstandard analysis.
One particular approach is to formulate axiomatically the theory of distributions so that it can be interpreted in smooth toposes that model the axioms of synthetic differential geometry and support a suitable notion of invertible infinitesimal objects and infinitely large integers.
This is discussed in (Moerdijk - Reyes 91).
which closely mirrors the original treatment in Robinson's book Non - standard Analysis.
Examples of models that support these axioms are the toposes $ mathcal{Z} $ and $ mathcal{B} $ described there.
In $ mathbb{R}^n $ the distributions and generalized functions boil down to the same thing, so the terminology identifies them.
But on a manifold, the distributions/generalized densities (functionals on test functions) and generalized functions (functionals on test densities) do not agree.
See V. Guillemin, S. Sternberg:
Geometric asymptotics (free online).
While generalized functions pull back, distributions/generalized densities push forward (under some conditions, though).
More generally one can study generalized differential $ k $ - forms in local coordinates they look like $ sum falpha dx^{alpha1}wedge cdot wedge dx^{alphak} $ .
Usually they are called currents.
They are useful e.g. in the study of higher dimensional residua in higher dimensional complex geometry (cf.
Principles of algebraic geometry by Griffiths and Harris) and in geometric measure theory (cf. the monograph by Federer).
Sometimes one considers larger spaces of distributions, where worse singularities than in Schwarz theory are allowed.
Most well known are the theory of hyperfunctions and the theory of Coulombeau distributions.
Distributions can be alternatively described using nonstandard analysis, see there.
See also hyperfunction, ultradistribution and references therein.
Generalized functions were introduced by S. L. Sobolev in 1935, and independently (under the name distributions) by Laurent Schwartz in the 1940's, who unaware of Sobolev's work developed an extensive theory for them.
For an infinite - dimensional variant used in the foundation of Feynman path integral see also Connes distribution.
The original articles include Modern accounts include Lecture notes include and several chapters of the course Applications of distributions in physics are discussed in Application of distributions in perturbative quantum field theory is discussed in For more on this see the references at perturbative AQFT.
See also References on Colombeau algebra include {InTermsOfSmoothToposes} Discussion of distributions in terms morphisms out of internal homs in a smooth topos (distributions are the smooth linear functionals) is in and for the Cahiers topos in using results of and following the general conception of "intensive and extensive" in Similar sheaf theoretic discussion of distributions as morphisms of smooth spaces is in category: analysis >
This entry is about the concept of distributional densities in functional analysis.
For the concept in differential geometry and Lie theory see at distribution of subspaces.
{Idea} In functional analysis, the concept of distributional density, usually just called distribution for short, is a generalization of the concept of density, hence of something that may be integrated against a bump function to produce a number.
If a non - degenerate background density/volume form $ dvol $ is fixed, then each other density is a function relative to $ dvol $ , and hence with such an identification understood distributional densities are generalized functions, namely objects that may arise as potentially singular limits of sequences of smooth functions (i.e. of non - singular distributions).
Famous examples of such are the delta distributions and the Heaviside distribution which behave like constant functions with an infinitely sharp spike or kink, respectively.
Distributional densities appear notably as fundamental solutions to linear partial differential equations (such as for the wave equation/Klein - Gordon equation, whose fundamental solutions are the propagators of free quantum fields), which is the context in which the concept was originally introduced.
The study of their singularity structure (encoded by their singular support and their wave front set) is a fundamental tool in PDE theory (for instance in the propagation of singularities theorem), known as microlocal analysis.
Distributions are also fundamental in the rigorous construction of perturbative quantum field theory, where they appear in the variant as operator - valued distributions.
Often distributions are considered by default just on open subsets of Euclidean space with its canonical volume form tacitly understood.
But the concept of distributions makes sense more generally on general smooth manifolds (at least).
If these are equipped with the structure of a (pseudo - ) Riemannian manifold then the induced volume form again identifies distributions with generalized functions.
More in detail, given an actual density/volume form $ dvol $ on some smooth manifold $ X $ , then the operation of integration of bump functions (elements in the topological vector space $ C^inftyc(X) $ ) against $ dvol $ yields the continuous linear functional $ array{ C^inftyc(X) &longrightarrow& mathbb{R} b &mapsto& int{x in X} b(x) dvol(x) } , $ .
However, not every continuous linear functional on $ C^inftyc(X) $ arises this way.
For example for $ x0 in X $ any point, the simple evaluation map $ delta{x0} ;colon; b mapsto b(x0) $ is also a continuous linear functional on $ C^inftyc(X) $ (the "delta distribution").
While this is not the integral against any bump function times a fixed density, it is the limit of integrations against any sequence of bump functions (times the fixed density) whose support narrows in on $ x0 $ .
Therefore one defines a distributional density simply to be any continuous linear functional on $ C^inftyc(X) $ .
Various immediate variants of this definition may be considered.
For instance if the space of "test functions" $ C^inftyc(X) $ is generalized to that of all smooth functions, then one speaks of compactly supported distributions, or if it is enlarged just to the Schwartz space of functions with all derivatives rapidly decreasing, then one speaks of tempered distributions.
These are important as on them there is a a good concept of Fourier transform of distributions.
Most of the usual constructions of differential calculus generalize from smooth functions to distributions, notably there is a concept of derivative of distributions (defined by generalizing the formula for integration by parts).
A key subtlety is that, however, some standard operations on functions become only partially defined on distributions, namely only when their singularity structure is compatible.
In particular there is a concept of pullback of distributions and the product of distributions compatible with that of smooth functions, but defined only whenever the wave front sets of the distributions involved satisfy suitable compatibility conditions.
Taking this subtlety into account for the operator - valued distributions appearing in perturbative quantum field theory is what leads to the concept of Wick algebras ("normal ordering"), see there for more.
Due to their potentially singular nature, there is more freedom in the extension of distributions than there is for smooth functions.
Notably for extensions from the complement of a single point to that point the freedom is in choosing a point - supported distribution, and these are precisely the derivatives of delta - distributions.
In the construction of time - ordered products of operator - valued distributions it is precisely this freedom in choosing point - extensions of distributions which in perturbative quantum field theory is known as "renormalization".
{Definitions} We first recall the Then we consider the axiomatic reformulation in terms of monads following Kock 1(i) {TraditionalDefinition} Distributions come in various flavors, depending on what spaces of functions they act on.
The functions they act on are called test functions; typically they are smooth functions on domains in Euclidean space satisfying some boundedness property.
The widest (and generally the default) notion is as follows.
For $ X subset mathbb{R}^n $ a smooth manifold given as an open subset of a Euclidean space, the topological vector space $ C^inftyc(X) $ of compactly supported test functions is the following (i) the underlying set is the set of bump functions, hence of smooth functions $ X to mathbb{R} $ to the real numbers with compact support; (i) equipped with evident real vector space structure given by pointwise addition and pointwise multipication of functions.
(i) equipped with the topology which is the metric topology induced from the family of seminorms $ rho{K, alpha}(f) = sup{x in K} |partial^{alpha} f| $ where $ K subseteq U $ is compact and $ alpha = (alpha1, ldots, alphan) $ is a multi - index and $ partial^{alpha} = frac{partial^{alpha1}}{partial x^{alpha1}} ldots frac{partial^{alphan}}{partial x^{alphan}} $ is the corresponding differential operator.
The topological vector space $ C^inftyc(X) $ of compactly supported test functions (def. ) is locally convex and complete with respect to its uniformity; it is in fact an LF - space: an inductive limit of Fréchet spaces $ Cc^{infty}(K) $ (each of which has empty interior as a subspace of $ Cc^{infty}(U) $ , so by the Baire category theorem, $ Cc^{infty}(U) $ is not itself a Fréchet space).
Let $ X subset mathbb{R}^n $ be a smooth manifold given as an open subset of Euclidean space.
A distribution on $ X $ is a continuous linear functional of the form $ C^inftyc(X) longrightarrow mathbb{R} $ from the locally convex topological vector space of compactly supported test functions (def. ) to the real numbers.
The space of distributions on $ X $ is denoted $ mathcal{D}'(X) $ (see also remark ).
There is an obvious bilinear pairing $ array{ mathcal{D}'(X) times Cc^{infty}(X) &longrightarrow& mathbb{R} (S, phi) &mapsto& S(phi) } $ given by evaluation.
Often one writes $ langle S, phirangle $ instead of $ S(phi) $ .
The space of distributions can be given the weak $ $ - topology, meaning the smallest topology rendering the maps $ langle - , phirangle ;colon; mathcal{D}'(U) to mathbb{R} $ continuous for all test functions $ phi $ .
As $ C_c^infty(U) $ is reflexive, this agrees with the weak topology.
See at locally convex topological vector space the section Continuous linear functionals for alternative characterizations of the continuity of distributions according to def. .
Notice that other natural topologies exist, such as uniform convergence on compact subsets of $ C_c^infty(U) $ (in this case, this agrees with uniform convergence on bounded subsets which usually goes by the name of the strong topology).
On general grounds the symbols $ D(X) $ or $ mathcal{D}(X) $ or similar would seem evident notation for the space of distributions on a smooth manifold $ X $ .
However, Laurent Schwartz in his seminal work (Schwartz 50) used $ mathcal{D}(X) $ to denote the space $ C^infty_c(X) $ of compactly supported continuous functions, and then $ mathcal{D}'(X) $ for its linear continuous dual, hence for the space of distributions (see also H&246;rmander 90, below def.
(ii)(i)1).
If $ f colon X to mathbb{R} $ is locally integrable, then for all test functions $ phi $ the Lebesgue integral $ langle f, phirangle = int_X f(x)phi(x) d x $ is defined; in this way a function $ f $ locally integrable over $ X $ may be regarded as a distribution on $ X $ (explaining both the sense in which distributions are "generalized functions" and a reason for the angle - bracket notation for the evaluation pairing).
In particular, there is an obvious inclusion $ C_c^{infty}(X) hookrightarrow mathcal{D}'(X) $ and this inclusion turns out to be dense.
Other notions of spaces of distributions, each endowed with the weak $ $ - topology, include $ rho{K, alpha, beta}(phi) = sup{x in K} |x^alpha partial^beta phi| $ where $ alpha $ , $ beta $ are multi - indices.
If $ X1, X2 subset mathbb{R}^n $ are two open subsets of Euclidean space, and if $ f ;colon; X1 overset{}{longrightarrow} X2 $ is a submersion (i.e. its differential is a surjective function $ d fx ;colon; Tx X1 to T{f(x)} X2 $ for all $ x in X1 $ ), then there is a unique continuous linear functional $ f^ast ;colon; mathcal{D}'(X2) longrightarrow mathcal{D}'(X1) $ between spaces of distributions (def. ) which extends the pullback of functions in that on a distribution represented by a bump function $ b $ it is given by precomposition $ f^ast b = b circ f , $ .
This is hence called the pullback of distributions.
(H&246;rmander 90, theorem (vi)(i)2) Let $ X $ be a smooth manifold.
Then a distribution on $ X $ is an equivalence class of (i) a choice of smooth atlas $ {mathbb{R}^n underoverset{simeq}{psii}{longrightarrow} Ui subset X } {i in I} $ ; (i) for each $ i in I $ a distribution $ phii ;colon; C^infty(mathbb{R}^n)to mathbb{R} $ on the $ i $ th chart, as above; (i) such that for all pairs $ (i, j) in I times I $ these component distributions are related on intersections of charts by pullback of distributions (def. )
along the coordinate change maps: $ phij = (psii^{ - 1} circ psij)^ast phii $ .
(H&246;rmander 90, def.
(vi)(iii)3) {CharacterizationByMonads} Since smooth functions on smooth manifolds are the subject of differential geometry, and since spaces of smooth functions are naturally themselves generalized smooth spaces, it makes sense to ask whether distribution theory is actually a native topic to differential geometry.
In particular we may ask how distributions in the functional analytic sense relate to the smooth linear functions on smooth spaces of smooth functions.
Indeed, with respect to the natural formulation of differential geometry via functorial geometry (topos theory) in terms of diffeological spaces, smooth sets etc.
it turns out that distributional densities are equivalently the smooth linear functionals on smooth spaces of smooth functions.
This is discussed at As $ mathcal{D}'(U) $ is dual to $ Cc^infty(U) $ , each continuous linear operator on $ Cc^infty(U) $ induces a corresponding linear operator on $ mathcal{D}'(U) $ in the obvious way.
Given $ Fcolon Cc^infty(U) to Cc^infty(U) $ we define $ F^colon mathcal{D}'(U) to mathcal{D}'(U) $ according to the usual formula for dualities $ F^ S(phi) = S(F phi) $ .
However, since there is an obvious inclusion $ Cc^infty(U) to mathcal{D}'(U) $ induced by the standard inner product on $ Cc^infty(U) $ , what is more usually desired is not this dual operator but an extension operator.
That is, instead of $ F^ $ we want an operator $ F^dagger colon mathcal{D}'(U) to mathcal{D}'(U) $ with the property that for $ phi in Cc^infty(U) $ then $ F^dagger(phi) = F(phi) $ (identifying $ Cc^infty(U) $ with its image in $ mathcal{D}'(U) $ ).
Being slightly more careful, let us write $ iota colon C_c^infty(U) to mathcal{D}'(U) $ for the inclusion induced by the inner product.
Then we want $ F^dagger(iota phi) = iota (F(phi)) $ .
If the extension exists, we have $ F^dagger(iota phi)(psi) = iota(F(phi))(psi) = langle F(phi), psi rangle $ Now suppose that $ F $ has an adjoint, say $ F^+ $ , with respect to the inner product.
Note that this is not automatic since $ Cc^infty(U) $ is not a Hilbert space.
Moreover, even if $ F $ extends to the Hilbert completion the Hilbertian adjoint may not work since it may not define a continuous linear map on the subspace $ Cc^infty(U) $ .
But if $ F^+ $ does exist then we have $ F^dagger(iota phi)(psi) = langle F(phi), psi rangle = langle phi, F^+(psi) rangle $ In this case, the definition of $ F^dagger $ on the whole of $ mathcal{D}'(U) $ is obvious: simply take $ {F^+}^ $ .
That is, the dual operator to the adjoint to $ F $ .
In full, $ F^dagger colon mathcal{D}'(U) to mathcal{D}'(U) $ is defined via the formula $ langle F^dagger(S), phirangle = langle S, F^+(phi) rangle $ If the ground field is $ mathbb{C} $ then this carries through essentially unchanged except for the fact that one does not use the inner product on $ Cc^infty(U) $ but rather the associated bilinear pairing $ (phi, psi) = intU phi psi $ This is to ensure that the inclusion $ Cc^infty(U) to mathcal{D}'(U) $ is complex linear and not conjugate linear.
Otherwise extending operators becomes complex.
Two instances are of particular importance: $ langle theta cdot phi, psi rangle = langle phi, psi cdot thetarangle $ where $ phi, psi $ are arbitrary test functions.
Thus we define $ theta cdot S $ by $ langle theta cdot S, psi rangle = langle S, theta cdot psi $ $ intU partial^i(psi)(x) phi(x); d x = - intU psi(x) partial^i(phi)(x); d x $ by simple integration by parts and the fact that $ phi $ , $ psi $ are compactly supported.
Thus differentiation is skew - adjoint and so we define the extension to distributions by $ langle partial^i(S), phirangle = - langle S, partial^i(phi) rangle $ for all test functions $ phi $ .
In general, $ langle partial^alpha S, phirangle = ( - 1)^{|alpha|}langle S, partial^alpha phi rangle $ where $ |alpha| = alpha1 + ldots + alphan $ is the total degree of the multi - index.
Thus derivatives of distributions are defined to all orders.
Some examples are given in the section "examples".
{MultiplicationsOfDistributions} See at multiplication of distributions As explained above, any locally integrable function on $ U $ defines a distribution on $ U $ .
Other examples may be produced fairly cheaply by restriction of functionals on various TVS which contain the test functions.
For instance: if $ Cc(U) $ denotes the space of real - valued continuous functions with compact support in $ U $ (topologized by uniform convergence on compacts), then a functional $ mu: Cc(U) to mathbb{R} $ is essentially the same as a signed measure on $ U $ (Riesz - Markov theorem), i.e., there is a unique signed measure $ d m $ for which $ mu(phi) = intU phi d m $ .
Since the inclusion $ i: Cc^infty(U) hookrightarrow Cc(U) $ is continuous, it follows that a measure $ mu $ defines a distribution by simple restriction along $ i $ : $ Cc^infty(U) overset{i}{to} Cc(U) overset{mu}{to} mathbb{R} $ Specializing further, consider any function of bounded variation on $ U = mathbb{R} $ , say a bounded monotone increasing function $ alpha $ .
Then the Riemann - Stieltjes integral $ int{mathbb{R}} f(x) dalpha(x) $ is defined for all functions $ f $ with compact support; this provides a measure $ dalpha $ and hence a distribution.
A prototypical example of this is provided by the Heaviside function: $ H(x) = 1 $ if $ x gt 0 $ , else 0.
("Heaviside": what a great pun!)
Here we have, for all $ f in Cc(mathbb{R}) $ , $ langle f, d H rangle = int{mathbb{R}} f(x) d H(x) = f(0) $ As a distribution, the Heaviside measure is the famous Dirac distribution.
The long - standing intuitive practice among physicists and engineers is to write $ d H(x) = delta0(x) d x $ where of course the function $ H(x) $ doesn't have a derivative in the classical sense (i.e., as a function), but as a distribution, it does.
Meanwhile, $ H(x) $ is itself the derivative of a continuous function: $ G(x) = max{x, 0 } $ .
For an example of a distribution on $ mathbb{R} $ which does not arise from a measure, consider the derivative of the Dirac distribution.
(As a functional, it maps a test function $ phi $ to $ - phi'(0) $ .)
These examples are by no means curiosities.
A fairly deep theorem is that every distribution arises as a linear combination of derivatives of continuous functions: $ S = sum{alpha in A} partial^alpha galpha $ The theory of distributions (and more generally of microlocal analysis) is central in perturbative quantum field theory in its rigorous incarnation via causal perturbation theory/perturbative algebraic quantum field theory.
For example the reason for normal ordered products in Wick algebras is given by the H&246;rmander criterion on wave front sets for the product of distributions to be well defind, and renormalization is understood to be the freedom in choosing extension of distributions of the resulting products of Feynman propagators.
See also operator - valued distribution and Wightman axioms.
A brief survey of applications of distribution theory to perturbative quantum field theory may be found here.
Within mathematics, distributions are quite commonplace; for example, de Rham appropriated them for his theory of currents.
Distribution theory has also long been used in the theory of partial differential equations.
Here is a sample theorem: A proof is given in these notes by Helgason.
The basic idea is to prove there exists a fundamental solution of $ D $ , i.e., a distribution $ T $ such that $ D T = delta0 $ .
Then $ u = f * T $ is smooth.
The existence of a fundamental solution involves a theorem of Paley - Wiener type.
There is another point of view on distributions: that they can be modeled by actual functions provided that one admits infinite and infinitesimal quantities of the type used in Robinson nonstandard analysis.
One particular approach is to formulate axiomatically the theory of distributions so that it can be interpreted in smooth toposes that model the axioms of synthetic differential geometry and support a suitable notion of invertible infinitesimal objects and infinitely large integers.
This is discussed in (Moerdijk - Reyes 91).
which closely mirrors the original treatment in Robinson's book Non - standard Analysis.
Examples of models that support these axioms are the toposes $ mathcal{Z} $ and $ mathcal{B} $ described there.
In $ mathbb{R}^n $ the distributions and generalized functions boil down to the same thing, so the terminology identifies them.
But on a manifold, the distributions/generalized densities (functionals on test functions) and generalized functions (functionals on test densities) do not agree.
See V. Guillemin, S. Sternberg:
Geometric asymptotics (free online).
While generalized functions pull back, distributions/generalized densities push forward (under some conditions, though).
More generally one can study generalized differential $ k $ - forms in local coordinates they look like $ sum falpha dx^{alpha1}wedge cdot wedge dx^{alphak} $ .
Usually they are called currents.
They are useful e.g. in the study of higher dimensional residua in higher dimensional complex geometry (cf.
Principles of algebraic geometry by Griffiths and Harris) and in geometric measure theory (cf. the monograph by Federer).
Sometimes one considers larger spaces of distributions, where worse singularities than in Schwarz theory are allowed.
Most well known are the theory of hyperfunctions and the theory of Coulombeau distributions.
Distributions can be alternatively described using nonstandard analysis, see there.
See also hyperfunction, ultradistribution and references therein.
Generalized functions were introduced by S. L. Sobolev in 1935, and independently (under the name distributions) by Laurent Schwartz in the 1940's, who unaware of Sobolev's work developed an extensive theory for them.
For an infinite - dimensional variant used in the foundation of Feynman path integral see also Connes distribution.
The original articles include Modern accounts include Lecture notes include and several chapters of the course Applications of distributions in physics are discussed in Application of distributions in perturbative quantum field theory is discussed in For more on this see the references at perturbative AQFT.
See also References on Colombeau algebra include {InTermsOfSmoothToposes} Discussion of distributions in terms morphisms out of internal homs in a smooth topos (distributions are the smooth linear functionals) is in and for the Cahiers topos in using results of and following the general conception of "intensive and extensive" in Similar sheaf theoretic discussion of distributions as morphisms of smooth spaces is in category: analysis A probability distribution is a measure used in probability theory whose integral over some subspace of a measurable space is regarded as assigning a probability for some event to take values in this subset.
Often a probability density.
A probability distribution is a measure $ rho $ on a measurable space $ X $ such that In measure theory, a probability measure or probability distribution on a $ sigma $ - frame or more generally a $ sigma $ - complete distributive lattice $ (L, leq, bot, vee, top, wedge, Vee) $ is a probability valuation $ mu:L to 0, 1 $ such that the elements are mutually disjoint and the probability valuation is denumerably/countably additive
$ forall sin L^mathbb{N}. forall m in mathbb{N}. forall n in mathbb{N}. (m neq n) wedge (s(m) wedge s(n) = bot) $ $ forall sin L^mathbb{N}. mu(Vee{n:mathbb{N}} s(n)) = sum{n:mathbb{N}} mu(s(n)) $ The collection of all probability distributions on a measurable space carries various metric structures that are studied in information geometry: >
This article is about support of a function.
For other notions of support, see support. - - - tableofcontents Given a pointed set $ A $ with specified element $ 0 in A $ , a set $ X $ , and a function $ f colon X to A $ , the support of $ f $ is the subset of $ X $ on which $ f $ is not equal to $ 0 $ .
In constructive mathematics, there are multiple notions of inequality, due to the failure of the double negation law.
As a result, there are multiple notion of support of a function.
Thus, we define the following: Given a pointed set $ A $ with specified element $ 0 in A $ , a set $ X $ , and a function $ f colon X to A $ , the support of $ f $ is the subset of $ X $ on which $ f $ is not equal to $ 0 $ .
Given a pointed set $ A $ with an tight apartness relation $ $ and specified element $ 0 in A $ , a set $ X $ , and a function $ f colon X to A $ , the strong support of $ f $ is the subset of $ X $ on which $ f $ is apart from $ 0 $ .
{InTopology} In topology the support of a continuous function $ f colon X to A $ as above is the topological closure of the set of points on which $ f $ does not vanish: $ Supp(f) = Cl({x in X vert f(x) neq 0 in A } ) , $ .
If $ Supp(f) subset X $ is a compact subspace, then one says that $ f $ has compact support.
A periodic function on a $ mathbb{Z} $ - module $ M $ with a strict linear order $ lt $ where left and right addition are strictly monotonic is a function $ f:M to M $ with a positive element $ a in M $ , $ 0 lt a $ called the period, such that for all integers $ n in mathbb{Z} $ and elements $ x in M $ , $ f(x) = f(x + n a) $ , and for any other integer $ b in M $ where $ 0 lt b $ and for all integers $ n in mathbb{Z} $ and elements $ x in M $ , $ f(x) = f(x + n b) $ , $ a leq b $ .
See also:
One of the most important observations of category theory is that large parts of mathematics can be internalized in any category with sufficient structure.
The most basic examples of this involve algebraic structures; for instance, a group can be defined in any category with finite products, and an internal strict category can be defined in any ambient category with pullbacks.
For such algebraic (or even essentially algebraic) structures, which are defined by operations with equational axioms imposed, it suffices for the ambient category to have (usually finite) limits.
However, if we assume that the ambient category has additional structure, then much more of mathematics can be internalized, potentially including fields, local rings, finite sets, topological spaces, even the field of real numbers.
The idea is to exploit the fact that all mathematics can be written in the language of logic, and seek a way to internalize logic in a category with sufficient structure.
The basic ideas of the internal logic induced by a given category $ C $ are: and so on.
Once we formalize the notion of "logical theory", the construction of the internal logic can be interpreted as a functor $ Lang $ from suitably structured categories to theories.
The morphisms of theories are "interpretations", and so an internalization of some theory $ T $ (such as the "theory of groups") into a category $ C $ is a morphism of theories $ Tto Lang(C) $ .
Moreover, the functor $ Lang $ has a left adjoint functor: the syntactic category $ Syn $ of a theory.
Thus, a model of $ T $ in $ C $ is equally well a functor $ Syn(T)to C $ .
Frequently, this adjunction is even an equivalence of categories; see relation between type theory and category theory.
There are many different kinds of of "logical theories", each of which corresponds to a type of category in which such theories can be internalized (and yields a corresponding adjunction $ Syn dashv Lang $ ).
|Theory| |Category| | - - - - - - | - | - - - - - - - - | |Lawvere (or "finite product")| |category with finite products| |cartesian/essentially algebraic (or "left exact" or "finite limit")| |finitely complete category| |minimal logic| |cartesian closed category |regular| |regular category| |coherent| |coherent category| |disjunctive| |pre - lextensive category| |geometric| |infinitary coherent category (aka geometric category)| |constructive first - order| |Heyting category| |classical first - order| |Boolean category| |extensional dependent types| |locally cartesian closed category| |constructive higher order| |elementary topos| |classical higher order| |Boolean topos| |linear logic| |symmetric monoidal category| |cohesive modal logic| |cohesive topos| Each type of logic up to and including "geometric" can also be described in terms of sketches.
Not coincidentally, the corresponding types of category up to and including "geometric" fit into the framework of familial regularity and exactness.
Sketches can also describe theories applicable to categories not even having finite products, such as finite sum sketches, but the type - theoretic approach taken on this page requires at least finite products (or else something closely akin, such as a cartesian multicategory).
However, there are other sorts of internalization that do not fit in this framework.
For instance, to describe a monoid internal to a monoidal category, one needs an internal linear logic.
See internalization for a discussion of the more general notion in the context of doctrines.
We begin with the interpretation of internal first - order logic, which is the most used in toposes and related categories.
In this section, what we mean by a theory is a type theory without dependent types, but with a dependent logic.
This entails the following.
For example, the theory of a group has one type $ G $ , three function symbols $ m:Gtimes Gto G $ , $ i:Gto G $ , and $ e:1to G $ , and axioms $ array{ x:G, y:G, z:G | top vdash m(m(x, y), z) = m(x, m(y, z)) x:G | top vdash m(x, i(x)) = e ;wedge; m(i(x), x) = e x:G | top vdash m(x, e) = x ;wedge; m(e, x) = x. } $ This is an equational theory, meaning that each axiom is just one or more equations between terms that must hold in a given context.
For a different sort of example, the theory of a poset has one type $ P $ , one relation $ le:Ptimes P $ , and axioms $ array{ x:P | top vdash xle x x:P, y:P | xle y ;wedge; yle x vdash x=y x:P, y:P, z:P | xle y ;wedge; yle z vdash xle z. } $ Now suppose that we have a category $ C $ with finite limits and we want to interpret such a theory internally in $ C $ .
We identify the aspects of the theory with structures in the category by what is called categorical semantics: First, for each type in the theory we choose an object of $ C $ .
Then for each function symbol in the theory we choose a morphism in $ C $ .
And finally, for each relation in the theory we choose a subobject in $ C $ .
(We always interpret the relation of equality on a type $ A $ by the diagonal $ Ahookrightarrow Atimes A $ in $ C $ .)
Thus, for example, to interpret the theory of a group in $ C $ we must choose an object $ G $ and morphisms $ m:Gtimes Gto G $ , $ i:Gto G $ , and $ e:1to G $ , while to interpret the theory of a poset, we must choose an object $ P $ and a subobject $ le hookrightarrow Ptimes P $ .
Of course, this is not enough; we need to say somehow that the axioms are satisfied.
We first define, inductively, an interpretation of every term that can be constructed from the theory by a morphism in $ C $ .
For example, given an object $ G $ and a morphism $ m:Gtimes Gto G $ , there are two evident morphisms $ Gtimes Gtimes G to G $ which are the interpretations of the two terms $ m(m(x, y), z) $ and $ m(x, m(y, z)) $ .
We then define, inductively, an interpretation of every logical formula that can be constructed from the theory by a subobject in $ C $ .
The idea is that if $ x:A $ is a variable of type $ A $ and $ varphi(x) $ is a formula with $ x $ as its free variable, then the interpretation of $ varphi(x) $ should be the "subset" $ {xin A | varphi(x) } $ of $ A $ .
The base case of this induction is that if $ t $ is a term interpreted by a morphism $ Ato B $ and $ R:B $ is a relation symbol, then $ R(t) $ is interpreted by the pullback of the chosen subobject $ Rhookrightarrow B $ representing $ R $ along the morphism $ t:Ato B $ .
The building blocks of logical formulas then correspond to operations on the posets $ Sub(A) $ of subobjects in $ C $ , as follows.
|Logical operator| |Operation on $ Sub(A) $ | | - - - - - - - - - - - - - - - - | - | - - - - - - - - - - - - - - - - - - - - - | |conjunction: $ wedge $ | |intersection (pullback)| |truth: $ top $ | |top element ( $ A $ itself)| |disjunction: $ vee $ | |union| |falsity: $ bot $ | |bottom element (strict initial object)| |implication: $ Rightarrow $ | |Heyting implication| |existential quantification: $ exists $ | |left adjoint to pullback| |universal quantification: $ forall $ | |right adjoint to pullback|
The fact that existential and universal quantifiers can be interpreted as left and right adjoints to pullbacks was first realized by Bill Lawvere.
One way to realize that it makes sense is to notice that in Set, the image of a subset $ Rsubset A $ under a function $ f:Ato B $ can be defined as $ {bin B | (exists ain A)(ain R ;wedge; f(a)=b) } , $ while its "dual image" (the right adjoint to pullback) can be defined as $ {bin B | (forall a in A)(f(a)=b Rightarrow ain R) } $ .
Of course, not in all finitely complete categories $ C $ do all these operations on subobjects exist.
Moreover, in order for the relationship with logic to be well - behaved, any of the operations we make use of must be stable under (preserved by) pullbacks.
(Pullbacks of subobjects correspond to "innocuous" logical operations such as adding extra unused variables, duplicating variables, and so on, so they should definitely not affect the meaning of the logical connectives.
However, in linear logic such operations become less innocuous.)
In any category with finite limits, the posets $ Sub(A) $ always have finite intersections (given by pullback), including a top element (given by $ A $ itself).
Thus in any such category, we can interpret logical theories that use only the connectives $ wedge $ and $ top $ .
This includes both the theories of groups and posets considered above.
In a regular category, the existence of pullback - stable images implies that the base change functor $ f^:Sub(B)to Sub(A) $ along any map $ f:Ato B $ has a left adjoint, usually written $ existsf $ , and that these adjoints "commute with pullbacks" in an appropriate sense (given by the Beck - Chevalley condition).
Thus, in a regular category we can interpret any theory in so - called regular logic_, which uses only $ wedge $ , $ top $ , and $ exists $ .
Actually, some instances of $ exists $ can be interpreted in any category with finite limits: if $ f $ is itself a monomorphism, then $ f^ $ always has a left adjoint, given simply by composition with $ f $ .
On the logical side, this means that we can interpret "provably unique existence" in any category with finite limits.
Logic with $ wedge $ , $ top $ , and "provably unique existence" is called cartesian logic or finite - limit logic.
A coherent category is basically defined to be a regular category in which the subobject posets additionally have pullback - stable finite unions.
Thus, in a coherent category we can interpret so - called coherent logic, which adds $ vee $ and $ bot $ to regular logic.
Likewise, in an infinitary - coherent (or "geometric") category we can interpret geometric logic, which adds infinitary disjunctions $ bigveei varphii $ to coherent logic.
Geometric logic is especially important because it is preserved by the inverse image parts of geometric morphisms, and because any geometric theory has a classifying topos.
On the other hand, in a lextensive category, we do not have images or all unions, but if we have two subobjects of $ A $ which are disjoint (their intersection is initial), then their coproduct is also their union in $ Sub(A) $ .
Therefore, in a lextensive category we can interpret disjunctive logic, which is cartesian logic plus $ bot $ and "provably disjoint disjunction."
Likewise, in an infinitary - lextensive category we can interpret "infinitary - disjunctive logic."
Finally, in a Heyting category the base change functors $ f^:Sub(B)to Sub(A) $ also have right adjoints, usually written $ forall_f $ , and it is easy to see that this implies that each $ Sub(A) $ is also a Heyting algebra, hence has an "implication" $ Rightarrow $ as well.
(We define "negation" by $ neg varphi equiv varphi Rightarrow bot $ .)
Thus, in a Heyting category we can interpret all of (finitary, first - order) intuitionistic logic.
Now that we know how to interpret logic, we can say that a model of a given theory in $ C $ consists of a choice of objects, morphisms, and subobjects for the types, function symbols, and relation symbols as above, such that for each axiom $ Gamma | varphi vdash psi $ , we have $ varphile psi $ in $ Sub(Gamma) $ .
Here, $ Gamma $ is the product of the objects that correspond to the types of the variables in $ Gamma $ , $ varphi $ and $ psi $ are the interpretations of the formulas $ varphi $ and $ psi $ as subobjects of $ Gamma $ , and $ leq $ is the relation of subobject inclusion.
It is easy to verify that a model of the theory of a group in $ C $ is precisely an internal group object in $ C $ , as usually defined.
For instance, the validity of the axiom $ x:G, y:G, z:G | top vdash m(m(x, y), z) = m(x, m(y, z)) $ means that the equalizer of the two morphisms $ Gtimes Gtimes G to G $ must be all of $ Gtimes Gtimes G $ , or equivalently that those two morphisms must be equal.
The same happens in most other cases.
As described above, a model of a given theory $ T $ in a category $ C $ consists of an assignment |
| | |
| - - - - - - - - - - - - - - - - | - | - - - - - - - - - - - - - - - - - - - - - | |types of $ T $ | $ to $ |objects of $ C $ | |function symbols of $ T $ | $ to $ |morphisms of $ C $ | |relation symbols of $ T $ | $ to $ |subobjects in $ C $ | |axioms of $ T $ | $ to $ |containments in $ C $ |
This is a sort of heteromorphism in that it changes the name of things as it operates on them.
We can describe it more simply as a "translation of theories" as follows.
Given a category $ C $ (which may be regular, coherent, geometric, Heyting, etc.), we define its internal type theory (with first - order logic) $ Lang(C) $ to be the theory whose Now a model of $ T $ in $ C $ can be described simply as a morphism of theories (a "translation" or "interpretation") $ T to Lang(C) $ .
The functor $ Lang : Categories to Theories $ has a left adjoint, the syntactic category of a theory.
Thus we have a chain of natural isomorphisms
$ Theories(T, Lang(C)) cong Models(T, C) cong Categories(Syn(T), C)) $ .
Internal logic is not just a way to concisely describe internal structures in a category, but also gives us a way to prove things about them by "internal reasoning."
We simply need to verify that the "usual" methods of logical reasoning (for example, from $ varphivdash psi $ and $ psivdash chi $ deduce $ varphivdashchi $ ) are internally valid, in the sense that if the premises are satisfied in some model $ C $ (in the example, if $ varphile psi $ and $ psile chi $ ) then so is the conclusion (in the example, $ varphile chi $ ).
This is called the Soundness Theorem.
It then follows that if we start from the axioms of a theory and "reason normally" within type theory, which in practice amounts to pretending that the types are sets, the function symbols are functions, and the relation symbols are subsets, then anything we prove will still be true when the theory is interpreted in an arbitrary category, not just Set.
For example, by easy equational reasoning from the theory of a group, we can prove that inverses are unique, which is expressed by the logical sequent $ x:G, y:G, z:G | m(x, y)=e ;wedge; m(x, z)=e vdash y=z $ .
It follows that this is also true, suitably interpreted, as a statement about internal group objects in any category.
There are (at least) three caveats.
Firstly, we must take care to use only the rules appropriate to the fragment of logic that is valid in the particular categories we are interested in.
For example, if we want our conclusions to be valid in any regular category, we must restrict ourselves to reasoning "within regular logic."
Most mathematicians are not familiar with making such distinctions in their reasoning, but in practice most things one would want to say about a regular theory turn out to be provable in regular logic.
(We will not spell out the details of what this means.)
And once we are in a Heyting category, and in particular in a topos, this problem goes away and we can use full first - order logic.
The second, more important, caveat is that the internal logic of all these categories is, in general, constructive.
This means that, among other things, the interpretation of $ negnegvarphi $ is, in general, distinct from that of $ varphi $ , and that $ varphivee negvarphi $ is not always valid.
So even if we believe that classical logic (including the principle of excluded middle and even the axiom of choice) is "true, " as many mathematicians do, there is still a reason to look for proofs that are constructively acceptable, since it is only these which are valid in the internal logic of most categories.
If the category is Boolean and/or satisfies the internal axiom of choice, however, then this problem goes away, but these fail in many categories in which one wants to internalize (such as many Grothendieck toposes).
The third caveat is that one must take care to distinguish the internal logic of a category from what is externally true about it.
In general, internal validity is "local" truth, meaning things which become true "after passing to a cover."
This is particularly important for formulas involving disjunction and existence.
For example, an object's being projective in the category $ C $ is a different statement from its being internally projective, meaning that " $ X $ is projective" is true in the internal logic.
Another good example can be found in the different notions of finite object in a topos.
This problem goes away if the ambient category is well - pointed, but well - pointed categories are even rarer than Boolean ones satisfying choice; the only well - pointed Grothendieck topos is Set itself.
{syntactic_categories} The converse of the Soundness Theorem is called the Completeness Theorem, and states that if a sequent $ varphivdashpsi $ is valid in every model of a theory, then it is provable from that theory.
This is noticeably less trivial.
In classical first - order logic, where the only models considered are set - valued ones, the completeness theorem is usually proven using ultraproducts.
However, in categorical logic there is a more elegant approach (which additionally no longer depends on any form of the axiom of choice).
The syntactic category $ CT = Syn(T) $ of a theory $ T $ was mentioned above, as the left adjoint to the "internal logic functor" $ Lang $ .
By the Yoneda lemma, the syntactic category $ CT $ contains a "generic" model of the theory.
Moreover, by the construction of $ CT $ (see syntactic category), the valid sequents in this model are precisely those provable from the theory.
Therefore, if a sequent is valid in all models, it is in particular valid in the generic model in $ CT $ , and hence provable from $ T $ .
The universal property of $ C_T $ is also sometimes useful for semantic conclusions.
For instance, sometimes one can prove something about the generic model and then carry it over to all models.
Furthermore, if $ T $ lives in a sub - fragment of geometric logic (such as regular, coherent, lextensive, or geometric logic), then the Grothendieck topos of sheaves on $ C_T $ for its appropriate (regular, coherent, extensive, or geometric) coverage contains a $ T $ - model which is generic for models in Grothendieck toposes: any $ T $ - model in a Grothendieck topos is its image under the inverse image of a unique geometric morphism.
This topos is called the classifying topos of the theory.
The syntactic category of a theory can be considered as the "extensional essence" of that theory, since functors out of $ CT $ completely determine the $ T $ - models in any category $ D $ with suitable structure.
It therefore makes sense, in some contexts, to define a morphism of theories to be a functor between their syntactic categories, and an equivalence of theories (sometimes called a Morita equivalence_) to be an equivalence between their syntactic categories.
A morphism $ Tto T' $ between theories, in this sense, induces a functor from $ T' $ - models in $ D $ to $ T $ - models in $ D $ , for any category $ D $ with suitable structure, in a way which is natural in $ D $ .
In particular, theories which are "Morita equivalent" in this sense have naturally equivalent categories of models in all categories $ D $ with suitable structure; so they have the same "meaning" even though they may be presented quite differently.
(Note that this is a much stronger sort of equivalence than merely having equivalent categories of models in some particular category, such as $ Set $ .)
Moreover, the fact that the syntactic category is defined "syntactically" means that a morphism $ Tto T' $ actually induces a "translation" of the types, functions, and relations of $ T $ into those of $ T' $ .
By first applying various "completion" processes to syntactic categories before asking about equivalence, we obtain coarser notions of equivalence, which only induce equivalences of models in more restricted sorts of categories.
For instance, if we compare the exact completions of syntactic categories of regular theories, we obtain a notion of equivalence that induces equivalences of categories of models in all exact categories (not necessarily all regular ones).
Likewise for coherent theories and pretoposes, and for geometric theories and infinitary pretoposes.
Note, though, that the infinitary - pretopos completion of a (small) geometric theory is in fact already a (Grothendieck) topos, and coincides with the classifying topos considered above.
Thus, passage to classifying toposes is also an instance of this construction, and an equivalence of classifying toposes means that two theories have equivalent categories of models in all toposes.
(This is still much stronger than just having equivalent categories of models in $ Set $ .)
To be written, but see Kripke - Joyal semantics.
We now consider the internal language of a locally cartesian closed category as a dependent type theory.
Material to be moved here from relation between type theory and category theory.
To be written, but see Mitchell–Bénabou language for the version in a topos.
The topos Set in classical mathematics of course has as its internal logic the "ordinary" logic.
This is reproduced by following the abstract nonsense as follows: the terminal object of Set is the one - element set $ {} $ , the subobject classifier in Set is the two - element set $ Omega = {true, false } $ equipped with the map $ T : {} to Omega $ that picks the element $ true $ in $ Omega $ .
The Heyting algebra of subobjects of the terminal object is the poset $ L = { emptyset hookrightarrow {} } $ consisting only of the two trivial subobjects of $ $ , the point itself and the empty set, and the unique inclusion morphism between them.
These are classified, respectively, by the truth values $ {} stackrel{true}{to} Omega $ and $ {} stackrel{false}{to} Omega $ , so that we can also write our poset of subobjects of the terminal object as $ L = { false to true } , $ .
The logical operation $ wedge = AND $ is the product in the poset $ L $ .
Indeed we find pullback diagrams in $ L $ $ array{ true times true = true &to& true downarrow true } ;;; ;;; ;;; array{ true times false = false &to& false downarrow true } ;;; ;;; ;;; array{ false times false = false &to& false downarrow false } , $ .
The logical operation $ vee = OR $ is the coproduct in the poset $ L $ .
Indeed we find pushout diagrams in $ L $ $ array{ && true && downarrow true &to& true coprod true = true } ;;;; ;;; ;;; array{ && false && downarrow true &to& true coprod false = true } ;;;; ;;; ;;; array{ && false && downarrow false &to& false coprod false = false } , $ .
The logical operation $ not = NOT $ is given by the internal hom into the initial object in $ L $ : $ not = hom( - , false) : L^{op} to L , $ .
We find the value of the internal hom by its defining adjunction.
For $ hom(true, false) $ we have $ HomL(true, hom(true, false)) simeq HomL(true times true, false) = Hom_L(true, false) = emptyset $ and $ HomL(false, hom(true, false)) simeq HomL(false times true, false) = Hom_L(false, false) = {} $ from which we deduce that $ hom(true, false) = false, $ .
Similarly for $ hom(false, false) $ we have $ HomL(true, hom(false, false)) simeq HomL(true times false, false) = HomL(false, false) = {*} $ and $ HomL(false, hom(false, false)) simeq HomL(false times false, false) = HomL(false, false) = {} $ from which we deduce that $ hom(false, false) = true , $ .
This way all the familiar logical operations are recovered from the internal logic of the topos Set.
{LogicOfPresheaves} Let $ X $ be a topological space and $ Op(X) $ its category of open subsets and $ Sh(X) := Sh(Op(X)) $ the Grothendieck topos of sheaves on $ X $ .
We discuss the internal logic of this sheaf topos (originally Tarski, 1938 ).
The terminal object is the sheaf represented by $ X $ : the one that is constant on the one - element set $ X : U mapsto {} , $ .
The subobjects of this object are the representable presheaves $ hom( - , V) : U mapsto left{ array{ {} & | if U subset V emptyset & otherwise } right $ . for $ V in Op(X) $ .
In the presheaf topos $ PSh(Op(X))= Func(Op(X)^{op}, Set) $ , the subobjects of $ 1 $ are arbitrary sieves in $ Op(X) $ , not just representables.
For instance, for any two open sets $ U $ and $ V $ there is a sieve consisting of all open sets contained in either $ U $ or $ V $ , which doesn't necessarily contain $ Ucup V $ .
It's only in the sheaf topos $ Sh(X) $ that the representables are precisely the subobjects of $ 1 $ .
The poset of subobjects formed by these is just the category of open subsets itself: $ L = Op(X) , $ . $ hom(U, V) = (U^c vee V)^circ $ (the interior of the union of the complement of $ U $ with V).
So negation is given by sending an open subset to the interior of its complement: $ not U = hom(U, emptyset) = (U^c vee emptyset)^circ = (U^c)^circ , $ .
In particular we find that in the internal logic of $ PSh(X) $ the law of the excluded middle fails in general, as in general we do not have that $ (not U) vee U = true $ because $ not U vee U = (U^c)^circ cup U = X backslash partial U $ is the total space $ X $ without the boundary (frontier) of $ U $ , and not $ true = X $ , all of the total space.
Thus, the internal logic of this sheaf topos is (in general) intuitionistic logic.
As remarked above, this is the case in many toposes.
Most books on topos theory develop some internal logic, at least in the context of a topos.
For example: is comprehensive.
Phoa has a presentation of the internal logic of a topos over a dependent type theory, as opposed to other systems which use simple type theory.
This is system is not minimal, but close to what is used in practice PS.
The book works in the even more general context of fibrations, allowing us to associate to each object $ A $ an arbitrary poset instead of $ Sub(A) $ .
The book is arguably all about this subject (although you wouldn't know it until about Chapter VIII), but from a different perspective.
In particular, Taylor allows us to replace having all pullbacks with pullbacks along a pullback - stable class of display morphisms.
A discussion of dependent type theory as the internal language of locally cartesian closed categories is in The observation that the poset of open subsets of a topological space serve as a model for intuitionistic logic is apparently originally due to {Applications} Discussion of fundamental constructions of algebraic geometry from the perspective of the internal logic of the sheaf topos over a scheme (Zariski topos, etale topos) is in As there are several notions of stability in mathematics there are several notions of stability including in dynamical systems and differential equations.
This entry is about the stability theory in the sense of model theory.
See also geometric stability theory and categoricity.
Stability is a highly overloaded word in mathematics.
An ordinary differential equation is a differential equation involving derivatives of a function with respect to one argument only, i.e. the function is on a manifold only of dimension $ d = 1 $ .
This function can be vector valued, what is sometimes viewed as a system of possibly coupled equations; still all of them have the derivatives taken with respect to the same parameter.
(Note that a higher - order differential equation can be turned into a system of first - order equations.)
A basic theorem concerns existence and uniqueness of local solutions to initial value problems.
Let $ X $ be a Banach space; given $ (t0, y0) in mathbb{R} times X $ and $ a, r gt 0 $ , put $ Q coloneqq t0 - a, t0 + a times Br(y0) $ m where $ Br(y0) $ is the closed ball in $ X $ of radius $ r $ about $ y_0 $ .
Suppose $ f: Q to X $ is a function satisfying the following conditions: $ {|f(t, x) - f(t, x')|} leq L{|x - x'|} $ for all $ (t, x) in Q $ ; Then for any $ c leq min(a, r/K) $ , there exists exactly one solution $ y: t0 - c, t0 + c to X $ to the initial value problem $ y'(t) = f(t, y(t)), qquad y(t0) = y0 $ .
We will define an infinite sequence of approximate solutions to the problem, prove that its limit exists, prove that this limit is an exact solution, and prove that this solution is unique.
(i) The infinite sequence is given by Picard iteration: Starting with the given constant $ y_0 $ , recursively define $ y{n+1}(t) coloneqq y0 + int{t=t0} f(t, y_n(t)) , mathrm{d}t ; $ that is, $ y{n+1} $ is that indefinite integral of $ f( - , yn) $ that takes the correct initial value.
(To define $ y1 $ , use abuse of notation to interpret $ y0(t) $ as $ y0 $ ; that is, think of $ y0 $ as a constant function.)
To prove that this integral exists, use the continuity conditions and an inductive proof that each $ y_n $ is continuous to show that we are integrating a continuous function.
(ii) Thinking of Picard iteration as an operator between Banach spaces of continuous functions, use Lipschitz continuity and boundedness to show that the Banach fixed point theorem applies, so that the sequence $ (y1, y2, ldots) $ uniformly converges to a limit $ y $ .
(iii) Since uniform convergence of continuous functions behaves well with integration, the limiting instance of Picard iteration holds: $ y(t) = y0 + int{t=t_0} f(t, y(t)) , mathrm{d}t $ .
By differentiating with respect to $ t $ , and by evaluating at $ t_0 $ , we confirm that $ y $ is a solution of the initial value problem.
(iv) Given any putative solution $ z $ , apply Grönwall's inequality to $ z - y $ to prove that $ z = y $ .
The singular homology of a topological space $ X $ is the simplicial homology of its singular simplicial complex: a singular $ n $ - chain on $ X $ is a formal linear combination of singular simplices $ sigma : Delta^n to X $ , and a singular $ n $ - cycle is such a chain such that its oriented boundary in $ X $ vanishes.
Two singular chains are homologous if they differ by a boundary.
The singular homology of $ X $ in degree $ n $ is the group of $ n $ - cycles modulo those that are boundaries.
Singular homology of a topological space conincide with its ordinary homology as defined more abstractly (see at generalized homology theory).
(Here "singular" refers to the contrast with cellular homology, referring to the fact that a simplex $ Delta_{top} to X $ in the singular simplicial complex is not required to be a topological embedding, but may be a "singular map", such as for instance a constant function.)
{Definition} Let $ X in $ Top be topological space.
Write $ Sing X in $ sSet for its singular simplicial complex.
For $ n in mathbb{N} $ , a singular $ n $ - chain on $ X $ is an element in the free abelian group $ mathbb{Z}(Sing X)_n $ : a formal linear combinations of singular simplices in $ X $ .
These are the chains on a simplicial set on $ Sing X $ .
The groups of singular chains combine to the simplicial abelian group $ mathbb{Z}Sing X in Ab^{Delta^{op}} $ .
The alternating face map complex $ C_bullet(X) coloneqq Cbullet(mathbb{Z}Sing X) in Chbullet $ is the singular complex of $ X $ .
Its chain homology is the ordinary singular homology of $ X $ .
One usually writes $ Hn(X, mathbb{Z}) $ or just $ Hn(X) $ for the singular homology of $ X $ in degree $ n $ .
See also at ordinary homology.
So we have $ C_bullet(X) = cdots stackrel{partial_2}{to} mathbb{Z}(Sing X)_2 stackrel{partial_1}{to} mathbb{Z}(Sing X)_1 stackrel{partial_0}{to} mathbb{Z}(Sing X)_0 $ where the differentials are defined on basis elements $ sigma in (Sing X)_n $ by $ partial_n sigma = - sum_{i = 0}^n ( - 1) d_i sigma $ (with $ d_i $ the $ i $ simplicial face map) and then extended linearly.
(One may change the global signs and obtain a quasi - isomorphic complex, in particular with the same homology groups.)
This means that a singular chain is a cycle if the formal linear combination of the oriented boundaries of all its constituent singular simplices sums to 0.
See the basic examples below More generally, for $ R $ any unital ring one can form the degreewise free module $ RSing X $ over $ R $ .
The corresponding homology is the singular homology with coefficients in $ R $ , denoted $ Hn(X, R) $ .
Given a continuous map $ f : X to Y $ between topological spaces, and given $ n in mathbb{N} $ , every singular $ n $ - simplex $ sigma : Delta^n to X $ in $ X $ is sent to a singular $ n $ - simplex $ f_ sigma : Delta^n stackrel{sigma}{to} X stackrel{f}{to} Y $ in $ Y $ .
This is called the push - forward of $ sigma $ along $ f $ .
Accordingly there is a push - forward map on groups of singular chains $ (f)n : Cn(X) to Cn(Y) , $ .
These push - forward maps make all diagrams of the form $ array{ C{n+1}(X) &stackrel{(f){n+1}}{to}& C{n+1}(Y) downarrow^{mathrlap{partial^Xn}} && downarrow^{mathrlap{partial^Yn}} Cn(X) &stackrel{(f)n}{to}& Cn(Y) } $ commute.
In other words, push - forward along $ f $ constitutes a chain map $ f : Cbullet(X) to Cbullet(Y) , $ .
It is in fact evident that push - forward yields a functor of singular simplicial complexes $ f : Sing X to Sing Y , $ .
From this the statement follows since $ mathbb{Z} - : sSet to sAb $ is a functor.
Accordingly we have: Sending a topological space to its singular chain complex $ C_bullet(X) $ , def. , and a continuous map to its push - forward chain map, prop.
, constitutes a functor $ Cbullet( - , R) : Top to Chbullet(R Mod) $ from the category Top to the category of chain complexes.
In particular for each $ n in mathbb{N} $ singular homology extends to a functor $ H_n( - , R) : Top to R Mod , $ . {BasicExamples} Let $ X $ be a topological space.
Let $ sigma^1 : Delta^1 to X $ be a singular 1 - simplex, regarded as a 1 - chain $ sigma^1 in C_1(X) , $ .
Then its boundary $ partial sigma in H_0(X) $ is $ partial sigma^1 = sigma(0) - sigma(1) $ or graphically (using notation as for orientals) $ partial left( sigma(0) stackrel{sigma}{to} sigma(1) right) = (sigma(0)) - (sigma(1)) , $ .
Let $ sigma^2 : Delta^2 to X $ be a singular 2 - chain.
The boundary is $ partial left( array{ && sigma(1) & {}^{mathllap{sigma(0, 1)}}nearrow & Downarrow^{mathrlap{sigma}}& searrow^{mathrlap{sigma^{1, 2}}} sigma(0) &&underset{sigma(0, 2)}{to}&& sigma(2) } right) = left( array{ && sigma(1) & {}^{mathllap{sigma(0, 1)}}nearrow & & sigma(0) } right) - left( array{ && & & & sigma(0) &underset{sigma(0, 2)}{to}& sigma(2) } right) + left( array{ && sigma(1) & & & searrow^{mathrlap{sigma^{1, 2}}} && && sigma(2) } right) , $ .
Hence the boundary of the boundary is $ partial partial sigma &= partial left( left( array{ && sigma(1) & {}^{mathllap{sigma(0, 1)}}nearrow & & sigma(0) } right) - left( array{ && & & & sigma(0) &underset{sigma(0, 2)}{to}& sigma(2) } right) + left( array{ && sigma(1) & & & searrow^{mathrlap{sigma^{1, 2}}} && && sigma(2) } right) right) & = left( array{ && & & & sigma(0) } right) - left( array{ && sigma(1) & & & } right) - left( array{ && & & & sigma(0) && } right) + left( array{ && & & & && sigma(2) } right) + left( array{ && sigma(1) & & & && && } right) - left( array{ && & & & && && sigma(2) } right) & = 0 $ For more illustrations see for instance (Ghrist, ((iv)5)).
{HomologyOfDisksAndSpheres} For all $ n in mathbb{N} $ the reduced singular homology of the $ n $ - sphere $ S^n $ is $ tilde H_k(S^n) = left{ array{ mathbb{Z} & if; k = n 0 & otherwise } right. , $ .
The $ n $ - sphere may be realized as the pushout $ S^n simeq D^n/S^{n - 1} coloneqq D^{n} coprod_{S^{n - 1}} $ which is the $ n $ - ball with its boundary $ (n - 1) $ - sphere identified with the point.
The inclusion $ S^{n - 1} hookrightarrow D^n $ is a "good pair" in the sense of def. , and so the long exact sequence from prop.
yields a long exact sequence $ cdots to tilde H{k+1}(S^n) to tilde Hk(S^{n - 1}) to tilde Hk(D^n) to tilde Hk(S^n) to tilde H{k - 1}(S^{n - 1}) to cdots , $ .
Since the disks are all contractible topological spaces we have $ Hk(D^n) simeq 0 $ for all $ k, n $ by this example at reduced homology.
This means that in the above long exact sequence all the morphisms $ tilde H{k+1}(S^{n+1}) to tilde Hk(S^n) $ are isomorphisms, for all $ k in mathbb{N} $ .
Since $ tilde Hn(S^0) simeq left{ array{ mathbb{Z} & if ; n = 0 0 & otherwise } right $ .
(by this example at reduced homology) the statement follows by induction on $ n $ .
{HomotopyInvariant} Singular homology is homotopy invariant:
If $ f : X to Y $ is a continuous map between topological spaces which is a homotopy equivalence, then the induced morphism on singular homology groups $ Hn(f) : Hn(X) to Hn(Y) $ is an isomorphism.
In other words: the singular chain functor of prop.
sends weak homotopy equivalences to quasi - isomorphisms.
A proof (via CW approximations) is spelled out for instance in (Hatcher, prop.
(iv)21).
{RelationToHomotopyGroups} The singular homology groups of a topologial space serve to some extent as an approximation to the homotopy groups of that space.
For $ (X, x) $ a pointed topological space, the Hurewicz homomorphism is the function $ Phi : pik(X, x) to Hk(X) $ from the $ k $ th homotopy group of $ (X, x) $ to the $ k $ th singular homology group defined by sending $ Phi : (f : S^k to X){sim} mapsto fS_k $ a representative singular $ k $ - sphere $ f $ in $ X $ to the push - forward along $ f $ of the fundamental class $ Sk in Hk(S^k) simeq mathbb{Z} $ .
For $ X $ a topological space the Hurewicz homomorphism in degree 0 exhibits an isomorphism between the free abelian group $ mathbb{Z}pi_0(X) $ on the set of connected components of $ X $ and the degree - 0 singular homlogy: $ mathbb{Z}pi_0(X) simeq H_0(X) , $ .
Since a homotopy group in positive degree depends on the homotopy type of the connected component of the base point, while the singular homology does not depend on a basepoint, it is interesting to compare these groups only for the case that $ X $ is connected.
For $ X $ a connected topological space the Hurewicz homomorphism in degree 1 $ Phi : pi1(X, x) to H1(X) $ is surjective.
Its kernel is the commutator subgroup of $ pi1(X, x) $ .
Therefore it induces an isomorphism from the abelianization $ pi1(X, x)^{ab} coloneqq pi1(X, x)/pi1, pi_1 $ : $ pi_1(X, x)^{ab} stackrel{simeq}{to} H_1(X) , $ .
For higher connected $ X $ we have the If $ X $ is (n - 1) - connected for $ n geq 2 $ then $ Phi : pin(X, x) to Hn(X) $ is an isomorphism.
This is known as the Hurewicz theorem.
{RelationToRelativeHomology} For the present purpose one makes the following definition.
A topological subspace inclusion $ A hookrightarrow X $ in Top is called a good pair if (i) $ A $ is inhabited and closed in $ X $ ; (i) $ A $ has a neighbourhood in $ X $ of which it is a deformation retract.
Write $ X/A $ for the cokernel of the inclusion, hence for the pushout $ array{ A &hookrightarrow& X downarrow && downarrow } $ in Top.
If $ A hookrightarrow X $ is a good pair, def. , then the singular homology of $ X/A $ coincides with the relative homology of $ X $ relative to $ A $ .
In particular, therefore, it fits into a long exact sequence of the form $ cdots to tilde H_n(A) to tilde H_n(X) to tilde H_n(X/A) to tilde H_{n - 1}(A) to tilde H_{n - 1}(X) to tilde H_{n - 1}(X/A) to cdots , $ .
For instance (Hatcher, theorem (ii)13).
Singular homology computes the generalized homology with coefficients in the Eilenberg - MacLane spectrum $ H mathbb{Z} $ or $ H R $ .
Original references on chain homology/cochain cohomology and singular homology/singular cohomology: Lecture notes: Textbook discussion in the context of homological algebra is around Application (i)(i)4 of {Weibel} and in the context of algebraic topology in chapter (ii)1 of and chapter 4 of {Ghrist} Discussion in the context of computing homotopy groups is in {Hutchings} Lecture notes include See also Vol.
13, No. 2 (Apr., 1962), pp. 293 - 297 (JSTOR) Measurable spaces are the traditional prelude to the general theory of measure and integration.
Basically, a measure is a recipe for computing the size - - - e.g., length, area, volume - - - of subsets of a given set $ X $ .
The structure of a 'measurable space' picks out those subsets of $ X $ for which the size is well - defined; these subsets are called 'measurable'.
The measure on $ X $ is then an operation that assigns a number to each measurable subset saying how big it is.
In short: you get a measure space by placing a measure on a measurable space.
Ideally, all subsets would be measurable, but this contradicts the axiom of choice for the basic example of Lebesgue measure on the real line.
Although it is possible to use nonstandard foundations of mathematics in which all subsets of the real line are Lebesgue measurable, any general theory that includes that example and is more general than those foundations requires some explicit notion of measurable space (or an alternative such as a measurable locale).
In any case, measurable spaces are of some interest in their own right, even without a measure on them.
We give first the usual notion, assuming the validity of excluded middle and power sets; see below for alternative versions, including the constructive and predicative theories.
Given a set $ X $ , a $ sigma $ - algebra is a collection of subsets of $ X $ that is closed under complementation, countable unions, and countable intersections.
A measurable space, by the usual modern definition, is a set $ X $ equipped with a $ sigma $ - algebra $ Sigma $ .
The elements of $ Sigma $ are called the measurable sets of $ X $ (or more properly, the measurable subsets of $ (X, Sigma) $ ).
Given measurable spaces $ X $ and $ Y $ , a measurable function from $ X $ to $ Y $ is a function $ fcolon X to Y $ such that the preimage $ f^(T) $ is measurable in $ X $ whenever $ T $ is measurable in $ Y $ .
Measurable spaces and measurable functions form a category Meas, which is topological over Set.
In classical measure theory, it is usually assumed that $ Y $ is the real line (or a variation) equipped with the Borel sets (see the examples below).
Then $ f $ is measurable if and only if $ f^{ - 1}(I) $ is measurable whenever $ I subseteq Y $ is an interval.
We will briefly examine variations of the notion of measurable space, from those most like the standard to those most unlike it.
Most of these are discussed at articles dedicated to them.
Historically, people have used more general notions that $ sigma $ - algebras, such as algebras, $ delta $ - rings, and similar concepts whose names you can probably now guess; these are all discussed at sigma - algebra.
These are all more general than $ sigma $ - algebras, being possibly not closed under some operations.
When using some of these more general rings of measurable sets, it is necessary to allow partial functions whose domain is a relatively measurable set as measurable functions; for details, see measurable function.
An enhanced measurable space has, in addition to the $ sigma $ - algebra of measurable sets, a $ sigma $ - ideal of measurable null sets.
That is, besides the set $ X $ and the $ sigma $ - alebra $ Sigma $ , we have a collection $ N subseteq Sigma $ that is closed under countable unions and taking subsets (within $ Sigma $ ).
(The elements of $ N $ are the measurable null sets; a null set is any subset of a measurable null set.)
One can equivalently specify a $ delta $ - filter of measurable full sets; the full sets are the complements of the null sets.
Either way, this allows us to use almost measurable almost functions up to almost equality, as described at measurable function.
In constructive mathematics, because complementation doesn't behave nicely, the concept of $ sigma $ - algebra is not so useful.
It's also essential to use almost functions to avoid a paucity of measurable functions.
One solution, due to Henry Cheng, may be found at Cheng measurable space; briefly, we use disjoint pairs $ (A, B) $ of sets instead of individual measurable sets and use formal complements in the algebra, as well as a notion of full sets.
Assuming excluded middle, a Cheng measurable space is actually equivalent to a measurable space equipped with null (or full) sets, as in the previous paragraph.
In order to have the most important theorems of measure theory, it is necessary and sufficient to restrict to localizable measures.
Since localizability refers only to the null (or full) sets, we can actually speak of a localizable measurable space: a measurable space equipped with null (or full) sets as above, with the property that the boolean algebra of measurable sets modulo the null sets is complete.
Another approach to measure theory, more abstract, is to ignore the set $ X $ and use only the $ sigma $ - algebra $ Sigma $ , as an abstract boolean algebra equipped with countable suprema; this is called a measurable algebra (or a measure algebra when equipped with a measure).
A measurable algebra might also can be equipped with a $ sigma $ - ideal of null sets (or a $ delta $ - filter of full sets), but really it is simpler to take the quotient algebra, which is itself a perfectly good measurable algebra.
Even if a measurable algebra is a complete lattice, it can still be pathological; but if it has enough normal measures, then we have a measurable locale; the category of measurable locales is equivalent to that of localizable measurable spaces (from the previous paragraph).
Yet another category equivalent to localizable measurable spaces and measurable locales is the opposite category of the category of commutative von Neumann algebras; this is really a version of the Gelfand–Neumark theorem.
Then a noncommutative (localizable) measurable space is (the formal dual of) any von Neumann algebra.
In this way, measure theory may be seen as a branch of operator algebra theory (at least if one assumes that only localizable measurable spaces are well enough behaved to be worthy of study).
{RelationToVonNeumannAlgebras} One version of the Gel'fand–Naimark theorem states that the category of commutative $ W^ $ - algebras is dual to the category of localizable measurable spaces.
(As such, arbitrary $ W^ $ - algebras may be interpreted as 'noncommutative' measurable spaces in a sense analogous to noncommutative geometry.)
See the references below.
To make this work correctly, we cannot simply define localizability as a property of measurable spaces; instead, a localizable measurable space is a measurable space (a set $ X $ with a $ sigma $ - algebra $ Sigma $ ) with a $ sigma $ - ideal $ mathcal{N} $ of $ Sigma $ and $ mathcal{P}X $ simultaneously (called the ideal of null sets) such that $ Sigma/mathcal{N} $ is a complete lattice; and a morphism of localizable measurable spaces is a measurable function, with the property that the preimage of any null set is null, up to an equivalence relation where $ f cong g $ if $ { x ;|; f(x) neq g(x) } $ is a null set.
The requirement that $ Sigma/mathcal{N} $ be complete is the real localizability condition here; the trick of equipping a measurable space with a $ sigma $ - ideal of null sets (or equivalently a $ sigma $ - filter of full sets) and taking measurable functions only up to equivalence is a common one in other situations.
Localizable measurable spaces can also be studied via the lattice $ Sigma/mathcal{N} $ , which is a frame; the morphisms correspond to certain continuous maps between locales, and thus we are studying locales with extra structure, called measurable locales.
In terms of topos theory, measurable spaces are closely related to Boolean toposes (e.g. Jackson 06, Henry 14).
While Lebesgue measure on $ mathbb{R}^n $ can be done in very weak foundations, a general theory of measure and measurable spaces seems to require powerful set - theoretic machinery.
Indeed, not much seems to be possible in predicative contexts, and the (nonpredicative) constructive theory is noticeably more complicated than the classical theory.
On the other hand, the classical theory has its own complications, with nonmeasurable sets and functions that can be proved to exist but which seem to never arise in practice.
Instead, there are classically false but apparently consistent foundations in which measure theory is extremely simple.
{Predicative} The main problem for measure theory in predicative mathematics is getting your hands on a $ sigma $ - algebra.
Once you've got that, you've got a measurable space (obviously) and go on to measure space, where there are no new difficulties.
However, what is (say) a Borel set in the real line?
This is difficult, if not impossible, to explain predicatively.
(In the case of Lebesgue measure, there are ways to describe the Lebesgue - measurable sets predicatively, but these do not seem to generalise to a broader theory.)
Note that there is no real problem in describing what, say, an open set is.
Not only can this be done for the real line in the usual $ epsilon $ - $ delta $ way, but it is easy to take any collection of subsets of any set $ X $ , call that collection a subbase, and describe which sets are the open sets in the topology generated by that subbase.
The reason is that there are only two steps in moving from a subbase to a topology, and while the latter step is too impredicative to allow one to speak of the set of all open sets, it's OK if you only want to talk about individual open sets.
(To be explicit: given a collection $ B $ to be used as subbase, a set $ G $ is open if, for every point $ x $ , if $ x in G $ , then there exist a natural number $ n $ and elements $ A1, ldots, An $ of $ B $ such that $ x in Ai $ for each $ i $ and, for every point $ y $ , if $ y in Ai $ for each $ i $ , then $ y in G $ .
Since we quantify only over points and natural numbers, not over sets or functions, this is a predicative definition, and it's easy to prove that the open sets satisfy the axioms of a topology.)
This cannot be done with $ sigma $ - algebras, since we need uncountably many sets.
To be sure, each individual step is predicative, and we can freely talk about $ Gdelta $ sets and the like, but to define a Borel set we need to quantify over all countable ordinals.
While it is possible to hypothesise the existence of an uncountable ordinal $ omega1 $ and be predicative 'over' $ omega1 $ (and after all, everything else in this section is only predicative over the first infinite ordinal $ omega0 $ , which we only have if we accept an axiom of infinity), this cannot be constructed predicatively.
(The immediate definition of $ omega1 $ as the Hartog's number of $ omega0 $ uses power sets; while the construction of an uncountable ordinal by applying the well - ordering theorem to the function set $ mathbf{N}^{mathbf{N}} $ doesn't seem to use reasoning that requires the existence of power sets as long as you don't also throw in excluded middle, it does use reasoning that is not accepted by any predicative school that I know.)
So as far as I (Toby Bartels) can tell, there is no general predicative theory of measurable spaces, only an ad hoc theory of Lebsegue measurability.
I would be delighted to learn otherwise!
From a constructive perspective, there are a couple of related problems with the classical theory.
One is that the notion of $ sigma $ - algebra is highly suspicious, because it relies on an operation, complementation, that behaves very differently in the intuitionistic logic that constructive mathematics uses.
The other is that, even you acept the definition of $ sigma $ - algebra anyway (after all, the Lebesgue - measurable sets on the real line do still form one), there may be very few measurable functions.
Indeed, if we set aside the general theory of measurable spaces and simply do Lebesgue measure ad hoc in a constructive (even predicative) way, we find that instead of measurable functions we really want measurable partial functions whose domain of definition is a full set.
This suggests that if we want to define the concept of measurable function, then we have to know what the full sets are.
There is a way out, due to Henry Cheng, for both of these problems at once.
Instead of dealing with individual sets, we will deal with pairs of disjoint sets.
The intuition is that we use disjoint pairs $ (A, B) $ such that $ A cup B $ is full - - - with $ (A, neg{A}) $ being the motivating example in the classical theory - - - , but we let the $ sigma $ - algebra itself tell us which pairs those are.
Once we fix a particular measure, we may find additional pairs whose union is full, somewhat like finding additional measurable sets when taking the completion in the classical theory (although taking the completion is a separate phenomenon here), but that's all right; the important thing is that each pair chosen really is full in any measure used (much as each set in a classical $ sigma $ - algebra must actually be measurable by any measure used).
See details at Cheng space.
While measure theory only gets more complicated in constructive mathematics, it becomes much easier in dream mathematics.
...
more coming ...
For Cheng's theory of measure spaces, see the 1985 edition of Bishop & Bridges, Constructive Analysis.
(And the references therein, obviously, but I haven't read those.)
{ReferencesRelationToVonNeumannAlgebras} A discussion of the abstract properties of the category of localizable measurable spaces and its relation to von Neumann algebras is in A useful series of expositions along these lines is in See also The mapping cone of a morphism $ f : X to Y $ in some homotopical category (precisely: a category of cofibrant objects) is, if it exists, a particular representative of the homotopy cofiber of $ f $ .
It is also called the homotopy cokernel of $ f $ or the weak quotient of $ Y $ by the image of $ X $ in $ Y $ under $ f $ .
The dual notion is that of mapping cocone.
<img src="http://ncatlab.org/nlab/files/mappingcone.jpg" width="660" > (graphics taken from Muro 2010) {Definition} The mapping cone construction is a means to present in a category with weak equivalences the following canonical construction in homotopy theory/(∞, 1) - category theory.
the In an (∞, 1) - category $ mathcal{C} $ with terminal object and (∞, 1) - pushout, the homotopy cofiber of a morphism $ f : X to Y $ is the homotopy pushout $ coker(f) coloneqq Y coprodX {*} $ hence the object universal construction sitting universally in a diagram of the form $ array{ X &stackrel{}{to}& {*} downarrow^{mathrlap{f}} &swArrow{simeq}& downarrow Y &to& coker(f) } , $ .
If the (∞, 1) - category $ mathcal{C} $ is presented by (is equivalent to the simplicial localization of) a category of cofibrant objects $ C $ (for instance given by the cofibrant objects in a model category) then this homotopy cofiber is presented by the ordinary colimit $ array{ && X &stackrel{f}{to}& Y && downarrow^{mathrlap{i1}} && downarrow^{mathrlap{i}} X &stackrel{i0}{to}& cyl(X) downarrow && &searrow & downarrow {} &to& &to& cone(f) } $ in $ C $ using any cylinder object $ cyl(X) $ for $ X $ .
This is discussed in detail at factorization lemma and at homotopy pullback.
Intuitively this says that $ cone(f) $ is the object obtained by (i) forming the cylinder over $ X $ ; (i) gluing to one end of that the object $ Y $ as specified by the map $ f $ .
(i) shrinking the other end of the cylinder to the point.
Intuitively it is clear that this way every cycle in $ Y $ that happens to be in the image of $ X $ can be "continuously" translated in the cylinder - direction, keeping it constant in $ Y $ , to the other end of the cylinder, where it becomes the point.
This means that every homotopy group of $ Y $ in the image of $ f $ vanishes in the mapping cone.
Hence in the mapping cone the image of $ X $ under $ f $ in $ Y $ is removed up to homotopy.
This makes it clear how $ cone(f) $ is a homotopy - version of the cokernel of $ f $ .
And therefore the name "mapping cone".
A morphism $ eta : cyl(X) to Y $ out of a cylinder object is a left homotopy $ eta : g Rightarrow h $ between its restrictions $ gcoloneqq eta(0) $ and $ h coloneqq eta(1) $ to the cylinder boundaries $ array{ X downarrow^{mathrlap{i_0}} & searrow^{mathrlap{g}} cyl(X) &stackrel{eta}{to}& Y uparrow^{mathrlap{i1}} & nearrow{mathrlap{h}} X } , $ .
Therefore prop.
says that the mapping cone is the the universal object with a morphism $ i $ from $ Y $ and a left homotopy from $ i circ f $ to the zero morphism.
This is of course also precisely what def. is saying.
The colimit in prop.
may be computed in two stages by two consecutive pushouts in $ C $ , and in two ways by the following pasting diagram: $ array{ && X &stackrel{f}{to}& Y && downarrow^{i_1} && downarrow X &stackrel{i_0}{to}& cyl(X) &to & cyl(f) downarrow && downarrow && downarrow {} &to& cone(X) &to& cone(f) } , $ .
Here every square is a pushout, (and so by the pasting law is every rectangular pasting composite).
This now is a basic fact in ordinary category theory.
The pushouts appearing here go by the following names:
The pushout $ array{ X &stackrel{i0}{to}& cyl(X) downarrow && downarrow {*} &to& cone(X) } $ defines the cone $ cone(X) $ over $ X $ (with respect to the chosen cylinder object): the result of taking the cylinder over $ X $ and identifying one $ X $ - shaped end with the point.
The pushout $ array{ X &stackrel{f}{to}& Y downarrow && downarrow cyl(X) &to& cyl(f) } $ defines the mapping cylinder $ cyl(f) $ of $ f $ , the result of identifying one end of the cylinder over $ X $ with $ Y $ , using $ f $ as the gluing map.
The pushout $ array{ cyl(X) &to& cyl(f) downarrow && downarrow cone(X) &to& cone(f) } $ defines the mapping cone $ cone(f) $ of $ f $ : the result of forming the cylinder over $ X $ and then identifying one end with the point and the other with $ Y $ , via $ f $ .
The geometric intuition behind this is best seen in the archetypical example of the classical model structure on topological spaces.
See the example For topological spaces below.
The example For chain complexes can be understood similarly geometrically by thinking of all chain complexes as singular chains on topological spaces.
We discuss realizations of the general construction in various contexts.
Some of these examples are regarded in parts of the literature as the default examples, notably that for topological spaces and that for chain complexes.
The mapping cone of the morphism $ X to {*} $ to the terminal object is the suspension object $ Sigma X $ of an object $ X $ .
The dual notion of the loop space object of $ X $ . {ForTopologicalSpaces} The notion mapping cone derives its name from its geometrical interpretation in the category Top of topological spaces.
For more details see also at topological cofiber sequence.
With respect to the standard model structure on topological spaces every CW - complex is a cofibrant object, and hence mapping cones on maps between CW - complexes have intrinsic meaning in homotopy theory.
Write $ I coloneqq 0, 1 subset mathbb{R} in $ Top for the closed interval with its Euclidean metric topology.
This is an interval object for the standard model structure.
We may therefore take the cylinder object of a topological space $ X $ to be $ cyl(X) coloneqq X times I , , $ which is literally the cylinder over $ X $ .
Given a continuous function $ f:Xto Y $ , the topological space $ cone(f) $ is $ cone(f) = (X times I) cup{f} Y $ This is the disjoint union of $ X times I $ with $ Y $ followed by an identification under which for each $ xin X $ a point $ (x, 1) in X times I $ is identified with the point $ f(x) in Y $ and followed by the contraction of $ Xtimes {0 } $ to a point.
Of course the opposite convention is also possible: identify $ (x, 0) $ with $ f(x) $ for all $ x $ and then contract $ Xtimes{1 } $ to a point; the two constructions of cones are canonically homeomorphic; the first is sometimes called the "inverse mapping cone".
The singular chain complex functor from Top to the category of chain complexes of abelian groups sends the mapping cone to a mapping cone in the sense of chain complexes (up to conventions on the orientation of the interval and vector order in the definition of mapping cone of chain complexes).
{InChainComplexes} Let $ Chbullet = Chbullet(R Mod) $ be the category of chain complexes in $ R $ Mod for some ring $ R $ .
(For instance if $ R = mathbb{Z} $ the integers, then this is $ Chbullet(Ab) $ , chain complexes of abelian groups.
More generally $ R Mod $ can be replaced by any abelian category in the following, with the evident changes in the presentation here and there.)
We derive an explicit presentation of the mapping cone $ cone(f) $ of a chain map $ f $ , according to the general definition .
The end result is prop.
below, reproducing the classical formula for the mapping cone.
Write $ *bullet in Chbullet(mathcal{A}) $ for the chain complex concentrated on $ R $ in degree 0 $ = cdots to 0 to 0 to R , $ .
This may be understood as the normalized chain complex of chains of simplices on the terminal simplicial set $ Delta^0 $ , the 0 - simplex.
Let $ Ibullet in Ch{bullet}(mathcal{A}) $ be given by $ Ibullet = (cdots 0 to 0 to R stackrel{( - id, id)}{to} R oplus R) , $ .
Denote by $ i0 : bullet to I_bullet $ the chain map which in degree 0 is the canonical inclusion into the second summand of a direct sum and by $ i1 : bullet to Ibullet $ correspondingly the canonical inclusion into the first summand.
This is the standard interval object in chain complexes.
It is in fact the normalized chain complex of chains on a simplicial set for the canonical simplicial interval, the 1 - simplex: $ Ibullet = Cbullet(Delta1) , $ .
The differential $ partial^I = ( - id, id) $ here expresses the alternating face map complex boundary operator, which in terms of the three non - degenerate basis elements is given by $ partial ( 0 to 1 ) = (1) - (0) , $ .
We decompose the proof of this statement is a sequence of substatements.
For $ Xbullet in Chbullet $ the tensor product of chain complexes $ (I otimes X)bullet in Chbullet $ is a cylinder object of $ Xbullet $ for the structure of a category of cofibrant objects on $ Chbullet $ whose cofibrations are the monomorphisms and whose weak equivalences are the quasi - isomorphisms (the substructure of the standard injective model structure on chain complexes).
The complex $ (I otimes X)bullet $ has components $ (I otimes X)n = Xn oplus Xn oplus X{n - 1} $ and the differential is given by $ array{ X{n+1} oplus X{n+1} &stackrel{partial^X oplus partial^X}{to}& Xn oplus Xn oplus &nearrow{( - id, id)}& oplus X{n} &underset{ - partial^X}{to}& X{n - 1} } , , $ hence in matrix calculus by $ partial^{I otimes X} = left( array{ partial^X oplus partial^X & ( - id, id) 0 & - partial^X } right) : (X{n+1} oplus X{n+1}) oplus X{n} to (X{n} oplus X{n}) oplus X{n - 1} , $ .
By the formula discussed at tensor product of chain complexes the components arise as the direct sum $ (I otimes X )n = (R{(0)} otimes Xn ) oplus (R{(1)} otimes Xn ) oplus (R{(0 to 1)} otimes X{(n - 1)} ) $ and the differential picks up a sign when passed past the degree - 1 term $ R{(0 to 1)} $ : $ partial^{I otimes X} ( (0 to 1), x ) &= ( (partial^I (0 to 1)), x ) - ( (0to 1), partial^X x ) & = ( - (0) + (1), x ) - ( (0 to 1), partial^X x ) & = - ((0), x) + ((1), x) - ( (0 to 1), partial^X x ) , $ .
The two boundary inclusions of $ Xbullet $ into the cylinder are given in terms of def. by $ i^X0 : Xbullet simeq *bullet otimes Xbullet stackrel{i0 otimes idX}{to} (Iotimes X)bullet $ and $ i^X1 : Xbullet simeq bullet otimes X_bullet stackrel{i1 otimes idX}{to} (Iotimes X)_bullet $ which in components is the inclusion of the second or first direct summand, respectively $ Xn hookrightarrow Xn oplus Xn oplus X{n - 1} , $ .
One part of definition now reads: For $ fbullet : Xbullet to Y_bullet $ a chain map, the mapping cylinder $ cyl(f) $ is the pushout $ array{ cyl(f)bullet &leftarrow& Ybullet uparrow && uparrow^{mathrlap{f}} Ibullet otimes Xbullet &stackrel{i0}{leftarrow}& Xbullet } , $ .
The components of $ cyl(f)_bullet $ are $ cyl(f)n = Xn oplus Yn oplus X{n - 1} $ and the differential is given by $ array{ X{n+1} oplus Y{n+1} &stackrel{partial^X oplus partial^Y}{to}& Xn oplus Yn oplus &nearrow_{( - id, f)}& oplus X{n} &underset{ - partial^X}{to}& X{n - 1} } , , $ hence in matrix calculus by $ partial^{cyl(f)} = left( array{ partial^X oplus partial^Y & ( - id, f_n) 0 & - partial^X } right) : (X{n+1} oplus Y{n+1}) oplus X_{n} to (X{n} oplus Y{n}) oplus X_{n - 1} , $ .
The colimits in a category of chain complexes $ Ch_bullet(mathcal{A}) $ are computed in the underlying presheaf category of towers in $ mathcal{A} $ .
There they are computed degreewise in $ mathcal{A} $ (see at limits in presheaf categories).
Here the statement is evident: the pushout identifies one direct summand $ X_n $ with $ Yn $ along $ fn $ and so where previously a $ id{Xn} $ appeared on the diagonl, there is now $ f_n $ .
The last part of definition now reads: For $ fbullet : Xbullet to Y_bullet $ a chain map, the mapping cone $ cone(f) $ is the pushout $ array{ cone(f) &leftarrow& cyl(f) uparrow && uparrow cone(X) &leftarrow& X otimes I uparrow && uparrow^{mathrlap{i_1}} 0 &leftarrow& X } $ In the literature this appears for instance as (Schapira, def.
(iii)(ii)2).
The components of the mapping cone $ cone(f) $ are $ cone(f)n = Yn oplus X_{n - 1} $ with differential given by $ array{ Y{n+1} &stackrel{partial^Y}{to}& Yn oplus &nearrow{fn}& oplus X{n} &underset{ - partial^X}{to}& X{n - 1} } , , $ and hence in matrix calculus by $ partial^{cone(f)} = left( array{ partial^Y{n+1} & fn 0 & - partial^X_n } right) : Y{n+1} oplus X{n} to Y{n} oplus X{n - 1} , $ .
As before the pushout is computed degreewise.
This identifies the remaining unshifted copy of $ X $ with 0.
For $ f : Xbullet to Ybullet $ a chain map, the canonical inclusion $ i : Ybullet to cone(f)bullet $ of $ Y_bullet $ into the mapping cone of $ f $ is given in components $ in : Yn to cone(f)n = Yn oplus X_{n - 1} $ by the canonical inclusion of a summand into a direct sum.
This follows by starting with remark and then following these inclusions through the formation of the two colimits as discussed above.
The construction above builds the mapping cone explicitly via the standard formula for homotopy pushouts.
Often however other presentations are more convenient: For $ fbullet colon Xbullet to Y_bullet $ a chain map, consider the double complex $ D_{bullet, bullet} $ concentrated in degrees $ D{1, bullet} coloneqq Xbullet $ and $ D{0, bullet} coloneqq Ybullet $ with $ partial{0, bullet} coloneqq fbullet colon D{1, bullet} to D{0, bullet} $ .
Then the total complex of $ D_{bullet, bullet} $ is also a model for the mapping cone of $ f $ : $ Cone(f) simeq tot(D_{bullet, bullet}) , $ .
One checks by inspection that $ tot(D_{bullet, bullet}) = Cone(tilde f) $ for $ tilde fcolon Xbullet to Ybullet $ for which there is a chain homotopy $ f Rightarrow f' $ (given only by multiplication by signs).
This appears for instance as (Weibel, Exercise (i)(ii)8).
{InCochainComplexes} We spell out the situation in more detail in a category of cochain complexes.
Let $ mathcal{A} $ be some concrete additive category and $ Ch^bullet(mathcal{A}) $ the category of chain complexes in $ mathcal{A} $ .
For $ f : V^bullet to W^{bullet} $ a morphism, the mapping cone is the complex $ Cone(f) & coloneqq (cdots to Cone(f)^{k - 1} stackrel{d_{Cone(f)}}{to} Cone(f)^k) to cdots) & coloneqq left( array{ cdots to & V^k &stackrel{ - d_V}{to}& V^{k+1} & to cdots & oplus &searrow^{f^k}& oplus cdots to & W^{k - 1} &underset{d_W}{to}& W^k & to cdots } right) , $ .
There is a canonical cochain homotopy $ array{ Cone(f) &leftarrow& 0 {}^{mathllap{i}}uparrow &swArrow_{eta}& uparrow W &stackrel{f}{leftarrow}& V } $ where $ i : W to Cone(f) $ is the canonical inclusion, componentwise given by $ i^k : W^k stackrel{(0, Id)}{to} V_{k+1} oplus W^k $ and where the cochain homotopy $ eta $ has components $ eta^k : V^k stackrel{(Id, 0)}{to} Cone(f)^{k - 1} = V^k oplus W^{k - 1} $ which we denote on $ v in V^k $ by $ eta : v mapsto (f(v))1 , $ .
The fact that this is a cochain homotopy means that $ d, eta = i circ f - 0 , , $ which we check on any $ v in V^k $ by computing $ d, eta &= d_{Cone(f)} circ eta (v) + eta(d_V v) & = d{Cone(f)} (f(v)1) + (f(dV v))1 & = left( f(v) - (d_{W}f(v))1 right) + (d_W (f(v)))1 & = f(v) , , $ where we used the above definition of $ d_{Cone(f)} $ and the fact that $ f $ is a chain homomorphism and hence intertwines the differentials.
This cochain homotopy is universal in that for any other cochain homotopy $ array{ X &leftarrow& 0 {}^{mathllap{j}}uparrow &swArrow_{rho}& uparrow W &stackrel{f}{leftarrow}& V } $ hence $ j circ f = d, rho $ we have a morphism $ (j, rho) : Cone(f) to X $ given on $ W $ by $ j $ and on $ V $ by $ rho $ $ (j, rho)^k : V^{k+1} oplus W^k stackrel{(rho, j)}{to} X^k $ which is indeed a cochain homomorphism because for all $ v + w in Cone(f) $ we have $ d_X (j, rho)(v + w) & = dX (rho v) + dX (j(w)) & = d, rho - rho dV v + j (dW w) & = j f (v) - rho dV v + j (d{Cone(f)} w) & = (j, rho) d_{Cone(f)}(v + w) $ and which is unique with the property that whiskering of 2 - morphisms gives $ array{ X &leftarrow& 0 {}^{mathllap{j}}uparrow &swArrow_{rho}& uparrow W &stackrel{f}{leftarrow}& V } ;;;;; = ;;;;; array{ X & nwarrow^{mathrlap{(j, rho)}} && Cone(f) &leftarrow& 0 && {}^{mathllap{i}}uparrow &swArrow_{eta}& uparrow && W &stackrel{f}{leftarrow}& V } $ hence that $ j = (j, rho) circ i $ and $ rho = (j, rho) circ eta , $ .
Let $ mathcal{A} $ be an additive category with translation $ T=1 : mathcal{A} to mathcal{A} $ .
Let $ X $ and $ Y $ be two differential objects in $ (mathcal{A}, T) $ and $ f : X to Y $ any morphism in $ C $ .
The mapping cone $ Cone(f) $ of $ f $ is the differential object whose underlying object is the direct sum $ T X oplus Y $ and whose differential $ d_{cone f} : T X oplus X to T T X oplus T X $ is given in matrix calculus notation by $ d_{cone f} := left( array{ d_{T X} & 0 T(f) & d_Y } right) = left( array{ - T(d_X) & 0 T(f) & d_Y } right) , $ .
Notice the minus sign here, coming from the definition of a shifted differential object.
{HomologyExactSequencesAndFiberSequences} We discuss the relation between mapping cones in categories of chain complexes, as above, and long exact sequences in homology.
For an exposition of the following see there the section Relation to homotopy fiber sequences.
Let $ f : Xbullet longrightarrow Ybullet $ be a chain map and write $ cone(f) in Ch_bullet(mathcal{A}) $ for its mapping cone as explicitly given in prop. .
Write $ X1bullet in Chbullet(mathcal{A}) $ for the suspension of a chain complex of $ X $ .
Write $ p : cone(f) to X1_bullet $ for the chain map which in components $ pn : cone(f)n to X1_n $ is given, via prop. , by the canonical projection out of a direct sum $ pn : Yn oplus X{n - 1} to X{n - 1} , $ .
The chain map $ p : cone(f)bullet to X1bullet $ represents the homotopy cofiber of the canonical map $ i : Ybullet to cone(f)bullet $ .
By prop.
and def.
the sequence $ Y_bullet stackrel{i}{to} cone(f)_bullet stackrel{p}{to} X1_bullet $ is a short exact sequence of chain complexes (since it is so degreewise, in fact degreewise it is even a split exact sequence).
In particular we have a cofiber pushout diagram $ array{ Ybullet &stackrel{i}{hookrightarrow}& cone(f)bullet downarrow && downarrow 0 &to& X1_bullet } , $ .
Now, in the injective model structure on chain complexes all chain complxes are cofibrant objects and an inclusion such as $ i : Ybullet hookrightarrow cone(f)bullet $ is a cofibration.
By the detailed discussion at homotopy limit this means that the ordinary colimit here is in fact a homotopy colimit, hence exhibits $ p $ as the homotopy cofiber of $ i $ .
For $ fbullet : Xbullet to Y_bullet $ a chain map, there is a homotopy cofiber sequence of the form $ X_bullet stackrel{f_bullet}{to} Y_bullet stackrel{i_bullet}{to} cone(f)_bullet stackrel{p_bullet}{to} X1_bullet stackrel{f1_bullet}{to} Y_bullet stackrel{i1_bullet}{to} cone(f)_bullet stackrel{p1_bullet}{to} X2_bullet to cdots $ In order to compare this to the discussion of nLab:connecting homomorphisms, we now turn attention to the case that $ f_bullet $ happens to be a monomorphism.
Notice that this we can always assume, up to quasi - isomorphism, for instance by prolonging $ f $ by the map into its mapping cylinder $ Xbullet to Ybullet stackrel{simeq}{to} cyl(f) , $ .
By the axioms on an abelian category in this case we have a short exact sequence $ 0 to Xbullet stackrel{fbullet}{to} Ybullet stackrel{pbullet}{to} Z_bullet to 0 $ of chain complexes.
The following discussion revolves around the fact that now $ cone(f)bullet $ as well as $ Zbullet $ are both models for the homotopy cofiber of $ f $ .
Let $ Xbullet stackrel{fbullet}{to} Ybullet stackrel{pbullet}{to} Z_bullet $ be a short exact sequence of chain complexes.
The collection of linear maps $ hn : Yn oplus X{n - 1} to Yn stackrel{}{to} Z_n $ constitutes a chain map $ hbullet : cone(f)bullet to Z_bullet , $ .
This is a quasi - isomorphism.
The inverse of $ Hn(hbullet) $ is given by sending a representing cycle $ z in Z_n $ to $ (hat zn, partial^Y hat zn) in Yn oplus X{n+1} , , $ where $ hat zn $ is any choice of lift through $ pn $ and where $ partial^Y hat z_n $ is the formula expressing the connecting homomorphism in terms of elements, as discussed at Connecting homomorphism - - In terms of elements.
Finally, the morphism $ ibullet : Ybullet to cone(f)_bullet $ is eqivalent in the homotopy category (the derived category) to the zigzag $ array{ && cone(f)_bullet && downarrow^{mathrlap{h}}_{mathrlap{simeq}} Ybullet &to& Zbullet } , $ .
In the literature this appears for instance as (Schapira, cor.
(vii)(ii)2).
To see that $ h_bullet $ defines a chain map recall the differential $ partial^{cone(f)} $ from prop. , which acts by $ partial^{cone(f)} (x{n - 1}, hat zn) = ( - partial^X x{n - 1} , partial^Y hat zn + x_{n - 1} ) $ and use that $ x{n - 1} $ is in the kernel of $ pn $ by exactness, hence $ h{n - 1}partial^{cone(f)}(x{n - 1}, hat z_n) &= h{n - 1}( - partial^X x{n - 1}, partial^Y hat zn + x{n - 1} ) & = p{n - 1}( partial^Y hat zn + x_{n - 1}) & = p{n - 1}( partial^Y hat zn ) & = partial^Z pn hat zn & = partial^Z hn(x{n - 1}, hat z_n) , $ .
It is immediate to see that we have a commuting diagram of the form $ array{ && cone(f)_bullet & {}^{mathllap{ibullet}}nearrow& downarrow^{mathrlap{h}}{mathrlap{simeq}} Ybullet &to& Zbullet } $ since the composite morphism is the inclusion of $ Y $ followed by the bottom morphism on $ Y $ .
Abstractly, this already implies that $ cone(f)bullet to Zbullet $ is a quasi - isomorphism, for this diagram gives a morphism of cocones under the diagram defining $ cone(f) $ in prop.
and by the above both of these cocones are homotopy - colimiting.
But in checking the claimed inverse of the induced map on homology groups, we verify this also explicity: We first determine those cycles $ (x{n - 1}, yn) in cone(f)n $ which lift a cycle $ zn $ .
By lemma a lift of chains is any pair of the form $ (x{n - 1}, hat zn) $ where $ hat zn $ is a lift of $ zn $ through $ Yn to Xn $ .
So $ x_{n - 1} $ has to be found such that this pair is a cycle.
By prop.
the differential acts on it by $ partial^{cone(f)} (x{n - 1}, hat zn) = ( - partial^X x{n - 1} , partial^Y hat zn + x_{n - 1} ) $ and so the condition is that $ x{n - 1} coloneqq - partial^Y hat zn $ (which implies $ partial^X x{n - 1} = - partial^X partial^Y hat zn = - partial^Y partial^Y hat zn = 0 $ due to the fact that $ fn $ is assumed to be an inclusion, hence that $ partial^X $ is the restriction of $ partial^Y $ to elements in $ X_n $ ).
This condition clearly has a unique solution for every lift $ hat zn $ and a lift $ hat zn $ always exists since $ pn : Yn to Zn $ is surjective, by assumption that we have a short exact sequence of chain complexes.
This shows that $ Hn(h_bullet) $ is surjective.
To see that it is also injective we need to show that if a cycle $ ( - partial^Y hat zn, hat zn) in cone(f)n $ maps to a cycle $ zn = pn(hat zn) $ that is trivial in $ Hn(Z) $ in that there is $ c{n+1} $ with $ partial^Z c{n+1} = zn $ , then also the original cycle was trivial in homology, in that there is $ (xn, y{n+1}) $ with $ partial^{cone(f)}(xn, y{n+1}) coloneqq ( - partial^X xn, partial^Y y{n+1} + x_n) = ( - partial^Y hat zn, hat zn) , $ .
For that let $ hat c{n+1} in Y{n+1} $ be a lift of $ c{n+1} $ through $ pn $ , which exists again by surjectivity of $ p_{n+1} $ .
Observe that $ p{n}( hat zn - partial^Y hat c_{n+1}) = zn - partial^Z ( pn hat c_{n+1} ) = zn - partial^Z ( c{n+1} ) = 0 $ by assumption on $ zn $ and $ c{n+1} $ , and hence that $ hat zn - partial^Y hat c{n+1} $ is in $ X_n $ by exactness.
Hence $ (zn - partial^Y hat c{n+1}, hat c{n+1}) in cone(f)n $ trivializes the given cocycle: $ partial^{cone(f)}( hat zn - partial^Y hat c{n+1} , hat c_{n+1}) & = ( - partial^X(hat zn - partial^Y hat c{n+1} ), partial^Y hat c{n+1} + (hat zn - partial^Y hat c_{n+1} ) ) & = ( - partial^Y(hat zn - partial^Y hat c{n+1}), hat z_n ) & = ( - partial^Y hat zn, hat zn ) , $ .
Let $ Xbullet stackrel{fbullet}{to} Ybullet to Zbullet $ be a short exact sequence of chain complexes.
Then the chain homology functor $ Hn( - ) : Chbullet(mathcal{A}) to mathcal{A} $ sends the homotopy cofiber sequence of $ f $ , cor.
, to the long exact sequence in homology induced by the given short exact sequence, hence to $ Hn(Xbullet) to Hn(Ybullet) to Hn(Zbullet) stackrel{delta}{to} H{n - 1}(Xbullet) to H{n - 1}(Ybullet) to H{n - 1}(Zbullet) stackrel{delta}{to} H{n - 2}(Xbullet) to cdots , , $ where $ delta_n $ is the $ n $ th connecting homomorphism.
By lemma the homotopy cofiber sequence is equivalen to the zigzag $ array{ && && && && && cone(f)1_bullet &to& cdots && && && && && downarrow^{mathrlap{h1bullet}}{mathrlap{simeq}} && && cone(f)bullet &to& X1bullet &stackrel{f1bullet}{to}& Y1bullet &to& Z1_bullet && && downarrow^{mathrlap{hbullet}}{mathrlap{simeq}} X_bullet &stackrel{f_bullet}{to}& Y_bullet &stackrel{}{to}& Z_bullet } , $ .
Observe that $ Hn( Xkbullet) simeq H{n - k}(Xbullet) , $ .
It is therefore sufficient to check that $ H_n left( array{ cone(f)bullet &to& X1bullet downarrow^{mathrlap{simeq}} Z_bullet } right) ;; : ;; Hn(Zbullet) to Hn(cone(f)bullet) to H{n - 1}(Xbullet) $ equals the connecting homomorphism $ delta_n $ induced by the short exact sequence.
By prop.
the inverse of the vertical map is given by choosing lifts and forming the corresponding element given by the connecting homomorphism.
By prop.
the horizontal map is just the projection, and hence the assignment is of the form $ zn mapsto x{n - 1}, yn mapsto x{n - 1} , $ .
So in total the image of the zig - zag under homology sends $ znZ mapsto - partial^Y hat znX , $ .
By the discussion there, this is indeed the action of the connecting homomorphism.
{DistinguishedTriangles} In summary, the above says that for every chain map $ fbullet : Xbullet to Y_bullet $ we obtain maps $ X_bullet stackrel{f}{to} Y_bullet stackrel{ left( array{ 0 id{Ybullet} } right) }{to} cone(f)_bullet stackrel{ left( array{ id{X1bullet} & 0 } right) }{to} X1_bullet $ which form a homotopy fiber sequence and such that this sequence continues by forming suspensions, hence for all $ n in mathbb{Z} $ we have $ Xn_bullet stackrel{f}{to} Yn_bullet stackrel{ left( array{ 0 id{Ynbullet} } right) }{to} cone(f)n_bullet stackrel{ left( array{ id{Xn+11bullet} & 0 } right) }{to} Xn+1_bullet $ To amplify this quasi - cyclic behaviour one sometimes depicts the situation as follows: $ array{ Xbullet &&stackrel{f}{to}&& Ybullet & {}_{mathllap{1}}nwarrow && swarrow && cone(f)_bullet } $ and hence speaks of a "triangle", or distinguished triangle or mapping cone triangle of $ f $ .
Due to these "triangles" one calls the homotopy category of chain complexes localized at the quasi - isomorphisms, hence the derived category, a triangulated category.
Notice that equivalently we can express the triangles via the mapping cylinder.
For every map of chain complexes $ f:Ato B $ , the cylinder $ Cyl(f) $ is quasi - isomorphic to $ B $ , and moreover in the homotopy category of chain complexes, every distinguished triangle is quasi - isomorphic to a distinguished triangle of the form $ Ato Cyl(u)to Cone(u)to A1 $ for some $ u:Ato B $ where all the morphisms in the triangle are appropriatedly induced by $ u $ .
In the context of chain complexes the construction is discussed for instance in In the context of spectra discussion includes Graphics taken from A topological space is totally bounded if it may be covered by finitely many sets of arbitrarily small size.
The Heine - Borel theorem, which states that a closed and bounded subset of the real line is compact (in the finite open subcover sense), applies to all Euclidean spaces but not to general metric spaces.
However, if we use two facts about the real line (which hold for all cartesian spaces) - - - that a subset is closed if and only if it is complete and that a subset is bounded if and only if it is totally bounded - - - , then we get a theorem that does apply to all metric spaces (at least assuming the axiom of choice): that a complete and totally bounded space is compact.
The concept (and the Heine - - Borel theorem, in this sense) apply not only to metric spaces but to uniform spaces; like completeness, total boundedness is a uniform property.
In the following definitions, 'finite' means Kuratowski - finite, or finitely indexed, for the purposes of constructive mathematics.
All of these definitions are constructively equivalent.
The slickest definition for uniform spaces is probably this one: A uniform space $ X $ is totally bounded if every uniform cover of $ X $ has a finite subcover.
Since uniform covers are not a common approach to uniform spaces, we unwrap the definition of uniform covers in terms of entouranges to get this definition: A uniform space $ X $ is totally bounded if, for every entourage $ U $ of $ X $ , there is a finite open cover $ mathcal{C} $ of $ X $ such that every set $ G $ in $ mathcal{C} $ satisfies $ G times G subseteq U $ .
In fact, it is enough to consider only basic entourages for some base of the uniformity.
Thus, we may specialise to gauge spaces: A gauge space $ X $ is totally bounded if, for every gauging distance $ d $ of $ X $ , there is a finite open cover $ mathcal{C} $ of $ X $ such that every set in $ mathcal{C} $ has $ d $ - diameter less than $ 1 $ .
In fact, it is enough to consider only basic gauging distances for some base of the gauge, or even for some subbase of the gauge if we make the requirement for arbitrarily small diameters (rather than the fixed diameter $ 1 $ as above).
Thus, we may specialise to metric spaces: A metric space $ X $ is totally bounded if, for every positive number $ epsilon $ , there is a finite open cover $ mathcal{C} $ of $ X $ such that every set in $ mathcal{C} $ has diameter less than $ epsilon $ .
The category of totally bounded uniform spaces and uniformly continuous functions is equivalent to the category of proximity spaces and proximally continuous functions.
Thus, proximity spaces can be considered yet another axiomatization of "totally bounded space" that doesn't rely on a pre - existing kind of "space".
All of these results hold constructively unless otherwise noted.
Every compact space is totally bounded; this is immediate from Definition , since every uniform cover is an open cover.
Conversely, if one assumes the ultrafilter principle, then every complete and totally bounded space is compact.
In constructive mathematics, "complete and totally bounded" is sometimes taken as a definition of "compact" - - see Bishop - compact space.
Any product of totally bounded spaces is totally bounded.
The totally bounded subspaces of a given space $ X $ form an ideal in the power set of $ X $ .
A subspace of a Cartesian space is totally bounded if and only if it is bounded.
Every totally bounded metric space is separable.
Every precompact uniform space is totally bounded; using Definition , this may be proved by checking that any uniform cover of $ X $ generates a uniform cover of $ overline{X} $ .
The converse, that every totally bounded space is precompact, is equivalent to the ultrafilter principle.
Of course, many totally bounded spaces may be proved precompact on weaker assumptions; in particular, that a bounded subset of a cartesian space is precompact is equivalent to the fan theorem (and so also follows from the principle of excluded middle), a fact related to the Heine–Borel theorem.
If $ A = (a{i j}) $ is a matrix with coefficients in a star algebra (such as the complex numbers under complex conjugation), then its conjugate transpose $ A^dagger $ is the matrix $ A^dagger coloneqq (a^ast{j i}) $ , hence the composite of passing to the transpose matrix and applying the star - operation $ A^dagger coloneqq left(A^tright)^ast = left(A^astright)^t $ Identifying matrices with linear maps and with respect to the standard inner product this operation represents passing to the adjoint operator.
Therefore one speaks also of adjoint matrices.
tableofcontents {Definition} The following definition of the degree of a polynomial is formulated vis the formal derivative or left shift of a polynomial.
The idea behind this lies in the traditional conception of polynomials as sums of monomials, namely of products of non - zero scalars with powers of an "indeterminate" - - which have an associated exponent because commutative rings are power - associative in multiplication.
Both the derivative and the left shift are functions on polynomials which reduce the exponent of the associated indeterminate by one and take polynomials, relative to the given indeterminate, to zero.
Since both operations are also linear functions, they act this way on each monomial summand, which means that after repeatedly taking derivatives or left shifts of polynomials, the result will eventually become zero.
This allows us to define the degree of a polynomial using induction on the natural numbers and on lists of natural numbers, as well as composition of left shifts, without having to write out long formulae using indices and ellipses everywhere in the definition, and without having to include additional structure with each polynomial $ p $ in the form of the scalar coefficients of $ p $ .
Given a commutative ring $ R $ , the commutative ring of polynomials $ Rx $ in one indeterminate $ x $ is the initial commutative ring $ Rx $ with an element $ x in Rx $ and a ring homomorphism $ h:R to Rx $ .
The formal derivative $ frac{d ( - )}{d x}:Rx to Rx $ is a function which is inductively defined on $ Rx $ by By the universal property of $ Rx $ , these constructors are enough to define the derivative on all polynomials $ p in Rx $ .
Let $ frac{d^{( - )} ( - )}{d x^{( - )}}:mathbb{N} to (RX to RX) $ be the function which takes a natural number $ n in mathbb{N} $ to the $ n $ - th derivative in the function set $ RX to RX $ .
This is inductively defined on the natural numbers by If $ R $ has characteristic zero, given a non - zero polynomial $ p in Rx $ , the degree of $ p $ is the maximum natural number $ n $ where the $ n $ - th iteration of the formal derivative of $ p $ is non - zero:
$ mathrm{deg}(p) coloneqq max_{n in mathbb{N}, frac{d^{n} p}{d x^{n}} neq 0}(n) $ The degree of the zero polynomial is undefined, since the formal derivative of the zero polynomial is never non - zero.
The above definition involving formal derivatives works for commutative rings $ R $ with characteristic zero.
However, if $ R $ has positive characteristic, the formal derivative is problematic for the degree, because given characteristic $ n $ , the derivative of the $ n $ - th power of the indeterminate $ x $ is zero.
Instead, we have to use something more general, the left shift.
For every polynomial $ p in Rx $ , $ p $ could be represented as the sum of a constant polynomial $ cp $ and the product of the indeterminate $ x $ and a polynomial $ sL(p) $ called the left shift of $ p $ : $ p = cp + x cdot sL(p) $ .
Given any two constant polynomials $ p = cp $ and $ q = cq $ , by definition, $ c{p cdot q} = cp cdot cq $ .
Now, given any two general polynomials $ p = cp + x cdot sL(p) $ and $ q = cq + x cdot s_L(q) $ , one then has the following, through the axioms of a commutative ring: $ p = x cdot sL(p) + cp, q = x cdot sL(q) + cq $ $ p cdot q = x cdot sL(p cdot q) + c{p cdot q} = x sL(p cdot q) + c{p} cdot c_{q} $ $ p cdot q = (x cdot sL(p) + cp) cdot (x cdot sL(q) + cq) = x^2 cdot sL(p) cdot sL(q) + x cdot sL(p) cdot cq + x cdot sL(q) cdot cp + cp cdot cq $ $ x cdot sL(p cdot q) = x^2 cdot sL(p) cdot sL(q) + x cdot sL(p) cdot cq + x cdot sL(q) cdot c_p $ $ sL(p cdot q) = x cdot sL(p) cdot sL(q) + sL(p) cdot cq + sL(q) cdot c_p $ $ p - x cdot sL(p) = cp, q - x cdot sL(q) = cq $ $ sL(p cdot q) = x cdot sL(p) cdot sL(q) + sL(p) cdot (q - x cdot sL(q)) + sL(q) cdot (p - x cdot sL(p)) = sL(p) cdot q + sL(q) cdot p - x cdot sL(p) cdot s_L(q) $ Thus, we have the formula for the left shift of the product $ p cdot q $ for any two polynomials $ p in Rx $ and $ q in Rx $ : $ sL(p cdot q) = sL(p) cdot q + p cdot sL(q) - x cdot sL(p) cdot s_L(q) $ The only difference from the Leibniz rule for the formal derivative is the extra term $ - x cdot sL(p) cdot sL(q) $ at the end of the formula.
This allows us to inductively define on $ Rx $ the formal left shift operator $ s_L:Rx to Rx $ in the same manner as the formal derivative, by By the universal property of $ Rx $ , these constructors are enough to define the left shift on all polynomials $ p in Rx $ .
Let $ s_L^n:mathbb{N} to (RX to RX) $ be the function which takes a natural number $ n in mathbb{N} $ to the $ n $ - th left shift in the function set $ RX to RX $ .
This is inductively defined on the natural numbers by the following constructors In this defintion, $ R $ is not required to have characteristic zero.
Given a non - zero polynomial $ p in Rx $ , the degree of $ p $ is the maximum natural number $ n $ where the $ n $ - th iteration of the formal left shift operator of $ p $ is non - zero:
$ mathrm{deg}(p) coloneqq max{n in mathbb{N}, sL^n(p) neq 0}(n) $ The degree of the zero polynomial is undefined, since the left shift of the zero polynomial is never non - zero.
Let us define the standard finite set $ mathrm{Fin}(n) $ as the set of all natural numbers less than $ n $ : $ mathrm{Fin}(n) coloneqq {i in mathbb{N} vert i lt n } $ Given a natural number less than $ n $ , $ i:mathrm{Fin}(n) $ , let $ mathrm{Fin}(n) setminus {i } $ be the set of natural numbers less than $ n $ which are not equal to $ i $ .
Given a commutative ring $ R $ with characteristic zero and a natural number $ n $ , the commutative ring of polynomials $ RX $ is the initial commutative ring $ RX $ with a function $ X:mathrm{Fin}(n) to RX $ and a ring homomorphism $ h:R to RX $ .
We write $ Xi $ for $ X(i) $ throughout.
Given a natural number less than $ n $ , $ i in mathrm{Fin}(n) $ , let $ RX setminus {Xi } $ be the polynomial subring of $ RX $ whose indeterminates do not include $ Xi $ , with monomorphism $ m:RX setminus {Xi } hookrightarrow RX $ .
Let $ mathrm{Fin}(n)^ $ be the free monoid on the set of natural numbers less than $ n $ .
Every free monoid $ mathrm{Fin}(n)^ $ has a length function $ mathrm{len}:mathrm{Fin}(n)^ to mathbb{N} $ which returns the number of elements in a list $ a in mathrm{Fin}(n)^ $ , inductively defined by the following constructors The formal partial derivative $ frac{partial( - )}{partial X_{( - )}}:mathrm{Fin}(n) times RX to RX $ is inductively defined by By the universal property of $ RX $ , these constructors are enough to define the partial derivatives on all polynomials $ P in RX $ .
Let $ d:mathrm{Fin}(n)^ to (RX to RX) $ be the monoid homomorphism which takes a list $ a in mathrm{Fin}(n)^ $ of natural numbers less than $ n $ , to the composition of formal partial derivatives $ d(a) coloneqq frac{partial^{mathrm{len}(a)} ( - )}{partial X{a0} partial X{a1} partial X{a2} ldots} coloneqq frac{partial ( - )}{partial X{a0}} circ frac{partial ( - )}{partial X{a1}} circ frac{partial ( - )}{partial X{a2}} circ ldots $ in the function set $ RX to RX $ .
This is inductively defined by the following constructors If $ R $ has characteristic zero, given a non - zero polynomial $ P in Rx $ , the degree of $ P $ is the maximum length of all lists $ a in mathrm{Fin}(n)^ $ of natural numbers less than $ n $ such that the evaluation of $ d(a) $ at $ P $ is non - zero
$ mathrm{deg}(P) coloneqq max{a in mathrm{Fin}(n)^*, d(a)(P) neq 0}(mathrm{len}(a)) $ The degree of the zero polynomial is undefined, since any composition of partial derivatives evaluated at the zero polynomial is never non - zero.
The above definition involving formal partial derivatives works for commutative rings $ R $ with characteristic zero.
However, if $ R $ has positive characteristic, the formal derivative is problematic for the degree, because given characteristic $ p $ , the derivative of the $ p $ - th power of any indeterminate $ Xi $ for natural number less than $ n $ , $ i in mathrm{Fin}(n) $ , is zero.
Instead, we have to use something more general, partial left shifts.
The formal partial left shift operator $ s{partial L}:mathrm{Fin}(n) times RX to RX $ is inductively defined by By the universal property of $ RX $ , these constructors are enough to define the partial left shifts on all polynomials $ P in RX $ .
Let $ S:mathrm{Fin}(n)^ to (RX to RX) $ be the monoid homomorphism which takes a list $ ain mathrm{Fin}(n)^ $ of natural numbers less than $ n $ , to the composition of formal partial left shifts $ S(a) coloneqq s{partial L}(a0, - ) circ s{partial L}(a1, - ) circ s{partial L}(a2, - ) circ ldots $ in the function set $ RX to RX $ .
This is inductively defined by the following constructors Given a non - zero polynomial $ P in Rx $ , the degree of $ P $ is the maximum length of all lists $ a in mathrm{Fin}(n)^* $ of natural numbers less than $ n $ such that the evaluation of $ S(a) $ at $ P $ is non - zero
$ mathrm{deg}(P) coloneqq max{a in mathrm{Fin}(n)^, S(a)(P) neq 0}(mathrm{len}(a)) $ The degree of the zero polynomial is undefined, since any composition of partial derivatives evaluated at the zero polynomial is never non - zero. ...
Given a polynomial $ p in Rx $ in one indeterminate, it is said to be an homogeneous polynomial of degree $ n $ if $ frac{d p}{d x}.x = n.p $ (see the Euler identity).
Given a polynomial $ p in RX $ in a finite number of indeterminates, it is said to be an homogeneous polynomial of degree $ n $ if $ underset{i in mathrm{Fin}(n)}{sum} frac{partial p}{partial Xi}.Xi = n.p $ .
One could also define a polynomial $ p in RX $ to be homogeneous of degree $ n $ with respect to $ i in mathrm{Fin}(n) $ if $ frac{partial p}{partial Xi}.Xi = n.p $ .
It is equivalent to the fact that $ p $ can be written under the form $ p=Xi^{n}.q $ where $ q in RX $ is such that $ frac{partial p}{partial Xi} = 0 $ .
In constructive mathematics, where excluded middle does not hold, the above definition is correct only if the ring $ R $ has decidable equality.
In more general circumstances, one has to assume that the ring $ R $ and thus the polynomial ring $ RX $ is an inequality space with a tight apartness relation $ $ , and replace all instances of "non - zero" $ p neq 0 $ with instances of "apart from zero" $ p 0 $ .
(That every set $ R $ is an inequality space in classical mathematics follows from the stability of decidable equality.)
For example, the degree function on the Dedekind real numbers is only defined on polynomials with at least one coefficient whose absolute value is greater than zero.
An inner automorphism $ phi:Gto G $ of a group $ G $ is any automorphism $ phig $ of the form $ hmapsto g h g^{ - 1} $ .
The inner automorphisms form a subgroup $ Inn(G) $ , called the inner automorphism group of $ G $ , of the entire automorphism group $ Aut(G) $ ; it is the image of the natural map $ Gto Aut(G) $ given by $ gmapstophig $ .
The center of a group $ G $ is precisely the kernel of this natural map.
Similarly, the monoidal center due to Drinfel'd and Majid, in the case when the monoidal category is Picard, is a $ 2 $ - category - theoretic kernel (an observation due to L. Breen).
Higher analogues of the inner automorphism group were studied by Roberts and Schreiber.
A permutation on a set $ X $ is equivalently In the case of a set that is already equipped with a natural ordering (such as a finite ordinal $ X = {1, dots, n } $ ), these two ways of defining permutations are interchangeable, but they correspond to different abstract structures that are more salient in different contexts, and to different natural ways of comparing permutations.
Typically, the definition of permutations - as - automorphisms is important in group theory, while the definition of permutations - as - linear - orders is more common in combinatorics.
Both views of permutations are relevant to the theory of symmetric operads.
As automorphisms $ sigma : X to X $ in Set, the permutations of $ X $ naturally form a group under composition, called the symmetric group (or permutation group) on $ X $ .
This group may be denoted $ SX $ , $ SigmaX $ , or $ X! $ .
When $ X $ is the finite set $ (n) = {1, dots, n } $ , then its symmetric group is a finite group of cardinality
$ n! $ = " $ n $ factorial", and one typically writes $ Sn $ or $ Sigman $ .
Two permutations $ sigma : X to X $ and $ tau : Y to Y $ are said to be conjugate (written $ sigma cong tau $ ) just in case there is a bijection $ f : X to Y $ such that $ sigma = f^{ - 1} tau f $ , or equivalently, when there is a commuting square of bijections: $ array{& X & overset{f}rightarrow & Y & sigma & downarrow &&downarrow & tau &X & underset{f}rightarrow& Y & } $ Observe that conjugacy is an equivalence relation, and that conjugacy classes of permutations of $ X $ are in one - to - one correspondence with partitions of $ X $ (see below).
If $ X $ is a set equipped with a linear ordering $ lt $ , then a permutation of $ X $ is the same thing as a second (unrelated) linear ordering $ lt_sigma $ on $ X $ .
Indeed, suppose we label the elements of $ X $ according to the $ lt $ order as $ x1 lt x2 lt dots $ , and according to the $ ltsigma $ order as $ sigma1 ltsigma sigma2 lt_sigma dots $ .
Then we can define a bijection $ sigma : X to X $ as the function sending $ x1 mapsto sigma1 $ , $ x2 mapsto sigma2 $ , and so on.
Conversely, any bijection $ sigma : X to X $ induces a linear ordering $ ltsigma $ on $ X $ by defining $ x ltsigma x' $ iff $ sigma(x) lt sigma(x') $ .
This way of viewing permutations naturally gives rise to "array notation" (or "one - line notation"), where a permutation $ sigma : X to X $ is represented as the list of elements $ sigma = (sigma1, sigma2, dots) $ , and it may be contrasted with "cycle notation" (see below).
Whereas cycle notation makes it easy to compare permutations for conjugacy, array notation leads to a different natural way of comparing permutations known as pattern containment.
Given two linearly ordered sets $ (X, ltX) $ and $ (Y, ltY) $ , a permutation (or "pattern") $ sigma : X to X $ is said to be contained in a permutation $ tau : Y to Y $ (written $ sigma preceq tau $ ) just in case there exists a monotone injective function $ f : X to Y $ such that $ sigmai ltX sigmaj Rightarrow tau{f(i)} ltY tau{f(j)} $ for all $ i, j in X $ , or in other words, if $ tau = (tau1, tau2, dots) $ contains a subsequence of elements whose relative ordering (in $ Y $ ) is the same as the relative ordering (in $ X $ ) of the sequence $ sigma = (sigma1, sigma2, dots) $ .
Note that this definition of $ sigma preceq tau $ is equivalent to asking for the existence of a commuting square: $ array{& X & overset{f}rightarrow & Y & sigma & downarrow &&downarrow & tau &X & underset{g}rightarrow& Y & } $ where $ f $ and $ g $ are monotone injections (each uniquely determined by the other).
Whereas conjugacy defines an equivalence relation on the permutations of a particular set $ X $ , pattern containment defines a partial order on the permutations of arbitrary linearly ordered sets (which restricts to the discrete order on the permutations of $ X $ ).
In combinatorics, one sometimes also wants a slight generalisation of the notion of permutation - as - linear - order: for any natural number $ r $ , an $ r $ - permutation of $ X $ is an injective function $ sigma : (r) to X $ .
An $ r $ - permutation corresponds to a list of $ r $ distinct elements of $ X $ , so that for a finite set $ X $ of cardinality $ n = |X| $ , an $ n $ - permutation is the same thing as an ordinary permutation of $ X $ (it is surjective and therefore bijective, since Set is a balanced category).
More generally, the number of $ r $ - permutations of a set of cardinality $ n $ is counted by the falling factorial $ n^{underline{r}} = n(n - 1)dots(n - r+1) $ .
As an element of the symmetric group $ S_X $ , every permutation $ sigma : X to X $ generates a cyclic subgroup $ langle sigma rangle $ , and hence inherits a group action on $ X $ .
The orbits of this action partition the set $ X $ into a disjoint union of cycles, called the cyclic decomposition of the permutation $ sigma $ .
For example, let $ sigma $ be the permutation on $ (6) $ defined by
$ sigma = (array{1 mapsto 1 & 2 mapsto 4 & 3 mapsto 5 & 4 mapsto 6 & 5 mapsto 3 & 6 mapsto 2}) $ The domain of the permutation is partitioned into three $ langlesigmarangle $ - orbits $ (6) = {1 } cup {2, 4, 6 } cup {3, 5 } $ corresponding to the three cycles $ 1 underset{sigma}{to} 1 qquad 2 underset{sigma}{to} 4 underset{sigma}{to} 6 underset{sigma}{to} 2 qquad 3 underset{sigma}{to} 5 underset{sigma}{to} 3 $ We can express this more compactly by writing $ sigma $ in "cycle notation", as the composition $ sigma = (1)(2, 4, 6)(3, 5) $ , or $ sigma = (2, 4, 6)(3, 5) $ leaving implicit the action of the identity (1).
For the operadic structure of permutations, see Volume 1, Chapter 1 of:
For more on permutation patterns, see: A polyhedron (beware remark ) is a topological space made up of very simple bits 'glued' together.
The 'bits' are simplices of different dimensions.
An abstract simplicial complex is a neat combinatorial way of giving the corresponding 'gluing' instructions, a bit like the plan of a construction kit!
A simplicial complex $ K $ (sometimes called an abstract simplicial complex) consists of (i) a set of objects, $ V(K) $ , called vertices (i) a set, $ S(K) $ , of finite non - empty subsets of $ V(K) $ , called simplices.
such that the simplices satisfy the following conditions: (i) if $ sigma subset V(K) $ is a simplex and $ tau subset sigma $ , $ tau ne emptyset $ , then $ tau $ is also a simplex; (i) every singleton $ {v } $ , $ v in V(K) $ , is a simplex.
We say $ tau $ is a face of $ sigma $ .
If $ sigma in S(K) $ has $ p+1 $ elements it is said to be a $ p $ - simplex.
The set of $ p $ - simplices of $ K $ is denoted by $ Kp $ .
The dimension of $ K $ is the largest $ p $ such that $ Kp $ is non - empty.
A map of simplicial complexes $ K to L $ is a function $ f: V(K) to V(L) $ such that whenever $ sigma subseteq V(K) $ belongs to $ S(K) $ , the image $ f(sigma) $ belongs to $ S(L) $ .
The word 'polyhedron' is used here as it is often used by algebraic topologists, as a space described by a simplicial complex.
Elsewhere in mathematics, it might mean a finite union of finite intersections of sets in Euclidean space defined by linear inequalities, usually assumed compact, and often with other assumptions as well (e.g., connected or convex).
The various usages have a long history, as recounted in detail in Lakatos's Proofs and Refutations.
(i) Recall that a 'simple' graph is an undirected graph with no loops or multiple edges.
A simple graph is essentially the same thing as a 1 - dimensional simplicial complex, by interpreting edges as simplices and vice versa (see undirected graphs as 1 - complexes).
(On the other hand, a 1 - dimensional simplicial set is essentially the same thing as a 'directed multigraph', i.e., a quiver.)
(i) Given a space and an open cover, the nerve of the cover is a simplicial complex (see Čech methods and the discussion there).
The Vietoris complex is another given by a related method.
(i) Given any two sets $ X $ and $ Y $ , and a relation $ Rsubseteq Xtimes Y $ , there are two simplicial complexes that encode information on the relation.
These are generalisations of the nerve and the Vietoris complex.
They are studied in detail in Dowker's theorem.
(i) If $ (P, leq) $ is a poset, then the nerve of the associated category has a simple description.
The vertices are the points of $ P $ and the simplices are the flags.
(i) Buildings: An important class of simplicial complexes is provided by the notion of building, due to Jacques Tits.
Simplicial complexes are, in some sense, special cases of simplicial sets, but only 'in some sense'.
To get from a simplicial complex to a fairly small simplicial set, you pick a total order on the set of vertices.
Without an order on the vertices, you cannot speak of the $ k^{th} $ face of a simplex, which is an essential feature of a simplicial set!
The degeneracies are obtained by repeating an element when listing the vertices of a simplex.
If $ sigma = {v0, v1, ldots, vn } $ , with $ v0lt v1lt ldots lt vn $ then, for instance, $ s0(sigma) = {v0, v0, v1, ldots, v_n } $ .
If you do not want to pick an order then you can still form a simplicial set where to each $ n $ - simplex of the original simplicial complex will correspond to
$ (n+1)! $ simplices of that associated simplicial set.
The result is more unwieldy, but can be useful under some circumstances as it defines a functor from the category of simplicial complexes to that of simplicial sets.
This is very important when discussing group actions on simplicial complexes and how this transfers to the associated simplicial set.
Simplicial sets are essentially (that is, up to equivalence) presheaves on the simplex category of finite nonempty totally ordered sets, whereas simplicial complexes may be regarded as concrete presheaves on the category $ Fin{+} $ of finite nonempty sets and functions between them.
This works as follows: given a simplicial complex, $ K = (V(K), S(K)) $ , define a presheaf $ K^sim: Fin{+}^{op} to Set $ whose values are sets of functions $ phi $ : $ K^sim(B) stackrel{def}{=} {phi: B to V(K)| phi(B) in S(K) } , qquad K^sim(f: A to B)(phi) stackrel{def}{=} phi circ f $ This defines an evident functor $ SimpComplex to Set^{Fin_{+}^{op}}: K mapsto K^sim $ that is full and faithful.
The essential image is the subcategory of concrete presheaves, where a presheaf $ F colon Fin_{+}^{op} to Set $ is concrete if the canonical map $ F(B) to F(1)^{hom(1, B)} $ is an injection.
The point is that a morphism of concrete presheaves $ F to G $ is uniquely determined from the function $ F(1) to G(1) $ between their underlying sets (i.e., the underlying - set functor on concrete presheaves is faithful, so that a concrete presheaf is a set equipped with extra structure - - that's what makes it "concrete").
(Equivalently but somewhat more elaborately, the category of concrete presheaves is the same as the full subcategory of concrete sheaves on $ Fin_{+} $ with respect to the trivial topology, where the only covering sieve $ F hookrightarrow hom( - , D) $ is the maximal sieve.)
From this point of view, it is immediate that simplicial complexes are the separated objects for the Lawvere - Tierney topology on $ Set^{Fin_{+}^{op}} $ whose sheaves are sets, via the sheafification functor $ Gamma = hom(mathbf{1}, - ) = ev1 colon Set^{Fin{+}^{op}} to Set $ which has a right adjoint.
(See local topos.)
It follows from this characterization that the category of simplicial complexes is a quasitopos, and in particular is locally cartesian closed.
The category of simplicial sets on the other hand is a topos.
An abstract simplicial complex is a combinatorial gadget that models certain aspects of a spatial configuration.
Sometimes it is useful, perhaps even necessary, to produce a topological space from that data in a simplicial complex.
To each simplicial complex $ K $ , one can associate a topological space called the polyhedron of $ K $ often also called the geometric realisation of $ K $ and denoted $ |K| $ .
(This is essentially a special case of the geometric realisation of a simplicial sets.)
This can be constructed by taking a copy $ K(sigma) $ of a standard topological $ p $ - simplex for each $ p $ - simplex of $ K $ and then 'gluing' them together according to the face relations encoded in $ K $ .
We therefore first need the definition of a standard $ p $ - simplex The standard (topological) $ p $ - simplex is (usually) taken to be the convex hull of the basis vectors $ mathbf{e}1, mathbf{e}2, ldots, mathbf{e}_{p+1} $ in $ mathbb{R}^{p+1} $ .
The geometric realisation $ |K| $ of a simplicial complex, $ K $ is then constructed by taking, for each abstract $ p $ - simplex, $ sigmain S(K) $ , a copy, $ K(sigma) $ of such a standard topological $ p $ - simplex, and then 'gluing' faces together, so whenever $ tau $ is a face of $ sigma $ we identify $ K(tau) $ with the corresponding face of $ K(sigma) $ .
This space is usually denoted $ Delta^p $ .
As a set, $ |K| $ is constructed as follows: $ |K| $ is the set of all functions from $ V(K) $ to the closed interval $ 0, 1 $ such that $ {v in V(K) mid alpha(v) neq 0 } $ is a simplex of $ K $ ; $ sum_{v in V(K)} alpha (v) = 1 $ .
There are two commonly used topologies on the set $ |K| $ .
The first is the metric topology: we put a metric $ d $ on $ |K| $ by $ d(alpha, beta) = Big(sum_{vin V(K)} (alpha(v) - beta(v))^2Big)^frac{1}{2} $ $ . |K| $ , when endowed with the metric space topology, will be denoted $ |K|d $ .
Notice that when $ V(K) $ is finite, this gives $ |K|d $ as a subspace of the metric space $ mathbb{R}^{ V(K))} $ (which is usually of much higher dimension than might seem geometrically significant in a given context).
The second topology is the coherent topology: each geometric simplex $ |s| $ consists of all $ alpha in {|K|} $ supported in $ s $ , and is given the subspace topology inherited as a subset of $ |K|_d $ ; then the coherent topology on $ |K| $ is the largest topology for which all inclusions $ {|s|} hookrightarrow {|K|} $ are continuous.
This topological space is normally denoted just $ |K| $ , reflecting the fact that the coherent topology is regarded as the default topology to put on the set $ |K| $ .
Note that if $ s subseteq t $ is an inclusion of simplices in $ K $ , then there is an induced subspace inclusion $ {|s|} hookrightarrow {|t|} $ .
The space $ |K| $ may then be characterized as the colimit in $ Top $ of the diagram consisting of geometric simplices $ |s| $ and inclusions between them, so that a function $ f: {|K|} to X $ is continuous if and only if its restriction to each simplex $ |s| $ is continuous.
In particular, the identity function $ {|K|} to {|K|}_d $ is continuous, so that the coherent topology contains the metric topology (and is often strictly larger).
If a topological space can be described up to homeomorphism as the geometric realization of a simplicial complex, we say it is triangulable, and a triangulation of a space $ X $ is a simplicial complex $ K $ together with a homeomorphism $ h: |K| to X $ .
(This is discussed in a bit more detail in the entry on classical triangulation.
There is another stronger notion of triangulation used by geometric topologists: a piecewise - linear (PL) structure on a topological manifold $ X $ is given by a PL atlas, where the transition functions are piecewise - linear homeomorphisms.
(A homeomorphism $ U to V $ is piecewise linear if its graph is the intersection of $ U times V $ with a semilinear set $ S $ , meaning that $ S $ is given by a finite Boolean combination of solution sets of linear inequalities.)
The following statement may seem obvious, but it requires careful proof: As an important step: The basic technique is to use subdivision.
Textbook account: Exposition:
On simplicial complexes forming a quasitopos of concrete sheaves: For $ V $ a vector space over the real numbers or some other $ mathbb{R} $ - module, its complexification is the tensor product over $ mathbb{R} $ with the complex numbers $ mathbb{C} $ : the extension of scalars along the canonical inclusion $ mathbb{R} hookrightarrow mathbb{C} $ .
The term intertwiner is a synonym for homomorphism of representations/actions/modules.
Notably for linear representations $ rho1 $ , $ rho2 $ of some group or associative algebra $ A $ on vector spaces $ V1, V2 $ , a linear map $ u : V1 to V2 $ is said to intertwine $ rho1 $ with $ rho2 $ if for all $ a in A $ we have that $ u circ rho1(a) = rho2(a)circ u , $ .
An exact sequence may be defined in a semi - abelian category, and more generally in a homological category.
It is a sequential diagram in which the image of each morphism is equal to the kernel of the next morphism.
{Definition} Let $ mathcal{A} $ be an additive category (often assumed to be an abelian category, for instance $ mathcal{A} = R $ Mod for $ R $ some ring).
An exact sequence in $ mathcal{A} $ is a chain complex $ C_bullet $ in $ mathcal{A} $ with vanishing chain homology in each degree: $ forall n in mathbb{N} . H_n(C) = 0 , $ .
A short exact sequence is an exact sequence, def. of the form $ cdots to 0 to 0 to A to B to C to 0 to 0 to cdots , $ .
One usually writes this just " $ 0 to A to B to C to 0 $ " or even just " $ A to B to C $ ".
A general exact sequence is sometimes called a long exact sequence, to distinguish from the special case of a short exact sequence.
Explicitly, a sequence of morphisms $ 0 to A stackrel{i}to B stackrel{p}to C to 0 $ is short exact, def. , precisely if (i) $ i $ is a monomorphism, (i) $ p $ is an epimorphism, (i) and the image of $ i $ equals the kernel of $ p $ (equivalently, the coimage of $ p $ equals the cokernel of $ i $ ).
The third condition is the definition of exactness at $ B $ .
So we need to show that the first two conditions are equivalent to exactness at $ A $ and at $ C $ .
This is easy to see by looking at elements when $ mathcal{A} simeq R $ Mod, for some ring $ R $ (and the general case can be reduced to this one using one of the embedding theorems):
The sequence being exact at $ 0 to A to B $ means, since the image of $ 0 to A $ is just the element $ 0 in A $ , that the kernel of $ A to B $ consists of just this element.
But since $ A to B $ is a group homomorphism, this means equivalently that $ A to B $ is an injection.
Dually, the sequence being exact at $ B to C to 0 $ means, since the kernel of $ C to 0 $ is all of $ C $ , that also the image of $ B to C $ is all of $ C $ , hence equivalently that $ B to C $ is a surjection.
A split exact sequence is a short exact sequence as above in which $ i $ is a split monomorphism, or (equivalently) in which $ p $ is a split epimorphism.
In this case, $ B $ may be decomposed as the biproduct $ A oplus C $ (with $ i $ and $ p $ the usual biproduct inclusion and projection); this sense in which $ B $ is 'split' into $ A $ and $ C $ is the origin of the general terms 'split (mono/epi)morphism'.
It is also helpful to consider a similar notion in the case of a pointed set.
In the category $ Set_ $ of pointed sets, a sequence $ array{ (A, a) & overset{f}{to} & (B, b) & overset{g}{to} & (C, c) } $ is said to be exact at $ (B, b) $ if $ im f = g^{ - 1}(c) $ .
For concrete pointed categories (ie. a category $ mathcal{C} $ with a faithful functor $ F: mathcal{C} to Set* $ ), a sequence is exact if the image under $ F $ is exact.
In the case of (abelian) categories like $ Ab $ and $ R - Mod $ , the two notions of exactness coincide if we pick the point of each group/module to be $ 0 $ .
Such a general notion is useful in cases such as the long exact sequence of homotopy groups where the homotopy "groups" for small $ n $ are just pointed sets without a group structure.
A typical use of a long exact sequence, notably of the homology long exact sequence, is that it allows to determine some of its entries in terms of others.
The characterization of short exact sequences in prop. is one example for this: whenever in a long exact sequence one entry vanishes as in $ cdot to 0 to Cn to cdot $ or $ cdot to Cn to 0 to cdots $ , it follows that the next morphism out of or into the vanishing entry is a monomorphism or epimorphism, respectively.
In particular: If part of an exact sequence looks like $ cdots to 0 to C{n+1} stackrel{partialn}{to} Cn to 0 to cdots , , $ then $ partialn $ is an isomorphism and hence $ C{n+1} simeq Cn , $ . {ExactnessAndQuasiIsomorphisms} A chain complex $ Cbullet $ is exact (is a long exact sequence), precisely if the unique chain map from the initial object, the 0 - complex $ 0 to Cbullet $ is a quasi - isomorphism.
{SESAndQuotients} The following are some basic lemmas that show how given a short exact sequence one obtains new short exact sequences from forming quotients/cokernels (see Wise).
Let $ mathcal{A} $ be an abelian category.
For $ A to B to C to 0 $ an exact sequence in $ mathcal{A} $ and for $ X to B $ any morphism in $ mathcal{A} $ , also $ A to B/X to C/X to 0 $ is a short exact sequence.
We have an exact sequence of complexes of length 2 $ array{ 0 &to& X &stackrel{id}{to}& X &to& 0 downarrow & & downarrow & & downarrow & & downarrow A &to& B &to& C &to& 0 } $ and the exact sequence to be demonstrated is degreewise the cokernel of this sequence.
So the statement reduces to the fact that forming cokernels is a right exact functor.
For $ 0 to A to B to C $ an exact sequence and $ X to A $ any morphism, also $ 0 to A/X to B/X to C $ is exact.
{SpecificExamples} Let $ mathcal{A} = mathbb{Z} $ Mod $ simeq $ Ab.
For $ n in mathbb{N} $ with $ n geq 1 $ let $ mathbb{Z} stackrel{cdot n}{to} mathbb{Z} $ be the linear map/homomorphism of abelian groups which acts by the ordinary multiplication of integers by $ n $ .
This is clearly an injection.
The cokernel of this morphism is the projection to the quotient group, which is the cyclic group $ mathbb{Z}n coloneqq mathbb{Z}/nmathbb{Z} $ .
Hence we have a short exact sequence $ 0 to mathbb{Z} stackrel{cdot n}{to} mathbb{Z} to mathbb{Z}n , $ .
The connecting homomorphism of the long exact sequence in homology induced from short exact sequences of the form in example is called a Bockstein homomorphism.
A standard introduction is for instance in section (i)1 of The quotient lemmas from above are discussed in {Wise} in the context of the salamander lemma and the snake lemma.
In field theory, what we call an 'absolute value' here is often called a 'valuation'.
However, there is also a more general notion of valuation used in field theory, which is what we call 'valuation'.
The notion of absolute value is also used in functional analysis, where it may be called a 'multiplicative norm' (rather than merely submultiplicative, as norms on Banach algebras are required to be).
For $ k $ a rig (typically either a field or at least an integral domain, or else an associative algebra over such), an absolute value on $ k $ is a (non - trivial) multiplicative seminorm, or equivalently a finite real - valued valuation.
This means it is a function $ {vert { - } vert}colon k to mathbb{R} $ to the real numbers such that for all $ x, y in k $ (i) $ {vert x vert} geq 0 $ ; (ii) $ {vert x vert} = 0 $ precisely if $ x = 0 $ ; (iii) $ {vert x cdot y vert} = {vert x vert} {vert y vert} $ ; (iv) $ {vert x + y vert} leq {vert x vert} + {vert y vert} $ (the triangle inequality).
If the last triangle inequality is strengthened to then $ {vert { - } vert} $ is called an ultrametric or non - archimedean absolute value, since then for any $ x, y in k $ with $ vert x vert lt vert y vert $ then for all natural numbers $ n $ , $ vert n x vert leq vert x vert lt vert y vert $ .
If the opposite holds, that whenever $ vert x vert lt vert y vert $ (and $ xneq 0 $ ) there exists a natural number $ n $ with $ vert n x vert gt vert y vert $ , then it is called archimedean.
Two absolute values $ {vert { - } vert}1 $ and $ {vert { - } vert}2 $ are called equivalent if for all $ x in k $ $ ({vert x vert}1 lt 1) Leftrightarrow ({vert x vert}2 lt 1) , $ .
An equivalence class of absolute values is also called a place.
A field equipped with an absolute value which is a complete metric space with respect to the corresponding metric is called a complete field.
Every field admits the trivial absolute value $ {vert { - } vert}0 $ defined by $ {vert x vert}0 = left{ array{ 0 & if; x = 0 1 & otherwise } right. , $ .
This is non - archimedean.
{OnTheRealAndComplexNumbers} Since the real numbers are a sequentially Cauchy complete Archimedean field, the standard absolute value $ {vert { - } vertinfty} $ on the real numbers is $ {vert x vertinfty} = lim{n to infty} x tanh(n x) $ With the standard absolute value function defined, the maximum and principal square root functions could be defined on the real numbers as well.
The standard absolute value on the complex numbers is $ {vert x + i y vertinfty} = sqrt{x^2 + y^2} , $ .
These standard absolute values are archimedean, and with respect to these standard absolute values, both $ mathbb{R} $ and $ mathbb{C} $ are complete and hence are complete archimedean valued fields.
Notice that $ mathbb{R} $ is in addition an ordered field and as such also an archimedean field.
Similar norms exist on the quaternions and octonions, showing that absolute values can be of interest on noncommutative and even nonassociative division rings.
The standard absolute value above restricts to the standard absolute value on the rational numbers $ {vert { - } vertinfty}colon mathbb{Q} to mathbb{R} , $ .
Moreover, for any prime number $ p $ and positive number $ epsilon lt 1 $ , there is an absolute value $ {vert { - } vert{p, epsilon}} $ on $ mathbb{Q} $ defined by $ leftvert frac{k}{l} p^nrightvert{p, epsilon} = epsilon^n $ whenever $ n $ is an integer and $ k $ and $ l $ are nonzero integers not divisible by $ p $ (and $ {vert 0 vert{p, epsilon}} = 0 $ ).
These are called the $ p $ - adic absolute values.
Given $ p $ , they are all equivalent (the open unit ball consists of all rational numbers whose denominator in lowest terms is not divisible by $ p $ ), so there is a unique $ p $ - adic place.
For most purposes, only the place matters, and one may write simply $ |q|p $ ; however, if one wants a specific absolute value, then the usual choice is to use $ epsilon = 1/p $ (so that $ {|p^n|p} = p^{ - n} $ whenever $ n $ is an integer).
The $ p $ - adic absolute value is non - archimedean.
The completion $ mathbb{Q}p $ of $ mathbb{Q} $ under this absolute value is called the field of p - adic numbers, which is therefore a non - archimedean field.
Ostrowski's theorem says that these examples exhaust the non - trivial absolute values on the rational numbers.
Therefore the real numbers and the p - adic numbers are the only possible field completions of $ mathbb{Q} $ .
The field of Laurent series $ k T $ over a field $ k $ is a complete field with respect to the absolute value that sends a series to $ epsilon^n $ for a fixed $ 0 lt epsilon lt 1 $ and with $ n $ the lowest integer such that the $ n $ th coefficient of the series is not $ 0 $ .
Section (i)5, (i)6 of The kernel of a morphism is that part of its domain which is sent to zero.
There are various definitions of the notion of kernel, depending on the properties and structures available in the ambient category.
We list a few definitions and discuss (in parts) when they are equivalent.
In a category with an initial object $ 0 $ and pullbacks, the kernel $ ker(f) $ of a morphism $ f: A to B $ is the pullback $ ker(f) to A $ along $ f $ of the unique morphism $ 0 to B $ $ array{ ker(f) &to& 0 {}^{mathllap{p}}downarrow && downarrow A &stackrel{f}{to}& B } , $ .
More explicitly, this characterizes the object $ ker(f) $ as the object (unique up to unique isomorphism) that satisfies the following universal property: for every object $ C $ and every morphism $ h : C to A $ such that $ fcirc h = 0 $ is the zero morphism, there is a unique morphism $ phi : C to ker(f) $ such that $ h = pcirc phi $ .
In a category with zero morphisms (meaning: enriched over the category of pointed sets), the kernel $ ker(f) $ of a morphism $ f : c to d $ is, if it exists, the equalizer of $ f $ and the zero morphism $ 0{c, d} $ .
In any category enriched over pointed sets, the kernel of a morphism $ f:cto d $ is the universal morphism $ k:ato c $ such that $ f circ k $ is the basepoint.
It is a weighted limit in the sense of enriched category theory.
This applies in particular in any (pre) - additive category.
This is a special case of the construction of generalized kernels in enriched categories.
Let $ Ab $ be the category of abelian groups.
It is a category with kernels.
In every $ Ab $ - enriched category $ A $ , for every morphism $ f: Xto Y $ in $ A $ there is a subfunctor $ ker f : A^{op}to Ab $ of the representable functor $ hom( - , X) $ , defined on objects by $ (ker f)(Z) = ker(hom(Z, X)to hom(Z, Y)), $ where $ ker $ on the right - hand side is the kernel n the category of abelian groups.
If the category is in fact preabelian, $ ker f $ is also representable with representing object $ Ker f $ .
One has to be careful with $ Coker f $ which does not represent the functor naive $ coker f $ defined as
$ (coker f)(Z) = coker(hom(Z, X)to hom(Z, Y)) $ in $ Ab $ , which is often not representable at all, even in the simple example of the category of abelian groups.
Instead, as a colimit construction, one should corepresent another functor, namely, the covariant functor $ Zmapsto ker(hom(Y, Z) to hom(X, Z)) $ (which is a quotient of the corepresentable functor $ hom(X, - ) $ ).
In short, $ Coker f $ is defined by the double dualization using the kernel in $ Ab $ : $ Coker f = (Ker f^{op})^{op} $ .
This is a particular case of the dualization involved in defining any colimit from its corresponding limit.
The kernel of a morphism in an (∞, 1) - category with $ infty $ - categorical zero object is the homotopy pullback as in the pullback definition above: the homotopy fiber.
See also stable (∞, 1) - category.
In some fields, the term 'kernel' refers to an equivalence relation that category theorists would see as a kernel pair.
This is especially important in fields such as monoid theory where both notions exist but are not equivalent (while in group theory they are equivalent).
In ring theory, even when one assumes that rings have units preserved by ring homomorphisms, the traditional notion of kernel (an ideal) exists in the category of non - unital rings (and is not itself a unital ring in general).
A purely category - theoretic theory of unital rings can be recovered either by using the kernel pair instead or (to fit better the usual language) moving to a category of modules.
In universal algebra, this may be handled in the framework of Mal'cev varieties.
Kashiwara - Schapira, following the terminology of EGA, uses kernel as a synonym of equalizer (and co - kernel of co - equalizer).
Let $ C $ be a category with pullbacks and zero object.
In $ C $ , the kernel of a kernel is 0.
By the <a href="http://nlab.mathforge.org/nlab/show/pullbackPasting">pasting law for pullbacks</a> we have that the total square $ array{ ker ker f &to& ker f &to& 0 downarrow && downarrow && downarrow 0 &to& c &stackrel{f}{to}& d } $ is a pullback.
Since $ 0 to c $ is a monomorphism and the pullback of a monomorphism along itself is the domain of the monomorphis, we have $ ker ker f simeq 0 $ .
This statement crucially fails to be true in higher category theory.
There, the kernel of a kernel is the based loop space object of $ d $ .
For this reason where one has short exact sequences in 1 - category theory, there are instead long fiber sequences in higher category theory.
In a category $ C $ with pullbacks and pushouts and zero object, kernel and cokernel form a pair of adjoint functors on the arrow categories $ (coker dashv ker) : Arr(C) stackrel{overset{coker}{leftarrow}}{underset{ker}{to}} Arr(C) , $ .
We check the hom - isomorphism of a pair of adjoint functors.
An element in the hom - set $ ArrC(g, ker f) $ is a diagram $ array{ c &to& ker(f) &to& 0 {}^{mathllap{g}}downarrow && downarrow && downarrow d &to& a &stackrel{f}{to}& b } , $ .
By the universal property of the pullback, this is the same as a diagram $ array{ c &to& &to& 0 {}^{mathllap{g}}downarrow && && downarrow d &to& a &stackrel{f}{to}& b } , $ .
By the dual reasoning, an element in $ ArrC(coker g, f) $ is a diagram $ array{ c &stackrel{g}{to}& d &to& a downarrow && downarrow && downarrow^{mathrlap{f}} 0 &to& coker g &to& b } , $ .
By the universal property of the pushout this is equivalently a diagram $ array{ c &stackrel{g}{to}& d &to& a downarrow && && downarrow^{mathrlap{f}} 0 &to& &to& b } , $ .
(This also follows from the general theory of generalized kernels.)
In the category Ab of abelian groups, the kernel of a group homomorphism $ f : A to B $ is the subgroup of $ A $ on the set $ f^{ - 1}(0) $ of elements of $ A $ that are sent to the zero - element of $ B $ .
More generally, for $ R $ any ring, this is true in $ R $ Mod: the kernel of a morphism of modules is the preimage of the zero - element at the level of the underlying sets, equipped with the unique sub - module structure on that set.
The cellular simplex is one of the basic geometric shapes for higher structures.
Variants of the same "shape archetype" exist in several settings, e.g., that of a simplicial set, the topological /cellular one, and categorical contexts, plus others.
{Definition} {SimplicialSimplex} For $ n in mathbb{N} $ , the standard simplicial $ n $ - simplex $ Deltan $ is the simplicial set which is represented (as a presheaf) by the object $ n $ in the simplex category, so $ Deltan= Delta( - , n) $ .
{CellularSimplex} Likewise, there is a standard topological $ n $ - simplex, which is (more or less by definition) the geometric realization of the standard simplicial $ n $ - simplex.
{TopologicalSimplex} The topological $ n $ - simplex $ Delta^n $ is a generalization of the standard filled triangle in the plane, from dimension 2 to arbitrary dimensions.
Each $ Delta^n $ is homeomorphic to the closed $ n $ - ball $ D^n $ , but its defining embedding into a Cartesian space equips its boundary with its cellular decomposition into faces, generalizing the way that the triangle has three edges (which are 1 - simplices) as faces, and three points (which are vertices or 0 - simplices) as corners.
The topological $ n $ - simplex is naturally defined as a subspace of a Cartesian space given by some relation on its canonical coordinates.
There are two standard choices for such coordinate presentation, which of course define homeomorphic $ n $ - simplices: Each of these has its advantages and disadvantages, depending on application, but of course there is a simple coordinate transformation that exhibits an explicit homeomorphism between the two: {BarycentricCoordinates} In the following, for $ n in mathbb{N} $ we regard the Cartesian space $ mathbb{R}^n $ as equipped with the canonical coordinates labeled $ x0, x1, cdots, x{n - 1} $ .
For $ n in mathbb{N} $ , the topological $ n $ - simplex is, up to homeomorphism, the topological space whose underlying set is the subset $ Delta^n coloneqq { vec x in mathbb{R}^{n+1} | sum{i = 0 }^n xi = 1 ; and ; forall i . xi geq 0 } subset mathbb{R}^{n+1} $ of the Cartesian space $ mathbb{R}^{n+1} $ , and whose topology is the subspace topology induces from the canonical topology in $ mathbb{R}^{n+1} $ .
For $ n in mathbb{N} $ , $ n geq 1 $ and $ 0 leq k leq n $ , the $ deltak : Delta^{n - 1} hookrightarrow Delta^n $ induced under the barycentric coordinates of def. , by the inclusion $ mathbb{R}^n hookrightarrow mathbb{R}^{n+1} $ which omits the $ k $ th coordinate $ (x0, cdots , x{n - 1}) mapsto (x0, cdots, x{k - 1} , 0 , x{k}, cdots, x{n - 1}) , $ .
The inclusion $ delta0 : Delta^0 to Delta^1 $ is the inclusion $ {1 } hookrightarrow 0, 1 $ of the "right" end of the standard interval.
The other inclusion $ delta1 : Delta^0 to Delta^1 $ is that of the "left" end $ {0 } hookrightarrow 0, 1 $ .
For $ n in mathbb{N} $ and $ 0 leq k lt n $ the $ k $ th degenerate $ n $ - simplex (projection) is the surjective map $ sigmak : Delta^{n} to Delta^{n - 1} $ induced under the barycentric coordinates of def.
under the surjection $ mathbb{R}^{n+1} to mathbb{R}^n $ which sends $ (x0, cdots, xn) mapsto (x0, cdots, x{k} + x{k+1}, cdots, xn) , $ .
The collection of face inclusions, def. and degeneracy projections, def. satisfy the (dual) simplicial identities.
Equivalently, they constitute the components of a functor $ Delta^bullet : Delta to Top $ from the simplex category $ Delta $ to the category Top of topological spaces.
This is, up to isomorphism, the standard cosimplicial object in $ Top $ .
{CartesianCoordinates} The standard topological $ n $ - simplex is, up to homeomorphism, the subset $ Delta^n coloneqq { vec x in mathbb{R}^n | 0 leq x1 leq cdots leq xn leq 1 } hookrightarrow mathbb{R}^n $ equipped with the subspace topology of the standard topology on the Cartesian space $ mathbb{R}^n $ .
This definition identifies the topological $ n $ - simplex with the space of interval maps (preserving top and bottom) $ {0 lt 1 lt ldots lt n+1 } to I $ into the topological interval.
This point of view takes advantage of the duality between the simplex category $ Delta $ and the category $ nabla $ of finite intervals with distinct top and bottom.
Indeed, it follows from the duality that we obtain a functor $ Delta simeq nabla^{op} stackrel{Int( - , I)}{to} Top $ $ . left{ (x0, x1) | 0 leq x0 leq x1 leq 1 right } = left{ array{ && && (1, 1) && & nearrow & downarrow && (tfrac{1}{2}, tfrac{1}{2}) && (tfrac{1}{2}, 1) & nearrow & && downarrow (0, 0) &stackrel{}{to}& (0, tfrac{1}{2}) & to & (0, 1) } right } $ {CoordinateTransformation} For $ n in mathbb{N} $ , write now explicitly $ Delta^n{bar} hookrightarrow mathbb{R}^{n+1} $ for the topological $ n $ - simplex in barycentric coordinate presentation, def. , and $ Delta^n{cart} hookrightarrow mathbb{R}^{n} $ for the topological $ n $ - simplex in Cartesian coordinate presentation, def. .
Write $ Sn : mathbb{R}^{n+1} to mathbb{R}^n $ for the continuous function given in the standard coordinates by $ (x0, cdots, x{n}) mapsto (x0, x0 + x1, cdots, sum{i = 0}^k xi, cdots, sum{i = 0}^{n - 1} xi) , $ .
By restriction, this induces a continuous function on the topological $ n $ - simplices $ array{ Delta^n{bar} &hookrightarrow& mathbb{R}^{n+1} downarrow^{mathrlap{Sn|{Delta^n{bar}}}} && downarrow^{pn} Delta^n{cart} &hookrightarrow& mathbb{R}^n } , $ .
For every $ n in mathbb{N} $ the function $ Sn $ is a homeomorphism and respects the face and degeneracy maps.
Equivalently, $ Sbullet $ is a natural isomorphism of functors $ Delta^n to Top $ , hence an isomorphism of cosimplicial objects $ Sbullet : Delta^bullet{bar} stackrel{simeq}{to} Delta^bullet{cart} , $ . {SingularSimplex} For $ X in $ nLab:Top and $ n in mathbb{N} $ , a singular $ n $ - simplex in $ X $ is a nLab:continuous map $ sigma : Delta^n to X , $ .
Write $ (Sing X)n coloneqq Hom{Top}(Delta^n , X) $ for the set of singular $ n $ - simplices of $ X $ .
As $ n $ varies, this forms the singular simplicial complex of $ X $ .
The orientals relate simplices to globes.
A monomorphism is regular if it behaves like an embedding.
The universal factorization through an embedding is the image.
A regular monomorphism is a morphism $ f : c to d $ in some category which occurs as the equalizer of some pair of parallel morphisms $ d stackrel{to}{to} e $ , i.e. for which a limit diagram of the form $ c stackrel{f}{to} d stackrel{longrightarrow}{longrightarrow} e $ exists.
From the defining universal property of the limit it follows directly that a regular monomorphism is in particular a monomorphism.
The dual concept is that of a regular epimorphism.
Beware that (CassidyHebertKelly) use 'regular monomorphism' in a more general way: for them, a regular monomorphism is by definition the joint equalizer of an arbitrary family of parallel pairs of morphisms with common domain.
This concept is sometimes called strict monomorphism, dual to the more commonly used strict epimorphism.
A monomorphism $ i: A to B $ is an effective monomorphism if it is the equalizer of its cokernel pair: if the pushout $ array{ A & stackrel{i}{to} & B i downarrow & & downarrow i1 B & underset{i2}{to} & B +A B } $ exists and $ i $ is the equalizer of the pair of coprojections $ i1, i2: B stackrel{to}{to} B +A B $ .
Obviously effective monomorphisms are regular.
In a category with equalizers and cokernel pairs, the class of regular monomorphism coincides with that of effective monomorphism (def. ).
It is clear that every effective monomorphism is regular, we need to show the converse.
Suppose $ i colon A to B $ is the equalizer of a pair of morphisms $ f, g: B to C $ , and with notation as in def. , let $ j: E to B $ be the equalizer of the pair of coprojections $ i1, i2 $ .
Since $ f circ i = g circ i $ , there exists a unique map $ phi: B +A B to C $ such that $ phi circ i1 = f $ and $ phi circ i2 = g $ .
Then, since $ f j = phi i1 j = phi i2 j = g j $ and since $ i: A to B $ is the equalizer of the pair $ (f, g) $ , there is a unique map $ k: E to A $ such that $ j = i k $ .
Since $ i1 i = i2 i $ , there is a unique map $ l: A to E $ such that $ i = j l $ .
The maps $ k $ , $ l $ are mutually inverse.
In the category Top of topological space, (i) the monomorphisms are the those continuous functions which are injective functions; (i) the regular monomorphisms are the topological embeddings (that is, the injective continuous functions whose sources have the topologies induced from their targets); these are in fact all of the extremal monomorphisms.
Regarding the first statement: an injective continuous function $ f colon X to Y $ clearly has the cancellation property that defines monomorphisms: for parallel continuous functions $ g1, g2 colon Z to X $ : if $ f circ g1 = f circ g1 $ , then $ g1 = g2 $ because continuous functions are equal precisely if their underlying functions of sets are equal.
Conversely, if $ f $ has the cancellation property, then testing on points $ g1, g2 colon ast to X $ gives that $ f $ is injective.
Regarding the second statement: from the construction of equalizers in Top (this example) we have that these are topological subspace inclusions.
Conversely, let $ i colon X to Y $ be a topological subspace embedding.
We need to show that this is the equalizer of some pair of parallel morphisms.
To that end, form the cokernel pair $ (i1, i2) $ by taking the pushout of $ i $ against itself (in the category of sets, and using the quotient topology on a disjoint union space).
By prop. , the equalizer of that pair is the set - theoretic equalizer of that pair of functions endowed with the subspace topology.
Since monomorphisms in Set are regular, we get the function $ i $ back and (again by this example)
it is equipped with the subspace topology.
In Grp, the monics are (up to isomorphism) the inclusions of subgroups, and every monomorphism is regular.
In contrast, the normal monomorphisms (where one of the morphisms $ d to e $ is required to be the zero morphism) are the inclusions of normal subgroups.
The elementary proof we give follows exercise 7H of (AdamekHerrlichStrecker).
It is however nonconstructive (because it contains if - then - else lines); for a constructive proof, see here.
Let $ K hookrightarrow H $ be a subgroup.
We need to define another group $ G $ and group homomorphisms $ f1, f2 : H to G $ such that $ K = {h in H | f1(h) = f2(h) } , $ .
To that end, let $ X := H/K coprod {hat K } := { h K | h in H } coprod {hat K } $ be the set of cosets together with one more element $ hat K $ .
Let then $ G = Aut{Set}(X) $ be the permutation group on $ X $ .
Define $ rho in G $ to be the permutation that exchanges the coset $ e K $ with the extra element $ hat K $ and is the identity on all other elements.
Finally define group homomorphism $ f1, f2 : H to G $ by $ f1(h) : x mapsto left{ array{ h h' K & if x = h' K hat K & if x = hat K } right $ . and $ f2(h) = rho circ f1(h) circ rho^{ - 1} , $ .
It is clear that these maps are indeed group homomorphisms.
So for $ h in H $ we have that $ f1(h) : hat K mapsto hat K , , $ and $ f1(h) : e K mapsto h K $ and $ f2(h) : hat K mapsto e K mapsto h K mapsto left{ array{ hat K & if h in K h K & otherwise } right. , $ . $ f2(h) : e K mapsto hat K mapsto hat K mapsto e K , $ .
So we have $ f1(h) = f2(h) $ precisely if $ h in K $ .
In the context of higher category theory the ordinary limit diagram $ c stackrel{f}{to} d stackrel{to}{to} e $ may be thought of as the beginning of a homotopy limit diagram over a cosimplicial diagram $ c stackrel{f}{to} d0 stackrel{to}{to} d1 stackrel{to}{stackrel{to}{to}} d2 cdots , $ .
Accordingly, it is not unreasonable to define a regular monomorphism in an (∞, 1) - category, to be a morphism which is the limit in a quasi - category of a cosimplicial diagram.
In practice this is of particular relevance for the $ infty $ - version of regular epimorphisms: with the analogous definition as described there, a morphism $ f : c to d $ is a regular epimorphism in an (∞, 1) - category $ C $ if for all objects $ e in C $ the induced morphism $ f^ : C(d, e) to C(c, e) $ is a regular monomorphism in ∞Grpd (for instance modeled by a homotopy limit over a cosimplicial diagram in SSet).
Textbook accounts: See also: tableofcontents A semisimple ring is a ring which is both an Artinian ring and a semiprimitive ring.
For commutative rings, a semisimple ring is a ring which is both an Artinian ring and a reduced ring.
Every semisimple integral domain is a field.
Similarly, every semisimple local ring is a field.
| commutative ring | reduced ring | integral domain | - - - - - - - - - - - - - - - - - - - - - | - - - - - - - - - - - - - - - - - | - - - - - - - - - - - - - - - - - | | local ring | reduced local ring | local integral domain | | Artinian ring | semisimple ring | field |
| Weil ring | field | field
|
If $ A = (a{i j}) $ is a matrix, then its transpose $ A^T $ is the matrix $ A^T coloneqq (a{j i}) $ .
A square matrix which is its onw transpose, $ A =A^T $ , is called a symmetric matrix.
The wedge sum $ A vee B $ of two pointed sets $ A $ and $ B $ is the quotient set of the disjoint union $ A uplus B $ where both copies of the basepoint (the one in $ A $ and the one in $ B $ ) are identified.
The wedge sum $ A vee B $ can be identified with a subset of the cartesian product $ A times B $ ; if this subset is collapsed to a point, then the result is the smash product $ A wedge B $ .
The wedge sum can be generalised to pointed objects in any category $ C $ with pushouts, and is the coproduct in the category of pointed objects in $ C $ (which is the coslice category $ /C $ ).
A very commonly used case is when $ C= $ Top is a category of topological spaces.
In particular, if $ C $ itself is a pointed category, then every object is uniquely a pointed object, so that the coproduct in $ C $ itself may be called a wedge sum.
A commonly used case is when $ C= $ Spectra is a category of spectra.
Also, the wedge sum also makes sense for any family of pointed objects, not just for two of them, as long as $ C $ has pushouts of that size.
For $ {xi colon to Xi } i $ a set of pointed objects in a category $ mathcal{C} $ , their wedge sum $ bigveei X_i $ is the pushout in $ mathcal{C} $ $ bigveei Xi coloneqq (coprodi Xi) coprod{coprod{i} } $ in $ array{ coprod{i} &stackrel{(xi)}{to}& coprodi Xi downarrow && downarrow } , , $ if this exists.
Equivalently (see at overcategory - - limits and colimits) this is just the coproduct in the undercategory $ mathcal{C}backslashast $ of pointed objects.
Texbook accounts: See also: The essential supremum of a measurable function is essentially the supremum of its image.
But we ignore things that happen only on a null set.
Until we write this article, see: >
This entry is mostly about cones in homotopy theory and category theory.
For more geometric cones see at cone (Riemannian geometry).
In homotopy theory, the cone of a space $ X $ is the space obtained by taking the $ X $ - shaped cylinder $ X times I $ , where $ I $ may be an interval object, and squashing one end down to a point.
The eponymous example is where $ X $ is the circle, i.e. the topological space $ S^1 $ , and $ I $ is the standard interval $ 0, 1 $ .
Then the cartesian product $ X times I $ really is a cylinder, and the cone of $ X $ is likewise a cone.
This notion also makes sense when $ X $ is a category, if $ I $ is taken to be the interval category $ { 0 to 1 } $ , i.e. the ordinal $ mathbf{2} $ .
Note that since the interval category is directed, this gives two different kinds of cone, depending on which end we squash down to a point.
Another, perhaps more common, meaning of 'cone' in category theory is that of a cone over (or under) a diagram.
This is just a diagram over the cone category, as above.
Explicitly, a cone over $ Fcolon J to C $ is an object $ c $ in $ C $ equipped with a morphism from $ c $ to each vertex of $ F $ , such that every new triangle arising in this way commutes.
A cone which is universal is a limit.
In category theory, the word cocone is sometimes used for the case when we squash the other end of the interval; thus $ c $ is equipped with a morphism to $ c $ from each vertex of $ F $ (but $ c $ itself still belongs to $ C $ ).
A cocone in this sense which is universal is a colimit.
However, one should beware that in homotopy theory, the word cocone is used for a different dualization.
This definition generalizes to higher category theory.
In particular in (∞, 1) - category theory a cone over an ∞ - groupoid is essentially a cone in the sense of homotopy theory.
If $ X $ is a space, then the cone of $ X $ is the homotopy pushout of the identity on $ X $ along the unique map to the point: $ array{ X & to & X downarrow & & downarrow }, $ .
This homotopy pushout can be computed as the ordinary pushout $ cone(X) := Xtimes I amalgX * $ $ array{ X &stackrel{d1}{to} & X times I downarrow && downarrow } , $ .
If $ X $ is a simplicial set, then the cone of $ X $ is the join of $ X $ with the point.
The mapping cone (q.v.) of a morphism $ f colon X to Y $ is then the pushout along $ f $ of the inclusion $ X to cone(X) $ .
In contexts where intervals $ I $ can be treated as monoid objects, the cone construction as quotient of a cylinder with one end identified with a point, $ C(X) = I times X/(0 times X) sim p, $ carries a structure of monad $ C $ .
In such cases, the monoid has a multiplicative identity $ 1 $ and an absorbing element $ 0 $ , where multiplication by $ 0 $ is the constant map at $ 0 $ .
In that case, a $ C $ - algebra consists of an object $ X $ together with such that $ a(0, x) = x0 $ for all $ x $ .
This equation can be expressed in any category $ mathbf{C} $ with finite products and a suitable interval object $ I $ as monoid (for example, $ Top $ , where $ I = 0, 1 $ is a monoid under real multiplication, or under $ min $ as multiplication).
Under some reasonable assumptions (e.g., if the $ mathbf{C} $ has quotients, and these are preserved by the functor $ I times - $ ), the category of $ C $ - algebras will be monadic over $ mathbf{C} $ and the free $ C $ - algebra on $ X $ will be $ C(X) $ as described above.
The category of $ C $ - algebras will also be monadic over the category of pointed $ mathbf{C} $ - objects, $ 1 downarrow mathbf{C} $ .
These observations apply for example to $ Top $ , and also to $ Cat $ where the interval category $ mathbf{2} $ is a monoid in $ Cat $ under the $ min $ operation (see below).
If in addition the underlying category $ mathbf{C} $ is cartesian closed, or more generally if $ I $ is exponentiable, the monad $ C $ on pointed $ mathbf{C} $ - objects also has a right adjoint $ P $ which can be regarded as a path space construction $ P $ , where we have a pullback $ array{ P(X) & to & 1 downarrow & & downarrow X^I & stackrel{eval0}{to} & X. } $ For general abstract reasons, the right adjoint $ P $ carries a comonad structure whereby $ C $ - algebras are equivalent to $ P $ - coalgebras.
Considered over the category of simplicial sets, this is closely connected to decalage.
If $ C $ is a category, then the cone of $ C $ is the cocomma category of the identity on $ C $ and the unique map to the terminal category: $ array{ C & to & C downarrow & Rightarrow & downarrow }, $ .
Again, this may be computed as a pushout: $ array{ C &stackrel{d1}{to} & C times mathbf{2} downarrow && downarrow } , $ .
The cone of $ C $ may equivalently be thought of, or defined, as the result of adjoining a new initial object to $ C $ .
A cone in a category $ C $ is given by a category $ J $ together with a functor $ cone(J) to C $ .
By the universal property of the cocomma category, to give such a functor is to give an object $ c $ of $ C $ , a functor $ F colon J to C $ , and a natural transformation $ T: Delta(c) to F $ where $ Delta(c):Jto C $ denotes the constant functor at the object $ c $ .
Such a transformation is called a cone over the diagram $ F $ .
In other words, a cone consists of morphisms (called the components of the cone) $ Tj: c to F(j), $ one for each object $ j $ of $ J $ , which are compatible with all the morphisms $ F(f): F(j) to F(k) $ of the diagram, in the sense that each diagram $ array{ {}&{}&c&{}&{} {}& mathllap{scriptsize{Tj}}swarrow &{}& searrowmathrlap{scriptsize{Tk}} &{} F(j) &{}&stackrel{F(f)}{longrightarrow} &{}& F(k) } $ commutes.
It's called a cone because one pictures $ c $ as sitting at the vertex, and the diagram itself as forming the base of the cone.
A cocone in $ C $ is precisely a cone in the opposite category $ C^{op} $ .
For $ F : D to C $ a diagram of (∞, 1) - categories, i.e. an (∞, 1) - functor, the $ (infty, 1) $ - category of $ (infty, 1) $ - cones over $ F $ is the over quasi - category denoted $ C{/F} $ .
Its objects are cones over $ F $ .
Its k - morphisms are $ k $ - homotopies between cones.
The (∞, 1) - categorical limit over $ F $ is, if it exists, the terminal object in $ C{/F} $ .
These are shaped like the homotopy - theoretic cone, so maybe there is a deeper relationship: Loosely speaking, the boundary of a subset $ S $ of topological space $ X $ consists of those points in $ X $ that are neither 'fully in' $ S $ nor are 'fully not in' $ S $ .
For $ S subset X $ a subset of a topological space $ X $ , the boundary or frontier $ partial S $ of $ S $ is its closure $ bar S $ minus its interior $ S^circ $ : $ partial S = bar S backslash S^circ $ Letting $ neg $ denote set - theoretic complementation, $ partial S = neg (S^circ cup (neg S)^circ) $ .
It is a closed set.
If we consider $ partial $ restricted to closed sets as an operation on closed sets, then it becomes a special case of the boundary operator on a co - Heyting algebra; see there for further properties.
In a manifold with boundary of dimension $ n $ the boundary is the collection of points which do not have a neighborhood diffeomorphic to an open n - ball, but do have a neighborhood homeomorphic to a half - ball, that is, an open ball intersected with closed half - space.
One reason behind the notation $ partial $ may be this (cf. co - Heyting boundary): Let $ X, Y $ be topological spaces.
Then for closed subsets $ A subseteq X $ and $ B subseteq Y $ , the Leibniz rule $ partial (A times B) = (partial A times B) cup (A times partial B) $ holds.
Notice the conclusion must fail if $ A $ , $ B $ are not closed, since in this case $ (partial A times B) cup (A times partial B) $ is not closed (it doesn't include $ partial A times partial B $ ).
The interior operation preserves intersections, so $ (A times B)^circ = ((A times Y) cap (X times B))^circ = (A^circ times Y) cap (X times B^circ) $ .
Its complement is $ (neg A^circ times Y) cup (X times neg B^circ) $ , whose intersection with $ widebar{A times B} = A times B $ is $ (partial A times B) cup (A times partial B) $ .
If $ A, B $ are connected open subsets of $ X $ and $ A cap B $ is inhabited, then $ partial A = partial B $ implies $ A = B $ .
Since $ B $ is open, we have $ B subseteq neg partial B = neg partial A = A^circ cup (neg A)^circ, $ where the right side is a disjoint union of open sets $ . B $ is connected, so $ B subseteq A^circ $ or $ B subseteq (neg A)^circ subseteq neg A $ .
The latter cannot occur since $ A cap B $ is inhabited.
So $ B subseteq A^circ subseteq A $ ; by symmetry $ A subseteq B $ .
For topological manifolds and smooth manifolds with boudnary, see: collar neighbourhood theorem.
The Leibniz rule shows that the boundary operator is better behaved when restricted to the lattice of closed subsets.
Since this lattice forms a co - Heyting algebra, one is led to study algebraic operators axiomatizing properties of $ partial $ (Zarycki 1927) on these, the so called co - Heyting boundary operators.
Since the lattice of subtoposes of a given topos carries a co - Heyting algebra structure, it becomes possible to define (co - Heyting) boundaries of subtoposes and thereby even boundaries of the geometric theories that the subtoposes correspond to!
Intuitively, such a boundary $ partial T $ of a theory $ T $ consists of those geometric sequents that neither 'fully follow' from $ T $ nor 'fully contradict' $ T $ .
The interior $ Int(mathcal{E}j) $ of a subtopos $ mathcal{E}j $ of a Grothendieck topos is defined in an exercise of SGA4 as the largest open subtopos contained in $ mathcal{E}j $ .
The boundary $ partialmathcal{E}j $ is then defined as the subtopos complementary to the (open) join of the exterior subtopos $ Ext(mathcal{E}j) $ and $ Int(mathcal{E}j) $ in the lattice of subtoposes.
The co - Heyting algebra perspective and the accompanying mereo - logic of theories was proposed by William Lawvere.
See the references at co - Heyting boundary for further pointers!
A function $ f $ (of sets) from $ A $ to $ B $ is surjective if, given any element $ y $ of $ B $ , $ y = f(x) $ for some $ x $ .
A surjective function is also called onto or a surjection.
Surjections are the same as epimorphisms in the category of sets and effective epimorphisms in the (infinity, 1) - category of sets.
A bijection is a function that is both surjective and injective.
In classical set theory, one writes $ |B| leq^ |A| $ to mean that either there is a surjection $ A to B $ or $ B=empty $ .
The relation $ leq^ $ is a preorder on the class of all sets, and its restriction to inhabited sets is the preorder reflection of the category $ Surj{inh} $ of inhabited sets and surjections.
To make this definition less piecemeal and more constructive, one can define $ |B| leq^* |A| $ to mean $ B $ is a subquotient of $ A $ , in other words one has a surjection $ B' to B $ and an injection $ B' to A $ .
For $ B $ inhabited and a subquotient of $ A $ , excluded middle implies there is a surjection from $ A $ to $ B $ , so in classical mathematics this coincides with the piecemeal definition.
Contrast with the notation $ |B| leq |A| $ if there is an injection $ Bto A $ .
Since subobjects are subquotients (e.g. we can take $ B'=B $ above), $ |B| leq |A| $ implies $ |B| leq^* |A| $ .
(If we wanted to prove this using the piecemeal definition, we would require excluded middle.)
The axiom of choice states precisely that every surjection in the category of sets has a section.
Thus in this setting one has: $ |B| leq^ |A| $ implies $ |B| leq |A| $ , and so $ |B| leq^ |A| $ iff $ |B| leq |A| $ assuming AC.
Some authors who doubt the axiom of choice use the term 'onto' for a surjection as defined above and reserve 'surjective' for the stronger notion of a function with a section (a split epimorphism).
The axiom WISC has an equivalent statement (that works in any Boolean topos) due to Fran&231;ois Dorais phrased almost entirely in terms of surjections (or epimorphisms): >
For every set $ X $ there is a set $ Y $ such that for every surjection $ qcolon Z to X $ there is a function $ scolon Y to Z $ such that $ qcirc scolon Yto X $ is a surjection.
One can view this as really a statement about the Grothendieck fibration over Set with fibre over $ X $ the full subcategory of $ Set/X $ on the surjections: every fibre has a weakly initial object.
Since an element $ a $ in a set $ A $ in the category of sets is just a global element $ a:1rightarrow A $ , one could define surjections in any category $ mathcal{C} $ with a terminal object $ 1 $ : A morphism $ f:Arightarrow B $ in a category $ mathcal{C} $ with a terminal object $ 1 $ is called a surjection.
a surjective morphism, or an onto morphism if, given any global element $ y:1rightarrow B $ , there exists a global element $ x:1rightarrow A $ such that $ y = f circ x $ .
Some authors regard surjection as a synonym of split epimorphism, and only use 'onto' for the definition above.
In a category $ mathcal{C} $ with a terminal object $ 1 $ , the unique morphism $ !:Arightarrow 1 $ is a surjection for every object $ A $ .
By definition of a terminal object, for every object $ A $ there exists a unique morphism $ !:Arightarrow 1 $ , and the identity morphism is the unique global element $ 1{1}:1rightarrow 1 $ .
The composite of a global element $ x:1rightarrow A $ with the function $ !:Arightarrow 1 $ results in a function $ ! circ x:1rightarrow 1 $ , which by definition of a terminal object is the same as $ 1{1}:1rightarrow 1 $ .
Since $ ! circ x = 1{1} $ , for every object $ A $ , $ !:Arightarrow 1 $ is a surjection.
In a category of pointed objects $ mathcal{C} $ , every morphism $ f:Arightarrow B $ is a surjection for every object $ A $ .
A pointed object in a category with terminal objects is a object $ A $ with a global element $ a:1rightarrow A $ to the object, and morphisms in the category preserve the global element, which means there is only a unique global element for each object $ A $ .
Therefore, for every morphism $ f:Arightarrow B $ and global element $ y:1rightarrow B $ , there exists a global element $ x:1rightarrow A $ such that $ y = f circ x $ .
Just because a morphism is a surjection in a concrete category does not mean that the morphism in the underlying category of sets is a surjection; equivalently, the forgetful functor from any category $ mathcal{C} $ to Set does not preserve surjections.
The fact that surjections are epimorphisms in Set is a result of the fact that Set is well - pointed.
This could be generalised to any category with a terminal separator $ 1 $ .
In a category $ mathcal{C} $ with a terminal object $ 1 $ such that $ 1 $ is a separator, every surjection is an epimorphism.
For any surjection $ f:Arightarrow B $ , suppose there are parallel morphisms $ g, h:Brightarrow C $ such
that there $ g circ f = h circ f $ (a fork).
Then for every global element $ y:1rightarrow B $ there exists a global element $ x:1rightarrow A $ such that $ y = f circ x $ , and thus $ g circ y = g circ f circ x $ and $ h circ y = h circ f circ x $ .
But since $ g circ f = h circ f $ , $ g circ f circ x = h circ f circ x $ , which implies that $ g circ y = h circ y $ .
Since $ 1 $ is a separator, then for every global element $ y:1rightarrow B $ , if $ g circ y = h circ y $ , then $ g = h $ .
Therefore, every surjection is an epimorphism.
The axiom of choice for surjections in Set is the following statement:
This axiom could be defined in every category with a terminal object, and could be contrasted with the axiom of choice for epimorphisms, as not every epimorphism is an surjection, nor is every surjection an epimorphism.
In a category $ mathcal{C} $ with a terminal object $ 1 $ and binary equalisers such that every surjection is a split epimorphism, the terminal object $ 1 $ is a separator.
Suppose there are parallel morphisms $ g, h:Brightarrow C $ such that for every global element $ y:1rightarrow B $ , $ g circ y = h circ y $ .
One could construct an equaliser $ f:eq(g, h)rightarrow B $ , which implies that $ g circ f = h circ f $ and that for any global element $ x:1rightarrow eq(g, h) $ , $ g circ f circ x = h circ f circ x $ .
This implies that for every global element $ y:1rightarrow B $ , there exists a global element $ x:1rightarrow eq(g, h) $ where $ y = f circ x $ , and the equaliser $ f:eq(g, h)rightarrow B $ is a surjection.
Since every surjection is a split epimorphism, $ f $ has a section $ i:Brightarrow eq(g, h) $ such that $ f circ i = 1{B} $ , the identity morphism on $ B $ , $ g circ f circ i = h circ f circ i $ , $ g circ 1{B} = h circ 1{B} $ , and $ g = f $ .
Because for every global element $ y:1rightarrow B $ , $ g circ y = h circ y $ implies $ g = h $ , the terminal object $ 1 $ is a separator.
An element $ x $ in a ring (or potentially even a nonassociative rig) $ A $ is nilpotent if there exist a natural number $ n $ such that $ x^n = 0 $ .
An ring/rig/algebra is nilpotent if there exists a uniform number $ n $ such that any product of $ n $ elements is $ 0 $ .
An algebra over a field is locally nilpotent if all of its finitely - generated subalgebras are nilpotent.
A Lie algebra element is ad - nilpotent if the multiplication with any of its elements is a nilpotent linear operator.
A Lie algebra $ A $ is nilpotent iff its lower central series $ A, A, A, A, A, A, ldots, A, A, A, ldots, A, Acdots, ldots $ terminates with $ 0 $ after finitely many steps.
By Engel's theorem (English Wikipedia) a finite - dimensional Lie algebra is nilpotent iff
it is locally nilpotent.
Thus sometimes locally nilpotent Lie algebras are called Engel's Lie algebras.
The class of locally nilpotent associative algebras is closed under extensions (defined in the category of associative algebras).
Consequently associative algebras have a largest nilpotent ideal (namely the sum of all locally nilpotent ideals), which is called Levitskii radical.
The structure rings of classical algebraic varieties are finitely generated noetherian commutative associative unital rings without nilpotent elements.
One of the principal advantages of Grothendieck's theory of schemes is to allow for nilpotent elements in local rings.
A scheme is reduced if there are no nilpotent elements in stalks of the structure sheaf.
For Lie algebras: a closed path in a topological space; a quasigroup with identity element category: disambiguation {Idea} The notion of topological space aims to axiomatize the idea of a space as a collection of points that hang together ("cohere") in a continuous way.
Some one - dimensional shapes with different topologies: the Mercedes - Benz symbol, a line, a circle, a complete graph with 5 nodes, the skeleton of a cube, and an asterisk (or, if you'll permit the one - dimensional approximation, a starfish).
A circle has the same topology as a line segment with a wormhole at its finish which teleports you to its start.
You can see this by putting overlapping open intervals on each of the shapes.
You'll see that they respond the same way, so they're equivalent in that sense.
The surface of a torus is also topologically equivalent to the surface of a mug.
You can see this by putting open circles or slightly looser loops all over each surface: you'll see that they also respond in the same way.
Abstractly, the surface of the mug can be deformed continuously to become the standard torus: the continuous cohesion among the collections of points of the two surfaces is the same.
There is a slight generalization of the notion of topological space to that of a locale, which consists of dropping the assumption that all neighbourhoods are explicitly or even necessarily supported by points.
In this form the definition is quite fundamental and can be naturally motivated from just pure logic - - as the formal dual of frames - - as well as, and dually, from category theory in its variant as topos theory - - by the notion of (0, 1) - toposes.
Topological spaces are the objects studied in topology.
By equipping them with a notion of weak equivalence, namely of weak homotopy equivalence, they turn out to support also homotopy theory.
Topological spaces equipped with extra property and structure form the fundament of much of geometry.
For instance a topological space locally isomorphic to a Cartesian space is a manifold.
A topological space equipped with a notion of smooth functions into it is a diffeological space.
The intersection of these two notions is that of a smooth manifold on which differential geometry is based.
And so on.
{Definitions} We present first the and then a list of different
Finally we mention genuine {StandardDefinition} A topological space is a set $ X $ equipped with a set of subsets $ U subset X $ , called the open sets, which are closed under (i) finite intersections (i) arbitrary unions.
The word 'topology' sometimes means the study of topological spaces but here it means the collection of open sets in a topological space.
In particular, if someone says 'Let $ T $ be a topology on $ X $ ', then they mean 'Let $ X $ be equipped with the structure of a topological space, and let $ T $ be the collection of open sets in this space'.
Since $ X $ itself is the intersection of zero subsets, it is open, and since the empty set $ emptyset $ is the union of zero subsets, it is also open.
Moreover, every open subset $ U $ of $ X $ contains the empty set and is contained in $ X $ $ emptyset subset U subset X , , $ so that the topology of $ X $ is determined by a poset of open subsets $ Op(X) $ with bottom element $ bot = emptyset $ and top element $ top = X $ .
Since by definition the elements in this poset are closed under finite meets (intersection) and arbitrary joins (unions), this poset of open subsets defining a topology is a frame, the frame of opens of $ X $ .
A homomorphism between topological spaces $ f : X to Y $ is a continuous function: a function $ f:Xto Y $ of the underlying sets such that the preimage of every open set of $ Y $ is an open set of $ X $ .
Topological spaces with continuous maps between them form a category, usually denoted Top.
The definition of continuous function $ f : X to Y $ is such that it induces a homomorphism of the corresponding frames of opens the other way around $ Op(X) leftarrow Op(Y) : f^{ - 1} , $ .
And this is not just a morphism of posets but even of frames.
For more on this see at locale.
{AlternateDefinitions} There are many equivalent ways to define a topological space.
A non - exhaustive list follows: {Variants} The definition of topological space was a matter of some debate, especially about 100 years ago.
Our definition is due to Bourbaki, so may be called Bourbaki spaces.
For some purposes, including homotopy theory, it is important to use nice topological spaces (such as sequential topological spaces) and/or a nice - or convenient category of topological spaces (such as compactly generated spaces), or indeed to directly use a model of $ infty $ - groupoids (such as simplicial sets).
On the other hand, when doing topos theory or working in constructive mathematics, it is often more appropriate to use locales than topological spaces.
Some applications to analysis require more general convergence spaces or other generalisations.
... ...
The Cartesian space $ mathbb{R}^n $ with its standard notion of open subsets generated from: unions of open balls $ D^n subset mathbb{R}^n $ .
See at topology.
In topology, a neighbourhood (or neighborhood) of a point $ x $ in some topological space $ X $ is a subset $ U $ such that there is enough room around $ x $ in $ U $ to move in any direction (but perhaps not very far).
One writes $ x in U^circ $ , $ U stackrel{circ}ni x $ , or any of the six other obvious variations to indicate that $ U $ is a neighbourhood of $ x $ .
Let $ (X, tau) $ be a topological space and $ x in X $ a point.
Then: (i) A subset $ U subset X $ is a neighbourhood of $ x $ if there exists an open subset $ O subset X $ such that $ x in O $ and $ O subset U $ .
(i) A subset $ U subset X $ is an open neighbourhood of $ x $ if it is both an open subset and a neighbourhood of $ x $ ; Beware, some authors use "neighbourhood" as a synonym for "open neighbourhood".
Similarly one says that a closed neighbourhood or compact neighbourhood etc. is a neighbourhood that is also a closed subset or compact subspace, respectively.
A zero - divisor is something that, like zero itself, when multiplied by something possibly nonzero still produces zero as a product.
Let $ M $ be a absorption monoid (such as a commutative ring or any ring).
An element $ x $ of $ M $ is a non - zero - divisor if, whenever $ x cdot y = 0 $ or $ y cdot x = 0 $ , then $ y = 0 $ .
An element $ x $ is a zero - divisor if there exists $ y ne 0 $ such that $ x cdot y = 0 $ or $ y x = 0 $ .
In constructive mathematics, we want $ ne $ to be a tight apartness relation on $ M $ in the definition of zero - divisor.
We also say that $ x $ is a strong non - zero - divisor if, whenever $ y ne 0 $ , then $ x y ne 0 $ and $ y x ne 0 $ .
(The notion of (weak) non - zero - divisor makes sense even without any apartness relation.)
If $ M $ is (or may be) non - commutative, then we may distinguish left and right (non) - zero - divisors in the usual way.
By this definition, zero itself is a zero - divisor if and only if $ M $ is non - trivial.
(Some authorities will differ on this point, but if you think about it, this is clearly the correct definition, by the same principle that the trivial ring is not a field, $ 1 $ is not a prime number, etc.
See too simple to be simple.)
An integral domain is precisely a commutative ring (whose multiplicative monoid is an absorption monoid by definition) in which zero is the unique zero - divisor of the multiplicative monoid of the commutative ring (or constructively, in which the strong non - zero - divisors are precisely the strong non - zero elements in the multiplicative monoid, that is those elements $ x $ such that $ x ne 0 $ ).
The non - zero - divisors of any absorption monoid $ M $ form a monoid under multiplication, which may be denoted $ M^{times} $ .
Note that if $ M $ happens to be a field, then this $ M^{times} $ agrees with the usual notation $ M^{times} $ for the group of invertible elements of the multiplicative monoid $ M $ , but $ M^{times} $ is not a group in general.
(We may use $ M^{div} $ or $ M^* $ for the group of invertible elements.)
If $ I $ is any ideal of $ M $ , then we can generalise from a zero - divisor to an $ I $ - divisor.
In a way, this is nothing new; $ x $ is an $ I $ - divisor in $ M $ if and only if $ x $ is a zero - divisor in $ M/I $ .
Ultimately, this is related to the notion of divisor in algebraic geometry.
tableofcontents Given sets $ A $ and $ B $ and a function $ fcolon A to B $ , the inverse function of $ f $ (if it exists) is the function $ f^{ - 1}colon B to A $ such that both composite functions $ f circ f^{ - 1} $ and $ f^{ - 1} circ f $ are identity functions.
Note that $ f $ has an inverse function if and only if $ f $ is a bijection, in which case this inverse function is unique.
Inverse functions are inverse morphisms in the category Set of sets.
More generally, in any concrete category, the inverse of any isomorphism is given by the inverse of the corresponding function between underlying sets.
In type theory, there are two different kinds of inverse functions, quasi - inverse functions, various kinds of more or less coherent quasi - inverse functions, and inverse functions.
For more on this see at equivalence in type theory.
Given types $ A $ and $ B $ and a function $ f:A to B $ , a quasi - inverse function of $ f $ is a function $ g:B to A $ such that $ g $ is a retraction and a section of $ f $ $ . prod{b:B} (f(g(b)) =B b) times prod{a:A} (a =A g(f(a))) $ Equivalently, there are functions $ epsilon0(a, b):(a =A g(b)) to (f(a) =B b) $ and
$ eta0(a, b):(f(a) =B b) to (a =A g(b)) $ for all $ a:A $ and $ b:B $
$ . prod{a:A} prod{b:B} ((a =A g(b)) to (f(a) =B b)) times ((f(a) =B b) to (a =A g(b))) $ A function $ f:A to B $ might have multiple quasi - inverse functions.
The type of quasi - inverses of $ f $ is given by
$ mathrm{QuasiInv}(f) coloneqq sum{g:B to A} prod{b:B} (f(g(b)) =B b) times prod{a:A} (a =A g(f(a))) $ There are also variants of quasi - inverse functions where they are the inverse functions for $ n $ - truncated types.
For example, every function $ g:B to A $ is a ( - 1)
- quasi inverse function, because it is an inverse function for h - propositions $ A $ and $ B $ .
A quasi - inverse function is a 0 - quasi inverse function, because it is an inverse function for h - sets $ A $ and $ B $ .
A 1 - quasi - inverse function is a quasi - inverse function with functions $ epsilon0(a, b):(a =A g(b)) to (f(a) =B b) $ and $ eta0(a, b):(f(a) =B b) to (a =A g(b)) $ for all $ a:A $ and $ b:B $ such that for all $ c:a =A g(b) $ and $ d:f(a) =B b $ , there are functions $ epsilon1(a, b, c, d):(epsilon0(a, b, c) ={f(a) =B b} d) to (c ={a =A g(b)} eta0(a, b, d)) $ $ eta1(a, b, c, d):(c ={a =A g(b)} eta0(a, b, d)) to (epsilon0(a, b, c) ={f(a) =B b} d) $ This is an inverse function for h - groupoids $ A $ and $ B $ .
So on and so forth.
Given types $ A $ and $ B $ and a function $ f:A to B $ , an inverse function of $ f $ is a function $ g:B to A $ with a function $ epsilon(a, b):(f(a) =B b) to (a =A g(b)) $ for all $ a:A $ and $ b:B $ , such that for all identities $ p:a =A g(b) $ , the fiber of $ epsilon(a, b) $ at $ p $ is contractible $ . mathrm{isInv}(f, g) coloneqq prod{a:A} prod{b:B} sum{epsilon(a, b):(f(a) =B b) to (a =A g(b))} prod{p:a =A g(b)} mathrm{isContr}(mathrm{fiber}(epsilon(a, b), p)) $ Given types $ A $ and $ B $ and a function $ f:A to B $ , a coherent inverse function of $ f $ is a quasi - inverse function $ g:B to A $ with homotopies $ G:prod{x:B} f(g(x)) =B x qquad H:prod{x:A} g(f(x)) =A x $ which additionally has homotopies
$ Kf:prod{x:A} mathrm{ap}f(H(x)) ={g(f(x)) =A x} G(f(x)) qquad Kg:prod{x:B} H(g(x)) ={f(g(x)) =B x} mathrm{ap}g(G(x)) $ The type of coherent inverse functions of $ f $ is given by the type $ mathrm{CohInv}(f) coloneqq sum{g:B to A} sum{G:prod{x:B} f(g(x)) =B x} sum{H:prod{x:A} g(f(x)) =A x} left(prod{x:A} mathrm{ap}f(H(x)) ={g(f(x)) =A x} G(f(x))right) times left(prod{x:B} H(g(x)) ={f(g(x)) =B x} mathrm{ap}g(G(x))right) $ Given a function $ f:A to B $ and a function $ g:B to A $ , there are functions $ G:prod{x:B} f(g(x)) =B x, H:prod{x:A} (g(f(x)) =A x) vdash mathrm{QInvToCohInv}1(f, g)(G, H):prod{x:A} mathrm{ap}f(H(x)) ={g(f(x)) =A x} G(f(x)) $ $ G:prod{x:B} f(g(x)) =B x, H:prod{x:A} (g(f(x)) =A x) vdash mathrm{QInvToCohInv}2(f, g)(G, H):prod{x:B} H(g(x)) ={f(g(x)) =B x} mathrm{ap}g(G(x)) $ which satisfies the commutative squares for all elements $ a:A $ and $ b:B $ $ array{& f(g(f(g(b)))) & overset{G(f(g(b))}= & f(g(b)) & mathrm{ap}{f}(H(g(b)))) & Vert & ={f(g(f(g(b)))) =B b} & Vert & pi1(mathrm{QInvToCohInv}1(f, g)(G, H))(b) & f(g(b)) & underset{G(b)}= & b & } $ $ array{& g(f(g(f(a)))) & overset{H(g(f(a))}= & g(f(a)) & mathrm{ap}{g}(G(f(a)))) & Vert & ={g(f(g(f(a)))) =A a} & Vert & pi1(mathrm{QInvToCohInv}2(f, g)(G, H))(a) & g(f(a)) & underset{H(a)}= & a & } $ Not really related For a category $ C $ , its opposite category $ C^{op} $ is the category obtained by formally reversing the direction of all its morphisms (while retaining their original composition law).
Categories generalize (are a horizontal categorification of) monoids, groups and algebras, and forming the opposite category corresponds to forming the opposite of a group, of a monoid, of an algebra.
For a category $ C $ , the opposite category $ C^{op} $ has the same objects as $ C $ , but a morphism $ f : x to y $ in $ C^{op} $ is the same as a morphism $ f : y to x $ in $ C $ , and a composite of morphisms $ g f $ in $ C^{op} $ is defined to be the composite $ f g $ in $ C $ .
More precisely, $ C{mathrm{obj}} $ and $ C{mathrm{mor}} $ are, respectively, the collections of objects and of morphisms of $ C $ , and if the structure maps of $ C $ are then $ C^{op} $ is the category with $ (C^{op}){mathrm{obj}} := C{mathrm{obj}} $ $ (C^{op}){mathrm{mor}} := C{mathrm{mor}} $ $ i{C^{op}} := iC $ $ s{C^{op}} := tC $ $ t{C^{op}} := sC $ $ circ{C^{op}} := circ{C} $ .
or more precisely, the composition operation of $ C^{op} $ is $ circ{C^{op}} : C{mathrm{mor}}^{op} {}{s^{op}}times{t^{op}} C{mathrm{mor}}^{op} = C{mathrm{mor}} {}{t} times{s} C{mathrm{mor}} stackrel{simeq}{to} C{mathrm{mor}} {}{s} times{t} C{mathrm{mor}} stackrel{circ}{to} C{mathrm{mor}} , , $ where the isomorphism in the middle is the unique one induced from the universality of the pullback.
Notice that hence the composition law does not change when passing to the opposite category.
Only the interpretation of in which direction the arrows point does change.
So forming the opposite category is a completely formal process.
Nevertheless, due to the switch of source and target, the opposite category $ C^{op} $ is usually far from being equivalent to $ C $ .
See the examples below.
If $ V $ is a monoidal category, then $ V^{op} $ is equivalent to $ (Sigma V)^{co} $ where $ Sigma V $ is the delooping of $ V $ , i.e $ . V $ viewed as a one - object bicategory and $ {co} $ is the opposite on 2 - cells Given categories $ C $ and $ D $ , the opposite functor of a functor $ F:Cto D $ is the functor $ F^{op}:C^{op}to D^{op} $ such that $ F^{op}{obj}=F{obj} $ and $ F^{op}{mor}=F{mor} $ .
In the literature, $ F^{op} $ is often confused with $ F $ .
This is unfortunate, since (for example) natural transformations $ F^{op}to G^{op} $ (of functors $ C^{op}to D^{op} $ ) can be identified with natural transformations $ Gto F $ (and not $ Fto G $ ).
Given categories $ C $ and $ D $ , functors $ F, G:Cto D $ , the opposite natural transformation of a natural transformation $ t:Fto G $ is the natural transformation $ t^{op}:G^{op}to F^{op} $ , induced by the same map $ C{obj}to D{mor} $ as $ t $ .
Again, in the literature $ t^{op} $ is often confused with $ t $ .
The above three constructions of the opposite category, opposite functor, and opposite natural transformation combine together into the oppositization 2 - functor $ Cat^{co}to Cat, $ where $ Cat^{co} $ denotes the 2 - cell dual of the 2 - category $ Cat $ , with the direction of 2 - morphisms reversed and the direction of 1 - morphisms preserved.
The definition has a direct generalization to enriched category theory.
For $ V $ a symmetric monoidal category and $ C $ a $ V $ - enriched category the opposite $ V $ - enriched category $ C^{op} $ is defined to be the $ V $ - enriched category with the same objects as $ C $ and with $ C^{op}(c, d) := C(d, c) $ and composition given by $ C^{op}(b, c)otimes C^{op}(a, b) := C(c, b) otimes C(b, a) stackrel{sigma}{to} C(b, a) otimes C(c, b) stackrel{circC}{to} C{c, a} =: C^{op}(a, c) , $ .
The unit maps $ ja : I to C^{op}(a, a) $ are those of $ C $ under the identification $ C^{op}(a, a) = C(a, a) $ .
Note that the braiding of $ V $ is used in defining composition for $ C^{op} $ .
So, we cannot define the opposite of a $ V $ - enriched category if $ V $ is merely a monoidal category, though $ V $ - enriched categories still make perfect sense in this case.
If $ V $ is a braided monoidal category there are (at least) two ways to define " $ C^{op} $ ", resulting in two different "opposite categories": we can use either the braiding or the inverse braiding.
If $ V $ is symmetric these two definitions coincide.
The opposite category can be regarded as a dual object of $ C $ in the monoidal bicategory $ V Prof $ of $ V $ - categories and $ V $ - profunctors.
(Note that this does not characterize $ C^{op} $ up to equivalence, but only up to Morita equivalence, i.e. up to Cauchy completion.)
When $ V $ is symmetric, then $ V Prof $ is also symmetric monoidal, so there is only one notion of dual object.
When $ V $ is braided, then $ V Prof $ is not symmetric and has two notions of dual: a left dual and a right dual.
These are exactly the two different opposite categories referred to above (the "left opposite" and "right opposite").
See The nerve $ N(C^{op}) $ of $ C^{op} $ is the simplicial set that is degreewise the same as $ N(C) $ , but in each degree with the order of the face and the order of the degeneracy maps reversed.
See opposite quasi - category for more details.
{OppositeGroup} For $ G = (S, cdot) $ a group (or monoid or associative algebra, etc.) with product operation $ cdotG : S times S to S $ the opposite group $ G^{op} $ is the group whose underlying set (underlying object, underlying vector space, etc.) is the same as that of $ G $ $ S^{op} := S $ but whose product operation is that of $ G $ but combined with a switch of the order of the arguments: $ cdot{G^{op}} : S times S stackrel{sigma}{to} S times S stackrel{cdotG}{to} S , $ .
So for $ g, h in S $ two elements we have that their product in the opposite group is $ g cdot{G^{op}} h := h cdot{G} g , $ .
Now, the group $ G $ may be thought of as the pointed one - object delooping groupoid $ mathbf{B}G $ which is the groupoid with a single object, with $ S $ as its set of morphisms, and with $ cdotG $ its composition operation.
Under this identification of groups with one - object categories, passing to the opposite category corresponds precisely to passing to the opposite group $ (mathbf{B}G)^{op} = mathbf{B}(G^{op}) , $ .
The opposite of an opposite category is the original category: $ (C^{op})^{op} = C , $ .
This is also true for $ V $ - enriched categories when $ V $ is symmetric monoidal, but not when $ V $ is merely braided.
However, in the latter case we can say $ (C^{op1})^{op2} = C = (C^{op2})^{op1} $ , i.e. the two different notions of "opposite category" are inverse to each other (as is always the case for left and right dualization operations in a non - symmetric monoidal (bi)category).
Every algebraic structure in a category, for instance the notion of monoid in a monoidal category $ C $ , has a co - version, where in the original definition the direction of all morphisms is reversed - - for instance the co - version of a monoid is a comonoid.
Of an algebra its a coalgebra, etc.
One may express this succinctly by saying that a co - structure in $ C $ is an original structure in $ C^{op} $ .
For instance a comonoid in $ C $ is a monoid in $ C^{op} $ .
Passing to the opposite category is a realization of abstract duality.
This goes as far as defining some entities as objects in an opposite category - - in particular, all generalizations of geometry which characterize spaces in terms of algebras.
The idea of noncommutative geometry is essentially to define a category of spaces as the opposite category of a category of algebras.
Similarly, a locale is opposite to a frame.
Are there examples where algebras are defined as dual to spaces?
Another example is the definition of the category of $ Linfty $ - algebroids as that opposite to quasi - free differential graded algebras, identifying every $ Linfty $ - algebra with its dual Chevalley - Eilenberg algebra.
The power set - functor $ mathcal{P} ;colon; Set^{op} to Bool $ constitutes an equivalence of categories from the opposite category of Set to that of complete atomic Boolean algebras.
See at Set - - Properties - - Opposite category and Boolean algebras Restricted to finite sets this says that the opposite of the category FinSet of finite sets is equivalent to the category of finite boolean algebras $ FinSet^{op} simeq FinBoolAlg , $ .
See at FinSet - - Properties - - Opposite category.
See at Stone duality for more.
For the definition in enriched category theory see page 12 of Let $ A: Hto H $ be an unbounded operator on a Hilbert space $ H $ .
An unbounded operator $ A^ $ is its adjoint if An adjoint does not need to exist in general.
An unbounded operator is symmetric if $ dom(A)subset dom(A^) $ and $ A x = A^x $ for all $ xin dom(A) $ (one also writes $ Asubset A^ $ ).
The domain of $ A^ $ is the set of all vectors $ yin H $ such that the linear functional $ xmapsto (Ax|y) $ is bounded on $ dom(A) $ .
The graph $ GammaAsubset Hoplus H $ satisfies $ Gamma{A^} = tau(GammaA)^perp $ where $ perp $ denotes the orthogonal complement and $ tau $ denotes the transposition of the direct summands changing the sign of one of the factors, i.e $ . xoplus ymapsto - yoplus x $ .
An unbounded operator $ A $ is closed if $ GammaA $ is closed subspace of $ Hoplus H $ .
An operator $ B $ is a closure of an operator $ A $ if $ GammaB $ is a closure of operator $ GammaA $ .
It is said that $ B $ is an extension of $ A $ and one writes $ Bsupset A $ if $ GammaBsupset GammaA $ .
The closure of an unbounded operator does not need to exist.
For any unbounded operator $ A $ with a dense $ dom(A)subset H $ , if the adjoint operator $ A^ $ exists, then $ A^ $ is closed, and if $ (A^)^ $ exists then it coincides with a closure of $ A $ .
An unbounded operator $ A : Hto H $ on a Hilbert space $ H $ is self - adjoint if An (unbounded) operator is essentially self - adjoint if it is symmetric and its spectrum (as a subspace of the complex plane) is contained in the real line.
Alternatively, it is symmetric if its closure is self - adjoint.
A Hermitean (or hermitian) operator is a bounded symmetric operator (which is necessarily self - adjoint), although some authors use the term for any self - adjoint operator.
For a bounded operator $ A: Hto K $ between Hilbert spaces, define the Hermitean conjugate operator $ A^: Kto H $ by $ (Ax|y)H = (x|A^y)K $ , for all $ xin K $ , $ yin H $ .
Distinguish it from the concept of the transposed operator $ A^T: K^to H^ $ between the dual spaces.
In an arbitrary $ $ - algebra, a self - adjoint or hermitian element is any element $ A $ such that $ A^ = A $ .
Original articles: See also: An analytic function is a function that is locally given by a converging power series.
Let $ V $ and $ W $ be complete Hausdorff topological vector spaces, let $ W $ be locally convex, let $ c $ be an element of $ V $ , and let $ (a0, a1, a2, ldots) $ be an infinite sequence of homogeneous operators from $ V $ to $ W $ with each $ ak $ of degree $ k $ .
Given an element $ c $ of $ V $ , consider the infinite series $ sumk ak(x - c) $ (a power series).
Let $ U $ be the interior of the set of $ x $ such that this series converges in $ W $ ; we call $ U $ the domain of convergence of the power series.
This series defines a function from $ U $ to $ W $ ; we are really interested in the case where $ U $ is inhabited, in which case it is a balanced neighbourhood of $ c $ in $ V $ (which is Proposition (v)3 of Bochnak - - Siciak).
Let $ D $ be any subset of $ V $ and $ f $ any continuous function from $ D $ to $ W $ .
This function $ f $ is analytic if, for every $ c in D $ , there is a power series as above with inhabited domain of convergence $ U $ such that $ f(x) = sumk ak(x - c) $ for every $ x $ in both $ D $ and $ U $ .
(That $ f $ is continuous follows automatically in many cases, including of course the finite - dimensional case.)
The vector spaces $ V $ and $ W $ may be generalised to analytic manifolds and (more generally) analytic spaces.
However, these are manifolds and varieties modelled on vector spaces using analytic transition functions, so the notion of analytic function between vector spaces is most fundamental.
If $ W $ is a vector space over the complex numbers, then we have this very nice theorem, due essentially to Édouard Goursat: A function from $ D subseteq mathbb{C} $ to $ W $ is differentiable if and only if it is analytic.
(Differentiability here is in the usual sense, that the difference quotient converges in $ W $ .)
See holomorphic function and Goursat theorem.
The theory of analytic function was constructed to some extent by and in full generality by Textbook accounts include {BS} A manifold is a topological space that is locally isomorphic to a Cartesian space $ mathbb{R}^n $ .
A manifold with boundary is a topological space that is locally isomorphic either to an $ mathbb{R}^n $ or to a half - space $ H^n = { vec x in mathbb{R}^n | x^n geq 0 } $ .
A manifold with corners is a topological space that is locally isomorphic to an $ H^ni = { vec x in mathbb{R}^n | x^{i+1}, cdots, x^n geq 0 } $ for $ 0 leq i leq n $ .
For details see at manifold.
The evident functor $ SmthMfdWBdrCrn overset{phantom{AAAA}}{hookrightarrow} DiffeologicalSpaces $ from the category of smooth manifolds with boundaries and corners to that of diffeological spaces is fully faithful, hence is a full subcategory - embedding.
(Iglesias - Zemmour 13, (iv)16, Gürer & Iglesias - Zemmour 19)
On cobordism theory of MUFr - manifolds with boundaries, their e - invariant and their appearance in the first line of the Adams - Novikov spectral sequence:
The full subcategory - embedding of manifolds with boundaries and corners into that of diffeological spaces is discussed in: On cobordism theory of manifolds with corners: > (their f - invariant and their appearance in the second line of the Adams - Novikov spectral sequence)
In dependent type theory, and particularly homotopy type theory, an identification is a word sometimes used for an inhabitant of an identity type.
Alternatives to the term identification include identity, path, or equality, though those phrases are also used in different contexts.
Thus an identification $ p:a=b $ provides a "reason", a "witness", or a "proof" that $ a $ and $ b $ "are equal", or more precisely a way in which to identify them.
The distinguishing feature of homotopy type theory is that in general, there may be more than one way to identify two things, i.e. more than one identification between two given elements.
For $ (X, mu) $ a measure space, the integral $ intX mu $ is, if it exists, the volume of $ X $ as seen by the measure $ mu $ .
Let $ X $ be a topological space and $ A hookrightarrow X $ a subspace.
Write $ Cbullet(X) $ for the chain complex of singular homology on $ X $ and $ Cbullet(A) hookrightarrow Cbullet(X) $ for the chain map induced by the subspace inclusion.
The cokernel of this inclusion, hence the quotient $ Cbullet(X)/Cbullet(A) $ of $ Cbullet(X) $ by the image of $ Cbullet(A) $ under the inclusion, is the chain complex of $ A $ - relative singular chains $ . Hn(X , A)coloneqq Hn(Cbullet(X)/Cbullet(A)) , $ .
This means that a singular $ (n+1) $ - chain $ c in C{n+1}(X) $ is an $ A $ - relative cycle if its boundary $ partial c in C{n}(X) $ is, while not necessarily 0, contained in the $ n $ - chains of $ A $ : $ partial c in Cn(A) hookrightarrow Cn(X) $ .
So it vanishes only "up to contributions coming from $ A $ ".
{LongExactSequences} Let $ A stackrel{i}{hookrightarrow} X $ .
The corresponding relative homology sits in a long exact sequence of the form $ cdots to Hn(A) stackrel{Hn(i)}{to} Hn(X) to Hn(X, A) stackrel{delta{n - 1}}{to} H{n - 1}(A) stackrel{H{n - 1}(i)}{to} H{n - 1}(X) to H{n - 1}(X, A) to cdots , $ .
The connecting homomorphism $ delta{n} colon H{n+1}(X, A) to Hn(A) $ sends an element $ c in H{n+1}(X, A) $ represented by an $ A $ - relative cycle $ c in C{n+1}(X) $ , to the class represented by the boundary $ partial^X c in Cn(A) hookrightarrow Cn(X) $ .
This is the homology long exact sequence induced by the given short exact sequence $ 0 to Cbullet(A) stackrel{i}{hookrightarrow} Cbullet(X) to coker(i) simeq Cbullet(X)/Cbullet(A) to 0 $ of chain complexes.
Let $ B hookrightarrow A hookrightarrow X $ be a sequence of two inclusions.
Then there is a long exact sequence of relative homology groups of the form $ cdots to Hn(A , B) to Hn(X , B) to Hn(X , A ) to H{n - 1}(A , B) to cdots , $ .
Observe that we have a (degreewise) short exact sequence of chain complexes $ 0 to Cbullet(A)/Cbullet(B) to Cbullet(X)/Cbullet(B) to Cbullet(X)/Cbullet(A) to 0 , $ .
The corresponding homology long exact sequence is the long exact sequence in question.
{Excision} Let $ Z hookrightarrow A hookrightarrow X $ be a sequence of topological subspace inclusions such that the closure $ bar Z $ of $ Z $ is still contained in the interior $ A^circ $ of $ A $ : $ bar Z hookrightarrow A^circ $ .
In the above situation, the inclusion $ (X - Z, A - Z) hookrightarrow (X, A) $ induces isomorphism in relative singular homology groups $ Hn(X - Z, A - Z) stackrel{simeq}{to} Hn(X, A) $ for all $ n in mathbb{N} $ .
Let $ A, B hookrightarrow X $ be two topological subspaces such that their interior is a cover $ A^circ coprod B^circ to X $ of $ X $ .
In the above situation, the inclusion $ (B, A cap B) hookrightarrow (X, A) $ induces isomorphisms in relative singular homology groups $ Hn(B, A cap B) stackrel{simeq}{to} Hn(X, A) $ for all $ n in mathbb{N} $ .
A proof is spelled out in (Hatcher, from p. 128 on).
These two propositions are equivalent to each other.
To see this identify $ B = X - Z $ .
{HomotopyInvariance} Relative homology is homotopy invariant in both arguments.
(...) {RelationToQuotientTopologicalSpaces} A topological subspace inclusion $ A hookrightarrow X $ is called a good pair if (i) $ A $ is closed inside $ X $ ; (i) $ A $ has an neighbourhood in $ X $ which is a deformation retract of $ A $ .
For $ X $ a CW complex, the inclusion of any subcomplex $ A hookrightarrow X $ is a good pair (called a CW - pair $ (X, A) $ ).
This is discussed at CW complex - - Subcomplexes.
If $ A hookrightarrow X $ is a topological subspace inclusion which is good in the sense of def. , then the $ A $ - relative singular homology of $ X $ coincides with the reduced singular homology of the quotient space $ X/A $ : $ Hn(X , A) simeq tilde Hn(X/A) , $ .
For instance (Hatcher, prop.
(ii)22).
By assumption we can find a neighbourhood $ A stackrel{j}{to} U hookrightarrow X $ such that $ A hookrightarrow U $ has a deformation retract and hence in particular is a homotopy equivalence and so induces also isomorphisms on all singular homology groups.
It follows in particular that for all $ n in mathbb{N} $ the canonical morphism $ Hn(X, A) stackrel{Hn(id, j)}{to} Hn(X, U) $ is an isomorphism, by prop. .
Given such $ U $ we have an evident commuting diagram of pairs of topological spaces $ array{ (X, A) &stackrel{(id, j)}{to}& (X, U) &leftarrow& (X - A, U - A) downarrow && downarrow && downarrow^{mathrlap{simeq}} (X/A, A/A) &stackrel{(id, j/A)}{to}& (X/A, U/A) &leftarrow& (X/A - A/A, U/A - A/A) } , $ .
Here the right vertical morphism is in fact a homeomorphism.
Applying relative singular homology to this diagram yields for each $ n in mathbb{N} $ the commuting diagram of abelian groups $ array{ Hn(X, A) &underoverset{simeq}{Hn(id, j)}{to}& Hn(X, U) &stackrel{simeq}{leftarrow}& Hn(X - A, U - A) downarrow && downarrow && downarrow^{mathrlap{simeq}} Hn(X/A, A/A) &underoverset{simeq}{Hn(id, j/A)}{to}& Hn(X/A, U/A) &stackrel{simeq}{leftarrow}& Hn(X/A - A/A, U/A - A/A) } , $ .
Here the left horizontal morphisms are the above isomorphims induced from the deformation retract.
The right horizontal morphisms are isomorphisms by prop.
and the right vertical morphism is an isomorphism since it is induced by a homeomorphism.
Hence the left vertical morphism is an isomorphism (2 - out - of - 3 for isomorphisms).
{RelationToReducedHomology} Let $ X $ be a inhabited topological space and let $ x colon hookrightarrow X $ any point.
Then the relative singular homology $ Hn(X , ) $ is isomorphic to the absolute reduced singular homology $ tilde Hn(X) $ of $ X $ $ Hn(X , *) simeq tilde Hn(X) , $ .
This is the special case of prop.
for $ A $ a point.
The reduced singular homology of the $ n $ - sphere $ S^{n} $ equals the $ S^{n - 1} $ - relative homology of the $ n $ - disk with respect to the canonical boundary inclusion $ S^{n - 1} hookrightarrow D^n $ : for all $ n in mathbb{N} $ $ tilde Hbullet(S^n) simeq Hbullet(D^n, S^{n - 1}) , $ .
The $ n $ - sphere is homeomorphic to the $ n $ - disk with its entire boundary identified with a point: $ S^n simeq D^n/S^{n - 1} , $ .
Moreover the boundary inclusion is evidently a good pair in the sense of def. .
Therefore the example follows with prop. .
If an inclusion $ A hookrightarrow X $ is such that all relative homology vanishes, $ Hbullet(X , A) simeq 0 $ , then the inclusion induces isomorphisms on all singular homology groups.
Under the given assumotion the long exact sequence in prop.
secomposes into short exact pieces of the form $ 0 to Hn(A) to Hn(X) to 0 , $ .
Exactness says that the middle morphism here is an isomorphism.
{RelativeHomologyOfCWComplexes} Let $ X $ be a CW - complex and write $ X0 hookrightarrow X1 hookrightarrow X2 hookrightarrow cdots hookrightarrow X $ for its filtered topological space - structure with $ X{n+1} $ the topological space obtained from $ Xn $ by gluing on $ (n+1) $ - cells.
The relative singular homology of the filtering degrees is $ Hn(Xk , X{k - 1}) simeq left{ array{ mathbb{Z}Cells(X)n & if; k = n 0 & otherwise } right. , , $ where $ Cells(X)n in Set $ denotes the set of $ n $ - cells of $ X $ and $ mathbb{Z}Cells(X)n $ denotes the free abelian group on this set.
For instance (Hatcher, lemma (ii)34).
The inclusion $ X{k - 1} hookrightarrow Xk $ is clearly a good pair in the sense of def. .
The quotient $ Xk/X{k - 1} $ is by definition of CW - complexes a wedge sum of $ k $ - spheres, one for each element in $ kCell $ .
Therefore by prop.
we have an isomorphism $ Hn(Xk , X{k - 1}) simeq tilde Hn( Xk / X{k - 1}) $ with the reduced homology of this wedge sum.
The statement then follows by the respect of reduced homology for wedge sums as discussed at Reduced homology - Respect for wedge sums.
A standard textbook account for relative singular homology is section (ii)1 of In general, the homology of a point is not trivial but is concentrated in degree 0 on the given coefficient object.
For some applications, though, it is convenient to divide out that contribution such as to have the homology of the point be entirely trivial.
This is called reduced homology.
We discuss the reduced version of singular homology.
Let $ X $ be a topological space.
Write $ Cbullet(X) $ for its singular chain complex.
The augmentation map is the homomorphism of abelian groups $ epsilon colon C0(X) to mathbb{Z} $ which adds up all the coefficients of all 0 - chains: $ epsilon colon colon sum{i} ni sigmai mapsto sumi ni , $ .
Since the boundary of a 1 - chain is in the kernel of this map, it constitutes a chain map $ epsilon colon Cbullet(X) to mathbb{Z} , , $ where now $ mathbb{Z} $ is regarded as a chain complex concentrated in degree 0.
The reduced singular chain complex $ tilde Cbullet(X) $ of $ X $ is the kernel of the augmentation map, the chain complex sitting in the short exact sequence $ 0 to tilde Cbullet(X) to Cbullet(X) stackrel{epsilon}{to} mathbb{Z} to 0 , $ .
The reduced singular homology $ tilde Hbullet(X) $ of $ X $ is the chain homology of the reduced singular chain complex $ tilde Hbullet(X) coloneqq Hbullet(tilde Cbullet(X)) , $ .
Equivalently: The reduced singular homology of $ X $ , denoted $ tilde Hbullet(X) $ , is the chain homology of the augmented chain complex $ cdots to C2(X) stackrel{partial1}{to} C1(X) stackrel{partial0}{to} C0(X) stackrel{epsilon}{to} mathbb{Z} to 0 , $ . {RelationToOrdinaryHomology} Let $ X $ be a topological space,
$ Hbullet(X) $ its singular homology and
$ tilde Hbullet(X) $ its reduced singular homology, def. .
For $ n in mathbb{N} $ there is an isomorphism $ Hn(X) simeq left{ array{ tilde Hn(X) & for ; n geq 1 tilde H0(X) oplus mathbb{Z} & for; n = 0 } right $ .
The homology long exact sequence of the defining short exact sequence $ tilde Cbullet(C) to Cbullet(X) stackrel{epsilon}{to} mathbb{Z} $ is, since $ mathbb{Z} $ here is concentrated in degree 0, of the form $ cdots to tilde Hn(X) to Hn(X) to 0 to cdots to 0 to cdots to tilde H1(X) to H1(X) to 0 to tilde H0(X) to H0(X) stackrel{epsilon}{to} mathbb{Z} to 0 , $ .
Here exactness says that all the morphisms $ tilde Hn(X) to Hn(X) $ for positive $ n $ are isomorphisms.
Moreover, since $ mathbb{Z} $ is a free abelian group, hence a projective object, the remaining short exact sequence $ 0 to tilde H0(X) to H0(X) to mathbb{Z} to 0 $ is split (as discussed there) and hence $ H0(X) simeq tilde H0(X) oplus mathbb{Z} $ .
For $ X = $ the point, the morphism $ H0(epsilon) colon H0(X) to mathbb{Z} $ is an isomorphism.
Accordingly the reduced homology of the point vanishes in every degree: $ tilde H_bullet() simeq 0 , $ .
By the discussion at Singular homology - - Relation to homotopy groups we have that $ Hn(*) simeq left{ array{ mathbb{Z} & for ; n = 0 0 & otherwise } right. , $ .
Moreover, it is clear that $ epsilon colon C0() to mathbb{Z} $ is the identity map.
{RelationToRelativeHomology} For $ X $ an inhabited topological space, its reduced singular homology, def. , coincides with its relative singular homology relative to any base point $ x colon to X $ : $ tilde Hbullet(X) simeq Hbullet(X, ) , $ .
Consider the sequence of topological subspace inclusions $ emptyset hookrightarrow stackrel{x}{hookrightarrow} X , $ .
By the discussion at Relative homology - long exact sequences this induces a long exact sequence of the form $ cdots to H{n+1}() to H{n+1}(X) to H_{n+1}(X, ) to Hn() to Hn(X) to H_n(X, ) to cdots to H1(X) to H1(X, ) to H0() stackrel{H0(x)}{to} H0(X) to Hn(X, ) to 0 , $ .
Here in positive degrees we have $ H_n() simeq 0 $ and therefore exactness gives isomorphisms $ Hn(X) stackrel{simeq}{to} Hn(X, );; forall_{n geq 1} $ and hence with prop.
isomorphisms $ tilde Hn(X) stackrel{simeq}{to} Hn(X, );; forall{n geq 1} , $ .
It remains to deal with the case in degree 0.
To that end, observe that $ H0(x) colon H0(*) to H0(X) $ is a monomorphism: for this notice that we have a commuting diagram $ array{ H0() &stackrel{id}{to}& H0() {}^{mathllap{H0(x)}}downarrow &{}^{mathllap{H0(f)}}nearrow& downarrow^{mathrlap{H0(epsilon)}}simeq H0(X) &stackrel{H0(epsilon)}{to}& mathbb{Z} } , , $ where $ f colon X to $ is the terminal map.
That the outer square commutes means that $ H0(epsilon) circ H0(x) = H0(epsilon) $ and hence the composite on the left is an isomorphism.
This implies that $ H0(x) $ is an injection.
Therefore we have a short exact sequence as shown in the top of this diagram $ array{ 0 &to& H0() &stackrel{H0(x)}{hookrightarrow}& H0(X) &stackrel{}{to}& H0(X, ) &to& 0 && & {}{mathllap{simeq}}searrow & downarrow^{mathrlap{H0(epsilon)}} & && && mathbb{Z} } , $ .
Using this we finally compute $ tilde H_0(X) & coloneqq ker H_0(epsilon) & simeq coker( H_0(x) ) & simeq H_0(X, ) , $ .
Moreover, for "good" inclusions $ A hookrightarrow X $ of topological space, the reduced singular homology of the quotient $ X/A $ is isomorphic to the $ A $ - relative singular homology of $ X $ .
See at Relative homology - Relation to reduced homology of quotient topological spaces.
{RelationToWedgeSums} Let $ {* to Xi } i $ be a set of pointed topological spaces.
Write $ veei Xi in Top $ for their wedge sum and write $ iotai colon Xi to veei Xi $ for the canonical inclusion functions.
For each $ n in mathbb{N} $ the homomorphism $ (tilde Hn(iotai))i colon oplusi tilde Hn(Xi) to tilde Hn(veei Xi) $ is an isomorphism.
For instance (Hatcher, cor.
(ii)25).
This follows with this proposition at relative homology.
For $ X $ a topological space, write $ Hn(X) $ for its singular homology with integer coefficients.
If $ X $ is a contractible topological space, then for all $ n in mathbb{N} $ $ tilde Hn(X) simeq 0 , $ .
The reduced singular homology of the 0 - sphere $ S^0 simeq {} coprod {} $ is $ tilde Hn(S^0) simeq left{ array{ mathbb{Z} & if ; n = 0 0 & otherwise } right. , $ .
Reduced singular homology is discussed for instance around p. 119 of Thoughout let $ R $ be some ring.
Write $ R $ Mod for the category of module over $ R $ .
Write $ U R Mod to $ Set for the forgetful functor that sends a module to its underlying set.
For $ N in R Mod $ a module, a submodule of $ N $ is a subset of $ U(N) $ which (i) is a subgroup of the underlying group (closed under the addition in $ N $ ); (i) is preserved by the $ R $ - action.
Equivalently this means: A submodule of $ N in R Mod $ is a module homomorphism $ i : K to N $ whose underlying map $ U(i) $ of sets is an injection.
And since the injections in $ R $ Mod are precisely the monomorphisms, this means that equivalently A submodule of $ N in R Mod $ is a monomorphism $ i : K hookrightarrow N $ in $ R $ Mod.
Hence a submodule is a subobject in $ R $ Mod.
Given a submodule $ K hookrightarrow N $ , the quotient module $ frac{N}{K} $ is the quotient group of the underlying abelian groups.
For $ N = R $ regarded as a module over itself, a submodule is precisely an ideal of $ R $ .
For $ f : N1 to N2 $ a homomorphism of modules, (i) the kernel $ ker(f) hookrightarrow N1 $ is a submodule of $ N1 $ , (i) the image $ im(f) hookrightarrow N2 $ is a submodule of $ N2 $ .
In example quotient module of $ N2 $ by the image is the cokernel of $ f $ $ coker(f) simeq frac{N2}{im(f)} , $ .
Let $ R $ be a ring.
Assuming the axiom of choice, the following are equivalent (i) every submodule of a free module over $ R $ is itself free; (i) every ideal in $ R $ is a free $ R $ - module; (i) $ R $ is a principal ideal domain.
A proof is in (Rotman, pages 650 - 651).
For instance {Rotman} A function $ f $ from $ A $ to $ B $ is injective if $ x = y $ whenever $ f(x) = f(y) $ .
Equivalently, a function is injective if all its fibers are subsingletons: for all elements $ b in B $ and for all elements $ x in A $ and $ y in A $ , if $ f(x) = b $ and $ f(y) = b $ , then $ x = y $ .
An injective function is also called one - to - one or an injection; it is the same as a monomorphism in the category of sets.
A bijection is a function that is both injective and surjective.
In constructive mathematics, a strongly extensional function between sets equipped with tight apartness relations is called strongly injective if $ f(x) ne f(y) $ whenever $ x ne y $ (which implies that the function is injective).
This is the same as a regular monomorphism in the category of such sets and strongly extensional functions (while any merely injective function, if strongly extensional, is still a monomorphism).
Some authors use 'one - to - one' for an injective function as defined above and reserve 'injective' for the stronger notion.
Since an element $ a $ in a set $ A $ in the category of sets is just a global element $ a:1rightarrow A $ , one could define injections in any category $ mathcal{C} $ with a terminal object $ 1 $ : A morphism $ f:Arightarrow B $ in $ mathcal{C} $ is an injection or a one - to - one morphism if, given any two global elements $ x, y:1rightarrow A $ , $ x = y $ if $ f circ x = f circ y $ .
The term injective morphism is already used in category theory in a different context to mean a morphism with a right lifting property.
In a category $ mathcal{C} $ with a terminal object $ 1 $ , every monomorphism is an injection.
This follows from the definition of a monomorphism.
In a category $ mathcal{C} $ with a terminal object $ 1 $ , every global element $ e:1rightarrow A $ is an injection.
By definition of terminal object $ 1 $ , the unique global element $ i:1rightarrow 1 $ is the identity morphism of the terminal object.
Thus for every global element $ e:1rightarrow A $ , for any two global elements $ x, y:1rightarrow 1 $ , $ x = y $ is always true, making $ e:1rightarrow A $ an injection.
If the category has a strict initial object $ emptyset $ , then every morphism $ f:emptysetrightarrow B $ is vacuously an injection, since there are no global elements $ x:1rightarrowemptyset $ .
A relation is the extension of a predicate.
That is, if you have a statement whose truth value may depend on some variables, then you get a relation that consists of those instantiations of the variables that make the statement true.
Equivalently, you can think of a relation as a function whose target is the set of truth values.
{DefinitionGeneralCase} Given a family $ (Ai){i: I} $ of sets, a relation on that family is a subset $ R $ of the cartesian product $ prod{i: I} Ai $ .
Equivalently, this is a function from $ prod{i: I} Ai $ to the set $ TV $ of truth values (because $ TV $ is the subobject classifier in Set).
Also equivalently, this is a monomorphism in/subobject of the cartesian product $ R hookrightarrow prod{i colon I} Ai , $ .
For $ I $ the 2 - element set (a binary relation) this is in particular a binary correspondence $ array{ && R & swarrow && searrow A1 && && A1 } , $ .
Hence relations are precisely the ( - 1) - truncated correspondences.
This identification induces a natural notion of composition of relations from the composition in the category of correspondences, see below at The 2 - poset of binary relations.
Formulated this way, the notion of relation generalizes to categories other than Set and to higher category theory.
For more on this see at Generalizations below.
A nullary relation is a relation on the empty family of sets.
This is the same as a truth value.
A unary relation on $ A $ is a relation on the singleton family $ (A) $ .
This is the same as a subset of $ A $ .
A binary relation on $ A $ and $ B $ is a relation on the family $ (A, B) $ , that is a subset of $ A times B $ .
This is also called a relation from $ A $ to $ B $ , especially in the context of the $ 2 $ - category Rel described below, or sometimes called a heterogenous relation.
A binary relation on $ A $ is a relation on $ (A, A) $ , that is a relation from $ A $ to itself.
This is sometimes called a homogenous relation on $ A $ , simply a relation on $ A $ , or just an endorelation with its set implicit as a property if not explicitly mentioned.
An $ n $ - ary relation on $ A $ is a relation on a family of $ n $ copies of $ A $ , that is a subset of $ A^n $ .
For a binary relation, one often uses a symbol such as $ sim $ and writes $ a sim b $ instead of $ (a, b) in sim $ .
Actually, even when a relation is given by a letter such as $ R $ , one often sees $ a R b $ instead of $ (a, b) in R $ , although now that does not look so good.
In foundations of mathematics with a sort of propositions and a separate sort of sets, such as most presentations of set theory in first - order logic with equality, there are actually two notions of relation.
The definition given above is the notion of internal relation, defined as a subset of the Cartesian product of a family of sets.
There is a second definition of relation on a set: external relations, which are not defined purely inside of the set theory.
Since each set has a type of elements inside of the set, an external relation is simply a proposition in the context of a family of variables $ xi $ inside of a family of sets $ Ai $ $ Gamma, x0 in A0, x1 in A1, x2 in A2, ldots, xn in An vdash P ; mathrm{prop} $ In any unsorted set theory, those variables would be expressed as $ Gamma, x0, A0, x0 in A0 ; mathrm{true}, x1, A1, x1 in A1 ; mathrm{true}, x2, A2, x2 in A2 ; mathrm{true}, ldots, xn, An, xn in An ; mathrm{true} vdash P ; mathrm{prop} $ It is in this second sense of external relation that equality in first - order logic with equality is an equivalence relation, and inequality is a tight apartness relation in a first - order theory with equality presented in classical logic.
In dependent type theory, where propositions are considered to be the subsingletons or the sets/types themselves, there is only one notion of relation, the internal notion given above.
If $ A $ and $ B $ are each sets equipped with a relation, then what makes a function $ f: A to B $ a morphism of sets so equipped?
There are really two ways to do this, shown below.
(We will write these as if each set is equipped with a binary relation $ sim $ , but any fixed arity would work.)
Now, if $ f $ is a bijection, then it preserves the relation if and only if its inverse reflects it, so clearly an isomorphism of relation - equipped sets should do both.
What about a mere morphism?
In general, it's more natural to require only preservation; these are the morphisms you get if you consider a set with a relation as a models of a finite - limit theory or a simply directed graph.
But in some contexts, particularly when dealing only with irreflexive relations, we instead require (only) that a morphism reflect the relation.
Sometimes an even stricter condition is imposed, as for well - orders.
But even in these cases, the definition of isomorphism comes out the same.
Binary relations are especially widely used.
Special kinds of relations from $ A $ to $ B $ include: Combinations of the above properties of binary relations produce: Special kinds of binary relations on $ A $ (so from $ A $ to itself) additionally include: Combinations of the above properties of binary relations produce: Given pointed sets $ (A, a) $ and $ (B, b) $ , a binary relation $ R $ from $ A $ to $ B $ is said to preserve the point if $ R(a, b) $ .
Given sets with endofunctions $ (A, fA) $ and $ (B, fB) $ , a binary relation $ R $ from $ A $ to $ B $ is said to preserve the endofunction if for every $ a in A $ and $ b in B $ , if $ R(a, b) $ , then $ R(f(a), f(b)) $ .
Given magmas $ (A, muA) $ and $ (B, mub) $ , a binary relation $ R $ from $ A $ to $ B $ is said to preserve the binary operation if for every $ a in A $ , $ c in A $ , $ b in B $ and $ d in B $ , if $ R(a, b) $ and $ R(c, d) $ , then
$ R(muA(a, b), muB(b, d)) $ .
And so forth.
Every binary endorelation $ R $ has an equivalence relation $ simR $ generated by $ R $ .
By currying the binary relation $ R: mathcal{P}(X times X) cong X times X rightarrow Omega $ , one gets a coalgebra $ theta: X rightarrow (X rightarrow Omega) cong X rightarrow mathcal{P}(X) $ for the powerset endofunctor on Set.
{The2PosetOfBinaryRelations} Binary relations form a $ 2 $ - category (in fact a $ 2 $ - poset)
Rel, which is the basic example of an allegory.
The objects are sets, the morphisms from $ A $ to $ B $ are the binary relations on $ A $ and $ B $ , and there is a 2 - morphism from $ R $ to $ S $ (both from $ A $ to $ B $ ) if $ R $ implies $ S $ (that is, when $ (a, b) in R $ , then $ (a, b) in S $ ).
The interesting definition is composition If $ R $ is a relation from $ A $ to $ B $ and $ S $ is a relation from $ B $ to $ C $ , then their composite relation - - written $ S circ R $ or $ R;S $ - - from $ A $ to $ C $ is defined as follows: $ (a, c) in R;S ;Leftrightarrow; exists b: B, ; (a, b) in R ;wedge; (b, c) in S $ .
The identity morphism is given by equality.
The composition operation of relation from def. is induced by the composition of the underlying correspondences, followed by ( - 1) - truncation.
The special properties of the kinds of binary relations listed earlier can all be described in terms internal to Rel; most of them make sense in any allegory.
Irreflexive and asymmetric relations are most useful if the allegory's hom - posets have bottom elements, and linear relations require this.
Comparisons require the hom - posets to have finite unions, and well - founded relations require some sort of higher - order structure.
As a function may be seen as a functional, entire relation, so the category Set of sets and functions is a subcategory of Rel (in fact a replete and locally full sub - $ 2 $ - category).
Endorelations on sets are the objects of the quasitopos $ EndoRel $ or $ Bin $ .
It is a reflective subcategory of Quiv the presheaf topos of quivers and its morphisms are quiver morphisms.
Endorelations are the separated presheaves for the double negation topology on $ Quiv $ .
"Separated" here translates to a quiver having at most one arc between pairs of verticies.
The reflector $ Quiv to EndoRel $ collapses parallel arcs together.
Such quivers might also be called singular or simple though sometimes "simple" also means "no loops".
All of the sub - types of endorelations with positive conditions (reflexive, symmetric, transitive, and left and right euclidean) and their combinations have an associated closure that can produce one from an arbitrary relation.
Such a closure completes a relation by adding the least number of arcs such that the conditions are satisfied.
Within $ EndoRel $ these closures are reflectors that produce reflective subcategories.
For example the symmetric closure $ sym: EndoRel to EndoSym $ will (possibly) enlarge a quiver that contains any arc $ va to vb $ to one that also contains $ vb to va $ .
The transitive and reflexive closure $ transRef: EndoRel to EndoTransRef $ produces a category which is isomorphic to PreOrd though its objects are the underlying quivers of the preorders which are the objects of $ PreOrd $ .
In addition to being reflective, the categories from the symmetric, reflexive, and symmetric and reflexive closures are also quasitoposes that can be directly defined through double negation separation.
The symmetric and reflexive closure (SimpGph) is also a Grothendieck quasitopos.
On the other hand $ PreOrd $ is not a quasitopos because it is not a regular category.
Apart from binary relations, there are important ternary relations used in mathematics, which for the most part are families of binary relations indexed by a third set: {Generalization} Most of the preceding makes sense in any category with enough products; giving rise to internal relations, for instance congruences in the case of internal equivalence relations.
Probably the trickiest bit is the definition of composition of binary relations, so not every category with finite products has an allegory of relations.
In fact, in a certain precise sense, a category has an allegory of relations if and only if it is regular.
It can then be recovered from this allegory by looking at the functional entire relations.
A (left/right/2 - sided) principal ideal in a ring $ R $ is a left/right/2 - sided ideal $ I $ generated by an element $ x in R $ , or equivalently a left sub - $ R $ - module/right sub - $ R $ - module/sub - $ R $ - $ R $ - bimodule generated by $ x $ .
This means there exists an element $ x in I $ such that $ y $ is a multiple of $ x $ whenever $ y in I $ ; we say that $ I $ is generated by $ x $ .
Thus every element $ x $ generates a unique principal ideal, the set of all left/right/two - sided multiples of $ x $ : $ a x $ , $ x b $ , or $ a x b $ if we are talking about left/right/two - sided ideals in a ring.
Clearly, every ideal $ I $ is a join over all the principal ideals $ Px $ generated by the elements $ x $ of $ I $ .
In commutative rings, since the set of all principal ideals is isomorphic to the quotient of (the multiplicative monoid structure on) $ R $ by the group of units, a principal ideal $ I $ is equivalently an element of the quotient monoid $ I in R/R^times $ .
The exterior of a subset of a topological space is the interior of its complement, or equivalently the complement of its closure.
In more elementary terms, $ x in Ext A $ iff there is some neighbourhood of $ x $ that is disjoint from $ A $ .
The exterior operation applied to open sets, i.e., to a topology $ mathcal{O} $ of a space, coincides with the negation operation $ neg: mathcal{O} to mathcal{O} $ when we view $ mathcal{O} $ as a frame or Heyting algebra.
See also regular open set.
This is about functionals in the sense of higher - order logic, which is the original sense and which has only that name.
For functionals in the sense of functional analysis, see linear functional; for the relation between these, see under Examples below.
For functionals on infinite - dimensional manifolds, see at nonlinear functional.
In a type theory with function types, given a type $ X $ , a functional of base type $ X $ is a term of type $ X^{X^X} $ aka $ (X to X) to X $ .
This should be distinguished from (on the one hand) an operator, which is a term of type $ (X^X)^{X^X} $ aka $ (X to X) to (X to X) $ , and (on the other hand) a function, which (in this context) is a term of type $ X^X $ aka $ X to X $ .
More generally, any term whose type has the form $ A^{B^C} $ aka $ (C to B) to A $ may be called a functional, although usually not if any of these types is very trivial (since any type has this form, up to equivalence, if $ B, C coloneqq 1 $ ).
Although one typically interprets type theory within set theory so that operations between types become functions, one may also use partial functions, which is necessary for many of the examples below.
A functional could also be interpreted within category theory as a simplicial 2 - morphism in the 2 - category of sets.
In variational calculus one studies functions on spaces of sections of jet bundles or other mapping spaces.
The notion of nonlinear functional is an abstraction of this.
For example, such functionals appear in physics as action functionals.
See covariant phase space and path integral for other functionals in physics.
If we interpret $ X $ as the real line, then $ X^X $ consists of real - valued maps of a real variable, which form a vector space.
The linear maps from $ X^X $ to $ X $ are the original linear functionals.
In functional analysis, we now replace $ X^X $ with an arbitrary topological vector space $ V $ (originally but no longer necessarily taken to be a subspace of $ X^X $ ) and consider linear maps from $ V $ to $ X $ instead; so these linear functionals are actually unstructured operations in a type - theoretic sense.
Given a subset $ S $ of (the underlying set of) a group $ G $ , its normalizer $ N(S) = NG(S) $ is the subgroup of $ G $ consisting of all elements $ gin G $ such that $ g S = S g $ , i.e. for each $ sin S $ there is $ s'in S $ such that $ g s = s'g $ .
Notice the similarity but also the difference to the definition of the centralizer subgroup, for which $ s' = s $ in the above.
{NormalizationAndWeylGroup} If the subset $ S $ is in fact a subgroup of $ G $ , then it is a normal subgroup of the normalizer $ NG(S) $ ; and $ NG(S) $ is the largest subgroup of $ G $ such that $ S $ is a normal subgroup of it, whence the terminology normalizer.
Indeed, if $ S $ is already a normal subgroup of $ G $ , then its normalizer coincides with the whole of $ G $ , and only then (e.g. here).
Hence when $ S $ is a group then the quotient $ WG S coloneqq NG(S)/S $ is a quotient group.
This is also called the Weyl group of $ S $ in $ G $ .
(This use of terminology is common in equivariant stable homotopy theory - - see e.g. May 96, p. 13 - - but not otherwise.)
Each group $ G $ embeds into the symmetric group $ Sym(G) $ on the underlying set of $ G $ by the left regular representation $ gmapsto lg $ where $ lg(h) = g h $ .
The image is isomorphic to $ G $ (that is, the left regular representation of a discrete group is faithful).
The normalizer of the image of $ G $ in $ Sym(G) $ is called the holomorph.
This solves the elementary problem of embedding a group into a bigger group $ K $ in which every automorphism of $ G $ is obtained by restricting (to $ G $ ) an inner automorphism of $ K $ that fixes $ G $ as a subset of $ K $ .
In (Gray 14) the concept of the normalizer of a subgroup of a group is generalized to the normalizer of a monomorphism in any pointed category in terms of a universal decomposition $ U stackrel{u}{to} N stackrel{f}{to}T $ of a monomorphism $ U to T $ with $ u $ a normal monomorphism.
In (Bourn - Gray 13) the condition that $ w $ be a monomorphism is dropped.
In semiabelian categories: A topological space $ X $ is said to be locally contractible if it has a basis of open subsets that consists of contractible topological spaces $ U hookrightarrow X $ .
Sometimes one requires just that the inclusions $ U to X $ are null - homotopic maps.
This might be called semi - locally contractible.
One could also consider a basis of open sets such that the opens $ U $ have (just) trivial homotopy groups, but this does not seem to crop up in practice.
A locale $ X $ is locally contractible if, viewing a locale as a $ (0, 1) $ - topos and hence a (very special kind of) $ (infty, 1) $ - topos, it is locally ∞ - connected.
For $ X $ a locally contractible topological space, the (∞, 1) - category of (∞, 1) - sheaves $ Sh{(infty, 1)}(X) $ is a locally ∞ - connected (∞, 1) - topos.
This is discussed at locally ∞ - connected (∞, 1) - site.
If one considers fundamental ∞ - groupoids, the inclusion $ U to X $ being null - homotopic is equivalent to the induced (∞, 1) - functor $ Pi(U) to Pi(X) $ being naturally isomorphic to the trivial functor sending everything to a single point.
David Roberts: The following may be straightforwardly obvious, but I have couched it as a conjecture, because I haven't seen it in print.
If the space $ X $ is semi - locally contractible then every locally constant $ n $ - stack on the site of open sets of $ X $ is locally trivial.
See also locally ∞ - connected (∞, 1) - topos.
There a converse to this conjecture is stated: Let $ C $ be a site coming from a coverage such that constant (∞, 1) - presheaves satisfy descent over objects of $ C $ with respect to the generating covering families.
Then the (∞, 1) - category of (∞, 1) - sheaves $ mathbf{H} = Sh{(infty, 1)}(C) $ is a locally ∞ - connected (∞, 1) - topos.
A topological space is separable if it has a countable dense subset.
To be explicit, $ X $ is separable if there exists an infinite sequence $ acolon mathbb{N} to X $ such that, given any point $ b $ in $ X $ and any neighbourhood $ U $ of $ b $ , we have $ ai in U $ for some $ i $ .
A second - countable space is separable (and trivially it is first - countable).
However, first - countability plus separability do not imply second - countability; a counterexample is $ mathbb{R} $ with the half - open topology (see Munkres, page 192), denoted $ mathbb{R}l $ .
An arbitrary product of separable spaces need not be separable, but a product of as many as a continuum number of separable spaces is separable (with the product computed in Top); a proof of the more general Hewitt - Marczewski - Pondiczery theorem can be found here.
In particular, the space $ mathbb{R}^mathbb{R} $ of all functions $ mathbb{R} to mathbb{R} $ under pointwise convergence is separable, but is not even first - countable (and thus not second - countable either).
A first - countable space need not be separable; a simple example of that is a discrete space of uncountable cardinality.
Although an arbitrary product of separable spaces need not be separable, an arbitrary product of separable spaces does satisfy the countable chain condition (see there for more discussion).
This is somewhat remarkable, since it is not necessarily true that even a finite product of spaces satisfying the countable chain condition also satisfies the countable chain condition (whether it does is independent of ZFC).
Subspaces of separable spaces need not be separable.
Example: the product $ mathbb{R}l times mathbb{R}l $ , also called the Sorgenfrey plane, is separable, but the subspace defined by the equation $ y = - x $ is uncountable and discrete and therefore not separable.
However, open subspaces of separable spaces are separable.
Many results in analysis are easiest for separable spaces.
This is particularly true if one wishes to avoid using strong forms of the axiom of choice, or to use arguments predicative over the natural numbers.
For example, the Hahn - Banach theorem for separable Banach spaces can be established using only mild forms of choice, e.g., dependent choice.
More precisely, it can be established in the weak subsystem $ WKL0 $ of second - order arithmetic; see Brown - Simpson.
A classical fact is Using countable choice, then: For a metric space $ X $ the following are equivalent (i) $ X $ is separable; (i) $ X $ is second - countable; (i) $ X $ is Lindelöf, i.e. any open cover admits a countable subcover.
The second property is implied by the first: given any dense subset $ {xn mid nin mathbb{N} } $ , form the countable system of sets $ {B{1/m}(xn) mid n, minmathbb{N} } $ .
To see that this is indeed a base for the topology of $ X $ , take any open set $ Usubset X $ , a point $ xin U $ and a radius $ 1/k $ such that $ B{1/k}(x)subset U $ .
By separability there is some $ n $ such that $ xnin B{1/(2k)}(x) $ and therefore $ xin B{1/(2k)}(xi)subset U $ .
To show (2) implies (3), let $ {Un } $ be a countable base of the topology.
Given any open cover $ {Vlambda } $ of $ X $ , we can form the index set $ Isubset mathbb{N} $ of those $ n $ that are contained in some $ Vlambda $ .
By assumption $ bigcup{iin I} U{i} = bigcuplambda Vlambda = X $ .
The axiom of countable choice provides now a section of $ bigsqcup{iin I} {lambda mid Ui subset Vlambda } to I $ .
Finally, we prove that (3) implies (1).
Consider the open covers $ {B{1/1}(x) mid xin X } $ , $ {B{1/2}(x) mid xin X } $ , ...
From each extract a countable subcover corresponding to collection of centers $ A1, A2, ldots $ .
We claim that that the union $ A1cup A2cupldots $ forms a dense set.
Indeed, given any $ yin X $ and $ n $ the point $ x $ has to be contained in some $ B{1/n}(x) $ for some $ xin An $ .
In the proof any variant of the axiom of choice is only used for the implication $ (2)Rightarrow(3) $ .
On the other hand, assuming countable choice, this implication holds in every topological space.
The implication $ (2)Rightarrow(1) $ holds in any topological space as well (see Example )
Similar in spirit to (1) $ Leftrightarrow $ (2) but less well - known is the following.
A metric space $ X $ is separable iff
every open set is a countable union of balls.
One direction is not hard: if $ xi $ is a countable dense subset of $ X $ and $ rj $ is an enumeration of the rationals, then according to the proof of Theorem , the balls $ B{rj}(xi) $ form a countable base ( $ X $ is a second - countable space).
Hence every open set is a union of a family of such balls that is at most countable.
The other direction is trickier.
(This is based on a MathOverflow discussion, which for the moment we record with little adaptation.)
Suppose $ X $ is not separable; construct by recursion a sequence $ xbeta $ of length $ omega1 $ such that no $ xbeta $ lies in the closure of the set of its predecessors $ xalpha $ (each such set is countable and therefore not dense, so such $ xbeta $ outside its closure can be found at each stage).
Therefore, for each $ xbeta $ we may choose a rational radius $ rbeta $ such that the ball $ B{rbeta}(xbeta) $ contains no predecessor $ xalpha $ .
There are uncountably many $ beta $ , so some rational radius $ r $ was used uncountably many times.
The collection of $ xbeta $ for which $ rbeta = r $ forms another $ omega1 $ - sequence which we now use instead of the first; since all the radii are the same, this sequence has the property that each $ Br(xbeta) $ contains no other $ xalpha $ , no matter whether $ alpha $ appears before or after $ beta $ in the sequence.
Provided that there uncountably many such $ xalpha $ that are non - isolated in $ X $ , we can construct an open set $ U $ that is not a countable union of balls.
For around each such $ xalpha $ we can find a point $ palpha neq xalpha $ within distance $ r/4 $ of $ xalpha $ ; put $ U = bigcupalpha B{d(xalpha, palpha)}(xalpha) $ .
Notice that $ palpha notin U $ .
If $ Bs(x) $ is any ball contained in $ U $ , then $ d(x, xgamma) lt r/4 $ for some $ gamma $ .
Supposing we have distinct $ xalpha, xbeta in Bs(x) $ , then $ r lt d(xalpha, xbeta) leq d(xalpha, x) + d(x, xbeta) lt s + s $ , so $ r/2 lt s $ .
But then from $ d(xgamma, pgamma) lt r/4 $ and $ d(x, xgamma) lt r/4 $ , we have $ d(x, pgamma) lt r/2 lt s $ so that $ pgamma in Bs(x) subset U $ , a contradiction.
We conclude that any ball contained in $ U $ contains at most one $ xalpha $ , and so $ U $ cannot be covered by countably many balls.
We are therefore left to deal with the case where there are at most countably many non - isolated $ xbeta $ .
Discard these, so without loss of generality we may suppose all the $ xbeta $ are isolated points of $ X $ and that for some fixed $ r $ the ball $ Br(xbeta) $ contains no other $ xalpha $ .
Let $ Z $ be this set of $ xbeta $ .
For each $ beta $ , let $ tbeta $ be the supremum over all $ t $ such that $ Bt(xbeta) cap Z $ is countable.
It follows that $ B{tbeta}(xbeta) cap Z $ is itself countable, as is $ {alpha: alpha lt beta } $ .
At each stage $ beta $ , there is a countable set $ Cbeta subset Z $ disjoint from $ B{tbeta}(xbeta) cup {xalpha: alpha lt beta } $ such that for each $ s gt tbeta $ , there exists $ y in Cbeta $ with $ d(xbeta, y) lt s $ .
By transfinite induction, we can construct a cofinal subset $ I $ of $ omega1 $ such that $ xbeta notin Calpha $ whenever $ alpha, beta in I $ and $ alpha lt beta $ .
The set $ Y = {xalpha: alpha in I } $ is open in $ X $ , and we claim that it is not a countable union of balls.
For suppose otherwise.
Let $ F $ be such a countable family of balls; then there is some minimal $ alpha $ for which $ Bt(xalpha) in F $ is uncountable, so that $ t gt talpha $ .
By construction of $ Calpha $ , there exists $ z in Calpha cap Bt(xalpha) $ .
But since $ Y = bigcup F $ , we have that $ z = xbeta $ for some $ beta in I $ , and this contradicts our condition on $ I $ .
Every second - countable topological space is separable.
To see this take a countable cover and select a point in each member of the cover (using countable choice).
An inverse of a morphism $ f colon X to Y $ in a category or unital magmoid (or an element of a monoid or unital magma) is another morphism $ f^{ - 1} colon Y to X $ which is both a left - inverse (a retraction) as well as a right - inverse (a section) of $ f $ , in that $ f circ f^{ - 1} , =, idY colon Y to Y $ equals the identity morphism on $ Y $ and $ f^{ - 1} circ f , =, idX colon X to X $ equals the identity morphism on $ X $ .
A morphism that has an inverse morphism (Def. ) is called an isomorphism.
A (small) category in which all morphisms have inverses is called a groupoid.
If $ f $ is an isomorphism (Def. ) with inverse morphism $ f^{ - 1} $ (Def. ), then any left inverse as well as any right inverse is already an actual inverse morphism and in fact is equal to $ f^{ - 1} $ .
In particular, inverse morphisms are unique when they exist.
Let $ g $ be a left inverse, hence such that $ g circ f , =, id $ .
Write $ f^{ - 1} $ for the actual inverse, hence such that $ f^{ - 1} circ f , =, id $ and $ f circ f^{ - 1} , =, id $ .
Then the following sequence of equalities implies that $ g = f^{ - 1} $ : $ g & ;=; g circ id & ;=; g circ ( f circ f^{ - 1} ) & ;=; (g circ f) circ f^{ - 1} & ;=; id circ f^{ - 1} & ;=; f^{ - 1} , $ .
Here all steps use just the definitions of the various morphisms, except the third step, which uses associativity of composition in any category.
An analogous argument applies to right inverses; and either argument applies to actual inverses.
Let $ f $ be an isomorphism (Def. ).
Then the inverse morphism $ left(f^{ - 1}right)^{ - 1} $ of an inverse morphism $ f^{ - 1} $ (Def. ) exists and is equal to the original morphism: $ left(f^{ - 1}right)^{ - 1} ;=; f , $ .
By the uniqueness of inverses (Prop. ) for $ f^{ - 1} $ .
Any identity morphism is its own inverse morphism (Def. ): $ id^{ - 1} , =, id , $ .
In a balanced category, such as in a topos (in particular in Sets) every morphism that is both a monomorphism and well as an epimorphism is actually an isomorphism and thus has an inverse morphism.
To see that this is not generally the case, notice that any partial order is an (necessarily unbalanced) category where every morphism is both a monomorphism as well as an epimorphism, but only its identity morphisms have inverse morphisms (as they must, by Exp. ).
In a magmoid or semicategory (or an element of a semigroup or magma), a morphism $ f:a to b $ has a unique retraction $ f^{ - 1}:b to a $ if and a morphism $ f:a to b $ has a unique section $ f^{ - 1}:b to a $ if A morphism $ f:a to b $ has a unique inverse if it has a retraction that is also a section.
Ideals show up both in ring theory and in lattice theory.
We recall both of these below and look at some slight generalizations.
A left ideal in a ring (or even rig) $ R $ is a subset $ I $ of (the underlying set of) $ R $ such that: A right ideal in $ R $ is a subset $ I $ such that: A two - sided ideal in $ R $ is a subset $ I $ that is both a left and right ideal; that is: This generalises to: Notice that all three kinds of ideal are equivalent for a commutative ring.
This definition also makes sense for nonassociative rings (or rigs), with the left/right/two - sided coincidence in the commutative case.
In the case of a nonunital ring (or rig), if $ R $ is being thought of as a module over some other ring $ K $ , then it won't immediately follow that $ I $ is a submodule of $ R $ over $ K $ , and so one usually includes that requirement as well: in the case of left - modules, and similarly in the case of right modules or bimodules.
(Technically, this should be distinguished in the terminology, say by calling $ I $ an ideal of $ R $ over $ K $ or the like.)
In particular, a (real or complex) Lie ideal of a Lie algebra $ R $ is an ideal of $ R $ over the real or complex field $ K $ .
An ideal in a lattice (or even proset) $ L $ is a subset $ I $ of (the underlying set of) $ L $ such that: We can make this look more algebraic if $ L $ is a (bounded) join - semilattice: If $ L $ is indeed a lattice, then we can make this look just like the ring version: The concept of ideal is dual to that of filter.
A subset of $ L $ that satisfies the first two of the three axioms for an ideal in a proset is precisely a directed subset of $ L $ ; notice that this is weaker than being a sub - join - semilattice even if $ L $ is a lattice.
There are some common situations where these two kinds of ideal might seem to clash but fortunately do not: On the other hand, every poset is a poset in an opposite way, and this does not give the same concept of ideal; an ideal in one is a filter in the opposite one.
We are lucky that the convention for interpreting a Boolean ring as a lattice goes in the correct direction, or the two notions of ideal in a Boolean algebra would not match; or perhaps it is not a matter of luck, but the convention for which way to define ideals in a lattice was chosen precisely to match the conventions for Boolean algebras!
There is a notion of ideal in a monoid (or even semigroup), or more generally in a monoid object in any monoidal category $ C $ , which generalises the notion of ideal in a ri(n)g or in a (semi)lattice.
That is, if $ C $ is Ab, then a monoid in $ C $ is a ring; if $ C $ is Ab Mon, then a monoid in $ C $ is a rig; and a semilattice is a commutative idempotent monoid in Set.
A left (right) ideal in a monoid (or semigroup) is a subset closed under multiplications with arbitrary elements in the semigroup from the left (right).
See ideal in a monoid.
This generalizes all of the above notions of ideal except for ideals in prosets that are not (possibly unbounded) join - semilattices.
More generally still, passing from monoids to their many - object version and from prosets to their many - morphism version, a right ideal or sieve in a category is a subcategory closed under precomposition with morphisms from the entire category, and a cosieve or left ideal is the dual notion closed under postcompositions with morphisms in the entire category.
See sieve.
In ringoids (small additive categories) and additive categories in general, a left/right/2 - sided ideal is just the ideal (sieve/cosieve) in the sense of categories which is also closed under group operations in hom groups.
Ideals form complete lattices where arbitrary meets are given by set - theoretic intersection.
In other words, ideals form a Moore collection of subsets of $ R $ if $ R $ is a rig, or of $ L $ if $ L $ is a lattice.
This implies we have an ideal generated by any subset: the intersection of all ideals containing the subset.
A subset $ S $ that generates a given ideal $ I $ may be called a subbase of $ I $ ; then $ S $ is a base if every element of $ I $ is a multiple (in a rig) or a predecessor (in an order) of some element of $ S $ .
(In particular, every singleton subset is a base of its generated ideal.)
See also filter base and dualize for more about bases and subbases of ideals in lattices and other posets.
Certain kinds of ideals are often characterized by the roles they play in ideal lattices, or in terms of the Moore closure operator.
Some examples follow.
The top element of an ideal lattice is called the improper ideal.
That is to say, an ideal $ I $ is the improper ideal if $ x in I $ for every $ x $ (which follows if $ 1 in I $ for the case of rigs, or $ top in I $ for the case of bounded lattices).
An ideal $ I $ is proper if it is not the improper ideal: if there exists an element $ x $ such that $ x notin I $ .
So in a rig, $ I $ is proper iff $ 1 notin I $ ; in a (bounded) lattice, $ I $ is proper iff $ top notin I $ .
An ideal is a maximal ideal if it is maximal among proper ideals.
A maximal ideal in a rig (including in a distributive lattice, but not in every lattice) is necessarily prime; conversely, a prime ideal in a Boolean algebra is necessarily maximal.
An ideal $ I $ is a principal ideal if it is generated by a singleton.
This means there exists an element $ x in I $ such that $ y $ is a multiple of $ x $ (in a rig) or $ y leq x $ (in an ordered set) whenever $ y in I $ ; we say that $ I $ is generated by $ x $ .
Thus every element $ x $ generates a unique principal ideal, the set of all left/right/two - sided multiples of $ x $ ( $ a x $ , $ x b $ , or $ a x b $ if we are talking about left/right/two - sided ideals in a rig) or the downset of $ x $ (in an an order).
Clearly, every ideal $ I $ is a join over all the principal ideals $ Px $ generated by the elements $ x $ of $ I $ .
As discussed at ideals in a monoid, there is for two - sided ideals an operation of ideal multiplication, making the ideal lattice a quantale (cf. Day convolution).
Namely, if $ I, J $ are ideals, then their product $ I J $ is the ideal generated by all products $ x y $ with $ x in I, y in J $ in the case of rigs.
Similarly, in the case of lattices, we could define $ I J $ to be the ideal generated by all meets $ x wedge y $ - - but in this case the result is the same as $ I cap J $ .
In any case, we say that a proper ideal $ P $ is prime if for any ideals $ I, J $ , the condition $ I J subseteq P $ implies $ I subseteq P $ or $ J subseteq P $ .
In order theory, the term 'prime ideal' is usually used for a strongly irreducible ideal, since the two are equivalent for prosets.
An (left, right, or two - sided) ideal $ I $ is irreducible if it is proper and, whenever it is written as the intersection of two ideals (of the same kind) $ I = J cap K $ , then at least one of $ J $ and $ K $ equals $ I $ .
If we replace equality here by containment, then we get something more analogous to the definition of prime ideal, called a strongly irreducible ideal.
(Indeed, for prosets, prime ideals and strongly irreducible ideals are the same.)
In general, prime ideals are strongly irreducible, and strongly irreducible ideals are irreducible, but the converses fail.
An ideal is completely irreducible if whenever $ I $ is an intersection of any (possibly infinite) collection of ideals, $ I $ is equal to at least one of them.
(This is not analogous to completely prime ideals.)
An ideal $ I $ is a nil ideal if for every $ xin I $ , there is an $ nin mathbb{N} $ with $ x^n=0 $ .
That is, every element of the ideal is nilpotent.
If on the other hand, there is an $ nin mathbb{N} $ , such that for every $ xin I $ , $ x^n=0 $ , the ideal is called nilpotent.
A maximal ideal $ M $ is prime.
Because the ideal lattice is a quantale, multiplication of ideals distributes over ideal joins.
Suppose $ I J subseteq M $ for two ideals $ I, J $ .
If neither is contained in $ M $ , then $ I vee M = top = J vee M $ (the improper ideal) since $ M $ is maximal.
Then $ top = top cdot top = (I vee M) cdot (J vee M) = I J vee M J vee I M vee M M $ where all four summands are contained in $ M $ ( $ I J subseteq M $ by supposition, and the other containments hold since $ M $ is an ideal).
Thus their join is contained in $ M $ , so we have proved $ top subseteq M $ , contradiction.
That every ideal is contained in a prime ideal is a prime ideal theorem; that every ideal is contained in a maximal ideal is a maximal ideal theorem.
A surface is a space of dimension (ii) In differential geometry this means a 2 - dimensional smooth manifold or something thereby parametrized.
In complex analytic geometry this usually means a complex manifold of complex dimension (ii) Similarly and more generally, in algebraic geometry an algebraic surface is a variety of algebraic dimension (ii) A magma $ (S, cdot) $ is called unital if it has an identity element $ 1 in S $ , hence an element such that for all $ x in S $ it satisfies the equation $ 1 cdot x = x = x cdot 1 $ holds.
The identity element is idempotent.
Some authors take a magma to be unital by default (cf.
Borceux - Bourn Def. (i)(ii)1).
There is also a possibly empty version, where the identity element is replaced with a constant function $ 1:S to S $ such that for all $ x, y in S $ , $ 1(x)cdot y = y $ and $ xcdot 1(y) = x $ .
The Eckmann - Hilton argument holds for unital magmas: two compatible ones on a set must be equal, associative and commutative.
Examples include unital rings etc. {Idea} In algebra, a subring is a subobject of a ring, i.e. a subobject of an object in the category Ring of rings with homomorphisms between them.
As usual, there is a little bit of variation of what exactly one takes to be the definition of "ring" (multiplicative unitality is usually understood by default, while commutativity is usually not assumed by default) but in each case the general notion of subobject reduces to the appropriare notion of subring.
For instance, a subring in the category of unital rings necessarily contains the unit - element of the ambient ring, etc.
See also: Given a Lie algebra $ L $ internal to some symmetric monoidal $ k $ - linear category $ C = (C, otimes, mathbf{1}, tau) $ , an enveloping monoid (or enveloping algebra) of $ L $ in $ C $ is any morphism $ f: Lto Lie(A) $ of Lie algebras in $ C $ where $ A $ is a monoid (= algebra) in $ C $ , and $ Lie(A) $ is the underlying object of $ A $ equipped with the Lie bracket $ , {Lie(A)}=mu - mucirctau{A, A} $ .
In further we will just write $ A $ for $ Lie(A) $ .
A morphism of enveloping algebras $ phi : (f:Lto A)to (f':Lto A') $ is a morphism $ g: Ato A' $ of monoids completing a commutative triangle of morphisms in $ C $ , i.e $ . gcirc f = f' $ .
With an obvious composition of morphisms, the enveloping algebras of $ L $ form a category.
A universal enveloping algebra of $ L $ in $ C $ is any universal initial object $ iL:Lto U(L) $ in the category of enveloping algebras of $ L $ ; it is of course unique up to an isomorphism if it exists.
If it exists for all Lie algebras in $ C $ , then the rule $ Lmapsto U(L) $ can be extended to a functor $ U $ which is the left adjoint to the functor $ Lie:Amapsto Lie(A) $ defined above and the morphism $ iL:Lto U(L) $ is the unit of the adjunction.
In the more general context of higher algebra there is a notion of universal enveloping E - n algebra of an L - infinity algebra for all $ n in mathbb{N} $ which generalizes the notion of universal associative algebra envelope of a Lie algebra.
See at universal enveloping E - n algebra.
The existence of the universal enveloping algebra is easy in many concrete symmetric monoidal categories, e.g. the symmetric monoidal category of bounded chain complexes (giving the universal enveloping dg - algebra of a dg - Lie algebra), but not true in general.
First of all if $ C $ admits countable coproducts, form the tensor algebra $ TL=coprod_{n=0}^infty L^{otimes n} $ on the object $ L $ ; this is a monoid in $ C $ .
In most standard cases, one can also form the smallest 2 - sided ideal (i.e $ . A $ - subbimodule) $ I $ in monoid $ A $ among those ideals whose inclusion into $ A $ is factorizing the map $ (, - m{TL}+m{TL}circtau)circ otimes :Lotimes Lto TL $ ; if the coequalizers exist in $ C $ then we can form the quotient object $ TL/I $ and there is an induced monoid structure in it.
Under mild conditions on $ C $ , the natural morphism $ iL:Lto TL/I $ is an universal enveloping monoid of $ L $ in $ C $ .
If $ C $ is an abelian tensor category and some flatness conditions on the tensor product are satisfied, then the enveloping monoid $ iL:Lto TL/I $ is a monic morphism in $ C $ and $ U(Lcoprod L)cong U(L)otimes U(L) $ .
The isomorphism problem for enveloping algebras is about the fact that the universal enveloping monoids of two Lie algebras of $ C $ are isomorphic as associative monoids in $ C $ , but this does not imply that the Lie algebras are isomorphic.
This is even not true in general for the Lie $ k $ - algebras (in classical sense), even if $ k $ is a field of characteristics zero.
It is known however in that case that the dimension of the finite - dimensional Lie $ k $ - algebra $ L $ can be read off from its universal enveloping $ k $ - algebra as its Gel'fand - Kirillov dimension
$ GK(U(L)) $ .
The universal enveloping algebra $ U(mathfrak{g}) $ of a Lie algebra is naturally a (non - commutative) Poisson algebra with the restriction of the Poisson bracket to generators being the original Lie bracket Suppose the universal enveloping algebras of Lie algebras exist in a $ k $ - linear symmetric monoidal category $ C $ and the functorial choice $ Lmapsto U(L) $ realizing the above construction with tensor products is fixed.
For example, this is true in the category of $ k $ - modules where $ k $ is a commutative ring.
Then the projection $ Lto 0 $ (where $ 0 $ is the trivial Lie algebra) induces the counit $ epsilon:U(L)to U(0)=mathbf{1} $ .
The coproduct $ Delta:U(L)to U(Ltimes L)cong U(L)otimes U(L) $ is induced by the diagonal map $ Lto Ltimes L $ whereas the antipode $ S=U( - id):U(L)to U(L) $ .
One checks that these morphisms make $ U(L) $ into a Hopf algebra in $ C $ .
(e.g Milnor - Moore 65, section 5) The Milnor - Moore theorem states conditions under which the converse holds (hence under which a primitively generated Hopf algebra is a universal enveloping algebra of a Lie algebra).
If the category is simply the vector spaces over a field $ k $ , then for $ lin L $ , after we identify $ L $ with its image in $ U(L) $ , $ Delta(l) = lotimes 1 + 1otimes l $ , i.e. the elements in $ L $ are the primitive elements in $ U(L) $ .
The Poincaré–Birkhoff–Witt theorem states that the associated graded algebra of an enveloping algebra $ U(g) $ in characteristics zero is canonically isomorphic to a symmetric algebra $ Sym(g) $ , and $ U(g) $ is isomorphic to $ S(g) $ as a coalgebra, via the projection map $ U(g)to Gr U(g) $ .
See at deformation quantization the section Relation to universal enveloping algebras.
The universal enveloping algebra of the tangent Lie algebra of a finite - dimensional Lie group $ G $ over real or complex numbers is canonically isomorphic to the algebra of the left invariant differential operators on $ G $ .
The concept of set appears in several different guises in mathematics, and particularly in category theory.
It is common to use foundations of mathematics in which 'set' is an undefined term; this is set theory as a foundation.
In a pure material set theory like ZFC, every object is a set.
Even in a structural approach such as ETCS, it is common for every object to be a structured set in some way or another.
Even if sets are not at the bottom of your foundations, still they are probably close.
For instance, in type theory sometimes sets are defined as predicates on types, or as setoids.
In homotopy type theory, sets are defined as 0 - truncated homotopy types; see below.
Material set theory conflates two notions of sets, which were elegantly (but not first) described by Mathieu Dupont in a blog post as 'set&185;' and 'set&178;', which we will here call 'abstract set' and 'concrete set'.
In the latter case (set&178;), we have some fixed universe of discourse (say, consisting of all real numbers), and a concrete set is a set of elements of this universe (so a set of real numbers, such as $ {5 } $ , $ { x | x gt 2 } $ , or $ empty $ ).
In the former case (set&185;), an abstract set is a purely abstract concept, an unstructured (except perhaps for the equality relation) collection of unlabelled elements.
Arguably (this argument goes back at least to Lawvere), Cantor's original concept of cardinal number (Kardinalzahl) was the abstraction from a concrete set to its underlying abstract set.
Here we adopt a structural approach, in which a set is an abstract set, a (mostly) unstructured collection.
For concrete sets, see subset; if the fixed universe of discourse is an abstract set $ S $ , then a concrete set will be a subset of $ S $ .
In material set theory (as usually conceived), the fixed universe of discourse is an abstract set (or proper class) $ V $ , an abstract set (internal to the theory) is an element of $ V $ , and a concrete set is a sufficiently small subset of $ V $ ; the concepts may be identified because $ V $ comes with an isomorphism to its class of small subsets.
We still need to clarify exactly what sort of collection a set is.
Although most foundations leave this unspecified, we may (perhaps circularly, and perhaps controversially) define it in various ways, as follows: A set is a category (or instead an $ infty $ - groupoid or even an $ infty $ - category) that is small, discrete, and skeletal.
(This definition needs explanation since it seems to be recursive, as "smallness" refers to what a set is.)
Each of these three adjectives describes a different aspect of what makes something a 'set', and they serve different purposes, which should not be conflated.
That a set is (in the category - theoretic sense) discrete is the most important point; nobody would call a category a 'set' merely because it is small and skeletal.
(This clause is also the reason why it makes no difference whether we start from categories, $ infty $ - groupois, or $ infty $ - categories; discreteness immediately limits us to $ 0 $ - groupoids.)
The discreteness of a set reflects its lack of internal structure; while a category may have much structure relating its objects, the only structure remaining in a discrete category is whether any two given objects are isomorphic (and the fact that isomorphism is an equivalence relation); if (and only if) they are, then they are considered equal as elements of the set.
That a set is small allows there to be a collection of 'all' sets; this collection is not itself small, but we still have a large category of all sets, Set.
A category that is merely discrete and skeletal may be called a class instead.
But notice that the difference between a set and a class is a rather technical one; a class is just like a set, only (possibly) larger.
Indeed, not everyone would agree with the requirement that a set must be small; although that is probably the most common way of talking to deal with size issues, it is not the only way.
Another way, used by no less an authority than Categories Work, is to posit the existence of a strongly inaccessible cardinal $ kappa $ and define a small set to be a set whose cardinality is less than $ kappa $ .
That a set is skeletal is arguably the least important requirement; in fact, it violates the principle of equivalence.
A category that is merely small and discrete may be called a setoid instead.
However, if you forbid yourself from referring to equality of elements of the setoid (which are the objects of the small discrete category) - - - or, equivalently, interpret "equality" to mean "isomorphism" therein - - - then you cannot distinguish the setoid from a set; each is merely a (small) collection of elements with an equivalence relation (called 'equivalence' in the setoid and 'equality' in the set, in both cases corresponding to isomorphism in a small discrete category).
While size issues are real and cannot be ignored completely, it is possible to adopt foundations in which the issue of skeletality simply does not appear.
As homotopy type theory may be viewed as a theory of $ infty $ - groupoids, it falls under the preceding section; but since the language of HoTT is important to learn, let us look at it explicitly: A set is a type in which there is an operation connecting any two parallel paths by a 2 - path: Definition isset A := forall (x y : A) (p q :
x == y), p == q (There are numerous other equivalent definitions; see h - set.)
Because this operation is defined internally, it acts on paths as well as points and implies that, for any two points of $ A $ , the type of paths between them is contractible as soon as it is inhabited.
Regarding types as ∞ - groupoids, this definition takes care only of the discreteness requirement.
Regarding smallness, HoTT is usually formulated in Martin - Löf type theory with universes (type of types).
If we have chosen one particular universe as the universe of "small" things, then "setness" could be restricted to types belonging to that universe.
Finally, skeletality is mostly meaningless in HoTT because paths are the only notion of (propositional) equality which we have to reason with.
(There is also the notion of "definitional" equality, but as we cannot assert or prove statements of the form " $ x $ and $ y $ are definitionally equal" inside the theory, this is mostly not relevant for the purposes of setness.)
Formalization of sets in homotopy type theory (via h - sets): &lbrack;doi:(x)1017/S0960129514000553, arXiv:130(v)3835&rbrack; An early definition of "set" appears in where in section 4 it says in translation >
There are wholes which, although they contain the same parts A, B, C, D, ..., nevertheless present themselves as different when seen from our point of view or conception (this kind of difference we call 'essential'), e.g. a complete and a broken glass viewed as a drinking vessel. ...
A whole whose basic conception renders the arrangement of its parts a matter of indifference (and whose rearrangement therefore changes nothing essential from our point of view, if only that changes), I call a set.
A (topological) space whose only connected subspaces are singletons is called totally disconnected.
Discrete spaces are totally disconnected.
The rational numbers $ mathbb{Q} subset mathbb{R} $ equipped with their subspace topology inherited from the Euclidean metric topology on the real numbers, form a totally disconnected space.
By construction, a base for the topology is given by the open subsets which are restrictions of open intervals of real numbers to the rational numbers $ (a, b){mathbb{Q}} coloneqq (a, b) cap mathbb{Q} $ for $ a lt b in mathbb{R} $ .
Now for any such $ a lt b $ there exists an irrational number $ r in mathbb{R}backslash mathbb{Q} $ with $ a lt r lt b $ .
This being irrational implies that $ (a, r){mathbb{Q}} subset mathbb{Q} $ and $ (r, b){mathbb{Q}} subset mathbb{Q} $ are disjoint subsets.
Therefore every basic open subset is the disjoint union of (at least) two open subsets: $ (a, b){mathbb{Q}} = (a, r){mathbb{Q}} cup (r, b){mathbb{Q}} , $ .
Hence no inhabited open subspace of the rational numbers is connected.
A product in $ Top $ of totally disconnected spaces is totally disconnected.
A subspace of a totally disconnected space is totally disconnected.
Hence limits in $ Top $ of diagrams of totally disconnected spaces are totally disconnected.
For example, the Baire space of irrational numbers is homeomorphic to a countable product space $ mathbb{N}^mathbb{N} $ (via continued fractions), so it is totally disconnected.
Similarly, Cantor space $ 2^mathbb{N} $ is totally disconnected.
Another notable special case of the preceding class of examples is the following.
Every profinite group is totally disconnected and in particular the set of p - adic numbers is totally disconnected.
See also Stone space.
The general class of examples in Example may be seen in the following light.
The category of totally disconnected spaces and continuous maps is a reflective subcategory of Top.
The reflector takes a space $ X $ to the space of connected components, i.e., the quotient space $ X/sim $ of $ X $ where $ sim $ - equivalence classes are precisely the connected components of $ X $ .
We check that connected components $ C $ of $ X/sim $ are singletons.
Let $ q: X to X/sim $ be the quotient map; it suffices to check that $ q^{ - 1}(C) subseteq X $ is connected (because then $ q^{ - 1}(C) $ is contained in a single $ sim $ - equivalence class, making $ C = q q^{ - 1}(C) $ a single point).
So, suppose the (closed) set $ q^{ - 1}(C) $ is a disjoint union $ K1 + K2 $ of closed sets $ K1, K2 $ ; we are required to show one or the other is empty.
For each $ c in C $ , the inverse image $ q^{ - 1}({c } ) $ is connected, hence we must have $ q^{ - 1}({c } ) subseteq K1 $ or $ q^{ - 1}({c } ) subseteq K2 $ .
Thus we can partition $ C $ into sets $ C1 coloneqq {c in C: q^{ - 1}({c } ) subseteq K1 } , qquad C2 coloneqq {c in C: q^{ - 1}({c } ) subseteq K2 } $ and we observe $ q^{ - 1}(C1) = K1 $ and $ q^{ - 1}(C2) = K2 $ .
By definition of quotient topology, since $ K1, K2 $ are closed we infer $ C1, C2 $ are closed.
They are also disjoint and $ C = C1 + C2 $ , so by connectedness of $ C $ either $ C1 = emptyset $ or $ C2 = emptyset $ , and therefore $ K1 = q^{ - 1}(C1) $ or $ K2 = q^{ - 1}(C2) $ is empty, as required.
Finally, given a continuous map $ f: X to Y $ with $ Y $ totally disconnected, each connected component $ C $ of $ X $ is mapped to a connected set $ f(C) $ of $ Y $ which is a singleton by total disconnectedness of $ Y $ , and so we get a (unique) factoring through a map $ X/sim to Y $ , continuous of course by virtue of the quotient topology.
This completes the proof.
Given a group $ G $ its derived series is the decreasing (under inclusion order), inductively defined sequence of its subgroups $ G = G0 supset G1 supset G2supset G3supset ldots $ in which $ Gk = G{k - 1}, G{k - 1} $ is the commutator, that is the subgroup of $ G{k - 1} $ generated by all elements of the form $ ghg^{ - 1}h^{ - 1} $ where $ g, hin G{k - 1} $ .
A group is solvable iff its derived series terminates with the trivial subgroup after finitely many terms.
Similarly, one defines a derived series for a Lie algebra $ L $ , and for $ Omega $ - groups.
Given a function $ f: X to Y $ and a subset $ S $ of $ Y $ , the preimage (sometimes also called the inverse image, though that may mean something different) of $ S $ under $ f $ is a subset of $ X $ , consisting of those arguments whose values belong to $ S $ .
That is, $ f^(S) = { a: X ;|; f(a) in S } $ .
A traditional notation for $ f^ $ is $ f^{ - 1} $ , but this can conflict with the notation for an inverse function of $ f $ (which indeed might not even exist).
In fact $ f^ast $ is borrowed from a notation for pullbacks; indeed, a preimage is an example of a pullback: $ array{ f^ast(S) & hookrightarrow & X downarrow & (pb) & downarrow mathrlap{f} S & hookrightarrow & Y } $ Notice also that $ f^ast $ may be regarded as an operator $ P(Y) to P(X) $ between power sets.
Power sets $ P(X) $ are exponential objects $ 2^X $ in the topos $ Set $ ; under this identification the pre - image operator $ f^ast $ is thereby identified with the map $ 2^f: 2^Y to 2^X $ (variously called "pulling back along $ f $ or substituting along $ f $ ) obtained by currying the composite map $ 2^Y times X stackrel{1 times f}{to} 2^Y times Y stackrel{eval}{to} 2 $ .
The appearance of the asterisk as a superscript in $ f^ast $ serves as a reminder of the contravariance of the map $ f mapsto f^ast = 2^f $ .
Similarly, one uses a subscript notation such as $ f $ (or sometimes $ f! $ ) for the direct image, considered as an operator $ f_ast: 2^X to 2^Y $ in the covariant direction.
Naturally all of this generalizes to the context of toposes, where the set $ 2 $ is replaced by the subobject classifier $ Omega $ and $ f^ast = Omega^f $ , with a pullback description similar to the above.
As emphasized by Lawvere, the quantifiers $ existsf, forallf $ are vastly generalized by the concept of enriched Kan extensions which provide left and right adjoints to pulling - back operators $ V^f: V^D to V^C $ for $ V $ - enriched functors $ f: C to D $ .
For partial endofunctions, one could also consider iterating the construction of the preimage of the partial endofunction.
For every set $ T $ and subset $ S subseteq T $ , let $ f:S to T $ be a function from the subset $ S $ to $ T $ .
Given any subset $ R subseteq T $ , the preimage $ f^{ - 1}(R) $ by definition is a subset of $ S $ and thus a subset of $ T $ .
One could restrict the domain of $ f $ to $ f^{ - 1}(R) $ and the codomain of $ f $ to $ R $ , and find the preimage of $ f^{ - 1}(R) $ under $ f $ , or the 2 - fold iterated preimage of $ R $ under $ f $ : $ f^{ - 2}(R) coloneqq {x in S vert exists b in f^{ - 1}(R).f(x) = b } $ One could repeat this definition indefinitely, which could be formalised by the indexed sets $ f^{ - n}(R) $ representing the $ n $ - fold iterated preimage of $ R $ under $ f $ $ . f^{ - 0}(R) coloneqq R $ and for $ n in mathbb{N} $ , $ f^{ - (n+1)}(S) coloneqq {x in S vert exists b in f^{ - (n)}(R).f(x) = b } $ One example of an iterated preimage is the set of iterated differentiable functions and the iterated continuously differentiable functions $ C^n(mathbb{R}) $ , which are the $ n $ - th iterated preimage of all functions and pointwise continuous functions on the real numbers under the derivative/Newton - Leibniz operator respectively.
The above definition of an iterated preimage is inductive; one could also consider the coinductive version of above.
This leads to infinitely iterated preimages: For every set $ T $ and subset $ S subseteq T $ , let $ f:S to T $ be a function from the subset $ S $ to $ T $ .
Given any subset $ R subseteq T $ , the infinitely iterated preimage is defined as the largest subset $ f^{ - infty}(R) subseteq T $ such that the preimage of $ f^{ - infty}(R) $ under $ f $ is $ f^{ - infty}(R) $ itself.
One example of an infinitely iterated preimage is the set of smooth functions $ C^infty(mathbb{R}) $ , which is the infinitely iterated preimage of pointwise continuous functions under the derivative/Newton - Leibniz operator.
For a generalisation to sheaves, see inverse image.
>
This entry is about the notion of spans/correspondences which generalizes that of relations.
For spans in vector spaces or modules, see linear span.
In set theory, a span or correspondence between sets $ A $ and $ B $ is a set $ C $ with a function $ R:C to A times B $ to the product set $ A times B $ .
A span between a set $ A $ and $ A $ itself is a directed pseudograph, which is used to define categories in set theory.
In dependent type theory, there is a distinction between a span, a multivalued partial function, and a correspondence:
However, from any one of the above structures, one could get the other two structures, provided one has identity types and dependent pair types in the dependent type theory.
Given a type family $ x:A vdash P(x) $ , let $ z:sum{x:A} P(x) vdash pi1(z):A $ and $ z:sum{x:A} P(x) vdash pi2(z):P(pi1(z)) $ be the dependent pair projections for the dependent pair type $ sum{x:A} P(x) $ .
Given types $ A $ , $ B $ , and $ C $ and spans $ (D, x:D vdash gD(x):A, x:D vdash hD(x):B) $ between $ A $ and $ B $ and $ (E, y:E vdash gE(y):B, y:E vdash hE(y):C) $ between $ B $ and $ C $ , there is a span $ (E circ D, z:E circ D vdash g{E circ D}(z):A, z:E circ D vdash h{E circ D}(z):C) $ defined by $ E circ D coloneqq sum{x:D} sum{y:E} hD(x) =B g_E(y) $ $ z:E circ D vdash g{E circ D}(z) coloneqq gD(pi_1(z)) $ $ z:E circ D vdash h{E circ D}(z) coloneqq hE(pi1(pi2(pi_1(z))(z))) $ Given types $ A $ , $ B $ , and $ C $ and correspondences $ x:A, y:B vdash R(x, y) $ and $ y:B, z:C vdash S(y, z) $ , there is a correspondence $ x:A, z:C vdash (S circ R)(x, z) $ defined by $ (S circ R)(x, z) coloneqq sum_{y:B} R(x, y) times S(y, z) $ In any category $ C $ , a span, or roof, or correspondence, from an object $ x $ to an object $ y $ is a diagram of the form $ array{ && s & {}^{f}swarrow && searrow^{g} x &&&& y } $ where $ s $ is some other object of the category.
(The word "correspondence" is also sometimes used for a profunctor.)
This diagram is also called a 'span' because it looks like a little bridge; 'roof' is similar.
The term 'correspondence' is prevalent in geometry and related areas; it comes about because a correspondence is a generalisation of a binary relation.
Note that a span with $ f = 1 $ is just a morphism from $ x $ to $ y $ , while a span with $ g = 1 $ is a morphism from $ y $ to $ x $ .
So, a span can be thought of as a generalization of a morphism in which there is no longer any asymmetry between source and target.
A span in the opposite category $ C^op $ is called a co - span in $ C $ .
A span that has a cocone is called a coquadrable span.
If the category $ C $ has pullbacks, we can compose spans.
Namely, given a span from $ x $ to $ y $ and a span from $ y $ to $ z $ : $ array{ && s &&&& t & {}^{f}swarrow && searrow^{g} & & {}^{h}swarrow && searrow^{i} x &&&& y &&&& z } $ we can take a pullback in the middle: $ array{ &&&& s times_y t & && {}^{p_s}swarrow && searrow^{p_t} && s &&&& t & {}^{f}swarrow && searrow^{g} & & {}^{h}swarrow && searrow^{i} x &&&& y &&&& z } $ and obtain a span from $ x $ to $ z $ : $ array{ && s times_y t & {}^{f p_s}swarrow && searrow^{i p_t} x &&&& z } $ This way of composing spans lets us define a bicategory Span $ (C) $ with: This is a weak 2 - category: it has a nontrivial associator: composition of spans is not strictly associative, because pullbacks are defined only up to canonical isomorphism.
A naturally defined strict 2 - category which is equivalent to $ Span(C) $ is the strict 2 - category of linear polynomial functors between slice categories of $ C $ .
(Note that we must choose a specific pullback when defining the composite of a pair of morphisms in $ Span(C) $ , if we want to obtain a bicategory as traditionally defined; this requires the axiom of choice.
Otherwise we obtain a bicategory with 'composites of morphisms defined only up to canonical iso - 2 - morphism'; such a structure can be modeled by an anabicategory or an opetopic bicategory.)
By including functions as well, instead of a bicategory we obtain a pseudo - double category.
Let $ C $ be a category with pullbacks and let $ Span1(C) := (Span(C)){sim 1} $ be the 1 - category of objects of $ C $ and isomorphism classes of spans between them as morphisms.
Then Next assume that $ C $ is a cartesian monoidal category.
Then clearly $ Span_1(C) $ naturally becomes a monoidal category itself, but more: then {UniversalPropertyOfTheBicategoryOfSpans} We discuss the universal property that characterizes 2 - categories of spans.
For $ C $ be a category with pullbacks, write (i) $ Span2(C) coloneqq (Span(C)){sim2} $ for the weak 2 - category of objects of $ C $ , spans as morphisms, and maps between spans as 2 - morphisms, (i) $ etaC: C rightarrow Span2(C) $ for the functor given by: & & & & x arrowld, "1_x"{above} arrowrd, "f" & x arrowr, "f" & y & mapsto & x & & y
Now let (i) $ K $ be any bicategory (i) $ F, G , colon, C rightarrow K $ be functors such that every map in $ C $ is sent to a map in $ K $ possessing a right adjoint and satisfying the Beck - Chevalley Condition for any commutative square in $ K $ , (i) $ alpha , colon, F rightarrow G $ be a natural transformation.
Then: linebreak The following holds: (i) $ etaC $ is universal among such functors $ F $ , i.e $ . F $ as above factors as $ F = hat{F} circ etaC $ for a functor $ hat{F} , colon, Span_2(C) rightarrow K $ which is unique up to isomorphism.
(i) There exists a unique lax natural transformation: $ hat{alpha} , colon, hat{F} rightarrow hat{G} $ such that $ hat{alpha} eta_C = alpha $ .
(i) Let $ x, y $ be objects in $ C $ and $ f: x rightarrow y $ be a morphism in $ C $ .
If $ (alphax, alphay) $ induce a pseudo - map of adjoints $ F(f) dashv (Ff)^ rightarrow G(f) dashv (Gf)^ $ , then $ hat{alpha} $ is a pseudonatural transformation Furthermore, if we denote $ Pbk $ as the 2 - category of categories with pullbacks, pullback - preserving functors, and equifibered natural transformations and $ BiCat $ as the tricategory of bicategories, $ Span( - ): Pbk rightarrow BiCat $ is well - defined as a functor.
This is due to Hermida 199(ix) {LimitsAndColimits} Since a category of spans/correspondences $ Corr(mathcal{C}) $ is evidently equivalent to its opposite category, it follows that to the extent that limits exists they are also colimits and vice versa.
If the underlying category $ mathcal{C} $ is an extensive category, then the coproduct/product in $ Corr(mathcal{C}) $ is given by the disjoint union in $ mathcal{C} $ .
(See also this MO discussion).
More generally, every van Kampen colimit in $ mathcal{C} $ is a (co)limit in $ Corr(mathcal{C}) $ &8212; and conversely, this property characterizes van Kampen colimits.
(Sobocinski - Heindel 11).
{RelationToRelations} Correspondences may be seen as generalizations of relations.
A relation is a correspondence which is ( - 1) - truncated as a morphism into the cartesian product.
See at relation and at Rel for more on this.
More generally symplectic dual pairs are correspondences between Poisson manifolds.
A category of correspondences is a refinement of a category Rel of relations.
See there for more.
The $ Span(C) $ construction was introduced by Jean B&233;nabou (as an example of a bicategory) in B&233;nabou cites an article by Yoneda (1954) for introducing the concept of span (in the category of categories).
An exposition discussing the role of spans in quantum theory: The relationship between spans and bimodules is briefly discussed in The relation to van Kampen colimits is discussed in The universal property of categories of spans is due to and further discussed in: The structure of a monoidal tricategory on spans in 2 - categories is discussed in Generally, an (∞, n) - category of spans is indicated in section (iii)2 of The permutations of a set $ X $ form a group, $ SX $ , under composition.
This is especially clear if one thinks of the permutation as a bijection on $ X $ , where the multiplication / composition is just composition of functions.
This group is called the symmetric group of $ X $ and often denoted $ SX $ , $ Sigma_X $ , $ Sym(X) $ or similar.
The subgroups of symmetric groups are the permutation groups.
When $ X $ is the finite set $ (n) = {1, dots, n } $ , then its symmetric group is a finite group of cardinality
$ n! $ = " $ n $ factorial", and one typically writes $ Sn $ or $ Sigman $ .
(We will make frequent use of the entry permutation for some key notation and concepts.)
In general, an element of $ S_n $ can be represented by a two row array $ sigma= left(array{1&2&ldots &n sigma(1)&sigma(2)&ldots&sigma(n)}right) $ .
It can also be given in cycle notation.
We repeat the example from the entry on permutations.
This is from $ S_6 $ : Let $ sigma $ be the permutation on $ (6) $ defined by $ sigma = (array{1 mapsto 1 & 2mapsto 4 & 3 mapsto 5 & 4 mapsto 6 & 5 mapsto 3 & 6 mapsto 2})= left(array{1&2&3&4&5&6 1&4&5&6&3&2}right) $ The domain of the permutation is partitioned into three $ langlesigmarangle $ - orbits $ (6) = {1 } cup {2, 4, 6 } cup {3, 5 } $ corresponding to the three cycles $ 1 underset{sigma}{to} 1 qquad 2 underset{sigma}{to} 4 underset{sigma}{to} 6 underset{sigma}{to} 2 qquad 3 underset{sigma}{to} 5 underset{sigma}{to} 3 $ We express this more compactly by writing $ sigma $ as the composition $ sigma = (1)(2, 4, 6)(3, 5) $ , or $ sigma = (2, 4, 6)(3, 5) $ leaving implicit the action of the identity (1).
We can also write $ sigma $ as a product of transpositions $ (2, 4)(2, 6)(3, 5) $ $ S_3 $ is the group of permutations of $ (3)={1, 2, 3 } $ .
One simple way to represent an element of $ S_3 $ is by listing the $ (3) $ on the top row of an array with a second row denoting the image of each element under the permutation.
For instance, the element $ sigma= (1mapsto 2, 2mapsto 1, 3mapsto 3) $ can be written more compactly as $ sigma= left(array{1&2&3 2&1&3}right) $ .
We can also use, even more compactly, 'cycle notation', as explained in more detail at permutation, in which successive images under the permutation, $ sigma $ , are listed until you get back to where you started.
Elements of (3), or more generally of (n), are usually not listed as cycles of length 1, exept that (1) may be used to indicate the identity element.
For the above permutation, this gives $ sigma = (1, 2) $ the transposition exchanging the elements 1 and 2 and leaving 3 'unmoved'.
Whilst the 3 - cycle, $ (1, 2, 3) $ , shifts every element to the right one position and then maps 3 to (i) The following shows the Cayley graph of the symmetric groups on 3 elements, $ Sym(3) $ , with edges corresponding to any transposition (not necessarily adjacent), hence whose graph distance is the Cayley distance: row sep= - 6pt, column sep=14pt 123 arrrrr, - arddddd, - arddrrr, - && && 132 arddddd, - {phantom{A} atop {phantom{A} atop {phantom{A} atop {phantom{A} atop {phantom{A} atop {phantom{A} atop {phantom{A}}}}}}}} &&& scalebox{.8}{ $ 321 $ } ardddr, - & scalebox{(i)2}{231} arddl, - aruuurrr, - , crossing over arurr, - {phantom{A} atop {phantom{A} atop {phantom{A} atop {phantom{A} atop {phantom{A} atop {phantom{A} atop {phantom{A}}}}}}}} 213 arrrrr, - &&&& 312 The symmetric group on 4 elements is isomorphic to the full tetrahedral group as well as to the orientation - preserving octahedral group.
As an element of the symmetric group $ S_X $ , every permutation $ sigma : X to X $ generates a cyclic subgroup $ langle sigma rangle $ , and hence inherits a group action on $ X $ .
The orbits of this action partition the set $ X $ into a disjoint union of cycles, called the cyclic decomposition of the permutation $ sigma $ .
For example, let $ sigma $ be the permutation on $ (6) $ defined by
$ sigma = (array{1 mapsto 1 & 2 mapsto 4 & 3 mapsto 5 & 4 mapsto 6 & 5 mapsto 3 & 6 mapsto 2}) $ The domain of the permutation is partitioned into three $ langlesigmarangle $ - orbits $ (6) = {1 } cup {2, 4, 6 } cup {3, 5 } $ corresponding to the three cycles $ 1 underset{sigma}{to} 1 qquad 2 underset{sigma}{to} 4 underset{sigma}{to} 6 underset{sigma}{to} 2 qquad 3 underset{sigma}{to} 5 underset{sigma}{to} 3 $ We can express this more compactly by writing $ sigma $ in "cycle notation", as the composition $ sigma = (1)(2, 4, 6)(3, 5) $ , or $ sigma = (2, 4, 6)(3, 5) $ leaving implicit the action of the identity (1).
Even in the simple example of $ S_3 $ one can see some patterns.
This gives a listing of the elements of $ S_3 $ as $ { 1, (12), (13), (23), (123), (132) } $ $ . langle a, b | a^3, b^2, (a b)^2 rangle $ . where $ a $ corresponds to the 3 - cycle, $ (123) $ , whilst $ b $ corresponds to any transposition.
It also has a presentation in which the generators correspond to the transpositions: $ langle sigma1, sigma2 | sigma1^2, sigma2^2, (sigma1sigma2)^3rangle $ It is easy to see that these relations imply that $ sigma1sigma2sigma1= sigma2sigma1sigma2 $ which relates this symmetric group to the braid group, Br 3, and to the trefoil group.
It is clear that there is an epimorphism $ S3to Br3 $ obtained by making the two braid generators become the transpositions.
{ConjugacyClasses} Let $ n in mathbb{N} $ and $ Sigma(n) $ the symmetric group on $ n $ elements.
Then the conjugacy classes of elements of $ Sigma(n) $ , hence of permutations of $ n $ elements, correspond to the cycle structures: two elements are conjugate to each other precisely if they have the same number $ cycles in mathbb{N} $ of distinct cycles of the same lengths $ (l1 geq l2 geq cdots geq l_{cycles}) $ , hence equivalently if they define the same underlying partition $ l1 + l2 + cdots + l_{ cycles} ;=; n $ of $ n $ .
(e.g. Sagan 01, p. 3 (18 of 254))
For the symmetric group on three elements there are three such classes: <div> <div style="float:left;width:30;margin:10"> <div style="padding - bottom:20px">(1 2 3) (1 3 2)</div> <div style="padding - bottom:20px">(1 2)(3) (1 3)(2) (1)(2 3)</div> <div>(1)(2)(3)</div> </div> <div style="float:left;width:20"> <div> <svg width="80" height="40" xmlns="http://www.w(iii)org/2000/svg" se:nonce="39384" xmlns:se="http://svg - edit.googlecode.com" xmlns:xlink="http://www.w(iii)org/1999/xlink">
<desc>Young diagram (3)</desc> <g> <title>Layer 1</title> <rect x="10" y="10" width="20" height="20" fill="ffdddd" stroke="000000" stroke - width="2" id="svg393841"/> <rect x="30" y="10" width="20" height="20" fill="ffdddd" stroke="000000" stroke - width="2" id="svg393842"/>
<rect x="50" y="10" width="20" height="20" fill="ffdddd" stroke="000000" stroke - width="2" id="svg393843"/> </g>
</svg>
</div> <div> <svg width="60" height="60" xmlns="http://www.w(iii)org/2000/svg" se:nonce="39384" xmlns:se="http://svg - edit.googlecode.com" xmlns:
xlink="http://www.w(iii)org/1999/xlink"> <desc>Young diagram (2, 1)</desc>
<g> <title>Layer 1</title> <rect x="10" y="10" width="20" height="20" fill="ffdddd" stroke="000000" stroke - width="2" id="svg393841"/> <rect x="30" y="10" width="20" height="20" fill="ffdddd" stroke="000000" stroke - width="2" id="svg393842"/>
<rect x="10" y="30" width="20" height="20" fill="ffdddd" stroke="000000" stroke - width="2" id="svg393843"/> </g>
</svg>
</div> <div> <svg width="40" height="90" xmlns="http://www.w(iii)org/2000/svg" se:nonce="39384" xmlns:se="http://svg - edit.googlecode.com" xmlns:xlink="http://www.w(iii)org/1999/xlink">
<desc>Young diagram (1, 1, 1)</desc>
<g> <title>Layer 1</title> <rect x="10" y="10" width="20" height="20" fill="ffdddd" stroke="000000" stroke - width="2" id="svg393841"/> <rect x="10" y="30" width="20" height="20" fill="ffdddd" stroke="000000" stroke - width="2" id="svg393842"/>
<rect x="10" y="50" width="20" height="20" fill="ffdddd" stroke="000000" stroke - width="2" id="svg393843"/> </g>
</svg>
</div>
</div>
<div style="float:left;width:20"> <img src="https://ncatlab.org/nlab/files/The3SheetedCoveringsOfTheCircle.png" width="100">
</div>
</div> <div style="width:200px;height:30px"></div> $ , $ $ , $ $ , $ $ , $ $ , $ $ , $ - - - See at representation theory of the symmetric group.
One may regard the symmetric group $ Sn $ as the general linear group in dimension $ n $ on the field with one element $ GL(n, mathbb{F}1) $ .
See there.
{ClassifyingSpaceAndThomSpace} The classifying space $ B Sigma(n) $ of the symmetric group on $ n $ elements may be presented by $ Emb({1, cdots, n } , mathbb{R}^infty)/Sigma(n) $ , the Fadell's configuration space on $ n $ unordered points in $ mathbb{R}^infty $ .
(e.g. Bödigheimer 87, Example 10) Write $ tau_n $ for the rank $ n $ vector bundle over this which exhibits the canonical action of $ Sigma(n) $ on $ mathbb{R}^n $ , by permutation of coordinates.
The Thom space $ B Sigma(n)^{taun} $ of this bundle appears as the cofficients of the spectral symmetric algebra of the "absolute spectral superpoint" $ Sym{mathbb{S}} Sigma mathbb{S} $ (see Rezk 10, slide 4).
See also (Hopkins - Mahowald - Sadofsky 94, around def.
(ii)8) {WhiteheadTowerAndSupersymmetry} The symmetric groups and alternating groups are the first stages in a restriction of the Whitehead tower of the orthogonal group to "finite discrete ∞ - groups" in the sense of homotopy type with finite homotopy groups.
The homotopy fibers of the stages of the "finite Whitehead tower" are the stable homotopy groups of spheres (Epa - Ganter 16).
(See also at super algebra - - Abstract idea and at Platonic 2 - group.) $ array{ && && vdots && && downarrow && && mathbf{B}Fivebrane(n) && downarrow && downarrow mathbf{B}^2 pi_3 mathbb{S} &stackrel{}{longrightarrow} & mathbf{B}mathcal{A}_n &hookrightarrow& mathbf{B} String(n) && downarrow && downarrow mathbf{B} pi2 mathbb{S} &longrightarrow & mathbf{B} tilde An &hookrightarrow& mathbf{B} Spin(n) && downarrow && downarrow pi1 mathbb{S} &longrightarrow& mathbf{B} An &hookrightarrow& mathbf{B} SO(n) && downarrow && downarrow && mathbf{B} S_n &hookrightarrow& mathbf{B} O(n) } $ Notice that the squares on the right are not homotopy pullback squares.
(The homotopy pullback of the string 2 - group along $ tilde A hookrightarrow Spin(n) $ is a $ mathbf{B}U(1) $ - extension of $ tilde A $ , but here we get the universal finite 2 - group extension, by $ mathbb{Z}/24 $ instead.
Recall that two sets $ A $ and $ B $ have the same cardinality if $ A $ is in bijection with $ B $ .
Given a natural number $ n:mathbb{N} $ , the symmetric group on the finite set with $ n $ elements $ Sigma(n) $ is in bijection with the finite set $ mathrm{Fin}(n!) $ elements, where $ n! $ is the factorial of $ n $ .
The symmetric group on the natural numbers $ mathrm{Sym}(mathbb{N}) $ is an uncountable set in bijection with the endofunction set $ mathbb{N}^mathbb{N} $ .
In the context of excluded middle, this is in bijection with $ mathcal{P}(mathbb{N}) $ , the power set of the natural numbers.
Assuming the axiom of choice, given an infinite set $ A $ , there is a bijection $ mathrm{Sym}(A) cong mathcal{P}(A) $ between the symmetric group of $ A $ and the power set of $ A $ .
Cayley distance kernel, Mallows kernel Textbook accounts:
Discussion of the classifying spaces of symmetric groups: See also For the operadic structure of permutations: For more on permutation patterns, see: That in the context of the axiom of choice, the symmetric group of an infinite set is in bijection (i.e. has the same cardinality) with the power set of that infinite set, see: A module over a ring whose underlying abelian group has trivial torsion subgroup is called torsion - free.
In classical mathematics, a torsion - free $ mathbb{Z} $ - module or torsion free abelian group $ M $ could be defined using a variant of the zero - divisor property characteristic of integral domains: for all $ r $ in $ mathbb{Z} $ and $ m $ in $ M $ , if $ r m = 0 $ , then $ r = 0 $ or $ m = 0 $ , or the contrapositive, if $ r neq 0 $ and $ m neq 0 $ , then $ r m neq 0 $ .
There is also an equivalent definition: a torsion - free $ mathbb{Z} $ - module $ M $ or torsion free abelian group is such that right multiplication by $ m $ is injective if $ m neq 0 $ and left multiplication by $ r $ is injective if $ r neq 0 $ , where "multiplication" refers to the $ mathbb{Z} $ - action.
In constructive mathematics, there are multiple inequivalent ways of defining a torsion - free $ mathbb{Z} $ - module.
One could define a torsion - free module as a module such that for all $ r $ in $ mathbb{Z} $ and $ m $ in $ M $ , if $ r m = 0 $ , then $ r = 0 $ and $ m = 0 $ .
The first definition is valid in all modules with decidable equality, and could be defined using coherent logic, but is not valid for $ mathbb{R} $ - modules.
If the module has a tight apartness relation, then one could define a torsion - free $ mathbb{Z} $ - module as a module such that for all $ r $ in $ mathbb{Z} $ and $ m $ in $ M $ , if $ r neq 0 $ and $ m 0 $ , then $ r m 0 $ .
This is valid in $ mathbb{R} $ , but is no longer capable of being defined in coherent logic.
Similarly, one could define a torsion - free $ mathbb{Z} $ - module $ M $ is such that right multiplication by $ m $ is injective if $ m 0 $ and left multiplication by $ r $ is injective if $ r neq 0 $ .
A torsion - free ring is a monoid object in torsion - free $ mathbb{Z} $ - modules.
In classical mathematics, given a commutative ring $ R $ , a torsion - free $ R $ - module is a module $ M $ such that for all $ r $ in $ Can(R) $ , where $ Can(R) $ is the multiplicative submonoid of cancellative elements in $ R $ and $ m $ in $ M $ , if $ r m = 0 $ , then $ r = 0 $ or $ m = 0 $ .
Equivalently, the contrapositive, if $ m neq 0 $ , then $ r m neq 0 $ .
Some authors require $ R $ to be an integral domain, where $ Can(R) $ is the monoid of nonzero elements in $ R $ .
In constructive mathematics, given a ring $ R $ , there are multiple inequivalent ways of defining a torsion - free $ R $ - module.
One could define a torsion - free module as a module such that for all $ r $ in $ Can(R) $ and $ m $ in $ M $ , if $ r m = 0 $ , then $ m = 0 $ .
The first definition is valid in all modules with decidable equality, and could be defined using coherent logic, but is not valid for $ mathbb{R} $ - modules.
If $ M $ has a tight apartness relations, then one could define a torsion - free module as a module such that for all $ r $ in $ Can(R) $ and $ m $ in $ M $ , if $ m 0 $ , then $ r m 0 $ .
This is valid in $ mathbb{R} $ - modules, but is no longer capable of being defined in coherent logic.
A torsion - free $ R $ - algebra is a monoid object in torsion - free $ R $ - modules.
Every divisible torsion - free $ mathbb{Z} $ - module is a rational vector space.
Every integral domain $ R $ is a torsion - free $ R $ - module.
See also + Wikipedia, Torsion - free module In topology, a (parametrised, oriented) path in a space $ X $ is a map (a morphism in an appropriate category of spaces, such as a continuous function between topological space) to $ X $ from the topological interval $ mathbb{I} = 0, 1 $ .
A path from $ a $ to $ b $ is a path $ f $ such that $ f(0) = a $ and $ f(1) = b $ .
An unparametrised path is an equivalence class of paths, such that $ f $ and $ g $ are equivalent if there is an increasing automorphism $ phi $ of $ mathbb{I} $ such that $ g = f circ phi $ .
An unoriented path is an equivalence class of paths such that $ f $ is equivalent to
$ (x mapsto f(1 - x)) $ .
If $ P $ is a path, then its reverse path^1, denoted $ overline{P} $ , is defined to be the composite $ P circ ( tmapsto 1 - t ) $ .
The operation $ Pmapstooverline{P} $ is called path reversal.
^1:
Cf. e.g. Introduction to Topology - - 2, or also Section (ii)1; beware that that reference, (0) like many others, uses the term "inverse path", even though the operation of concatenation of paths does not in and of itself yield a strict groupoid, in which $ overline{P} $ would be an inverse, and (1) that it uses $ a $ and $ b $ for the endpoints of the interval, not the endpoints of the paths in the space $ X $ , and (2) that it uses $ P^ - $ instead of $ overline{P} $ , which however is less suited for notational iterating (compare $ overline{overline{P}}=P $ with $ (P^ - )^ - =P $ ), and that (3) the 2008 edition has a typo: " $ w(1 - t) $ " in loc.
cit., when inverse path gets defined, should be $ u(1 - t) $ .
A Moore path is defined like a path, except for having another domain: replace $ 0, 1 $ with the interval $ 0, n $ for some natural number (or, more commonly, any non - negative real number) $ n $ .
All of these variations can be combined, of course.
(For unoriented paths, one usually says 'between $ a $ and $ b $ ' instead of 'from $ a $ to $ b $ '.
Also, a Moore path from $ a $ to $ b $ has $ f(n) = b $ instead of $ f(1) = b $ .
Finally, there is not much difference between unparametrised paths and unparametrised Moore paths, since we may interpret $ (t mapsto n t) $ as a reparametrisation $ phi $ .)
In graph theory, a path is a list of edges, each of which ends where the next begins.
Actually, this is a special case of the above, if we use Moore paths and interpret $ 0, n $ as the linear graph with $ n + 1 $ vertices and $ n $ edges; in this way, the other variations become meaningful.
(However, as the only directed graph automorphism of $ 0, n $ is the identity, parametrisation is trivial for directed graphs and equivalent to orientation for undirected graphs.
Note that a non - Moore path is simply an edge, one of the fundamental ingredients of a graph.)
Given a Moore path $ f $ from $ a $ to $ b $ and a Moore path $ g $ from $ b $ to $ c $ , the concatenation of $ f $ and $ g $ is a Moore path $ f ; g $ or $ g circ f $ from $ a $ to $ c $ .
If the domain of $ f $ is $ 0, m $ and the domain of $ g $ is $ 0, n $ , then the domain of $ f ; g $ is $ 0, m+n $ , and $ (f ; g)(x) coloneqq left { array { f(x) & quad x leq m g(x - m) & quad x geq m .} right $ .
In this way, we get a (strict) category whose objects are points in $ X $ and whose morphisms are Moore paths in $ X $ , with concatenation as composition.
This category is called the Moore path category.
Often we are more interested in a quotient category of the Moore path category.
If we use unparametrised paths (in which case we may use paths with domain $ mathbb{I} $ if we wish), then we get the unparametrised path category.
If $ X $ is a smooth space, then we may additionally identify paths related through a thin homotopy to get the path groupoid.
Finally, if $ X $ is a continuous space and we identify paths related through any (endpoint - preserving) homotopy, then we get the fundamental groupoid of $ X $ .
In graph theory, the Moore path category is known as the free category on the graph.
E.g. (...)
For a linear operator between Banach spaces, compactness is a natural strengthening of continuity (boundedness).
A linear operator is compact if it sends the bounded subsets to relatively compact subsets.
The quotient of the bounded operators by the compact operators is called the Calkin algebra.
Since every relatively compact subspace (in a Banach space, or indeed in any metric space) is bounded, every compact operator is bounded.
Instead of checking compactness on all bounded subsets it is sufficient to check it for a ball of one fixed radius: an operator is compact iff
it sends the ball of unit radius to a relatively compact set.
See also compact self - adjoint operator.
In the setup of Hilbert spaces, instead of a compact operator, one sometimes says a completely continuous operator.
However, in the full generality of Banach spaces, by a completely continuous operator one means slightly less: an operator that maps every weakly convergent sequence to a norm convergent sequence.
For Hilbert spaces and, more generally, for reflexive Banach spaces, the two notions are equivalent.
category: analysis A quaternion or Hamilton number is a kind of number similar to the complex numbers but with three instead of one square root of $ ( - 1) $ adjoined, satisfying certain relations.
The quaternions form the largest associative normed division algebra, usually denoted $ mathbb{H} $ after William Rowan Hamilton (since $ mathbb{Q} $ is taken for the rational numbers).
The structure of $ mathbb{H} $ as an $ mathbb{R} $ - algebra is given by a basis $ {1, i, j, k } $ of the underlying vector space of $ mathbb{H} $ , equipped with a multiplication table where $ 1 $ is the identity element and otherwise uniquely specified by the equations $ i^2 = j^2 = k^2 = i j k = - 1, $ and extended by $ mathbb{R} $ - linearity to all of $ mathbb{H} $ .
The norm on $ mathbb{H} $ is given by $ {|alpha|}^2 = alpha widebar{alpha} $ where given an $ mathbb{R} $ - linear combination $ alpha = a 1 + b i + c j + d k $ , we define the conjugate $ widebar{alpha} coloneqq a 1 - b i - c j - d k $ .
A simple calculation yields $ {|alpha|}^2 = a^2 + b^2 + c^2 + d^2 $ whence for $ alpha neq 0 $ , the multiplicative inverse is $ alpha^{ - 1} = frac1{{|alpha|}^2} widebar{alpha} $ .
In this way $ mathbb{H} $ is a normed division algebra.
We have canonical left and right module structures on $ mathbb{H}^n $ , but as $ mathbb{H} $ is not commutative, if we want to talk about tensor products of modules, we need to consider bimodules.
This also means that ordinary linear algebra as is used over a field is not quite the same when dealing with quaternions.
For instance, one needs to distinguish between left and right eigenvalues of matrices in $ M_n(mathbb{H}) $ (using the left and right module structures on $ mathbb{H}^n $ respectively), and only left eigenvalues relate to the spectrum of the associated linear operator.
Using the conjugation operation one can define an inner product $ langle q, prangle := overline{q} p $ on $ mathbb{H}^n $ so that the corresponding orthogonal group is the compact symplectic group.
The automorphism group of the quaternions, as a real algebra, is SO(3), acting canonically on their imaginary part (in generalization of how the product of complex numbers respects the complex conjugation action) See also at normed division algebra - - automorphism (e.g. Klimov - Zhuravlev, p. 85)
Review See also If $ G $ is a topological group, then the identity component is the connected component of the identity element $ e $ in $ G $ .
The identity component $ G_0 $ is a closed normal subgroup of $ G $ .
It is clearly closed (indeed, any connected component is closed).
If $ g, h in G0 $ , then $ g h $ is in the same connected component as $ g $ (since $ h $ is in the same connected component as $ e $ and left multiplication by $ g $ is a homeomorphism), which in turn is in the same connected component as $ e $ .
Using similar reasoning, if $ g $ is in the connected component as $ e $ , then $ e $ is in the same connected component as $ g^{ - 1} $ .
Hence $ G0 $ is a subgroup.
If $ phi $ is any automorphism of $ G $ , then $ phi(G0) = G0 $ .
(Indeed, $ phi(G0) $ is a connected set containing $ e $ and therefore $ phi(G0) subseteq G0 $ .
Replacing $ phi $ by its inverse $ phi^{ - 1} $ , we similarly have $ phi^{ - 1}(G0) subseteq G0 $ and therefore $ G0 subseteq phi(G0) $ .)
Applying this to inner automorphisms $ phi $ , we conclude that $ G0 $ is a normal subgroup of $ G $ .
The group $ G/G_0 $ , equipped with the quotient space topology, is a Hausdorff topological group.
Given the fact that $ p colon G to G/G0 $ is an open surjection, the product $ p times p colon G times G to G/G0 times G/G0 $ is also an open surjection and therefore a quotient map.
It follows easily from the universal property of quotient maps that the multiplication $ G times G to G $ therefore descends to a continuous multiplication $ G/G0 times G/G0 to G/G0 $ , so that $ G/G_0 $ is a topological group.
Because a topological group is a uniform space, the Hausdorff condition follows from a weaker separation axiom such as $ T1 $ (points are closed).
It suffices that the identity of $ G/G0 $ be closed.
Its complement $ C $ is the image under $ p $ of the complement of $ G_0 $ in $ G $ (just by examining coset decompositions), which is open.
Since $ p $ is an open map, it follows that $ C $ is open, so that $ {e } $ is closed, as desired.
The tensor product of linear representations.
Let $ G $ be a group and let $ rhoi ;colon; G times Vi longrightarrow V_i $ be two linear representations of $ G $ on vector spaces $ Vi $ , for $ i in {1, 2 } $ .
Then the tensor product of representations of these is the linear representation whose underlying vector space is the tensor product of vector spaces $ V1 otimesk V2 $ equipped with the $ G $ - action induced by the diagonal action $ G times V1 times V2 overset{Delta_G times id}{longrightarrow} G times G times V1 times V2 simeq G times V1 times G times V1 overset{rho1 times rho2}{longrightarrow} V1 times V2 , $ .
A double complex or bicomplex is a diagram of shape $ mathbb{Z}{leq} times mathbb{Z}{leq} $ (in some additive category): $ array{ && vdots && vdots & & downarrow^{mathrlap{partial^v}} && downarrow^{mathrlap{partial^v}} cdots &to & X{n, m} &stackrel{partial^h}{to}& X{n - 1, m} & to & cdots & & downarrow^{mathrlap{partial^v}} && downarrow^{mathrlap{partial^v}} cdots &to & X{n, m - 1} &stackrel{partial^h}{to}& X{n - 1, m - 1} & to & cdots & & downarrow^{mathrlap{partial^v}} && downarrow^{mathrlap{partial^v}} && vdots && vdots } $ such that each row and each column is a complex (the differentials square to 0: $ partial^v circ partial^v = 0 $ and $ partial^h circ partial^h = 0 $ ) and such that all the squares commute.
This means that a double complex is a complex in a category of complexes.
Accordingly, a double chain complex is a chain complex in a category of chain complexes $ . X_{bullet, bullet} = left cdots to X{n, bullet} stackrel{partial^h}{to} X{n - 1, bullet} to cdots right , $ .
In the presence of direct sums, there is a total complex $ (Tot X)bullet $ associated to a double complex, which in degree $ n $ is the direct sum of all terms of total degree_ $ n $ $ (Tot X)n coloneqq oplus{k+l = n} X_{k, l} $ .
Often it is such total complexes that are of interest.
The differential of the total complex is the sum of the horizontal and the vertical differential made anti - commutative by adjusting signs.
There is a second convention in which one often sees the double complex defined as above from a complex of complexes, but then with the differentials in every second row (or every second column) multiplied by $ ( - 1) $ .
This is just a different way of sign - bookkeeping, a detailed discussion of this is below.
Which convention to use is sometimes influenced by the context, the traditions of the sources in that application of double complexes, and largely a question of taste, that is which one the writer is used to.
Double chain complexes often arise from the application of bifunctors - - additive functors of two variables - - of additive categories $ C1, C2, C_3 $ $ F : C1 times C2 to C_3 $ to complexes in their two arguments.
Combining this with the formation of total complexes then yields bifunctors from categories of complexes to categories of complexes $ . tilde F : Ch(C1) times Ch(C2) to Ch(C_3) , $ .
The most important examples of this are induced by the hom - functor and the tensor product functor together with their derived functors, Ext and Tor.
Notice that under the Dold - Kan correspondence and with sufficient resolutions, such $ tilde F $ can be understood as the internal hom or tensor products, etc., between higher groupoids.
Although we suggest (and prefer) the 'complex of complexes' definition, as above, rather than the equivalent anticommutiing diagram one, we give both and will discuss how to go between them in some detail.
A double complex, $ X $ , is a commutative diagram in an additive category in which the objects are bi - indexed by the integers, $ { X_{p, q} mid p, qin mathbb{Z} } $ and with two classes of 'differentials' or 'boundary morphisms': and such that all squares commute (To state the obvious, this means $ dX^h dX^v - dX^v dX^h=0 $ , in contrast to the formula in the second version below.)
This gives a commutative diagram: $ array{ && vdots && vdots & & downarrow^{dX^v} && downarrow^{dX^v} cdots &to & X{n, m} &stackrel{dX^h}{to}& X_{n, m - 1} & to & cdots & & downarrow^{dX^v} && downarrow^{dX^v} cdots &to & X{n - 1, m} &stackrel{dX^h}{to}& X_{n - 1, m - 1} & to & cdots & & downarrow^{dX^v} && downarrow^{dX^v} && vdots && vdots } $ {AntiCommutingDifferentials} A double complex, $ X $ , is an anticommutative diagram in an additive category in which the objects are bi - indexed by the integers, $ { X_{p, q} mid p, qin mathbb{Z} } $ and with two classes of 'differentials' or 'boundary morphisms': and in addition $ bar{d}X^h dX^v + dX^v bar{d}X^h = 0 $ .
This gives an anticommutative diagram: $ array{ && vdots && vdots & & downarrow^{dX^v} && downarrow^{dX^v} cdots &to & X{n, m} &stackrel{bar{d}X^h}{to}& X_{n, m - 1} & to & cdots & & downarrow^{dX^v} & swArr{ - 1} & downarrow^{d_X^v} cdots &to & X{n - 1, m} &stackrel{bar{d}X^h}{to}& X_{n - 1, m - 1} & to & cdots & & downarrow^{dX^v} && downarrow^{dX^v} && vdots && vdots } $ {EquivalenceOfTheTwoDefinitions} Which definition is 'better'?
'Commuting squares', i.e., the first version, is convenient if you want to define a double complex as a chain complex in the category of chain complexes.
On the other hand, 'anticommuting squares' and version 2 is sometimes convenient for defining the total complex (for computing total homology).
Does it matter which you use?
The following says they are just two views of the same situation.
One makes a double complex $ X $ with commutative squares into a double complex with anticommutative squares by using the same vertical differential $ d^v $ but taking $ bar{d}^h : X{p, q} to X{p, q - 1} $ to be $ ( - 1)^p d^h $ .
The same trick can, of course, be used to make a double complex with anticommutative squares into a double complex with commutative squares.
The total complex of a double complex (under the convention that squares commute) is $ tot{oplus}^k = bigoplus{m+n=k} X_{n, m} $ $ d^k{totoplus}|{X{n, m}} = d^vX + ( - 1)^bullet dX^h $ Similarly, one can define the product total complex as $ tot{prod}^k = prod{m+n=k} X_{n, m} $ $ d^k{totprod}|{X{n, m}} = d^vX + ( - 1)^bullet dX^h $ Note that these two coincide when the set of non - zero objects $ X_{n, m} $ such that $ n + m = k $ is finite, for example, when $ X $ is a first quadrant double complex.
There is series of basic lemmas in homological algebra which determine the horizontal/vertical homology groups of a double complex in some row or column from exactness information in other columns.
The most fundamental of these is maybe the from which a series of others follow: The total complex of the double complex induced by a chain map is a model for the mapping cone of that map, see at _mapping cone - - via double complexes for more.
The fiber of a morphism or bundle $ f : E to B $ over a point of $ B $ is the collection of elements of $ E $ that are mapped by $ f $ to this point.
For $ f : A to B $ a morphism in a category and $ B $ equipped with the structure of a pointed object $ pt : to B $ , the fiber of $ f $ is the fiber product of $ f $ with $ pt $ , hence the pullback $ array{ A timesB &to& downarrow && downarrowpt A &stackrel{f}{to}& B } , $ .
Given a bundle $ p: E to B $ and a global element $ x: 1 to B $ , the fibre or fiber $ Ex $ of $ (E, p) $ over $ x $ is the pullback $ array { Ex & to & E downarrow & & downarrowp 1 & stackrel{x}to & B } $ if it exists.
In a fiber bundle, all fibres are isomorphic to some standard fibre $ F $ in a coherent way.
In an additive category fibers over the zero object are called kernels.
The fiber of a sheaf $ mathcal{E} $ of $ mathcal{O} $ - modules over a locally ringed space $ (X, mathcal{O}) $ at a point $ x in X $ is defined as the vector space $ mathcal{E}(x) coloneqq mathcal{E}x otimes{mathcal{O}x} k(x) $ over the residue field $ k(x) $ .
If $ mathcal{E} $ is quasicoherent, the associated vector bundle of the fiber is the pullback of the associated vector bundle of $ mathcal{E} $ : $ array { V(mathcal{E}(x)) = mathrm{Spec} mathrm{Sym} mathcal{E}(x) & to & underline{Spec}X mathrm{Sym} mathcal{E} = V(mathcal{E}) downarrow & & downarrow mathrm{Spec} k(x) & to & X } $ An element of a ring (or rig) or lattice (or proset) is called prime if the ideal that it generates is a prime ideal (thus a principal prime ideal).
Note that by this definition zero is a prime element of the rig of natural numbers, although it is not a prime number.
Prime numbers as such correspond more closely to maximal ideals or irreducible ideals than to prime ideals.
Classically (using excluded middle), a prime element of a frame corresponds precisely to a point of the corresponding locale.
For a constructive treatment, however, one must use the completely prime filters of the frame instead.
Georg Cantor used to define the continuum as a perfect space that is connected as well.
Hence, the property of 'being perfect', as the name indicates as well, can be viewed as forming part of the concept of a 'prototypical' topological space.
A topological space $ X $ is perfect if it has no isolated points, i.e., if every point $ x $ belongs to the topological closure of its complement $ X setminus {x } $ .
Sometimes one requires a perfect space to be inhabited (nonempty), although it is better to allow the empty space.
In a topological space $ X $ , a subset is said to be perfect if it is closed in $ X $ and perfect in its subspace topology.
In other words, a set $ A $ is perfect if and only if it equals its set $ A' $ of accumulation points.
Because of the closure requirement, being a perfect set/subset/subspace depends on the ambient space and is stronger than being a perfect space.
(But $ X $ is a perfect subset of itself iff $ X $ is a perfect space.)
In a topological space $ X $ , a subset $ A $ has the perfect - set property if it is either countable (possibly finite or even empty) or has an inhabited perfect subset.
Of course, any perfect set has the perfect - set property.
If for each set $ B $ , ( $ B $ has a point apart from each point in $ A $ if $ B $ is inhabited and $ B $ is perfect) and ( $ B $ is empty if $ B $ is contained in $ A $ and $ B $ is perfect) and ( $ B $ has an isolated point if $ B $ is contained in $ A $ and inhabited), then $ A $ is countable.
category: foundational axiom Given a matrix $ A = (a^ij){i, j = 1, ldots n} $ with entries in a commutative ring $ R $ , the principal minors are the minors of the upper left corner square matrices, i.e $ . det (a^ij){i, j = 1, ldots k} $ where $ k = 1, ldots, n $ (i.e there are $ n $ principal minors).
Sometimes it is convenient to consider the principal minors of the matrix in the oppositely ordered basis, i.e. the minors of the lower right corner $ det (a^ij){i, j = n - k+1, ldots n} $ Of course, as it is true for the expression minor in general, sometimes it denotes the determinant of the submatrix and for some authors it is the submatrix itself called that way.
The principal minors appear as the denominators in the Gauss decomposition of matrices, and consequently in the description of relations between matrix elements in a linear group $ GL(n) $ (or $ SL(n) $ ) and canonical coordinates on the big Bruhat cell on its flag variety.
Quasideterminant of a matrix $ |A|{ij} $ with entries in a noncommutative ring, generalizes (up to sign), from the commutative case, the ratio of $ ntimes n $ - determinant and the determinant of the $ (n - 1)times(n - 1) $ submatrix obtained by crossing out the $ i $ - th row and $ j $ - th column.
In particular the determinant of $ A $ in the commutative case can be obtained as a product of all its principal quasiminors, provided the latter are defined (quasideterminants are rational expressions not necesarilly always defined).
Principal quasiminors play role in the study of noncommutative flag varieties.
Similar role play quantum principal minors in the study of quantum flag variety, cf. sec, 14 in {Definition} The following is the classical discussion of universal covering spaces in point - set topology.
Let $ X $ be a topological space which is (i) path - connected, (i) locally path connected.
Then if $ Ei overset{pi}{to} X $ are two covering spaces over $ X $ , $ i in {1, 2 } $ , which are both path - connected and simply connected, then they are isomorphic as covering spaces.
Since both $ E1 $ and $ E2 $ are simply connected, the assumption of the lifting theorem for covering spaces is satisfied (this prop.).
This says that there are horizontal continuous function making the following diagrams commute: $ array{ E1 && overset{f}{longrightarrow} && E2 & {}{mathllap{p1}}searrow && swarrow{mathrlap{p2}} && X } phantom{AAAAAA} array{ E2 && overset{g}{longrightarrow} && E1 & {}{mathllap{p2}}searrow && swarrow{mathrlap{p1}} && X } $ $ array{ Ei && overset{id}{longrightarrow} && Ei & {}{mathllap{pi}}searrow && swarrow{mathrlap{pi}} && X } $ and that these are unique once we specify the image of a single point, which we may freely do (in the given fiber).
So if we pick any point $ x in X $ and $ hat x1 in E1 $ with $ p(hat x) = x $ and $ hat x2 in E2 $ with $ p(hat x2) = x $ and specify that $ f(hat x1) = hat x2 $ and $ g(hat x2) = hat x1 $ then uniqueness applied to the composites implies $ f circ g = id{E{2}} $ and $ g circ f = id{E1} $ .
Let $ X $ be a topological space which is (i) path - connected, (i) locally path connected.
Then a path - connected and simply connected covering space, is called the universal covering space of $ X $ .
This is well - defined, if it exists, up to isomorphism, by prop. .
Let $ X $ be a topological space which is well - connected in that it is Then a universal covering space of $ X $ (def. ) exists.
By this prop.
the covering space is connected and simply connected precisely if its monodromy representation is free and transitive.
By the fundamental theorem of covering spaces every permutation representation of the fundamental groupoid $ Pi1(X) $ arises as the monodromy of some covering space.
Hence it remains to see that a free and transitive representation of $ Pi1(X) $ exists.
Let $ x in X $ be any point, then $ Hom{Pi1(X)}(x, - ) $ is such a representation.
This is a functorial construction of a universal covering spaces $ Top*^{wc} longrightarrow Cov* $ where $ Top*^{wc} $ denotes the full subcategory of pointed topological spaces $ Top $ on the well - connected spaces and $ Cov $ is the subcategory of $ Top^2 $ of pointed maps of spaces with objects the covering space maps.
Specifically, if $ X $ is a space with basepoint $ x0 $ , we define $ X^{(1)} $ to be the space whose points are homotopy classes of paths in $ X $ starting at $ x0 $ , with the projection $ X^{(1)}to X $ projecting to the endpoint of a path.
We can equip this set $ X^{(1)}to X $ with a topology coming from $ X $ so that it becomes a universal covering space as above.
As described at covering space, under the correspondence between covering spaces and $ Pi1(X) $ - actions, the space $ X^{(1)} $ corresponds to the "regular representation" of $ Pi1(X) $ .
This regular representation can be seen to arise by taking a category of elements in the same way that the regular representation of a group is gotten by taking its action on itself: we can see that the universal covering groupoid $ Pi(X)^{(1)} $ in the slice category $ mathbf{Grpd}/Pi(X) $ (see the universal covering $ infty $ - groupoid below) is just the category of elements of the action of $ Pi(X) $ on itself, and can be topologized in a natural way by lifting the topology on $ X $ along the canonical projection $ Pi(X)^{(1)} to Pi(X) $ ; decategorifying this yields $ X^{(1)} $ .
{InCohesiveHomotopyTheory} We describe now how the universal cover construction may be understood from the nPOV, using a fragment of cohesive homotopy theory.
The basic idea is that the universal cover of a space $ X $ is the homotopy fiber of the canonical morphism $ X longrightarrow Pi1(X) $ from $ X $ to its fundamental groupoid, which exists if both objects are regarded as "topological ∞ - groupoids".
We may think of this as a precise way of the intuitive idea of "forcing $ Pi1(X) $ to become trivial in a universal way".
Let $ mathcal{S} $ be some ∞ - cohesive site of spaces and consider $ mathbf{H} coloneqq Shinfty(mathcal{S}) $ the corresponding cohesive (∞, 1) - topos over this site.
This is the (∞, 1) - category of "topological ∞ - groupoids" modeled on $ mathcal{S} $ .
A canonical choice relating to the traditional discussion would be $ mathcal{S} = Top^kappa{lcont} $ a small full subcategory of Top on locally contractible topological spaces, in which case the objects of $ mathbf{H} $ might be called "locally contractible topological ∞ - groupoids".
A more restrictive choice would be $ mathcal{S} = $ CartSp, in which case the objects of $ mathbf{H} $ might be called Euclidean - topological ∞ - groupoids.
In fact for the discussion of just universal covering spaces as opposed to the higher stages in the Whitehead tower it would be sufficient and more natural to take $ mathcal{S} $ the full subcategory of locally simply connected topological spaces and consider just the (2, 1) - category $ mathbf{H} $ of stacks over this site.
But the following discussion is completely formal and applies globally to all such realizations.
Namely all we need is that Assume that (i) $ mathbf{H} $ is a cohesive (n, 1) - topos $ mathbf{H} array{ overset{Pi}{longrightarrow} overset{Delta}{longleftarrow} overset{Gamma}{longrightarrow} overset{nabla}{longleftarrow} } mathbf{B} $ over the given base (n, 1) - topos of n - groupoids.
(i) such that its shape modality preserves homotopy fiber products over discrete objects (objects in the essential image of $ Delta $ ).
We write $ &643; coloneqq Delta Pi $ for the induced shape modality and $ X overset{etaX}{longrightarrow} &643; X $ for its unit morphism ona given object $ X $ .
Assumption is satisfied for the case of $ (infty, 1) $ - toposes over an ∞ - cohesive site and for $ (n, 1) $ - toposes by an $ n $ - cohesive site as in example : by this prop.. Now consider $ X in mathbf{H} $ any object, for instance a topological space regarded as a 0 - truncated topological infinity - groupoid.
Assume, just for ease of discussion, that $ X $ is geometrically connected in that the 0 - truncation of its shape is contractible: $ tau0(&643; X) simeq ast , $ .
Using the axiom of choice in the base topos $ mathbf{H} $ we choose a point $ ast to tau1(&643; X) , $ .
The universal cover of $ X $ is the homotopy pullback in $ array{ hat X &longrightarrow& ast downarrow &(pb)& downarrow X &underset{L{tau1} circ etaX}{longrightarrow}& tau1(&643; X) } , $ .
The universal property of $ hat X $ is immediate from the abstract setup: (i) $ hat X $ is simply connected, in that $ tau1 &643; hat X simeq ast $ This is because $ &643; X $ is discrete by construction, and hence so is $ tau1(&643; X) $ .
So by assumption applying $ &643; $ to the above square yields another homotopy pullback of the form $ array{ &643; hat X &longrightarrow& ast downarrow &(pb)& downarrow &643; X &underset{&643; etaX}{longrightarrow}& tau1(&643; X) } , $ .
Now the long exact sequence of homotopy groups (in $ mathbf{B} $ ) applied to this homotopy fiber sequence is of the form $ 0 to pi1(&643; hat X) longrightarrow pi1(&643; X) overset{=}{longrightarrow} pi1(tau1 &643; X) to cdots $ which implies that $ pi1( &643; hat X ) $ and hence $ tau1 &643; hat X $ is indeed trivial.
(i) Let $ E longrightarrow X $ be any other object of $ mathbf{H}{/X} $ such that $ tau1(&643; E) simeq ast $ , then there is a morphism $ array{ E && longrightarrow && hat X & searrow && swarrow && X } $ This is because the naturality of the shape unit and of the truncation unit gives a homotopy commuting square of the form $ array{ E &overset{etaE}{longrightarrow}& &643; E &overset{}{longrightarrow}& tau1(&643; E ) simeq ast downarrow && && downarrow X &underset{etaX}{longrightarrow}& &643; X &longrightarrow& tau1 &643; X } $ and thus a cone over the diagram which defines $ hat X $ via its universal property.
This shows that $ hat X $ is the universal cover on abstract grounds.
We may also check explicitly that $ hat X $ is given as the space of homotopy classes of paths in $ X $ from the given basepoint.
To that end we use that, at least over the site CartSp, the shape of $ X $ is represented by the topological path ∞ - groupoid.
See at shape via cohesive path ∞ - groupoid.
>
The following is old material that deserves to be harmonized a bit more with the above stuff.
Let $ X $ be a suitably well behaved pointed space.
The universal cover $ X^{(1)} $ of $ X $ is (equivalent to) the homotopy fiber of $ X to Pi(X) $ in the (∞, 1) - category $ mathbf{H} = Sh{(infty, 1)}(Top{cg}) $ of topological ∞ - groupoids.
In other words, the principal ∞ - bundle classified by the cocycle $ X to Pi1(X) $ is the universal cover $ X^{(1)} $ : we have a homotopy pullback square $ array{ X^{(1)} &to& {} downarrow && downarrow X &to& Pi(X) } , $ .
Urs Schreiber: may need polishing.
We place ourselves in the context of topological ∞ - groupoids and regard both the space $ X $ as well as its fundamental ∞ - groupoid $ Pi(X) $ and its truncation to the fundamental groupoid $ Pi_1(X) $ as objects in there.
The canonical morphism $ X to Pi(X) $ hence $ X to Pi1(X) $ given by the inclusion of constant paths may be regarded as a cocycle for a $ Pi(X) $ - principal ∞ - bundle, respectively for a $ Pi1(X) $ - principal bundle.
Let $ pi0(X) $ be the set of connected components of $ X $ , regarded as a topological $ infty $ - groupoid, and choose any section $ pi0(X) to Pi(X) $ of the projection $ Pi(X) to pi_0(X) $ .
Then the $ Pi(X) $ - principal $ infty $ - bundle classified by the cocycle $ X to Pi(X) $ is its homotopy fiber, i.e. the homotopy pullback $ array{ UCov(X) &to& pi_0(X) downarrow && downarrow X &to& Pi(X) } , $ .
We think of this topological $ infty $ - groupoid $ UCov(X) $ as the universal covering $ infty $ - groupoid of $ X $ .
To break this down, we check that its decategorification gives the ordinary universal covering space: for this we compute the homotopy pullback $ array{ UCov_1(X) &to& {} downarrow && downarrow^{mathrlap{x}} X &to& Pi1(X) } , , $ where we assume $ X $ to be connected with chosen baspoint $ x $ just to shorten the exposition a little.
By the laws of homotopy pullbacks in general and homotopy fibers in particular, we may compute this as the ordinary pullback of a weakly equivalent diagram, where the point $ * $ is resolved to the universal $ Pi1(X) $ - principal bundle $ mathbf{E}x Pi1(X) = Tx Pi1(X) , $ . >
(More in detail, what we do behind the scenes is this: we regard the diagram as a diagram in the global model structure on simplicial presheaves on Top.
In there all our topological groupoids are fibrant, hence all we have to ensure is that one of the morphisms of the diagram becomes a fibration, which is what the passage to $ mathbf{E}x Pi1(X) $ achieves.
Then the ordinary pullback in the category of simplicial presheaves is the homotopy pullback in $ infty $ - prestacks.
Then by left exactness of $ infty $ - stackification, the image of that in $ infty $ - stacks is still a homotopy pullback. )
The topological groupoid $ mathbf{E}x Pi1(X) $ has as objects homotopy classes rel endpoints of paths in $ X $ starting at $ x $ and as morphisms $ kappa : gamma to gamma' $ it has commuting triangles $ array{ && x &{}^{mathllap{gamma}}swarrow && searrow^{mathrlap{gamma'}} y &&stackrel{kappa}{to}&& y' } $ in $ Pi1(X) $ .
The topology on this can be deduced from thinking of this as the pullback $ array{ mathbf{E}x Pi1(X) &to& {*} downarrow && downarrow^{mathrlap{x}} Pi1(X)^I &stackrel{d0}{to}& Pi1(X) } $ in simplicial presheaves on Top.
Unwinding what this means we find that the open sets in $ Mor(mathbf{E}x Pi1(X)) $ are those where the endpoint evaluation produces an open set in $ X $ .
Now it is immediate to read off the homotopy pullback as the ordinary pullback
$ array{ UCov1(X) &to& mathbf{E}x Pi1(X) downarrow && downarrow X &to& Pi1(X) , . } $ Since $ X $ is categorically discrete, this simply produces the space of objects of $ mathbf{E}x Pi1(X) $ over the points of $ X $ , which is just the space of all paths in $ X $ starting at $ x $ with the projection $ UCov1(X) to X $ being endpoint evaluation.
This indeed is then the usual construction of the universal covering space in terms of paths, as described for instance in On the other hand, we can view a space $ X $ as the little $ (infty, 1) $ - topos $ Sh{(infty, 1)}(X) $ of $ (infty, 1) $ - sheaves on $ X $ .
If $ X $ is locally connected and locally simply connected in the "coverings" sense, then $ Sh(X) $ is locally 1 - connected.
In fact, for the construction of the universal cover we require only the (2, 1) - topos $ Sh{(2, 1)}(X) $ of sheaves (stacks) of groupoids on $ X $ , so we will work in that context because it is simpler.
The construction can be adapted, however, to produce a "universal cover" of any locally 1 - connected $ (infty, 1) $ - topos.
Let $ E $ be any (2, 1) - topos which is locally 1 - connected.
This means that in the unique global sections geometric morphism $ (E^, E)colon Eto Gpd $ , the functor $ E^ $ has a left adjoint $ E!colon E to Gpd $ , which is automatically $ Gpd $ - indexed.
The fundamental groupoid of $ E $ is defined to be $ Pi1(E)coloneqq E!() $ , where $ * $ is the terminal object of $ E $ .
As discussed here in the $ (infty, 1) $ - case, the construction of $ Pi1(E) $ is a left adjoint to the inclusion of groupoids into locally 1 - connected (2, 1) - toposes (which sends $ Gmapsto Gpd/G simeq Gpd^G $ ).
Thus we have a geometric morphism $ Eto Pi1(E) $ (where we regard $ Pi1(E) $ as the (2, 1) - topos $ Gpd^{Pi1(E)} $ ).
Suppose, for simplicity, that $ E $ is connected.
Then $ Pi1(E) $ is also connected, and so we have an essentially unique functor $ *to Pi1(E) $ .
We define the universal cover of $ E $ to be the pullback (2, 1) - topos: $ array{ E^{(1)} & to & E downarrow & & downarrow * & to & Pi1(E)} $ (where of course $ $ denotes the terminal (2, 1) - topos $ Gpd $ ).
Now observe that $ to Pi_1(E) $ is a local homeomorphism of toposes, since we have
$ Gpd simeq Gpd/Pi_1(E)/(to Pi_1(E)) $ .
Since local homeomorphisms of toposes are stable under pullback, $ E^{(1)}to E $ is also a local homeomorphism, i.e. there exists an object $ widetilde{E}in E $ and an equivalence $ E^{(1)} simeq E/widetilde{E} $ over $ E $ .
Moreover, it is not hard to see that $ widetilde{E} $ can be identified with the pullback $ array{ widetilde{E} & to & downarrow & & downarrow mathrlap{eta} & to & E^(Pi_1(E)) mathrlap{= E^(E_!())}} $ in $ E $ .
Note that the bottom map $ to E^(E!()) $ is $ E^ $ applied to the unique map $ to E!() $ , while the right - hand map is the unit of the adjunction $ E_!dashv E^ $ .
In order to see that this is a sensible definition, we first observe that $ E^{(1)} $ is itself locally 1 - connected (since it is etale over $ E $ ).
Moreover, it is actually 1 - connected, which is equivalent to saying that $ E!(widetilde{E}) = $ .
This is because the "Frobenius reciprocity" condition for the adjunction $ E!dashv E^ $ (which is equivalent to saying that
$ E_! $ is $ Gpd $ - indexed) applied to the defining pullback of $ widetilde{E} $ implies that we also have a pullback $ array{ E!(widetilde{E}) & to & E!() downarrow & & downarrow mathrlap{id} & to & E_!()} $ which clearly implies that $ E!(widetilde{E}) = * $ .
Thus, $ E^{(1)} $ is a connected and simply connected space with a local homeomorphism to $ E $ , but is it a covering space?
In other words, is it locally trivial?
Since we have supposed that $ E $ is locally 1 - connected, as a (2, 1) - category it can be generated by 1 - connected objects, i.e. objects $ U $ such that $ E!(U)simeq $ .
In particular, we have a 1 - connected object $ U $ and a regular 1 - epic $ Uto $ .
We claim that if $ U $ is any 1 - connected object of $ E $ , then $ widetilde{E} $ is trivialized (or split) over $ U $ , in that $ Utimes widetilde{E} $ is equivalent, over $ U $ , to $ Utimes E^S $ for some $ Sin Gpd $ .
For pulling back the defining pullback to $ U $ , we obtain
$ array{ Utimes widetilde{E} & to & U downarrow & & downarrow mathrlap{Utimes eta} U & to & Utimes E^(Pi1(E)).} $ But $ Utimes E^(Pi1(E)) cong (E/U)^ (Pi1(E)) $ , so to give a map $ U to (E/U)^ (Pi1(E)) $ over $ U $ is the same as to give a map $ (E/U)!() to Pi1(E) $ in $ Gpd $ .
But $ (E/U)!()simeq $ , since $ U $ is 1 - connected, and $ Pi1(E) $ is connected, so there is only one such morphism.
Therefore, the two maps $ Uto Utimes E^(Pi1(E)) $ in the pullback above are in fact the same, and in particular both are the pullback to $ E/U $ of the map $ to Pi1(E) $ .
Thus, $ Utimes widetilde{E} $ is equivalent to $ (E/U)^*(S) cong Utimes E^*(S) $ , where $ S= Omega(Pi1(E)) $ is the loop object of $ Pi1(E) $ , i.e. what we might call the fundamental group of the connected (2, 1) - topos $ E $ .
Therefore, since $ widetilde{E} $ is trivialized over any 1 - connected object, and $ E $ is generated by 1 - connected objects, $ widetilde{E} $ is locally trivial.
Moreover, since $ * $ is a discrete object of $ E $ , so is $ widetilde{E} $ .
Thus, if we specialize all this to the case $ E=Sh{(2, 1)}(X) $ of (2, 1) - sheaves on a topological space, then we conclude that $ widetilde{E} $ is an honest 1 - sheaf on $ X $ which, when regarded as a local homeomorphism over $ X $ , is locally trivial (hence a covering space), connected, and 1 - connected - - - i.e. a universal cover of $ X $ .
{Example} Let (i) $ mathbb{R}^1 $ be the real line with its Euclidean metric topology; (i) $ S^1 coloneqq left{ xin mathbb{R}^2 ;vert; {Vert xVert} = 1 right } subset mathbb{R}^2 $ be the circle with its subspace topology induced from the Euclidean plane.
Consider the continuous function $ array{ mathbb{R}^1 &overset{p}{longrightarrow}& S^1 subset mathbb{R}^2 t &mapsto& (cos(2pi t), sin(2pi t)) } , $ .
This exhibits the universal covering space (def. ) of the circle.
Let $ p in S^1 $ be any point.
It is clear that we have a homeomorphism of the form $ array{ S^1 setminus p &overset{simeq}{longrightarrow}& (0, 1) } , $ .
and hence a homeomorphism of the form $ array{ S^1 times Disc(mathbb{Z}) &simeq& (0, 1) times Disc(mathbb{Z}) &overset{simeq}{longrightarrow}& p^{ - 1}(S^1 setminus {p } ) && (t, n) &mapsto& (cos(2pi n t), sin(2pi n t)) } , $ .
Now for $ p1 neq p2 $ two distinct point in $ S^1 $ , their complements constitute an open cover $ left{ S^1 setminus pi subset S^1 right } {i in {1, 2 } } $ and so this exhibits $ p colon mathbb{R}^1 to S^1 $ as being covering spaces.
Now (i) $ S^1 $ is path - connected and locally path connected (this example); (i) $ mathbb{R}^1 $ is simply connected (this example).
Therefore $ p $ exhibits $ mathbb{R}^1 $ as a universal covering space of $ S^1 $ , by def. .
See also the references at covering space.
Original discussion of universal covering spaces in terms of equivalence classes of based paths: Formulation in cohesive homotopy theory and explicitly so in cohesive homotopy type theory: Discussion of equivariant universal covers in the generality of equivariant homotopy theory: in algebraic topology a representative for a class in a homology theory e.g. category: disambiguation A measure $ mu $ is absolutely continuous with respect to $ nu $ if we can think of $ mu $ as a weighted variation on $ nu $ .
Fix a measurable space $ X $ and let $ mu $ and $ nu $ be two measures on $ X $ .
The measure $ mu $ is absolutely continuous with respect to $ nu $ if every $ nu $ - full set is also $ mu $ - full.
Because null sets are more familiar than full sets, we may equivalently express things as follows (but this is not correct in constructive mathematics):
The measure $ mu $ is absolutely continuous with respect to $ nu $ if every $ nu $ - null set is also $ mu $ - null.
If $ mu $ and $ nu $ are positive measures, then we may also express this as follows: The positive measure $ mu $ is absolutely continuous with respect to $ nu $ if, for every measurable set $ A $ ,
$ mu(A) = 0 $ if $ nu(A) = 0 $ .
Since the absolute value of a measure is a positive measure, we can also express the general definition as follows: The measure $ mu $ is absolutely continuous with respect to $ nu $ if, for every measurable set $ A $ , $ {|mu|}(A) = 0 $ if $ {|nu|}(A) = 0 $ .
Since only the full sets (or, classically, the null sets) matter, we do not need to have the full structure of a measure.
Sometimes we equip a measurable space with a $ delta $ - filter $ mathcal{F} $ of full sets (or a $ sigma $ - ideal $ mathcal{N} $ of null sets) without specifying a measure that produces these.
(For example, a smooth manifold is so equipped, effectively the full/null sets under Lebesgue measure, even though there is no canonical such measure, since these sets are the same regardless of coordinate chart.)
Then we say: The measure $ mu $ is absolutely continuous with respect to $ mathcal{F} $ (or $ mathcal{N} $ ) if every element of $ mathcal{F} $ is $ mu $ - full (or every element of $ mathcal{N} $ is $ mu $ - null).
In fact, only the full/null sets of $ mu $ matter either, but until somebody has use for the notion of one $ delta $ - filter (or $ sigma $ - ideal) being absolutely continuous with respect to another, I will refrain from writing it down.
(See centipede mathematics.)
If one calls a measure on the real line 'absolutely continuous', this means with respect to Lebesgue measure.
This generalises to any cartesian space (with Lebesgue measure) or indeed to any smooth manifold of finite dimension (where there is no canonical Lebesgue measure but a family of local ones and so still a notion of Lebesgue - full and Lebesgue - null sets).
Or, this generalises to any compact group (with Haar measure) or indeed to any locally compact group (where there is no canonical Haar measure but a proportional family of them and so still a canonical notion of Haar - full and Haar - null sets).
Let $ nu $ be a measure, and let $ f in L^1(nu) $ be an absolutely integrable function with respect to $ nu $ ; then integration defines a measure $ f nu $ : $ (f nu)(E) = intE f nu = intE f(x) nu(mathrm{d}x) $ .
This measure $ f nu $ is absolutely continuous with respect to $ nu $ .
Conversely, given any absolutely continuous measure $ mu $ , there is (at most) a unique (up to almost equality) absolutely integrable function $ f $ such that $ mu = f nu $ ; and this function must exist if $ mu $ and $ nu $ are localizable.
This converse is the subject of the Radon–Nikodym theorem.
A function $ fcolon mathbb{R} to mathbb{R} $ is absolutely continuous iff the Lebesgue–Stieltjes measure $ mathrm{d}f $ is absolutely continuous with respect to Lebesgue measure.
(All such functions are continuous, and this example is actually the origin of the term.)
In general, the center (or centre) of an algebraic object $ A $ is the collection of elements of $ A $ which "commute with all elements of $ A $ ."
This has a number of specific incarnations.
The original example is the center $ Z(G) $ of a group $ G $ , which is defined to be the subgroup consisting of all elements $ gin G $ such that for all elements $ hin G $ the equality $ g h=h g $ holds.
The center is an abelian subgroup, but not every abelian subgroup is in the center.
See also centralizer.
This notion of center of a group can be generalized to the center of a monoid in an obvious way.
Let $ C $ be an object in a 2 - category.
The center of $ C $ , $ Z(C) $ is the monoid of endomorphisms of the identity morphism, $ idC : C rightarrow C $ .
One can invoke the Eckmann - Hilton argument to prove that vertical and horizontal composition agree on $ Z(C) $ and are commutative.
The center $ Z(R) $ of a ring $ R $ is defined to be the multiplicative subset consisting of all elements $ r in R $ such that for all elements $ s in R $ , $ r cdot s = s cdot r $ is true $ . R $ is a commutative ring if $ R $ is isomorphic to $ Z(R) $ .
The center of a Lie algebra $ L $ is an abelian Lie subalgebra $ Z(L) $ , consisting of all elements $ zin L $ such that $ l, z=0 $ for all $ lin L $ .
There are generalizations for some other kinds of algebras.
The center of a monoid can be horizontally categorified to the center of a category.
Specifically, the center of a category $ C $ is defined to be the commutative monoid $ C, C $ of endo - natural - transformations of the identity functor of $ C $ .
It is straightforward to check that this reduces to the usual definition if $ C = mathbf{B}(A, times) $ is the delooping of a monoid.
The notion of center can also be vertically categorified.
It is easy to categorify the notion of center of a category as defined above: if $ C $ is an n - category, then its center is the monoidal $ (n - 1) $ - category $ C, C $ of endo - transformations of its identity functor.
One expects that in general, this center will actually admit a natural structure of braided monoidal $ (n - 1) $ - category, just as the center of a category is actually a commutative monoid, not merely a monoid.
For instance if $ C = mathbf{B}otimes mathcal{C} $ is the delooping of a monoidal category, then this center is called the Drinfeld center_ of $ (C, otimes) $ .
Generally, we can now obtain a notion of the center of a monoidal $ n $ - category by regarding it as a one - object $ (n+1) $ - category, according to the delooping hypothesis.
It follows that the center of a monoidal $ n $ - category should naturally be a braided monoidal $ n $ - category.
This is known to be true when $ n=0 $ (the center of a monoid is a commutative monoid) and also for $ n=1 $ and $ n=2 $ .
Note that a monoidal $ n $ - category has two different centers: if we regard it as a one - object $ (n+1) $ - category, then its center is a braided monoidal $ n $ - category, but if we regard it merely as an $ n $ - category, then its center is a braided monoidal $ (n - 1) $ - category.
The latter construction makes no reference to the monoidal structure.
Likewise, a braided monoidal $ n $ - category has three different centers, depending on whether we regard it as an $ n $ - category, a connected $ (n+1) $ - category, or a 2 - connected $ (n+2) $ - category, and so on (a $ k $ - tuply monoidal $ n $ - category has $ k+1 $ different centers).
It seems that in applications, however, one is usually most interested in the sort of center of a monoidal $ n $ - category $ C $ obtained by regarding it as a one - object $ (n+1) $ - category, thereby obtaining a braided monoidal $ n $ - category.
It is in this case, and seemingly this case only, that the center comes with a natural forgetful functor to $ C $ , corresponding to the classical inclusion of the center of a monoid.
(For $ ngt 0 $ , however, this functor will not be an inclusion; the objects of the center of $ C $ are objects of $ C $ equipped with additional structure.)
Moreover, one expects that if we perform this "canonical" operation on a k - tuply monoidal n - category (for $ kge 1 $ ), the resulting braided monoidal $ n $ - category will actually be $ (k+1) $ - tuply monoidal.
This is known to be true in the cases $ nle 4 $ : the center of a braided monoidal category is symmetric monoidal, the center of a braided monoidal 2 - category is sylleptic, and the center of a sylleptic monoidal 2 - category is symmetric.
Finally, if we decategorify further, we find that the center of a set (i.e. a 0 - category) is a monoidal ( - 1) - category, i.e. the truth value "true."
This is what we ought to expect, since when $ C $ is a set, there is precisely one endo - transformation of its identity endofunction (namely, the identity).
An old query about the categorical notion of center is archived at $ n $ Forum here.
A special case is the center of an abelian category which has a special entry because of a number of special applications and properties.
See center of an ∞ - group.
See also A category is small if it has a small set of objects and a small set of morphisms.
In other words, a small category is an internal category in the category Set.
A category which is not small may be called large, especially when it is not essentially small (see below).
Small categories are free of some of the subtleties that apply to large categories.
A category is said to be essentially small if it is equivalent to a small category.
Assuming the axiom of choice, this is the same as saying that it has a small skeleton, or equivalently that it is locally small and has a small number of isomorphism classes of objects.
A small category structure on a locally small category $ C $ is an essentially surjective functor from a set (as a discrete category) to $ C $ .
A category is essentially small iff
it is locally small and has a small category structure; unlike the previous paragraph, this result does not require the axiom of choice.
{SmallnessInTheContextOfUniverses} If Grothendieck universes are being used, then for $ U $ a fixed Grothendieck universe, a category $ C $ is $ U $ - small if its collection of objects and collection of morphisms are both elements of $ U $ .
Thus, This of course is a material formulation.
We may call $ C $ structurally $ U $ - small if there is a bijection from its set of morphisms to an element of $ U $ (the same for the set of objects follows).
This gives an up - to - isomorphism version of $ U $ - smallness (see universe in a topos for an alternative structural formulation).
Such structural $ U $ - smallness may be substituted in the discussion below.
Let $ USet $ be the category of $ U $ - small sets.
Similar considerations lead us to say and that a category $ C $ essentially $ U $ - small if it is locally $ U $ - small and admits an essentially surjective functor from a discrete $ U $ - small category.
A category is $ U $ - moderate if its set of objects and set of morphisms are both subsets of $ U $ .
However, some categories (such as the category of $ U $ - moderate categories!) are larger yet.
Given an operation (function) $ colon X times Y to Y $ , an element $ e $ of $ X $ is called a left identity for $ $ if $ e a = a $ for every element $ a $ of $ Y $ .
That is, the map $ Y to Y $ given by $ e - $ is the identity function on $ Y $ .
If $ colon Y times X to Y $ , then there is a similar concept of right identity.
If $ colon X times X to X $ , then $ e $ is a two - sided identity, or simply identity, if it is both a left and right identity.
Identity elements are sometimes also called neutral elements.
Historically, identity elements (as above) came first, then identity functions, and then identity morphisms.
These are all the same basic idea, however: an identity morphism is an identity element for the operation of composition.
An identity is also called a neutral element or sometimes a unit (although that term also has a broader meaning, and an operation that has an identity element is called unital or unitary).
In particular, a magma whose underlying operation $ colon X times X to X $ has an identity is called a unital magma or a unitary magma.
Similarly, a unit law is the statement that a given operation has an identity element.
In higher category theory, we generalise from the property of uniticity/unitality to the structure of a unitor.
A submonoid of a monoid $ M $ with unit $ 1 $ is a subset $ N $ of $ M $ containing $ 1 $ which is also a monoid with respect to the inherited multiplication.
>
For other kinds of units see also unit of an adjunction and unit of a monad.
Different (but related) is physical unit.
Considering a ring $ R $ , then by the unit element or the multiplicative unit one usually means the neutral element $ 1 in R $ with respect to multiplication.
This is the sense of "unit" in terms such as nonunital ring.
But more generally a unit element in a unital (!)
ring is any element that has an inverse element under multiplication.
This concept generalizes beyond rings, and this is what is discussed in the following.
Exactly what this means depends on context.
A very general definition is this: Given sets $ R $ and $ M $ , and a function $ {cdot}colon R times M to M $ , an element $ u $ of $ M $ is a unit (relative to the operation $ {cdot} $ ) if, given any element $ x $ of $ M $ , there exists a unique element $ a $ of $ R $ such that $ x = a cdot u $ .
That is, every element of $ M $ is a multiple (in a unique way) of $ u $ , where 'multiple' is defined in terms of the operation $ {cdot} $ .
If $ R $ is a ring (or rig), then $ R $ comes equipped with a multiplication map $ {cdot}colon R times R to R $ .
So $ R $ can play the role of both $ R $ and $ M $ above, although there are two ways to do this: on the left and on the right.
We find that $ u $ is a left unit if and only if $ u $ has a left inverse, and $ u $ is a right unit if and only if $ u $ has a right inverse.
First, an element $ u $ with an inverse is a unit because, given any element $ x $ , we have $ x = (x u^{ - 1}) u $ (on the left) or $ x = u (u^{ - 1} x) $ (on the right).
Conversely, a unit must have an inverse, since there must a solution to $ 1 = a u $ (on the left) or $ 1 = u a $ (on the right).
In a commutative ring (or rig), a unit is an element of $ R $ that has an inverse, period.
Of course, a commutative ring $ R $ is a field just when every non - zero element is a unit.
Notice that addition plays no role in the characterisation above of a unit in a ring.
Accordingly, a unit in a monoid may be defined in precisely the same way.
A group is precisely a monoid in which every element is a unit.
In a rng (or, ignoring addition, in a semigroup), we cannot speak of inverses of elements.
However, we can still talk about units; $ u $ is a left unit if, for every $ x $ , there is an $ a $ such that $ x = a u ; $ and $ u $ is a right unit if, for every $ x $ , there is an $ a $ such that $ x = u a $ .
In a nonassociative ring (or, ignoring addition, in a magma), even if we have an identity element, an invertible element might not be a unit.
So we must use the same explicit definition as in a rng (or semigroup) above.
A quasigroup is precisely a magma in which every element is a two - sided unit.
If $ R $ is a ring (or rig) and $ M $ an $ R $ - module, then a unit in $ M $ is an element $ u in M $ such that every other $ x in M $ can be written as $ x = a u $ (or $ x = u a $ for a right module) for some $ a in R $ .
This is the same as a generator of $ M $ as an $ R $ - module.
There is no need to distinguish left and right units unless $ M $ is a bimodule.
Note that a (left or right) unit in $ R $ qua ring is the same as a unit in $ R $ qua (left or right) $ R $ - module.
{UnitsOfMeasurement} In physics, the quantities of a given dimension generally form an $ mathbb{R} $ - line, a $ 1 $ - dimensional real vector space.
Since $ mathbb{R} $ is a field, any non - zero element is a unit, called in this context a unit of measurement.
This is actually a special case of a unit in a module, where $ R coloneqq mathbb{R} $ and $ M $ is the line in question.
Often (but not always) these quantities form an oriented line, so that nonzero quantities are either positive or negative.
Then we usually also require a unit of measurement to be positive.
In fact, for some dimensions, there is no physical meaning to a negative quantity, in which case the quantities actually form a module over the rig $ mathbb{R}_{ge 0} $ and every nonzero element is "positive."
For example, the kilogram is a unit of mass, because any mass may be expressed as a real multiple of the kilogram.
Further, it is a positive unit; the mass of any physical object is a nonnegative quantity (so that mass quantities actually form an $ mathbb{R}_{ge 0} $ - module) and may be expressed as a nonnegative real multiple of the kilogram.
Often the term 'unit' (or 'unity') is used as a synonym for 'identity element', especially when this identity element is denoted $ 1 $ .
For example, a 'ring with unit' (or 'ring with unity') is a ring with an identity (used by authors who say 'ring' for a rng).
Of course, a rng with identity has a unit, since $ 1 $ itself is a unit; conversely, a commutative rng with a unit must have an identity.
I haven't managed to find either a proof or a counterexample to the converse (in the noncommutative case): that a rng with a unit must have an identity.
Response: If $ R $ is a rng with a unit $ u $ , then every element uniquely factors through $ u $ .
In particular, $ u $ itself does $ . u = a u $ , with $ a $ unique.
So $ a $ is an identity.
Reply: Why is $ a $ an identity then?
This works if the rng is commutative: given any $ v $ , write $ v $ as $ b u $ , and then $ a v = a (b u) = b (a u) = b u = v $ .
But without commutativity (and associativity), this doesn't work.
It is this meaning of 'unit' which gives rise to the unit of an adjunction.
See also A topological group is a topological space with a continuous group structure: a group object internal to the category Top of topological spaces and continuous functions between them.
A topological group is (i) a group, hence (i) a set $ G $ , (i) a neutral element $ e in G $ , (i) a associative unitality function (i) $ ( - )cdot ( - ) ;colon; G times G to G $ , (i) a function $ ( - )^{ - 1} ;colon; G to G $ such that $ g cdot g^{ - 1} = e = g^{ - 1} cdot g $ for all $ g in G $ ; (i) a topology $ tau_G subset P(G) $ giving $ G $ the structure of a topological space such that the operations $ ( - )^{ - 1} $ and $ ( - )cdot ( - ) $ are continuous functions (the latter with respect to the product topology).
Sometimes topological groups are understood to be Hausdorff (e.g. Bredon 72, p. 1).
Every open subgroup $ H subset G $ of a topological group is closed, hence a closed subgroup.
(e.g Arhangel'skii - Tkachenko 08, theorem (i)(iii)5) The set of $ H $ - cosets is a cover of $ G $ by disjoint open subsets.
One of these cosets is $ H $ itself and hence it is the complement of the union of the other cosets, hence the complement of an open subspace, hence closed.
Every connected locally compact topological group is sigma - compact.
Every locally compact topological group is paracompact.
(e.g. Arhangel'skii - Tkachenko 08, cor.
(iii)(i)4, cor.
(iii)(i)5) By assumption of local compactness, there exists a compact neighbourhood $ Ce subset G $ of the neutral element.
We may assume without restriction of generality that with $ g in Ce $ any element, then also the inverse element $ g^{ - 1} in C_e $ .
For if this is not the case, then we may enlarge $ Ce $ by including its inverse elements, and the result is still a compact neighbourhood of the neutral element: Since taking inverse elements $ ( - )^{ - 1} colon G to G $ is a continuous function, and since continuous images of compact spaces are compact, it follows that also the set of inverse elements to elements in $ Ce $ is compact, and the union of two compact subspaces is still compact (obviously, otherwise see this prop).
Now for $ n in mathbb{N} $ , write $ Ce^n subset G $ for the image of $ underset{k in {1, cdots n } }{prod} Ce subset underset{k in {1, cdots, n } }{prod} G $ under the iterated group product operation $ underset{k in {1, cdots, n } }{prod} G longrightarrow G $ .
Then $ H coloneqq underset {n in mathbb{N}} {cup} C_e^n ;subset; G $ is clearly a topological subgroup of $ G $ .
Observe that each $ Ce^n $ is compact.
This is because $ underset{k in {1, cdots, n } }{prod}Ce $ is compact by the Tychonoff theorem, and since continuous images of compact spaces are compact.
Thus $ H = underset{n in mathbb{N}}{cup} C_e^n $ is a countable union of compact subspaces, making it sigma - compact.
Since locally compact and sigma - compact spaces are paracompact, this implies that $ H $ is paracompact.
Observe also that the subgroup $ H $ is open, because it contains with the interior of $ Ce $ a non - empty open subset $ Int(Ce) subset H $ and we may hence write $ H $ as a union of open subsets $ H = underset{h in H}{cup} Int(C_e) cdot h , $ .
Finally, as indicated in the proof of Lemma , the cosets of the open subgroup $ H $ are all open and partition $ G $ as a disjoint union space (coproduct in Top) of these open cosets.
From this we may draw the following conclusions.
A topological group $ G $ carries two canonical uniformities: a right and left uniformity.
The right uniformity consists of entourages $ sim{l, U} $ where $ x sim{l, U} y $ if $ x y^{ - 1} in U $ ; here $ U $ ranges over neighborhoods of the identity that are symmetric: $ g in U Leftrightarrow g^{ - 1} in U $ .
The left uniformity similarly consists of entourages $ sim{r, U} $ where $ x sim{r, U} y $ if $ x^{ - 1} y in U $ .
The uniform topology for either coincides with the topology of $ G $ .
Obviously when $ G $ is commutative, the left and right uniformities coincide.
They also coincide if $ G $ is compact Hausdorff, since in that case there is only one uniformity whose uniform topology reproduces the given topology.
Let $ G $ , $ H $ be topological groups, and equip each with their left uniformities.
Let $ f: G to H $ be a group homomorphism.
The following are equivalent: Suppose $ f $ is continuous at $ g in G $ .
Since neighborhoods of a point $ x $ are $ x $ - translates of neighborhoods of the identity $ e $ , continuity at $ g $ means that for all neighborhoods $ V $ of $ e in H $ , there exists a neighborhood $ U $ of $ e in G $ such that $ f(g U) subseteq f(g) V $ Since $ f $ is a homomorphism, it follows immediately from cancellation that $ f(U) subseteq V $ .
Therefore, for every neighborhood $ V $ of $ e in H $ , there exists a neighborhood $ U $ of $ e in G $ such that $ x y^{ - 1} in U Rightarrow f(x) f(y)^{ - 1} = f(x y^{ - 1}) in V $ in other words such that $ x simU y Rightarrow f(x) simV f(y) $ .
Hence $ f $ is uniformly continuous with respect to the right uniformity.
By similar reasoning, $ f $ is uniformly continuous with respect to the right uniformity.
A unitary representation $ R $ of a topological group $ G $ in a Hilbert space $ mathcal{H} $ is a continuous group homomorphism $ R colon G to mathcal{U}(mathcal{H}) $ where $ mathcal{U}(mathcal{H}) $ is the group of unitary operators on $ mathcal{H} $ with respect to the strong topology.
Here $ mathcal{U}(mathcal{H}) $ is a complete, metrizable topological group in the strong topology, see (Schottenloher, prop.
(iii)11).
In physics, when a classical mechanical system is symmetric, i.e. invariant in a proper sense, with respect to the action of a topological group $ G $ , then an unitary representation of $ G $ is sometimes called a quantization of $ G $ .
See at geometric quantization and orbit method for more on this.
The reason that in the definition of a unitary representation, the strong operator topology on $ mathcal{U}(mathcal{H}) $ is used and not the norm topology, is that only few homomorphisms turn out to be continuous in the norm topology.
Example: let $ G $ be a compact Lie group and $ L^2(G) $ be the Hilbert space of square integrable measurable functions with respect to its Haar measure.
The right regular representation of $ G $ on $ L^2(G) $ is defined as $ R: G to mathcal{U}(L^2(G)) $ $ g mapsto (R_g: f(x) mapsto f(x g)) $ and this will generally not be continuous in the norm topology, but is always continuous in the strong topology.
{Protomodularity} The category TopGrp of topological groups and continuous group homomorphisms between them is a protomodular category.
A proof is spelled out by Todd Trimble here on MO.
The following monograph is not particulary about group representations, but some content of this page is based on it: The general idea of completion is that given an object of some sort $ C $ , we construct from it a larger object, containing $ C $ as a subobject, which moreover has certain properties that $ C $ might have lacked.
This larger object is then called the completion of $ C $ with respect to these properties.
Outside of category theory (see below), "completion" is usually used mostly for idempotent operations.
That is, the completion of a thing with respect to some property is itself complete with respect to that property, and the completion process doesn't change an object that is already complete.
From the perspective of stuff, structure, property this makes sense because we complete with respect to a property.
Namely, according to the yoga of SSP, given some ambient category $ K $ , the subcategory of objects having a property $ P $ should be a full subcategory, whose inclusion functor forgets that property.
A "completion" operation is then usually a left (or, occasionally, right) adjoint to that inclusion functor, making the category of objects with property $ P $ reflective (or coreflective).
Note that a full and faithful functor with a left adjoint is always monadic and the monad is idempotent.
By contrast, when we add structure to objects, i.e. we consider an adjoint to a forgetful functor which is faithful but not necessarily full, we usually do not use the word "completion" but rather the word "free".
For example, the category of complete metric spaces is a full reflective subcategory of the category of metric spaces, and the reflection is called "completion."
By contrast, the forgetful functor from the category of groups to the category of sets has a left adjoint, but we call that left adjoint the "free group on a set" rather than the "completion of a set into a group."
Additionally, we tend to use the term 'completion' only for a faithful reflector.
Note that the reflector is faithful if and only if the unit of the reflection is monic; we might even want to require it to be a regular monomorphism.
For example, the left adjoint of the forgetful functor from abelian groups to groups is called 'abelianisation' and may even be called 'free abelian group on a group' but is not normally called 'abelian completion' or anything like that.
(The tendency in such cases is rather to resort to suffixes like " - ification" and " - ization": sheafification, abelianization, localization.)
This fits with the intuition that a completion "adds more stuff" to the object we started with in order to "make it complete".
David:
It's not clear to me when in the 'List of completions' we have examples of enriched category completions: Cauchy completion of a metric space (yes) of a uniform space (no?), Dedekind completion of a linear order (yes for 2 - enriched categories?).
Mike Shulman:
Although orders are 2 - enriched categories, Dedekind completion of an order is not a categorical completion, at least not in the sense of adding limits or colimits.
That would be the construction of downsets or ideals.
Cauchy completion of a metric space is, of course, an instance of Cauchy completion of enriched categories.
I believe that Cauchy completion of a uniform space is actually also an instance of a general categorical notion of Cauchy completion, but in the more general setting of an equipment (namely, the equipment of sets and filters).
See "Categorical interpretation" at uniform space for a too - brief summary of this point of view.
David Corfield: so is there are clear - cut distinction of level in all these cases, where we can separate completions of (enriched) categories (equipment) from completions of sets (with properties and structures)?
Mike Shulman: I think the reason that completion of metric spaces and uniform spaces feels more like the completion of sets (than categories) is that they are basically (enriched) (0, 1) - categories.
If the question is where to separate this list from the one below, I would put completions of anything enriched in a preorder up here, and completions of things enriched non - posetally below.
The general contrast between "completion" for adding a property and "free" for adding structure applies to operations on categories as well.
For instance, since split idempotents are preserved by any functor, the 2 - category of categories with split idempotents is a full sub - 2 - category of Cat.
Therefore, it makes perfect sense to call the left adjoint of its inclusion a "completion, " in this case the (Set - enriched) Cauchy completion or Karoubi envelope.
By contrast, the forgetful functor from the 2 - category of monoidal categories to $ Cat $ forgets structure, rather than properties, so its left adjoint should be called a "free" construction rather than a "completion."
However, in this case there is an intermediate notion between properties and structure, namely property - like structure.
Intuitively, property - like structure is "structure which, when it exists, is essentially unique" or "a property which is not necessarily preserved by morphisms."
The canonical example is the existence of limits and colimits in a category: when they exist they are unique up to unique canonical isomorphism (so that "having limits" is intuitively a property of a category), but not every functor preserves limits, so the forgetful functor from categories - with - limits to categories is not full.
(Left) adjoints to functors which forget property - like structure are usually called free completions.
The monads they induce are not idempotent, but they are often lax - idempotent or colax - idempotent.
(For example, when we freely add limits to a category that already had limits, the old limits are no longer limits and the new ones take their place.)
Property - like structure is most common in category theory, but it does occur elsewhere as well.
For instance, a monoid is a semigroup with property - like structure: a semigroup has at most one identity element, but that identity element is not necessarily preserved by semigroup homomorphisms.
Thus the adjoining of a new formal identity element to a semigroup (which is not an idempotent operation) might be called its "free completion into a monoid".
Notice that if the original semigroup is already a monoid, then its free completion into a monoid will be a different monoid (with a new identity); this shows the distinction between free completion and mere completion.
The following completions add a property in the strictest sense, and as such are idempotent.
These completions add a property - like structure, are often lax - idempotent or colax - idempotent.
Note that these completions take small categories to large categories.
Free completions and cocompletions of large categories can be obtained using categories of accessible presheaves.
However, if we only want to add limits and/or colimits for a given set of diagram shapes, the free completion process will preserve smallness.
For example we have: All these sorts of completions work just as well in an enriched setting, as long as the enriching category $ V $ is nice enough (locally presentable is certainly enough).
Some other non - idempotent completions: {nonunique} The completions above are mostly (all?) unique in the relevant sense: unique up to unique isomorphism for objects of groupoids (or categories), more generally with a contractible $ infty $ - groupoid of completions.
However, there are other sorts of completions in mathematics, such as: {Idea} Given a category with weak equivalences $ (mathcal{C}, W) $ , then its homotopy category $ Ho(mathcal{C}) $ is, if it exists, the result of universally forcing the weak equivalences to become actual isomorphisms, also called the localization at the weak equivalences $ mathcal{C} longrightarrow Ho(mathcal{C})= mathcal{C}W^{ - 1} , $ .
The classical example is the category of topological spaces with weak equivalences those continuous functions which are homotopy equivalences or weak homotopy equivalences.
The corresponding homotopy category is often referred to as "the homotopy category", by default, or the "classical homotopy category" for emphasis.
This turns out to be equivalent to the category of topological spaces or (for weak homotopy equivalences) of just those homeomorphic to CW - complexes with left homotopy - classes of continuous functions between them, whence the name "homotopy category".
The existence of a homotopy category, as well as tractable presentations of it typically require extra properties of the class of weak equivalences (such as that they admit a calculus of fractions) or even extra structure (such as fibration category/cofibration category structure, or full model category structure, or further enhancements of that to simplicial model category structures, etc).
See at homotopy category of a model category for more on this.
More generally, to every (∞, 1) - category is associated a homotopy category, whose morphisms are literally the homotopy classes of the original morphisms.
See at homotopy category of an (∞, 1) - category for more on this.
These two concepts of "homotopy category" are compatible: to a category with weak equivalences is associated, if it exists,
an (∞, 1) - category obtained by universally forcing the weak equivalences to become actual homotopy equivalences, also called the simplicial localization $ LW mathcal{C} $ at the weak equivalences.
The homotopy categories of $ (mathcal{C}, W) $ and of $ LW mathcal{C} $ coincide, which justifies the terminology "homotopy category" generally.
Given a simplicially enriched category $ C $ , we can form for each pair of objects, $ x, y $ , of objects of $ C $ , the set, $ pi0C(x, y) $ , of connected components of the 'function space' $ C(x, y) $ .
As $ pi0 $ preserves finite limits, this gives a category, denoted $ pi0(C) $ .
As 1 - simplices in $ C(x, y) $ can be often interpreted as being homotopies, this category $ pi0(C) $ is often called the homotopy category of $ C $ , and then the notation $ Ho(C) $ may be used.
This notions is closely related to the next, by using, say the hammock localisation of Dwyer and Kan, as then $ pi_0 $ of that simplicially enriched category, coincides with the following.
Given a category with weak equivalences (such as a model category), its homotopy category $ Ho(C) $ is - - if it exists - - the category which is universal with the property that there is a functor $ Q : C to Ho(C) $ that sends every weak equivalence in $ C $ to an isomorphism in $ Ho(C) $ .
One also writes $ Ho(C) := W^{ - 1}C $ or $ CW^{ - 1} $ and calls it the localization of $ C $ at the collection $ W $ of weak equivalences.
More in detail, the universality of $ Ho(C) $ means the following: $ array{ C &&stackrel{F}{to}& A downarrow^Q& Downarrow^{simeq}& nearrow{FQ} Ho(C) } $ The second condition implies that the functor $ F_Q $ in the first condition is unique up to unique isomorphism $ . array{& to W & Downarrow & C & to} $ where $ W $ is the category whose objects are morphisms in $ C $ and whose morphisms are commutative squares in $ C $ .
Early discussion: For more see the references at model category or classical homotopy category.
A group is solvable if it is a finite iterated group extension of an abelian group by abelian groups.
In other words, a group $ G $ is solvable if and only if there exists a finite sequence $ { 1 } ;subset; G_1 ;subset; G_2 ;subset; ldots ;subset; G_k ;=; G , , $ in which (i) $ G{j - 1} $ is normal in $ Gj $ (i) the quotient groups $ Gj/G{j - 1} $ are abelian.
Solvability can equivalently be expressed in terms of breaking a group down rather than building it up.
Given elements $ g, h $ of a group $ G $ , the commutator is $ g, h := g^{ - 1} h^{ - 1} g h $ .
The commutator subgroup of $ G $ is the subgroup of $ G $ generated by the commutators $ g, h $ for all $ g, h in G $ .
A group is solvable if the series of groups produced by repeatedly taking the commutator subgroup, the derived series, terminates with the trivial group after finitely many steps.
The terminology "solvable groups" comes from elementary Galois theory: every polynomial equation $ phi $ over an integral domain $ K $ has a corresponding Galois group $ Gal(phi/K) $ , and $ Gal(phi/K) $ is a solvable group if and only if $ phi $ is a solvable equation (meaning that all its solutions in an algebraic closure of $ K $ are expressible using the elements of $ K $ , the field operations, and extraction of roots).
Informally, this can be thought of as each step in the derived series of the Galois group requiring an additional level of nesting of radicals.
If the derived series does not terminate, then the solutions of the polynomial equation cannot be expressed by radicals, no matter how deeply nested.
A nilpotent group is a solvable group given by central group extensions.
Textbooks: Articles: See also: A subrepresentation is a subobject in a category of representations.
An identiy matrix is a diagonal matrix with all diagonal entries equal to the identity element $ 1 in R $ of the ground ring.
The identiy matrices are the identity elements in their matrix algebra, whence the name.
See also A transitive relation is a semicategory or magmoid $ A $ such that for all objects $ a $ and $ b $ in $ A $ , there are no more than one morphism with domain $ a $ and codomain $ b $ .
Equivalently, a transitive relation is a semicategory or magmoid enriched on truth values.
Set theoretically, a (binary) relation $ sim $ on a set $ A $ is transitive if in every chain of $ 3 $ pairwise related elements, the first and last elements are also related: $ forall (x, y, z: A), ; x sim y ;wedge; y sim z ;Rightarrow; x sim z $ which generalises from $ 3 $ to any finite, positive number of elements.
In the language of the $ 2 $ - poset Rel of sets and relations, a relation $ R: A to A $ is transitive if it contains its composite with itself: $ R^2 subseteq R $ from which it follows that $ R^n subseteq R $ for any positive natural number $ n $ .
To include the case where $ n = 0 $ , we must explicitly state that the relation is reflexive.
Transitive relations are often understood as orders.
For $ S $ a simplicial set and $ A $ an abelian group, the simplicial homology of $ S $ is the chain homology of the chain complex corresponding under the Dold - Kan correspondence to the simplicial abelian group $ S cdot A $ of $ A $ - chains on $ S $ : formal linear combinations of simplices in $ S $ with coefficients in $ A $ .
Let $ S $ be a simplicial set and $ A $ an abelian group.
For $ n in mathbb{N} $ write $ Sn cdot A coloneqq mathbb{Z}Sn otimes A $ for the free abelian group on the set $ S_n $ of $ n $ - simplices tensored with $ A $ : the group of formal linear combinations of $ n $ - simplices with coefficients in $ A $ .
These abelian groups arrange to a simplicial abelian group $ X cdot A in Ab^{Delta^{op}} , $ .
The alternating face map complex of these groups is called the complex of simplicial chains on $ S $ $ Cbullet(S cdot A) = Cbullet(S, A) , $ .
The simplicial homology of $ S $ is the chain homology of the complex of simplicial chains: $ H_bullet(S, A) coloneqq Hbullet(Cbullet(S, A)) , $ .
This means that the differentials in $ Cbullet(S, A) $ are given on basis elements $ sigma in Sn $ by the formal linear combination $ partial sigma = sum{k = 0}^{n} ( - 1)^k dk sigma , , $ where $ dk : Sn to S_{n - 1} $ are the face maps of $ S $ .
Let $ S = partial Delta^3 $ be the boundary of the simplicial 3 - simplex, the (hollow) simplicial tetrahedron.
Since this has the normalized chain complex of $ mathbb{Z} $ is of the form $ cdots to 0 to 0 to mathbb{Z}^4 to mathbb{Z}^6 to mathbb{Z}^4 to 0 , $ .
By writing out the two non - trivial differentials, one can deduce explicitly that The term simplicial homology is also used in the literature for the homology of polyhedral spaces, based on the theory of simplicial complexes.
That homology is defined by first looking at a chain complex of simplicial chains on, say, a triangulation of a space, and then passing to the corresponding homology.
The theory then proceeds by proving that the end result is independent of the triangulation used.
The resulting homology theory is isomorphic to singular homology, but historically was the earlier theory.
A basic discussion is for instance around application (i)(i)3 of Homology for spaces is discussed in chapter 2 of and this includes a discussion of the homology of simplicial complexes.
A division algebra is a possibly non - associative algebra $ A $ , typically over a field $ k $ , which has the property that for any nonzero element $ a $ and any element $ b $ , the equations $ a x=b $ and $ x a=b $ each have a unique solution for $ x $ in the algebra.
Usually the algebra is assumed to have a multiplicative identity, in which case this condition implies that each element has a left inverse and a right inverse.
These inverses necessarily coincide if the algebra is associative, but this may fail in the absence of associativity.
A sub - topic of interest is the existence of a multiplicative norm for the algebra, see at normed division algebra.
An alternative definition is used in Baez 02: The axioms given there require that the algebra is finite - dimensional over $ k $ and that for any $ a $ and $ b $ in the algebra, $ a b = 0 $ implies at least one of $ a $ or $ b $ is already $ 0 $ .
This coincides with the definition given above for finite dimensional algebras.
For many applications (also to physics) the most interesting division algebras are the normed division algebras over the real numbers: By the Hurwitz theorem these are the real numbers, complex numbers, quaternions and octonions.
These have important relations to supersymmetry.
See at division algebra and supersymmetry.
See also A natural isomorphism is the "correct" notion of isomorphism between functors.
Informally, one sometimes speaks of two objects being "naturally isomorphic" if they are the images of two functors that are naturally isomorphic.
However, sometimes one encounters functors that are "pointwise isomorphic" but not naturally.
There is not much to say mathematically about such "unnatural isomorphisms", but some discussion of them can help the intuitive understanding of natural isomorphisms and their importance.
On this page we will adhere to the convention that an "unnatural isomorphism" means an isomorphism that is not necessarily natural (but might be), similarly to how a "noncommutative ring" might happen to be commutative.
The word "unnatural" is not to be taken perjoratively or as suggesting that unnatural isomorphisms are rare; in cardinality terms there are many more unnatural isomorphisms than natural ones, although in mathematical practice surprisingly many isomorphisms are indeed natural.
Other possible terms with the same meaning are "pointwise isomorphic" or "objectwise isomorphic".
The term "natural" is used for traditional reasons, cf.
EilenbergMac Lane45, and is an example of the common phenomenon that concepts branded natural, normal or regular tend to be rather non - generic or non - random.
In fact, Eilenberg and MacLane comment (cf.
p. 233, first paragraph in loc. cit) on the term, associating it with an intuition of simultaneity, rather than genericity.
This intuition is in tune with conceiving of naturality as generalized commutatitivity.
Let $ F, G:Cto D $ be functors.
An unnatural isomorphism between $ F $ and $ G $ consists of, for each object $ cin C $ , an isomorphism $ F(c) cong G(c) $ , satisfying no further conditions.
In other words, it is an unnatural transformation whose components are isomorphisms, or equivalently that is an isomorphism in the category of unnatural transformations.
Note that if each component of a natural transformation is an isomorphism, then it is necessarily a natural isomorphism.
(Depending on the definition of "natural isomorphism", this could be a tautology; but the non - tautologous statement is that if each component of a natural transformation is an isomorphism then it is an isomorphism in the functor category.
This statement, though non - tautologous, is easy to prove for 1 - categories, but more difficult for higher categories.)
More generally, an unnatural isomorphism (or transformation) might be natural with respect to only some morphisms in the domain, such as for instance the isomorphisms.
Some people have proposed calling transformations that are natural only with respect to isomorphisms "canonical".
If one says that two objects $ A $ and $ B $ are "unnaturally isomorphic", it might mean that they are the images of two functors that are unnaturally isomorphic, but it might also mean only that there is no obvious way even to make them the images of two functors.
For instance, this seems to be the meaning in Section (i)1 of Strickland.
Somewhat relatedly, the complex numbers $ mathbb{C} $ and the p - adic complex numbers $ mathbf{C}_p $ are "unnaturally isomorphic".
More precisely, there is no way of making constructions such as "algebraic closure of a field" or "injective hull of an $ R $ - module" functorial, if the desired embeddings into these constructions are to be natural, and this precludes speaking of any two such constructions as "naturally isomorphic".
We touch on this again below, but see here.
Intuitively, there are several reasons that an isomorphism might fail to be natural.
Unnatural isomorphisms are not very well - behaved mathematically, so if we have an unnatural isomorphism we may want to "make it natural".
There are several ways to do this: (i) Use a different definition that includes more structure, such as derivators instead of triangulated categories.
See for instance this Wikipedia discussion on axioms for triangulated categories.
(ii) Relatedly, pass to a higher - categorical context in which a non - commuting square can commute up to a higher transformation; see pseudonatural transformation and lax natural transformation.
(iii) Cut down to a smaller class of morphisms in the domain category for which the naturality square does commute.
The use of adjectives like canonical, invariant, functorial, natural is sometimes satirized.
For example, as quoted in MO2010, Andr&233; Weil writes: > I can assure you, at any rate, that (...)
my results are invariant, probably canonical, perhaps even functorial.
(Oeuvres, vol. 2, page 558) which may be subtly mocking.
These three terms can be distinguished in the following way: In particular, the adjectives "functorial" and "natural" in general apply to different classes of things.
See non - canonical isomorphism for examples of natural isomorphisms that are not canonical.
(i) Let
$ U: Vectto Aff $ be the functor taking the underlying affine space of a vector space, and $ D:Affto Vect $ the functor constructing the vector space of displacements of an affine space.
Then there is a natural isomorphism $ D circ U cong Id{Vect} $ , but only an unnatural isomorphism " $ U circ D cong Id{Aff} $ ".
In particular, these functors do not form an equivalence of categories.
A similar phenomenon occurs with groups and heaps, and with torsors of groups.
(i) As a particular example of the last phenomenon: there is a bijective correspondence between linear orderings of a set $ S $ and permutations of $ S $ .
Indeed, the set $ Lin(S) $ is a torsor over $ Perm(S) $ : there is a group action $ alpha: Perm(S) times Lin(S) to Lin(S) $ such that for any choice of linear ordering $ L $ , the map $ alpha( - , L): Perm(S) to Lin(S) $ is a bijection.
But, there is no canonical choice of ordering $ L $ .
(i) Species are functors for which unnatural isomorphisms are sometimes discussed.
For example, the species of linear orders is unnaturally isomorphic to the species of permutations; for a related example, see the commentary under this MathOverflow answer MO201(iv)
Yorgey2014 explicitly uses the term: his definition (iii)(iii)4 introduces an "equipotence between species (...) as an "unnatural" isomorphism between the two species in question".
(i) The term unnatural isomorphism is often used in homological algebra, in particular in discussions of splittings of exact sequences.
An example is Hilton - Stammbach, Theorem (iv)3, which explicitly uses the term to describe an isomorphism between Hom - and Ext - functors.
More generally, unnatural transformations also often occur in homological algebra.
(i) It is often said that while there is an isomorphism between the field of complex numbers $ mathbb{C} $ and the completion $ mathbf{C}p $ (with respect to the canonical absolute value) of the algebraic closure of the p - adic numbers $ mathbb{Q}p $ , this isomorphism is not natural.
This statement, while somewhat loose since there are no functors specified, can be made formally precise along the lines of Ad&225;mek, Herrlich, Rosick&253;, and Tholen.
The abstract reads: "In a category with injective hulls and a cogenerator, the embeddings into injective hulls can never form a natural transformation, unless all objects are injective.
In particular, assigning to a field its algebraic closure, to a poset or Boolean algebra its MacNeille completion, and to an $ R $ - module its injective envelope is not functorial, if one wants the respective embeddings to form a natural transformation."
(i) If $ C $ and $ D $ have only one object (or slightly more generally, one isomorphism class of objects), then any two functors $ F, G:Cto D $ are unnaturally isomorphic.
For example, for any ring $ R $ , any two endofunctors of the category of rank - one free $ R $ - modules are unnaturally isomorphic.
(i) See MathOverflow201(iii) Volume 48, Issue 4 (December 2002), 379&8211;38(viii) (Citeseer link)
The measurable functions are those functions between measure spaces amenable to treatment in measure theory, hence they are the evident homomorphisms between measure spaces.
Given measurable spaces $ X $ and $ Y $ , a measurable function from $ X $ to $ Y $ is a function $ fcolon X to Y $ such that the preimage $ f^(T) $ is measurable in $ X $ whenever $ T $ is measurable in $ Y $ .
In classical measure theory, it is usually assumed that $ Y $ is the real line (or a variation such as the extended real line or the complex plane) equipped with the Borel sets.
Then $ f $ is measurable if and only if $ f^{ - 1}(I) $ is measurable whenever $ I subseteq Y $ is an interval.
More generally, if $ Y $ is any topological space equipped with the Borel sets, then $ f $ is measurable if and only if $ f^{ - 1}(I) $ is measurable whenever $ I subseteq Y $ is open.
In some variations of measure theory based on $ delta $ &8209; or $ sigma $ - rings instead of on $ sigma $ - algebras, it is necessary to allow partial functions whose domain is a relatively measurable set.
Classically (when $ Y $ is the real line), one achieves (for purposes of integration) essentially the same result by requiring only that $ f^{ - 1}(I) $ be measurable whenever $ I subseteq Y $ is an interval that does not contain $ 0 $ ; in other words, one effectively assumes that $ f $ is zero wherever it would otherwise be undefined.
If (as in a measure space, a Cheng space, or a localisable measurable space), we have a notion of null sets (or full sets) in $ X $ and $ Y $ , then we may allow a measurable function to be an almost function: a partial function whose domain is full.
Specifically, an almost function $ fcolon X to Y $ is measurable if the preimage of every full set in $ Y $ is full in $ X $ and the preimage of every measurable set in $ Y $ is, if not quite measurable in $ X $ , at least equal to a measurable set in $ X $ up to a full set in $ X $ .
(To emphasise this last change, we may call such functions almost measurable.)
Additionally, we consider two measurable almost functions to be equal (or equivalent if one prefers) if they are almost equal: their equaliser is full.
category: analysis An automorphism of an object $ x $ in a category $ C $ is an isomorphism $ f : x to x $ .
In other words, an automorphism is an isomorphism that is an endomorphism.
Given an object $ x $ , the automorphisms of $ x $ form a group under composition, the automorphism group of $ x $ , which is a submonoid of the endomorphism monoid of $ x $ : $ AutC(x) = EndC(x) cap Iso(C) = IsoC(x, x) , $ which may be written $ Aut(x) $ if the category $ C $ is understood.
Up to equivalence, every group is an automorphism group; see delooping.
(...) A simply connected topological space is a 1 - connected topological space $ X $ : a connected space whose fundamental group is the trivial group: $ pi1(X) = {mathrm{e} } $ .
Equivalently: if it is a simply connected object of the (∞, 1) - topos Top.
See n - connected object of an (infinity, 1) - topos for more.
A groupoid is connected if it is inhabited and every object is connected by a morphism to every other object.
Every category $ C $ induces a groupoid $ G(C) $ by freely inverting all its morphisms.
A category is connected if the groupoid $ G(C) $ is.
A category $ C $ is connected if it is inhabited and the following equivalent conditions hold Note that the empty category is not connected.
For other purposes, one can argue about whether the empty set should be called "connected" (see connected space), but for the applications of connected categories, the empty category should definitely not be called connected.
In particular, a terminal object is not a connected limit.
A connected limit is a limit whose domain diagram category is connected.
In topology, a (parametrised, oriented) path in a space $ X $ is a map (a morphism in an appropriate category of spaces, such as a continuous function between topological space) to $ X $ from the topological interval $ mathbb{I} = 0, 1 $ .
A path from $ a $ to $ b $ is a path $ f $ such that $ f(0) = a $ and $ f(1) = b $ .
An unparametrised path is an equivalence class of paths, such that $ f $ and $ g $ are equivalent if there is an increasing automorphism $ phi $ of $ mathbb{I} $ such that $ g = f circ phi $ .
An unoriented path is an equivalence class of paths such that $ f $ is equivalent to
$ (x mapsto f(1 - x)) $ .
If $ P $ is a path, then its reverse path^1, denoted $ overline{P} $ , is defined to be the composite $ P circ ( tmapsto 1 - t ) $ .
The operation $ Pmapstooverline{P} $ is called path reversal.
^1:
Cf. e.g. Introduction to Topology - - 2, or also Section (ii)1; beware that that reference, (0) like many others, uses the term "inverse path", even though the operation of concatenation of paths does not in and of itself yield a strict groupoid, in which $ overline{P} $ would be an inverse, and (1) that it uses $ a $ and $ b $ for the endpoints of the interval, not the endpoints of the paths in the space $ X $ , and (2) that it uses $ P^ - $ instead of $ overline{P} $ , which however is less suited for notational iterating (compare $ overline{overline{P}}=P $ with $ (P^ - )^ - =P $ ), and that (3) the 2008 edition has a typo: " $ w(1 - t) $ " in loc.
cit., when inverse path gets defined, should be $ u(1 - t) $ .
A Moore path is defined like a path, except for having another domain: replace $ 0, 1 $ with the interval $ 0, n $ for some natural number (or, more commonly, any non - negative real number) $ n $ .
All of these variations can be combined, of course.
(For unoriented paths, one usually says 'between $ a $ and $ b $ ' instead of 'from $ a $ to $ b $ '.
Also, a Moore path from $ a $ to $ b $ has $ f(n) = b $ instead of $ f(1) = b $ .
Finally, there is not much difference between unparametrised paths and unparametrised Moore paths, since we may interpret $ (t mapsto n t) $ as a reparametrisation $ phi $ .)
In graph theory, a path is a list of edges, each of which ends where the next begins.
Actually, this is a special case of the above, if we use Moore paths and interpret $ 0, n $ as the linear graph with $ n + 1 $ vertices and $ n $ edges; in this way, the other variations become meaningful.
(However, as the only directed graph automorphism of $ 0, n $ is the identity, parametrisation is trivial for directed graphs and equivalent to orientation for undirected graphs.
Note that a non - Moore path is simply an edge, one of the fundamental ingredients of a graph.)
Given a Moore path $ f $ from $ a $ to $ b $ and a Moore path $ g $ from $ b $ to $ c $ , the concatenation of $ f $ and $ g $ is a Moore path $ f ; g $ or $ g circ f $ from $ a $ to $ c $ .
If the domain of $ f $ is $ 0, m $ and the domain of $ g $ is $ 0, n $ , then the domain of $ f ; g $ is $ 0, m+n $ , and $ (f ; g)(x) coloneqq left { array { f(x) & quad x leq m g(x - m) & quad x geq m .} right $ .
In this way, we get a (strict) category whose objects are points in $ X $ and whose morphisms are Moore paths in $ X $ , with concatenation as composition.
This category is called the Moore path category.
Often we are more interested in a quotient category of the Moore path category.
If we use unparametrised paths (in which case we may use paths with domain $ mathbb{I} $ if we wish), then we get the unparametrised path category.
If $ X $ is a smooth space, then we may additionally identify paths related through a thin homotopy to get the path groupoid.
Finally, if $ X $ is a continuous space and we identify paths related through any (endpoint - preserving) homotopy, then we get the fundamental groupoid of $ X $ .
In graph theory, the Moore path category is known as the free category on the graph.
E.g. (...)
In linear algebra a projector is a linear map $ e colon V to V $ that "squares to itself" in that its composition with itself is again itself: $ e circ e = e $ .
A projector $ e $ leads to a decomposition of the vector space $ V $ that it acts on into a direct sum of its kernel and its image: $ V simeq ker(e) oplus im(e) , $ .
The notion of projector is the special case of that of idempotent morphism.
In functional analysis, one sometimes requires additionally that this idempotent is in fact self - adjoint; or one can use the slightly different terminology projection operator.
Projectors relate to the notion of projections in category theory as follows: the existence of the projector $ P colon V to V $ canonically induces a decomposition of $ V $ as a direct sum $ V simeq ker(V) oplus im(V) $ and in terms of this $ P $ is the composition $ P colon V simeq im(v) oplus ker(V)to im(V) hookrightarrow V $ of the projection (in the sense of maps out of products) out of the direct sum $ im(V) oplus ker(V) simeq im(V) times ker(V) $ followed by the subobject inclusion of $ im(V) $ .
Hence: A projector is a projection followed by an inclusion.
>
This article is about the notion prevalent in category theory and homotopy theory, also known as a Brandt groupoid (Brandt 27).
For the notion involving a globally defined binary operation, see magma.
{Idea} Where a group may be thought of as a group of symmetry transformations that isomorphically relates one object to itself (the symmetries of one object, such as the isometries of a polyhedron) a groupoid is a collection of symmetry transformations acting between possibly more than one object.
Hence a groupoid consists of a set of objects $ x, y, z, cdots $ and for each pair of objects $ (x, y) $ there is a set of transformations, usually denoted by arrows $ x overset{f}{longrightarrow} y $ which may be composed if they are composable (i.e. if the first ends where the second starts) $ array{ && y & {}^{mathllap{f}}nearrow && searrow^{mathrlap{g}} x && underset{g circ f}{longrightarrow} && z } $ such that this composition is associative "filename": "AssociativityDiagram.png", "width": 400 and such that for each object $ x $ there is identity transformation $ x overset{idX}{longrightarrow} x $ in that this is a neutral element for the composition of transformations, whenever defined.
So far this structure is what is called a small category.
What makes this a (small) groupoid is that all these transformations are to be "symmetries" in that they are invertible morphisms meaning that for each transformation $ x overset{f}{longrightarrow} y $ there is a transformation the other way around
$ y overset{f^{ - 1}}{longrightarrow} x $ such that $ f^{ - 1} circ f = idx phantom{AAAA} f circ f^{ - 1} = idy , $ .
If there is only a single object $ x $ , then this definition reduces to that of a group, and in this sense groupoids are "groups with many objects".
Conversely, given any groupoid $ mathcal{G} $ and a choice of one of its objects $ x $ , then the subcollection of transformations from and to $ x $ is a group, sometimes called the automorphism group $ Aut{mathcal{G}}(x) $ of $ x $ in $ mathcal{G} $ .
Just as for groups, the "transformations" above need not necessarily be given by concrete transformations (say by bijections between objects which are sets).
Just as for groups, such a concrete realization is always possible, but is an extra choice (called a representation of the groupoid).
Generally one calls these "transformations" morphisms: $ x overset{f}{longrightarrow} y $ is a morphism with "source" $ x $ and "domain" $ y $ .
An archetypical example of a groupoid is the fundamental groupoid $ Pi1(X) $ of a topological space (def. below, for introduction see here): For $ X $ a topological space, this is the groupoid whose and composition is given, on representatives, by concatenation of paths.
Here the class of the reverse path $ bargamma ;colon; t mapsto gamma(1 - t) $ constitutes the inverse morphism, making this a groupoid.
If one chooses a point $ x in X $ , then the corresponding group at that point is the fundamental group $ pi1(X, x) coloneqq Aut{Pi1(X)}(x) $ of $ X $ at that point.
This highlights one of the reasons for being interested in groupoids over groups: Sometimes this allows to avoid unnatural ad - hoc choices and it serves to streamline and simplify the theory.
A homomorphism between groupoids is the obvious: a function between their underlying objects together with a function between their morphisms which respects source and target objects as well as composition and identity morphisms.
If one thinks of the groupoid as a special case of a category, then this is a functor.
Between groupoids with only a single object this is the same as a group homomorphism.
For example if $ f ;colon; X to Y $ is a continuous function between topological spaces, then postcomposition of paths with this function induces a groupoid homomorphism $ fast ;colon; Pi1(X) longrightarrow Pi1(Y) $ between the fundamental groupoids from above.
Groupoids with groupoid homomorphisms (functors) between them form a category Grpd (def. below) which includes the categeory Grp of groups as the full subcategory of the groupoids with a single object.
This makes precise how groupoid theory is a generalization of group theory.
However, for groupoids more than for groups one is typically interested in "conjugation actions" on homomorphisms.
These are richer for groupoids than for groups, because one may conjugate with a different morphism at each object.
If we think of groupoids as special cases of categories, then these "conjugation actions on homomorphisms" are natural transformations between functors.
For examples if $ f, g ;colon; X longrightarrow Y $ are two continuous functions between topological spaces, and if $ eta ;colon; f Rightarrow g $ is a homotopy from $ f $ to $ g $ , then the homotopy relative boundary classes of the paths $ eta(x, - ) ;colon; 0, 1 to Y $ constitute a natural transformation between $ f*, gast ;colon; Pi1(X) to Pi1(Y) $ in that for all paths $ x1 overset{gamma}{longrightarrow} x2 $ in $ X $ we have the "conjugation relation" $ eta(x1, - ) cdot fcircgamma = g circ gamma cdot eta(x2, - ) phantom{AAAA} text{i.e.} phantom{AAAA} array{ f(x1) &overset{eta(x1, - )}{longrightarrow}& g(x1) {}^{mathllap{f circ gamma}}downarrow && downarrow^{mathrlap{g circ gamma}} f(x2) &underset{eta(x2, - )}{longrightarrow}& g(x2) } , $ .
One may take care of the existence of these conjugation actions/natural transformation in two ways: (i) If one quotients them out, i.e. if one identifies two groupoid homomorphisms that differ by a conjugation action, then the resulting category of groupoids and classes of homomorphisms is called the homotopy category $ Ho(Grpd) $ of Grpd (def. below).
This is equivalent to the full subcategory of the classical homotopy category of topological spaces on those that are (CW - complexes and) homotopy 1 - types, i.e. those for which the fundamental groupoid is the only homotopy invariant, with all higher homotopy groups being trivial: $ Ho(Grpd) simeq Ho(Top^{CW}{leq 1}) hookrightarrow Ho(Top^{CW}) , $ .
This means that the concept of groupoids may be regarded as a combinatorial model for homotopy 1 - types in homotopy theory, in contrast to the models by topological spaces given by topological homotopy theory.
This equivalence generalizes to homotopy n - types as one passes to n - groupoids and eventually to all homotopy types as one passes to infinity - groupoids.
(i) Instead of forgetting all the information encoded in the conjugations/natural transformations, one may also collect it all into the structure of a 2 - category Grpd (in fact a (2, 1) - category).
As such this is the sub - 2 - category of Cat on those (small) categories all whose morphisms are invertible morphism.
For more introduction on this see at geometry of physics - - homotopy types.
In either of these two cases, beware that the category Grp of groups is not a full subcategory either of the homotopy category $ Ho(Grpd) $ or of the (2, 1) - category Grpd, because conjugation action is is not part of the definition of $ Grp $ .
Instead in homotopy theory it is pointed one - object groupoids which are equivalent to groups $ Grp hookrightarrow Grpd^{ast/} , $ .
(Even though there is a unique choice of point for a one - object groupoid, the respect for this (unique) choice forces the conjugation actions on groupoids to be trivial. )
This simple statement is in fact a special case of the May recognition theorem (see there) which holds for more general homotopy types and even for directed homotopy types.
The equivalence of groupoids with homotopy 1 - types shows immediately that, with homotopy taken into accont, the difference between groupoids and groups is rather mild, after all: Every groupoid is equivalent (isomorphic in $ Ho(Grpd) $ ) to a disjoint union of groupoids with a single object (prop. below).
In particular groupoid representations are equivalently just tuples of group representations (prop. below.)
This is the reason why the competition between general topology textbooks that do and that do not prefer the fundamental groupoid over the fundamental group remains inconclusive.
However, this equivalence of groupoids with disjoint unions of groups depends on the axiom of choice.
Even if this is assumed in the underlying foundations/set theory, it breaks once one considers groupoids equipped with geometric structure: Just as one may consider topological groups and Lie groups, etc., there are the evident concepts of topological groupoids and Lie groupoids etc.
(generally: internal groupoids).
Their theory turns out to be genuinely richer than that of their group analogs, due to the interaction between the geometry and the homotopy theory ("higher geometry").
The correct concept of homomorphisms between Lie groupoids for instance goes by many names, including Morita morphisms, Hilsum - Skandalis morphisms and bibundles.
The general way to understand this and all other geometric groupoid theory is via the concept of stacks of groupoids.
For more pointers on this see at higher geometry and for introduction in the case of higher differential geometry see at geometry of physics - - smooth homotopy types.
A small groupoid $ mathcal{G} $ is a space or homotopy type such that for all points $ a $ and $ b $ in $ mathcal{G} $ , all paths $ c $ and $ d $ in the path space (type) $ a = b $ , all homotopies (2 - paths) $ e $ and $ f $ in the path space type $ c = d $ , the path space type $ e = f $ is contractible.
A small groupoid $ mathcal{G} $ is (i) a set $ X $ , to be called the set of objects; (i) for all pairs of objects $ (x, y) in X times X $ a set $ Hom(x, y) $ , to be called the set of morphisms with domain or source $ x $ and codomain or target $ y $ ; (i) for all triples of objects $ (x, y, z) in X times X times X $ a function $ circ{x, y, z} ;colon; Hom(y, z) times Hom(x, y) longrightarrow Hom(x, z) $ to be called composition (i) for all objects $ x in X $ an element $ idx in Hom(x, x) $ to be called the identity morphism on $ x $ ; (i) for all pairs $ (x, y) in X times X $ of objects a function $ ( - )^{ - 1} ;colon; Hom(x, y) longrightarrow Hom(y, x) $ to be called the inverse - assigning function such that (i) (associativity) for all quadruples of objects $ x1, x2, x3, x4 in X $ and all triples of morphisms $ f in Hom(x1, x2) $ , $ g in Hom(x2, x3) $ and $ h in Hom(x3, x4) $ an equality $ h circ (g circ f) ;=; (h circ g) circ f $ (i) (unitality) for all pairs of objects $ x, y in X $ and all moprhisms $ f in Hom(x, y) $ equalities $ idy circ f = f phantom{AAAA} f circ idx = f $ (i) (invertibility) for all pairs of objects $ x, y in X $ and every morphism $ f in Hom(x, y) $ equalities $ f^{ - 1}circ f = id{x} phantom{AAAA} f circ f^{ - 1} = idy , $ .
If $ mathcal{G}1, mathcal{G}2 $ are two groupoids, then a homomorphism or functor between them, denoted $ F ;colon; mathcal{G}1 longrightarrow mathcal{G}2 $ is (i) a function $ F0 ;colon; X1 longrightarrow X2 $ between the respective sets of objects; (i) for each pair $ x, y in X1 $ of objects a function
$ F{x, y} ;colon; Hom{mathcal{G}1}(x, y) longrightarrow Hom{mathcal{G}2}(F0(x), F0(y)) $ between sets of morphisms such that (i) (respect for composition) for all triples $ x, y, z in X1 $ and all $ f in Hom(x, y) $ and $ g in Hom(y, z) $ an equality $ F{y, z}(g) circ2 F{x, y}(f) ;=; F{x, z}(gcirc1 f) $ (i) (respect for identities) for all $ x in X $ an equality $ F{x, x}(idx) = id{F0(x)} , $ .
For $ mathcal{G}1, mathcal{G}2 $ two groupoids, and for $ F, G ;colon; mathcal{G}1 to mathcal{G}2 $ two groupoid homomorphisms/functors, then a conjugation or homotopy or natural transformation (necessarily a natural isomorphism) $ eta ;colon; F Rightarrow G $ is such that $ etay circ2 F(f) = G(f) circ etax phantom{AAAAAA} array{ F(x) &overset{etax}{longrightarrow}& G(x) {}^{mathllap{F(f)}}downarrow && downarrow^{mathrlap{G(f)}} F(y) &underset{etay}{longrightarrow}& G(y) } $ For $ mathcal{G}1, mathcal{G}2 $ two groupoids and $ F, G, H colon mathcal{G}1 longrightarrow mathcal{G}2 $ three functors between them and $ eta1 ;colon; F Rightarrow G $ and $ eta2 ;colon; G Rightarrow H $ conjugation actions/natural isomorphisms between these, there is the composite $ eta2 circ eta1 ;colon; F Rightarrow H $ with components the composite of the components $ (eta2 circ eta1)(x) coloneqq eta2(x) circ eta1(x) , $ .
This yields for any two groupoid a hom - groupoid $ Hom{Grpd}(mathcal{G}1, mathcal{G}2) $ whose objects are the groupoid homomorphisms / functors, and whose morphisms are the conjugation actions / natural transformations.
A small groupoid (def. ) is equivalently a small dagger category in which all morphisms are unitary.
A small groupoid (def. ) is equivalently a small category in which all morphisms are isomorphisms.
Due to the two preceding remarks, groupoid theory may be regarded as a special case of dagger category theory or category theory, it is noteworthy that the two theories are quite different in character.
For example higher groupoid theory is homotopy theory which is rich but quite tractable, for instance via tools such as simplicial homotopy theory or homotopy type theory, while higher category theory and higher dagger category theory is intricate and becomes tractable mostly by making recourse to higher groupoid theory in the guise of (infinity, 1) - category theory and (infinity, n) - categories.
A small groupoid $ mathcal{G} $ is (i) a set $ G0 $ called its set of objects; (i) a set $ G1 $ called its set of morphisms or set of arrows (i) a pair of functions $ s, t ;colon; G1 rightrightarrows G0 $ called source and target or domain and codomain (an element $ gin G1 $ is denoted by $ s(g) overset{g}{longrightarrow} t(g) $ ); (i) a multiplication or composition map $ m colon G1 times{s, G0, t} G1 to G1 $ , usually denoted as $ g h $ for $ m(g, h) $ , which satisfies (i) $ s(g h)=s(h) $ , $ t(g h)=t(g) $ , and (i) associativity: $ (g h)k=g(h k) $ , (i) identity section: $ e: G0to G1 $ , such that $ e(t(g))g=g=ge(s(g)) $ (in particular, $ scirc e= t circ e $ ), (i) inverse, $ i: G1 to G1 $ , also denoted by $ i(g)=g^{ - 1} $ , such that for all $ gin G $ , $ g^{ - 1} g = e(s(g)), quad g g^{ - 1} = e(t(g)) $ .
If $ x, y $ are objects (also called vertices) of the groupoid $ G $ then the set of morphisms (also called arrows) from $ x $ to $ y $ is written $ G(x, y) $ , or other notations for hom - sets.
The set $ G(x, x) $ (which is a group under composition) is also written $ G(x) $ and called the vertex group of $ G $ at $ x $ .
It is also written $ AutG(x) $ and called the automorphism group of $ x $ in $ G $ , or written $ pi1(G, x) $ and called the fundamental group of $ G $ at $ x $ (especially if you think of a groupoid as giving a homotopy 1 - type).
As in any category, there is a question of notation for the composition, and in particular of the order in which to write things.
It can be more convenient to write the composition of $ a:x to y $ and $ b: y to z $ as $ a b:x to z $ , although a more traditional notation would be $ b a $ .
The two conventions can be distinguished by writing $ a; b $ or $ bcirc a $ (which is the most traditional notation for categories).
See composition for further discussion.
A groupoid $ G $ is connected, or transitive, if $ G(x, y) $ is nonempty for all $ x, y in Ob(G) $ ; it is called inhabited, or nonempty, if it has at least one object.
A maximal inhabited connected subgroupoid of $ G $ is called a component of $ G $ , and $ G $ is then the disjoint union (the coproduct in $ Grpd $ ) of its connected components.
The set of components of $ G $ is written $ pi0(G) $ (especially if you think of a groupoid as giving a homotopy 1 - type).
A groupoid is called tame if its groupoid cardinality is finite.
{CategoriesOfGroupoids} From def.
we see that there is a category whose But since this 1 - category does not reflect the existence of homotopies/natural isomorphisms between homomorphsims/functors of groupoids (def. )
this 1 - category is not what one is interested in when considering homotopy theory/higher category theory.
In order to obtain the right notion of category of groupoids that does reflect homotopies, we first consider now the horizontal composition of homotopies/natural transformations.
Let $ mathcal{G}1 $ , $ mathcal{G}2 $ , $ mathcal{G}3 $ , $ mathcal{G}4 $ be groupoid and let $ mathcal{G}1 overset{F1}{longrightarrow} mathcal{G}2 underoverset {underset{phantom{AA}F2phantom{AA}}{longrightarrow}} {overset{phantom{AA}F^{'}2phantom{AA}}{longrightarrow}} {Downarrow{mathrlap{eta}}} mathcal{G}3 overset{F3}{longrightarrow} mathcal{G}4 $ be morphisms and a homotopy $ eta $ .
Then there is a homotopy $ mathcal{G}1 phantom{AAAA} underoverset {underset{F3 circ F2circ F1}{longrightarrow}} {overset{F3 circ F^{'}2circ F1}{longrightarrow}} {Downarrow{mathrlap{ F3 cdot eta cdot F1 }}} phantom{AAAA}mathcal{G}2 $ between the respective composites, with components given by $ (F3 cdot eta cdot F1)(x) ;coloneqq; F3(eta(F1(x))) , $ .
This operation constitutes a groupoid homomorphism/functor $ F3cdot ( - )cdot F1 ;colon; Hom{Grpd}(mathcal{G}2, mathcal{G}3) longrightarrow Hom{Grp}(mathcal{G}1, mathcal{G}4) , $ .
The respect for identities is clear.
To see the respect for composition, let $ mathcal{G}2 array{ overset{F}{longrightarrow} Downarrow eta1 overset{G}{longrightarrow} Downarrow eta2 underset{H}{longrightarrow} } mathcal{G}3 $ be two composable homotopies.
We need to show that $ F3 cdot (eta2 circ eta1) cdot F1 = ( F3 cdot eta2 cdot F1 ) circ ( F3 cdot eta1 cdot F1 ) , $ .
Now for $ x $ any object of $ mathcal{G}1 $ we find $ (F3 cdot (eta2 circ eta1) cdot F1)(x) & coloneqq F2((eta2 circ eta1)(F1(X))) & coloneqq F3( eta2(F1(x)) circ eta1 (F1(x))) &= F2( eta2(F1(x)) ) circ F2( eta1(F1(X)) ) & = (( F3 cdot eta2 cdot F1 ) circ ( F3 cdot eta1 cdot F1 ))(x) , $ .
Here all steps are unwinding of the definition of horizontal and of ordinary (vertical) composition of homotopies, except the third equality, which is the functoriality of $ F2 $ .
Consider a diagram of groupoids, groupoid homomorphsims (functors) and homotopies (natural transformations) as follows: $ mathcal{G}1 underoverset {underset{phantom{AA}F'1phantom{AA}}{longrightarrow}} {overset{phantom{AA}F1phantom{AA}}{longrightarrow}} {Downarrow {eta1}} mathcal{G}2 underoverset {underset{phantom{AA}F'2phantom{AA}}{longrightarrow}} {overset{phantom{AA}F2phantom{AA}}{longrightarrow}} {Downarrow {eta2}} mathcal{G}3 $ The horizontal composition of the homotopies to a single homotopy of the form $ mathcal{G}1 underoverset {underset{F'2 circ F'1}{longrightarrow}} {overset{F2circ F1}{longrightarrow}} {Downarrow eta2 cdot eta1} mathcal{G}3 $ may be defined in temrs of the horizontal composition of homotopies with morphisms (lemma ) and the ("vertical") composition of homotopies with themselves, in two different ways, namely by decomposing the above diagram as $ array{ mathcal{G}1 underoverset {underset{phantom{AA}F'1phantom{AA}}{longrightarrow}} {overset{phantom{AA}F1phantom{AA}}{longrightarrow}} {Downarrow {eta1}} mathcal{G}2 underoverset {} {overset{phantom{AA}F2phantom{AA}}{longrightarrow}} {} mathcal{G}3 mathcal{G}1 underoverset {underset{phantom{AA}F'1phantom{AA}}{longrightarrow}} {} {} mathcal{G}2 underoverset {underset{phantom{AA}F'2phantom{AA}}{longrightarrow}} {overset{phantom{AA}F2phantom{AA}}{longrightarrow}} {Downarrow {eta2}} mathcal{G}3 } $ or as $ array{ mathcal{G}1 underoverset {} {overset{phantom{AA}F1phantom{AA}}{longrightarrow}} {} mathcal{G}2 underoverset {underset{phantom{AA}F'2phantom{AA}}{longrightarrow}} {overset{phantom{AA}F2phantom{AA}}{longrightarrow}} {Downarrow {eta2}} mathcal{G}3 mathcal{G}1 underoverset {underset{phantom{AA}F'1phantom{AA}}{longrightarrow}} {overset{phantom{AA}F1phantom{AA}}{longrightarrow}} {Downarrow {eta1}} mathcal{G}2 underoverset {underset{phantom{AA}F'2phantom{AA}}{longrightarrow}} {} {} mathcal{G}3 } $ In the first case we get $ eta2 cdot eta1 ;coloneqq; (eta2 cdot F'1) circ (F2 cdot eta1) $ while in the second case we get $ eta2 cdot eta1 ;coloneqq; ( F'2 cdot eta1 ) circ (eta2 cdot F1) , $ .
These two definitions coincide.
For $ x $ an object of $ mathcal{G}1 $ , then we need that the following square diagram commutes in $ mathcal{G}3 $ $ array{ F2(F1(x)) &overset{ (F2cdot eta1)(x) }{longrightarrow}& F2(F'1(x)) {}^{mathllap{ (eta2 cdot F1)(x) }}downarrow && downarrow^{mathrlap{ (eta2cdot F'1)(x) }} F'2(F1(x)) & underset{ (F'2 cdot eta1)(x) }{longrightarrow} & F'2(F'1(y)) } phantom{AAAA} = phantom{AAAA} array{ F2(F1(x)) &overset{F2(eta1(x))}{longrightarrow}& F2(F'1(x)) { }^{mathllap{eta2(F1(x))}}downarrow && downarrow^{mathrlap{ eta2(F'1(x)) }} F'2(F1(x)) & underset{F'2(eta1(x))}{longrightarrow} & F'2(F'1(y)) } , $ .
But the ommutativity of the square on the right is the defining compatibility condition on the components of $ eta2 $ applied to the morphism $ eta1(x) $ in $ mathcal{G}_2 $ .
Consider groupoids, homomorphisms and homotopies of the form $ mathcal{G}1 underoverset {underset{F'1}{longrightarrow}} {overset{F1}{longrightarrow}} {Downarrow eta1} mathcal{G}2 phantom{AAAAAAA} mathcal{G}3 underoverset {underset{F'3}{longrightarrow}} {overset{F3}{longrightarrow}} {Downarrow eta3} mathcal{G}4 , $ .
Then horizontal composition with the homotopies (lemma ) constitutes a natural transformation between the functors of horizontal composition with morphisms (lemma ) $ ( eta3cdot ( - )cdot eta1 ) ;colon; ( F3 cdot ( - )cdot F1 ) ;Rightarrow; ( F'3 ( - ) cdot F'1 ) ;colon; Hom{Grpd}(mathcal{G}2, mathcal{G}3) longrightarrow Hom{Grpd}(mathcal{G}1, mathcal{G}4) , $ .
By lemma .
It first of all follows that the following makes sense There is also the homotopy category $ Ho(Grpd) $ whose This is usually denoted $ Ho(Grpd) $ .
Of course what the above really means is that, without quotienting out homotopies, groupoids form a 2 - category, in fact a (2, 1) - category, in fact an enriched category which is enriched over the naive 1 - category of groupoids from remark , hece a strict 2 - category with hom - groupoids.
Given two groupoids $ mathcal{G}1 $ and $ mathcal{G}2 $ , then a homomorphism $ F;colon; mathcal{G}1 longrightarrow mathcal{G}2 $ is an equivalence if it is an isomorphism in the homotopy category $ Ho(Grpd) $ (def. ), hence if there exists a homomorphism the other way around $ G ;colon; mathcal{G}2 longrightarrow mathcal{G}1 $ and a homotopy/natural transformations of the form $ G circ F simeq id{mathcal{G}1} phantom{AAAA} F circ G simeq id{mathcal{G}2} , $ .
Given a groupoid $ mathcal{G} $ with set of objects $ X $ , then the relation "there exists a morphism from $ x $ to $ y $ ", i.e $ . (xsim y) ;coloneqq; left( Hom(x, y) neq emptyset right) $ is clearly an equivalence relation on $ X $ .
The corresponding set of equivalence classes is denoted $ pi0(mathcal{G}) $ and called the set of connected components of $ mathcal{G} $ .
Given a groupoid $ mathcal{G} $ and an object $ x $ , then under composition the set $ Hom{mathcal{G}}(x, x) $ forms a group.
This is called the automorphism group $ Aut{mathcal{G}}(x) $ or vertex group or isotropy group of $ x $ in $ mathcal{G} $ .
Let $ mathcal{G}1 $ and $ mathcal{G}2 $ be groupoids.
Then a morphism (functor) $ F ;colon; mathcal{G}1 longrightarrow mathcal{G}2 $ is called a weak homotopy equivalence if (i) it induces a bijection on connected components (def. ): $ pi0(F) ;colon; pi0(mathcal{G}1) overset{simeq}{longrightarrow} pi0(mathcal{G}2) $ (i) for each object $ x $ of $ mathcal{G}1 $ the morphism $ F{x, x} ;colon; Aut{mathcal{G}1}(x) overset{simeq}{longrightarrow} Aut{mathcal{G}2}(F0(x)) $ is an isomorphism of automorphism groups (def. )
Let $ mathcal{G} $ be a groupoid.
Then: A linear representation of $ mathcal{G} $ is a groupoid homomorphism (functor) $ rho ;colon; mathcal{G} longrightarrow Core(Vect) $ to the groupoid core of the category Vect of vector spaces (example ).
Hence this is (i) For each object $ x $ of $ mathcal{G} $ a vector space $ Vx $ ; (i) for each morphism $ x overset{f}{longrightarrow} y $ of $ mathcal{G} $ a linear map $ rho(f) ;colon; Vx to Vy $ such that (i) (respect for composition) for all composable morphisms $ x overset{f}{to}y overset{g}{to} z $ in the groupoid we have an equality $ rho(g) circ rho(f) = rho(g circ f) $ (i) (respect for identities) for each object $ x $ of the groupoid we have an equality $ rho(idx) = id{Vx} , $ .
Similarly a permutation representation of $ mathcal{G} $ is a groupoid homomorphism (functor) $ rho ;colon; mathcal{G} longrightarrow Core(Set) $ to the groupoid core of Set.
Hence this is (i) For each object $ x $ of $ mathcal{G} $ a set $ Sx $ ; (i) for each morphism $ x overset{f}{longrightarrow} y $ of $ mathcal{G} $ a function $ rho(f) ;colon; Sx to Sy $ such that composition and identities are respected, as above.
For $ rho1 $ and $ rho2 $ two such representations, then a homomorphism of representations $ phi ;colon; rho1 longrightarrow rho2 $ is a natural transformation between these functors, hence is $ (V1)x overset{phi(x)}{longrightarrow} (V2)x $ we have $ phi(y) circ rho1(f) = rho2(x) circ phi(x) phantom{AAAAAA} array{ (V1)x &overset{phi(x)}{longrightarrow}& (V2)x {}^{mathllap{rho1(f)}}downarrow && downarrow^{mathrlap{phi2(f)}} (V1)y &underset{phi(y)}{longrightarrow}& (V2)y } $ Representations of $ mathcal{G} $ and homomorphisms between them constitute a category, called the representation category $ Rep{Grpd}(mathcal{G}) $ .
Let $ X $ be a topological space.
For $ x, y in X $ two points, write $ P{x, y}X $ for the set of paths in $ X $ from $ x $ to $ y $ .
Consider the equivalence relation "homotopy relative boundary" on this set and write $ Hom(x, y) coloneqq (P{x, y}X)/simeq $ for the set of equivalence classes under this relation.
The concatenation of paths descends to these equivalence classes.
This yields a groupoid with set of objects the set $ X $ of points in the topological space.
This is the called the fundamental groupoid $ Pi1(X) $ of $ X $ .
This construction extends to a functor $ Pi1 ;colon; Top longrightarrow Grpd1 $ from the 1 - category Top to the 1 - category Grpd.
In fact it extends to a functor $ Pi1 ;colon; Ho(Top) longrightarrow Ho(Grpd) $ on homotopy categories.
If $ X $ and $ Y $ are topological spaces and $ f ;colon; X longrightarrow Y $ is a continuous function between them, then this induces a groupoid homomorphism (functor) between the respective fundamental groupoids (def. ) $ Ff ;colon; Pi1(X) longrightarrow Pi1(Y) $ given on objects by the underlying function of $ f $ $ (Ff)0 coloneqq f $ and given on the class of a path by the evident postcomposition with $ f $ $ (Ff){x, y} ;colon; (x overset{gamma}{longrightarrow} y) ;mapsto; (f(x) overset{f circ gamma}{longrightarrow} f(y) ) , $ .
This construction clearly respects identity morphisms and composition and hence is itself a functor of the form $ Pi1 ;colon; Top longrightarrow Grpd1 $ from the category Top of topological space to the 1 - category Grpd of groupoids.
But more is true: If $ f, g ;colon; X longrightarrow Y $ are two continuous function and $ eta ;colon; f Rightarrow g $ is a left homotopy between them, hence a continuous function $ eta ;colon; X times 0, 1 longrightarrow Y $ such that $ eta( - , 0) = f $ and $ eta( - , 1) = g $ , then this induces a homotopy between the above groupoid homomorphisms (a natural transformation of functors).
This shows that the fundamental groupoid functor in fact descends to homotopy categories $ Pi1 ;colon; Ho(Top) longrightarrow Ho(Grpd) , $ .
(In fact this means it even extends to a (2, 1) - functor from the (2, 1) - category of topological spaces, continuous functions, and higher homotopy - classes of left homotopues, to that of groupoids.)
As a direct consequence it follows that if there is a homotopy equivalence $ X simeqh Y $ between topological spaces, then there is an induced equivalence of groupoids betwee their fundamental groupoids
$ Pi1(X) simeq Pi1(Y) , $ .
Hence the fundamental groupoid is a homotopy invariant of topological spaces.
Of course by prop.
the fundamental groupoid is equivalent, as a groupoid, to the disjoint union of the deloopings of all the fundamental groups of the given topological spaces, one for each connected component, and hence this is equivalently the statement that the set of connected components and the fundamental groups of a topological space are homotopy invariants.
For $ X $ any set, there is the discrete groupoid $ Disc(X) $ , whose set of objects is $ X $ and whose only morphisms are identity morphisms.
This is also the fundamental groupoid (example ) of the discrete topological space on the set $ X $ .
For $ X $ any set, there is the codiscrete groupoid $ Codisc(X) $ , whose set of objects is $ X $ and whose homsets are singletons.
In other words, it is a groupoid where every object is uniquely isomorphic to every object.
Let $ G $ be a group.
Then there is a groupoid, denoted $ B G $ , with a single object $ p $ , with morphisms $ Hom{B G}(p, p) coloneqq G $ the elements of $ G $ , with composition the multiplication in $ G $ , with identity morphism the neutral element in $ G $ and with inverse morphisms the inverse elements in $ G $ .
This is also called the delooping of $ G $ (because the loop space object of $ B G $ at the unique point is the given group: $ Omega B G simeq G $ ).
For $ G1, G2 $ two groups, then there is a natural bijection between group homomorphisms $ phi colon G1 to G2 $ and groupoid homomorphisms $ B G1 to B G2 $ : the latter are all of the form $ B phi $ , with $ (B phi)0 $ uniquely fixed and $ (B phi){p, p} = phi $ .
This means that the construction $ B( - ) $ is a fully faithful functor $ B( - ) ;colon; Grp hookrightarrow Grpd1 $ into from the category Grp of groups to the 1 - category of groupoids.
But beware that this functor is not fully faithful when homotopies of groupoids are taken into acount, because there are in general non - trivial homotopies between morphims of the form $ B phi1, B phi2 ;colon; B G longrightarrow B H $ By definition, such a homotopy (natural transformation) $ eta ;colon; B phi1 Rightarrow B phi2 $ is a choice of a single elemet $ etap in H $ such that for all $ g in G $ we have $ phi2(g) = h cdot phi1(g) cdot h^{ - 1} phantom{AAAAAAAAA} array{ p &overset{h}{longrightarrow}& p {}^{mathllap{phi1(g)}}downarrow && downarrow^{mathrlap{phi2(g)}} p &underset{h}{longrightarrow}& p } $ hence such that $ phi2 = Adh circ phi1 , $ .
Therefore notably the induced functor $ B( - ) ;colon; Grp longrightarrow Ho(Grp) $ to the homotopy category of groupoids is not fully faithful.
But since $ B G $ is canonically a pointed object in groupoids, we may also regard delooping as a functor $ B( - ) ;colon; Grp longrightarrow Grpd^{ast/} $ to the category of pointed objects of Grpd.
Since groupoid homomorphisms $ B G1 to B G2 $ necessarily preserve the basepoint, this makes no difference at this point.
But as we now pass to the homotopy category $ B( - ) ;colon; Grp hookrightarrow Ho(Grpd^{ast/}) $ then also the homotopies are required to preserve the basepoint, and for homotopies between homomorphisms between delooped groups this means, since there only is a single point, that these homotopies are all trivial.
Hence regarded this way the functor is a fully faithful functor again, hence an equivalence of categories onto its essential image.
By prop.
below this essential image consists precisely of the (pointed) connected groupoids: Groups are equivalently pointed connected groupoids.
Let $ {mathcal{G}i } {i in I} $ be a set of groupoids.
Then their disjoint union (coproduct) is the groupoid $ underset{i in I}{sqcup} mathcal{G}i $ whose set of objects is the disjoint union of the sets of objects of the summand groupoids, and whose sets of morphisms between two objects is that of $ mathcal{G}i $ if both objects are form this groupoid, and is empty otherwise.
Let $ {Gi } {i in I} $ be a set of groups.
Then there is a groupoid $ underset{i in I}{sqcup} B Gi $ which is the disjoint union groupoid (example ) of the delooping groupoids $ B Gi $ (example ).
Its set of objects is the index set $ I $ , and $ Hom(i, j) = left{ array{ Gi &vert& i = j emptyset &vert& text{otherwise} } right $ .
For $ mathcal{C} $ any (small) category, then there is a maximal groupoid inside $ Core(mathcal{C}) hookrightarrow mathcal{C} $ sometimes called the core of $ mathcal{C} $ .
This is obtained from $ mathcal{C} $ simply by discarding all those morphisms that are not isomorphisms.
For instance For $ mathcal{C} $ FinSet then the skeleton of this groupoid (prop. ) is the disjoint union of deloopings (example ) of all the symmetric groups: $ Core(FinSet) simeq underset{n in mathbb{N}}{sqcup} Sigma(n) $ For $ mathcal{C} = $ FinVect then the skeleton of this groupoid is the disjoint union of delooping of all the general linear groups $ Core(FinVect) simeq underset{n in mathbb{N}}{sqcup} GL(n) , $ .
If $ B G $ is the delooping groupoid of a group $ G $ (example ), then a groupoid representation of $ B G $ according to def. is equivalently a group representation of the group $ G $ : $ Rep{Grpd}(B G) simeq Rep(G) , $ .
Here is some further examples that should be merged into the above text.
(iii) From any action of a group $ H $ on a set $ X $ we obtain an action groupoid or "weak quotient"
$ X/ !! /H $ .
This is also written $ X rtimes H $ , a semidirect product, since it is a special case of the semidirect product of an action of a groupoid on a groupoid.
If $ X={ } $ this gives the groupoid $ mathbf{B}H $ , above.
(iv) A symmetric proset, that is a set $ X $ equipped with an equivalence relation $ E $ , becomes a groupoid with the multiplication $ (x, y);(y, z) = (x, z) $ for all $ (x, y), (y, z) in E $ .
(This gives one reason for the forward notation for composition.)
Such a groupoid is equivalent to the discrete category on the quotient set $ X/E $ .
(v) In particular, if $ E $ is the universal relation $ X times X $ , then we get the square groupoid $ X^2 $ , also called the trivial groupoid on $ X $ .
Despite the latter name, there is an important special case, namely the groupoid $ I= {0, 1 } ^2 $ .
This groupoid has non - identity elements $ iota:0 to 1, iota^{ - 1}: 1 to 0 $ , and can be regarded as a groupoid model of the unit interval $ 0, 1 $ in topology.
(vi) More generally, if we choose some subset $ S $ of the points of a space $ X $ , then we have a full subgroupoid of $ pi1(X) $ containing only those points in $ S $ , denoted $ pi1(X, S) $ .
This can result in much more manageable groupoids; for instance $ Pi1(0, 1, {0, 1 } ) $ is the groupoid $ I $ considered above, while $ Pi1(0, 1) $ has uncountably many objects (but is equivalent to $ I $ ).
(vii) If $ Gamma $ is a directed graph or quiver, then the free groupoid $ F(Gamma) $ is well defined.
It is the left adjoint functor to the forgetful functor from groupoids to directed graphs.
This shows an advantage of groupoids: the notion of free equivalence relation or free action groupoid does not easily make sense.
But we can still talk of a presentation of an equivalence relation or action groupoid by generators and relations, by considering presentations of groupoids instead.
(viii) A paper by &381;ivaljevi&263; gives examples of groupoids used in combinatorics.
(ix) The book "Topology and Groupoids" listed below takes the view that 1 - dimensional homotopy theory, including the Seifert - van Kampen Theorem, the theory of covering spaces, and the less well known theory of the fundamental group(oid) of an orbit space by a discontinuous group action, is best presented using the notion of groupoid rather than group as basic.
This had led in the 1960s to the question of the prospective use of (strict) groupoids in higher homotopy theory.
One answer is given in the book Nonabelian algebraic topology.
{Properties} {PropertiesEquivalencesOfGroupoids} For $ mathcal{G} $ a groupoid, let $ x $ and $ y $ be two objects in the same connected component (def. ).
Then there is a group isomorphism $ Aut{mathcal{G}}(x) simeq Aut{mathcal{G}}(y) $ between their automorphism groups (def. ).
By assumption, there exists some morphism from $ x $ to $ y $ $ x overset{f}{longrightarrow} y , $ .
The operation of conjugation with this morphism $ array{ Aut_{mathcal{G}}(x) &overset{Ad_{f}}{longrightarrow}& Aut_{mathcal{G}}(y) g &mapsto& f^{ - 1} circ g circ f } $ is clearly a group isomorphism as required.
Let $ {Gi } {i in I} $ and $ {Hj } {j in J} $ be sets of groups and consider a homomorphism (functor) $ F ;colon; underset{i in I}{sqcup} G_i longrightarrow underset{j in J}{sqcup} H_j $ between the corresponding disjoint unions of delooping groupoids (example ).
Then the following are equivalent: (i) $ F $ is an equivalence of groupoids (def. ); (i) $ F $ is a weak homotopy equivalence (def. ).
The implication 2) $ Rightarrow 1) $ is immediate.
In the other direction, assume that $ F $ is an equivalence of groupoids, and let $ G $ be an inverse up to natural isomorphism.
It is clear that both induces bijections on connected components.
To see that both are isomorphisms of automorphisms groups, observe that the conditions for the natural isomorphisms $ alpha ;colon; G circ F Rightarrow id phantom{AAAA} beta ;colon; F circ G Rightarrow id $ are in each separate delooping groupoid $ B H_j $ of the form $ array{ ast &overset{alpha}{longrightarrow}& ast {}^{mathllap{G{F0(i), F0(i)}(F{i, i}(f))}}downarrow && downarrow^{mathrm{id}} ast &underset{alpha}{longrightarrow}& ast } phantom{AAAAAAAAAAAAAAAAAAAAA} array{ ast &overset{beta}{longrightarrow}& ast {}^{mathllap{F{G0(j), G0(j)}(G{j, j}(f))}}downarrow && downarrow^{mathrm{id}} ast &underset{beta}{longrightarrow}& ast } $ since there is only a single object.
But this means $ F{i, i} $ and $ F{j, j} $ are group isomorphisms.
Assuming the axiom of choice, then: For $ mathcal{G} $ any groupoid, then there exists a set $ {Gi } {i in I} $ of groups and an equivalence of groupoids (def. ) $ mathcal{G} simeq underset{i in I}{sqcup} B G_i $ between $ mathcal{G} $ and a disjoint union of delooping groupoids (example ).
This is called a skeleton of $ mathcal{G} $ .
Concretely, this exists for $ I = pi0(mathcal{G}) $ the set of connected components of $ mathcal{G} $ (def. ) and for $ Gi coloneqq Aut_{mathcal{G}}(x) $ the automorphism group (def. ) of any object $ x $ in the given connected component.
Using the axiom of choice we may find a set $ {xi } {i in pi0(mathcal{G})} $ of objects of $ mathcal{G} $ , with $ xi $ being in the connected component $ i in pi_0(mathcal{G}) $ .
This choice induces a functor $ inc ;colon; underset{i in pi0(mathcal{G})}{sqcup} Aut{mathcal{G}}(x_i) longrightarrow mathcal{G} $ which takes each object and morphism "to itself".
Now using the axiom of choice once more, we choose in each connected component $ i in pi_0(mathcal{G}) $ and for each object $ y $ in that connected component a morphism $ xi overset{f{x_i, y}}{longrightarrow} y , $ .
Using this we obtain a functor the other way around $ p ;colon; mathcal{G} longrightarrow underset{i in pi0(mathcal{G})}{sqcup} Aut{mathcal{G}}(x_i) $ which sends each object to its connected component, and which for pairs of objects $ y $ , $ z $ of $ mathcal{G} $ is given by conjugation with the morphisms choosen above: $ array{ Hom{mathcal{G}}(y, z) &overset{p{y, z}}{longrightarrow}& & Aut{mathcal{G}}(xi) & y && y & overset{f{xi, y}}{longleftarrow}& x_i {}^{mathllap{f}} downarrow &mapsto& {}^{mathllap{f}}downarrow z && z & underset{f{xi, z}^{ - 1}}{longrightarrow} & x_i } , $ .
It is now sufficient to show that there are conjugations/natural isomorphisms $ p circ inc simeq id phantom{AAAA} inc circ p simeq id , $ .
For the first this is immediate, since we even have equality $ p circ inc ;=; id , $ .
For the second we observe that choosing $ eta(y) coloneqq f{xi, y} $ yields a naturality square by the above construction: $ array{ xi &overset{f{x_i, y}}{longrightarrow}& y {}^{ mathllap{ f{xi, z} circ f circ f{xi, y}^{ - 1} } }downarrow && downarrow^{mathrlap{f}} xi &underset{f{x_i, z}}{longrightarrow}& z } , $ .
Let $ F ;colon; mathcal{G}1 longrightarrow mathcal{G}2 $ be a homomorphism of groupoids.
Assuming the axiom of choice then the following are equivalent: (i) $ F $ is an equivalence of groupoids (def. ); (i) $ F $ is a weak homotopy equivalence in that (i) it induces an bijection of sets of connected components (def. ); $ pi0(F) ;colon; pi0(mathcal{G}1) overset{simeq}{longrightarrow} pi0(mathcal{G}_0) , , $ (i) for each object $ x in mathcal{G}_1 $ it induces an isomorphism of automorphism groups (def. ): $ F{x, x} ;colon; Aut{mathcal{G}1}(x) overset{simeq}{longrightarrow} Aut{mathcal{G}2}(F0(x)) , $ .
In one direction, if $ F $ has an inverse up to natural isomorphism, then this induces by definition a bijection on connected components, and it induces isomorphism on homotopy groups by lemma .
In the other direction, choose equivalences to skeleta as in prop.
to get a commuting diagram in the 1 - category of groupoids as follows: $ array{ mathcal{G}1 &underoverset{simeq}{inc1}{longleftarrow}& underset{i in pi0(mathcal{G}1)}{sqcup} Aut{mathcal{G}1}(x_i) {}^{mathllap{F}}downarrow && downarrow^{mathrlap{tilde F }} mathcal{G}2 &underoverset{inc2}{simeq}{longleftarrow}& underset{i in pi0(mathcal{G}1)}{sqcup} Aut{mathcal{G}2}(F0(xi)) } , $ .
Here $ inc1 $ and $ inc2 $ are equivalences of groupoids by prop. .
Moreover, by assumption that $ F $ is a weak homotopy equivalence $ tilde F $ is the union of of deloopings of isomorphisms of groups, and hence has a strict inverse, in particular a homotopy inverse, hence is in particular an euivalence of groupoids.
In conclusion, when regarded as a diagram in the homotopy category $ Ho(Grpd) $ (def. ), the top, bottom and right moprhism of the above diagram are isomorphisms.
It follows that also $ f $ is an isomorphism in $ Ho(Grpd) $ .
But this means exactly that it is a homotopy equivalence of groupoids, by def. .
Assuming the axiom of choice then the following holds: Let $ mathcal{G} $ be a groupoid.
Then its category of groupoid representations is equivalent to the product category indexed by the set of connected components $ pi_0(mathcal{G}) $ (def. ) of group representations of the automorphism group $ Gi coloneqq Aut{mathcal{G}}(xi) $ (def. ) for $ xi $ any object in the $ i $ th connected component: $ Rep(mathcal{G}) ;simeq; underset{i in pi0(mathcal{G})}{prod} Rep(Gi) , $ .
Let $ mathcal{C} $ be the category that the representation is on.
Then by definition $ Rep(mathcal{G}) = Hom( mathcal{G} , mathcal{C} ) , $ .
Consider the injection functor of the skeleton (from lemma ) $ inc ;colon; underset{i in pi0(mathcal{G})}{sqcup} B Gi overset{}{longrightarrow} mathcal{G} , $ .
By lemma the pre - composition with this constitutes a functor $ inc^ast ;colon; Hom( mathcal{G}, mathcal{C} ) longrightarrow Hom( underset{i in pi0(mathcal{G})}{sqcup} B Gi, mathcal{C} ) $ and by combining lemma with lemma this is an equivalence of categories.
Finally, by example the category on the right is the product of group representation categories as claimed.
Groupoids $ K $ are equivalent to 1 - hypergroupoids, which are in particular 2 - coskeletal Kan complexes $ N(K) $ - - their nerves.
The objects of the groupoids are the 0 - simplices and the morphisms of the groupoid are the 1 - simplices of the Kan complex.
The composition operation $ (f, g) mapsto g circ f $ in the grouopoid is encoded in the 2 - simplices of the Kan complex $ array{ && y & {}^{mathllap{f}}nearrow &=& searrow^{mathrlap{g}} x &&underset{gcirc f}{to}&& z } , $ .
The associativity condition on the composition is exhibited by the 3 - coskeleton - property of the Kan complex.
This says that every simplicial 2 - sphere in the Kan complex has a unique filler.
With the above identification of 2 - simplices with composition operations, this means that the 2 ways $ array{ y &stackrel{g}{to}& &to& z uparrow && &nearrow& downarrow^{mathrlap{h}} {}^{mathllap{f}}uparrow &^{mathllap{g circ f}}nearrow& && downarrow x &underset{h circ (gcirc f )}{to}&&to& w } ;;; and ;;; array{ y &stackrel{g}{to}& &to& z uparrow &searrow& && downarrow^{mathrlap{h}} {}^{mathllap{f}}uparrow && &searrow^{mathrlap{hcirc g}}& downarrow x &underset{(h circ g)circ f}{to}&&to& w } $ of composing a sequence of three composable morphisms are equal $ array{ y &to& &to& z downarrow && &nearrow& downarrow downarrow &nearrow& && downarrow x &to&&to& w } ;;; stackrel{=}{to} ;;; array{ y &to& &to& z downarrow &searrow& && downarrow downarrow && &searrow& downarrow x &to&&to& w } , $ .
For handling just groupoids exclusively their description in terms of Kan complexes may be a bit of an overkill, but the advantage is that it embeds groupoids naturally in the more general context of 2 - groupoids, 3 - groupoids and eventually ∞ - groupoids.
For instance a pseudo - functor out of an ordinary groupoid into a 2 - groupoid is simply a homomorphism of the corresponding Kan complexes.
The disadvantage of the simplicial approach is the difficulty of describing multiple compositions in higher dimensions, an important idea which is quite conveniently handled cubically.
An early occurence of the concept is (see also Brandt groupoid): A motivation and introduction of the concept of groupoid and a tour of examples (including the refinement to topological groupoids and Lie groupoids) is in Further exposition: > (about groupoids in topology, notably fundamental groupoids - - not about topological groupoids) With an eye towards homotopy theory: See also:
Nostrand, New York, 1971, Reprints in Theory and Applications of Categories, 7 (2005) pp 1 - - 19(v) (web (http://www.tac.mta.ca/tac/reprints/articles/7/tr7abs.html))
A differentiable manifold is a topological space which is locally homeomorphic to a Euclidean space (a topological manifold) and such that the gluing functions which relate these Euclidean local charts to each other are differentiable functions, for a fixed degree of differentiability.
If one considers arbitrary differentiablity, then one speaks of smooth manifolds.
For a general discussion see at manifold.
Differential and smooth manifolds are the basis for much of differential geometry.
They are the analogs in differential geometry of what schemes are in algebraic geometry.
If one relaxes the condition from being locally isomorphic to a Euclidean space to admitting local smooth maps from a Euclidean space, then one obtains the concept of diffeological spaces or even smooth sets, see at generalized smooth space for more on this.
The generalization of differentiable manifolds to higher differential geometry are orbifolds and more generally differentiable stacks.
If one combines this with the generalization to smooth sets then one obtains the concept of smooth stacks and eventually smooth infinity - stacks.
Smooth manifolds form a category, SmoothManifolds.
For the traditional definition see at differentiable manifold.
In an exercise of his 1973 Perugia lectures F. William Lawvere reported a somewhat surprising observation: In the case of smooth manifolds the process of piecing together the local data can be elegantly summed up as splitting of idempotents in a category of open subsets of Euclidean spaces.
More precisely: Let $ Diff $ be the category of smooth manifolds and smooth maps, where by a "smooth manifold", we mean a finite - dimensional, second - countable, Hausdorff, $ C^infty $ manifold without boundary.
Let $ i: Open hookrightarrow Diff $ be the full subcategory whose objects are the open subspaces of finite - dimensional Cartesian spaces.
The subcategory $ i: Open hookrightarrow Diff $ exhibits $ Diff $ as an idempotent - splitting completion of $ Open $ .
By a general lemma for idempotent splittings, it suffices to prove that For the first statement, we use the fact that any manifold $ M $ can be realized as a closed submanifold of some $ mathbb{R}^n $ , and every closed submanifold has a tubular neighborhood $ U subseteq mathbb{R}^n $ .
In this case $ U $ carries a structure of vector bundle over $ M $ in such a way that the inclusion $ M hookrightarrow U $ is identified with the zero section, so that the bundle projection $ U to M $ provides a retraction, with right inverse given by the zero section.
For the second statement, assume that the origin $ 0 $ is a fixed point of $ p $ , and let $ T0(U) cong mathbb{R}^n $ be its tangent space (observe the presence of a canonical isomorphism to $ mathbb{R}^n $ ).
Thus we have idempotent linear maps $ d p(0), Id - d p(0): T0(U) to T0(U) $ where the latter factors through the inclusion $ ker ; d p(0) hookrightarrow T0(U) $ via a projection map $ pi: T_0(U) to ker ; d p(0) $ .
We have a map $ f: U to mathbb{R}^n $ that takes $ x in U $ to $ x - p(x) $ ; let $ g $ denote the composite $ U stackrel{f}{longrightarrow} mathbb{R}^n cong T_0(U) stackrel{pi}{longrightarrow} ker; d p(0) $ .
Now we make some easy observations: (i) $ Fix(p) subseteq g^{ - 1}(0) $ .
(i) The map $ p: U to U $ restricts to a map $ p: g^{ - 1}(0) to g^{ - 1}(0) $ , by idempotence of $ p $ .
(i) The derivative $ d g(0): T0(U) to T0(ker ; d p(0)) cong ker ; d p(0) $ is $ pi $ again since $ Id - d p(0) $ is idempotent.
Thus $ d g(0) $ has full rank ( $ m $ say), and so the restriction of $ g $ to some neighborhood $ V $ has $ 0 $ as a regular value, and $ g^{ - 1}(0) cap V $ is a manifold of dimension $ m $ by the implicit function theorem.
The tangent space $ T_0(g^{ - 1}(0) cap V) $ is canonically identified with
$ im(d p(0)) $ .
(i) There are smaller neighborhoods $ V'' subseteq V' subseteq V $ so that $ p $ restricts to maps $ p1, p2 $ as in the following diagram ( $ i, i', i'' $ are inclusion maps, all taking a domain element $ x $ to itself): $ array{ g^{ - 1}(0) cap V'' & stackrel{i''}{hookrightarrow} & g^{ - 1}(0) mathllap{p2} downarrow & & downarrow _mathrlap{p} g^{ - 1}(0) cap V' & stackrel{i'}{hookrightarrow} & g^{ - 1}(0) mathllap{p1} downarrow & & downarrow _mathrlap{p} g^{ - 1}(0) cap V & stackrel{i}{hookrightarrow} & g^{ - 1}(0) } $ and such that $ p1, p2 $ are diffeomorphisms by the inverse function theorem (noting here that $ d p_i(0): im(d p(0)) to im(d p(0)) $ is the identity map, by idempotence of $ p $ ).
(i) Letting $ q: g^{ - 1}(0) cap V' to g^{ - 1}(0) cap V'' $ denote the smooth inverse to $ p_2 $ , we calculate $ i' = p circ i'' circ q $ , and $ i p_1 = p i' = p p i''q = p i'' q = i', $ so that $ p_1(x) = x $ for every $ x in g^{ - 1}(0) cap V' $ .
Hence $ g^{ - 1}(0) cap V' subseteq Fix(p) $ .
From all this it follows that $ Fix(p) cap V' = g^{ - 1}(0) cap V' $ , meaning $ Fix(p) $ is locally diffeomorphic to $ mathbb{R}^m $ , and so $ Fix(p) $ is an embedded submanifold of $ mathbb{R}^n $ .
Another proof of this result may be found here.
Lawvere comments on this fact as follows: > {LawvereComment} "This powerful theorem justifies bypassing the complicated considerations of charts, coordinate transformations, and atlases commonly offered as a "basic" definition of the concept of manifold.
For example the 2 - sphere, a manifold but not an open set of any Euclidean space, may be fully specified with its smooth structure by considering any open set $ A $ in 3 - space $ E $ which contains it but not its center (taken to be $ 0 $ ) and the smooth idempotent endomap of $ A $ given by $ e(x) = x/{|x|} $ .
All general constructions (i.e., functors into categories which are Cauchy complete) on manifolds now follow easily (without any need to check whether they are compatible with coverings, etc.) provided they are known on the opens of Euclidean spaces: for example, the tangent bundle on the sphere is obtained by splitting the idempotent $ e' $ on the tangent bundle $ A times V $ of $ A $ ( $ V $ being the vector space of translations of $ E $ ) which is obtained by differentiating $ e $ .
The same for cohomology groups, etc."
(Lawvere 1989, p.267) {GeneralAbstractCharacterization} There is a fundamental and general abstract way to think of smooth manifolds, which realizes their theory as a special case of general constructions in higher geometry.
In this context one specifies for instance $ mathcal{G} $ a geometry (for structured (∞, 1) - toposes) and then plenty of geometric notions are defined canonically in terms of $ mathcal{G} $ .
The theory of smooth manifolds appears if one takes $ mathcal{G} = $ CartSp.
Alternatively one can specify differential cohesion and proceed as discussed at differential cohesion - - structures - Cohesive manifolds (separated).
This is discussed in The geometry CartSp below.
Let CartSp be the category of Cartesian spaces and smooth functions between them.
This has finite products and is in fact (the syntactic category) of a Lawvere theory: the theory of smooth algebras.
Moreover, $ CartSp $ is naturally equipped with the good open cover coverage that makes it a site.
Both properties together make it a pregeometry (for structured (∞, 1) - toposes) (if the notion of Grothendieck topology is relaxed to that of coverage in StrSp).
For $ mathcal{X} $ a topos, a product - preserving functor $ mathcal{O} : mathcal{G} to mathcal{X} $ is a $ mathcal{G} $ - algebra in $ mathcal{X} $ .
This makes $ mathcal{X} $ is $ mathcal{G} $ - ringed topos.
For $ mathcal{G} = $ CartSp this algebra is a smooth algebra in $ mathcal{X} $ .
If $ mathcal{X} $ has a site of definition $ X $ , then this is a sheaf of smooth algebras on $ X $ .
If $ mathcal{O} $ sends covering families $ {Ui to U } $ in $ mathcal{G} $ to effective epimorphism $ coprodi mathcal{O}(Ui) to mathcal{O}(U) $ we say that it is a local $ mathcal{G} $ - algebra_ in $ mathcal{X} $ , making $ mathcal{X} $ a $ mathcal{G} $ - locally ringed topos.
The big topos $ Sh(mathcal{G}) $ itself is canonically equipped with such a local $ mathcal{G} $ - algebra, given by the Yoneda embedding $ j $ followed by sheafification $ L $ $ mathcal{O} : mathcal{G} stackrel{j}{to} PSh(mathcal{G}) stackrel{L}{to} Sh(mathcal{G}) , $ .
It is important in the context of locally representable locally ringed toposes that we regard $ Sh(mathcal{G}) $ as equipped with this local $ mathcal{G} $ - algebra.
This is what remembers the site and gives a notion of local representability in the first place.
The big topos $ Sh(CartSp) $ is a cohesive topos of generalized smooth spaces.
Its concrete sheaves are precisely the diffeological spaces.
See there for more details.
We now discuss how with $ Sh(CartSp) $ regarded as a $ CartSp $ - structured topos, smooth manifolds are precisely its locally representable objects.
The representables themselves should evidently be locally representable and canonically have the structure of $ CartSp $ - structured toposes.
Indeed, every object $ U in mathrm{CartSp} $ is canonically a CartSp - ringed space, meaning a topological space equipped with a local sheaf of smooth algebras.
More generally: every object $ U in CartSp $ is canonically incarnated as the $ CartSp $ - structured (∞, 1) - topos $ (mathcal{X}, mathcal{O}_{mathcal{X}}) := (Sh_{(infty, 1)}(CartSp)/U , ;;; mathcal{O}U : CartSp stackrel{j}{to} Sh{(infty, 1)}(CartSp) stackrel{U^}{to} Sh{(infty, 1)}(CartSp)/U) $ given by the over - (∞, 1) - topos of the big (∞, 1) - sheaf (∞, 1) - topos over $ CartSp $ and the structure sheaf given by the composite of the (∞, 1) - Yoneda embedding and the inverse image of the etale geometric morphism induced by $ U $ .
Say a concrete object $ X $ in the sheaf topos $ Sh(CartSp) $ - - a diffeological space - - is locally representable if there exists a family of open embeddings $ {Ui hookrightarrow X } {i in X} $ with $ Ui in CartSp stackrel{j}{hookrightarrow} Sh(CartSp) $ such that the canonical morphism out of the coproduct $ coprodi Ui to X $ is an effective epimorphism in $ Sh(CartSp) $ .
Let $ LocRep(CartSp) hookrightarrow Sh(CartSp) $ be the full subcategory on locally representable sheaves.
There is an equivalence of categories $ Diff simeq LocRep(CartSp) $ of the category Diff of smooth manifolds with that of locally representable sheaves for the pre - geometry $ CartSp $ .
Define a functor $ Diff to LocRep(CartSp) $ by sending each smooth manifold to the sheaf over $ CartSp $ that it naturally represents.
By definition of manifold there is an open cover $ {Ui hookrightarrow X } $ .
We claim that $ coprodi Ui to X $ is an effective epimorphism, so that this functor indeed lands in $ LocRep(CartSp) $ .
(This is a standard argument of sheaf theory in Diff, we really only need to observe that it goes through over CartSp, too.)
For that we need to show that $ coprod{i, j} Ui timesX Uj stackrel{longrightarrow}{longrightarrow} coprodi Ui to X $ is a coequalizer diagram in $ Sh(CartSp) $ (that the Cech groupoid of the cover is equivalent to $ X $ .).
Notice that the fiber product here is just the intersection in $ X $ $ Ui timesX Uj simeq Ui cap Uj $ .
By the fact that the sheaf topos $ Sh(CartSp) $ is by definition a reflective subcategory of the presheaf topos $ PSh(CartSp) $ we have that colimits in $ Sh(CartSp) $ are computed as the sheafification of the corresponding colimit in $ PSh(CartSp) $ .
The colimit in $ PSh(CartSp) $ in turn is computed objectwise.
Using this, we see that that we have a coequalizer diagram $ coprod{i, j} Ui timesX Uj stackrel{longrightarrow}{longrightarrow} coprodi Ui to S({Ui } ) $ in $ PSh(CartSp) $ , where $ S({Ui } ) $ is the sieve corresponding to the cover: the subfunctor $ S({Ui } ) hookrightarrow X $ of the functor $ X : CartSp^{op} to Set $ which assigns to $ V in CartSp $ the set of smooth functions $ V to X $ that have the property that they factor through any one of the $ Ui $ .
Essentially by the definition of the coverage on $ CartSp $ , it follows that sheafification takes this subfunctor inclusion to an isomorphism.
This shows that $ X $ is indeed the tip of the coequalizer in $ Sh(CartSp) $ as above, and hence that it is a locally representable sheaf.
Conversely, suppose that for $ X in Conc(Sh(CartSp)) hookrightarrow Sh(CartSp) $ there is a family of open embeddings $ {Ui hookrightarrow X } $ such that we have a coequalizer diagram $ coprod{i, j} Ui timesX Uj stackrel{longrightarrow}{longrightarrow} coprod{i} Ui to X $ in $ Sh(CartSp) $ , which is the sheafification of the corresponding coequalizer in $ PSh(CartSp) $ .
By evaluating this on the point, we find that the underlying set of $ X $ is the coequalizer of the underlying set of the $ Ui $ in $ Set $ .
Since every plot of $ X $ factors locally through one of the $ Ui $ it follows that $ X $ is a diffeological space.
It follows that in the pullback diagrams $ array{ Ui timesX Uj &to& Uj downarrow && downarrow Ui &to& X } $ the object $ Ui cap Uj $ is the diffeological space whose underlying topological space is the intersection of $ Ui $ and $ Uj $ in the topological space underlying $ X $ .
In particular the inclusions $ Ui timesX Uj hookrightarrow Ui $ are open embeddings.
We may switch from regarding smooth manifolds as objects in the big topos $ X in Sh(CartSp) $ to regrading them as toposes themselves, by passing to the over - topos $ Sh(CartSp)/X $ .
This remembers the extra (smooth) structure on the topological space $ X $ by being canonically a locally ringed topos with the structure sheaf of smooth functions on $ X $ : a CartSp - structured (∞, 1) - toposes For every choice of geometry (for structured (∞, 1) - toposes) there is a notion of $ mathcal{G} $ - locally representable structured (∞, 1) - topos (StrSp).
Smooth manifolds are equivalently the 0 - localic CartSp - generalized schemes of locally finite presentation.
The statement says that a smooth manifold $ X $ may be identified with an ∞ - stack on CartSp (an ∞ - Lie groupoid) which is represented by a CartSp - structured (∞, 1) - topos $ (mathcal{X}, mathcal{O}{mathcal{X}}) $ such that (i) $ mathcal{X} $ is a 0 - localic (∞, 1) - topos; (i) There exists a family of objects $ {Ui in mathcal{X} } $ such that the canonical morphism $ coprodi Ui to *{mathcal{X}} $ to the terminal object in $ mathcal{X} $ is a regular epimorphism; (i) For every $ i in I $ there is an equivalence $ (mathcal{X}/Ui, mathcal{O}{mathcal{X}|Ui}) underoverset{simeq}{ti}{to} (Sh{(infty, 1)}(mathbb{R}^n), mathcal{O}(mathbb{R}^n)) , $ .
The second and third condition say in words that $ (mathcal{X}, mathcal{O}{mathcal{X}}) $ is locally equivalent to the ordinary cannonically CartSp - locally ringed space $ mathbb{R}^n $ (for $ n in mathbb{N} $ the dimension.
The first condition then says that these local identifications cover $ mathcal{X} $ .
(...) (...)
The functor $ C^infty( - ) colon SmthMfd hookrightarrow cAlg{mathbb{R}}^{op} $ (from the category of smooth manifolds to the opposite category of commutative algebras over the real numbers) that sends a smooth manifold $ X $ to its commutative $ mathbb{R} $ - algebra of smooth functions $ X to mathbb{R} $ is a fully faithful functor, hence exhibits $ SmthMfd $ as a full subcategory of $ cAlg^{op} $ .
(Kolar - Slovak - Michor 93, lemma 3(v)8, corollaries 3(v)9, 3(v)10)
For more see at embedding of smooth manifolds into formal duals of R - algebras.
The original works include Early account with an eye towards cobordism theory and the Pontrjagin - Thom isomorphism: Textbook accounts: > (with an eye towards mathematical physics)
With an eye towards application in mathematical physics: Smooth manifolds are defined as locally ringed spaces in Discussion of smooth manifolds as colimits of the Cech nerves of their good open covers is also at The general abstract framework of higher geometry referred to above is discussed in The proof that idempotents split in the category of smooth manifolds was adapted from this MO answer: Which provides a solution to exercise (iii)21 in The above comment by Lawvere is taken from >
This entry is about the term of "class function" as it is used in algebraic contexts.
(Such class functions are usually set - maps.)
For the notion of the same name in set theory see at class function (set theory).
A function on a group is a class function if it is invariant under conjugation action, i.e. it is equivalent to a function on the set of conjugacy classes.
Every group character is in particular a class function.
See also The basic concept is for vector spaces, and the remainder are defined in terms of that.
Given an ordered field $ K $ and a vector space $ V $ over $ K $ of dimension $ n $ (a natural number), an orientation of $ V $ is a choice of one of the two equivalence classes of ordered bases of $ V $ , where two bases are considered equivalent if the transformation matrix from one to the other has positive determinant.
In the case $ n = 0 $ , the only ordered basis is the empty list, but we still declare there to be two orientations by fiat, usually called positive and negative.
We can make the definition seamless by taking the elements of the equivalence class to be pairs consisting of an ordered basis and a nonzero sign (positive or negative), with $ (B1, s1) sim (B2, s2) $ iff $ sgn det I^{B1}{B2} = s1/s2 $ .
This is redundant except in dimension $ 0 $ , where now each equivalence class has a single element, $ (, +) $ for the positive orientation and $ (, - ) $ for the negative orientation (where $ * $ is the empty list).
In any case, this ensures that if $ omega $ is an orientation, then there is also an opposite orientation $ - omega $ .
A fancier way to say the same is For $ V $ a vector space of dimension $ n $ , an orientation of $ V $ is an equivalence class of nonzero elements of the line $ bigwedge^n V $ , the $ n $ th alternating power of $ V $ , where two such elements are considered equivalent when either (hence each) is a positive multiple of the other.
Note that by both definitions, an orientation of a line (with $ n = 1 $ ) is an equivalence class of nonzero elements.
Assuming that $ K $ is the field of real numbers or something like it, we can generalize from vector spaces to vector bundles: For $ X $ a manifold and $ V to X $ a vector bundle of rank $ n $ , an orientation on $ V $ is an equivalence class of trivializations of the line bundle $ bigwedge^k V $ that is obtained by associating to each fiber of $ V $ its $ k $ th alternating power.
Equivalently for a smooth manifold this is an equivalence class of an everywhere non - vanishing element of $ bigwedge^k{C^infty(X)} Gamma(V) $ , which may be considered the sign of the element.
For $ X $ a manifold of dimension $ n $ , an orientation of $ X $ is an orientation of the tangent bundle $ T X $ (or cotangent bundle $ T^ X $ ).
This is equivalently a choice of everywhere non - vanishing differential form on $ X $ of degree $ n $ ; the orientation may be considered the sign of the $ n $ - form (and the $ n $ - form's absolute value is a pseudo - $ n $ - form).
A vector space always has an orientation, but a manifold or bundle may not.
If an orientation exists, $ V $ (or $ X $ ) is called orientable.
If $ X $ is connected space and $ V $ (or $ X $ ) is orientable, then there are exactly $ 2 $ orientations; more generally, the entire bundle is orientable iff
the restriction to each connected component is orientable, and then the number of orientations is $ 2^k $ , where $ k $ is the number of orientable components.
(Or we can always say that the number of orientations is $ 2^k 0^m $ , where now $ m $ is also the number of nonorientable components.
An orientation on a Riemannian manifold $ X $ is equivalently a lift $ hat g $ of the classifying map $ g : X to mathcal{B}O(n) $ of its tangent bundle through the fist step $ S O(n) to O(n) $ in the Whitehead tower of $ X $ : $ array{ && mathcal{B}S O(n) & {}^{hat g}nearrow & downarrow X &stackrel{g}{to}& mathcal{B} O(n) } , $ .
From this perspective a choice of orientation is the first in a series of special structures on $ X $ that continue with For $ R $ an E - ∞ ring spectrum, there is a general notion of $ R $ - orientation of vector bundles.
This is described at For $ R = H(mathbb{R}) $ be the Eilenberg - MacLane spectrum for the discrete abelian group $ mathbb{R} $ of real numbers, orientation in $ R $ - cohomology is equivalent to the ordinary notion of orientation described above.
Complex conjugation is the operation on complex numbers which reverses the sign of the imaginary part, hence the function $ array{ mathbb{C} & overset{ ;;; ( - )^ast ;;; }{ longrightarrow } & mathbb{C} a + mathrm{i} b &mapsto& a - mathrm{i} b } phantom{AAAAAA} for;; a, b in mathbb{R} , $ .
More generally, the anti - involution on any star - algebra may be referred to as conjugation.
For instance one speaks of quaternionc conjugation for the analogous operation on quaternions: $ array{ mathbb{H} & overset{ ;;; ( - )^ast ;;; }{ longrightarrow } & mathbb{H} a + mathrm{i} b + mathrm{j} c + mathrm{k} d &mapsto& a - mathrm{i} b - mathrm{j} c - mathrm{k} d } phantom{AAAAAA} for;; a, b, c, d in mathbb{R} , $ .
For an unrelated (or vaguely related) notion with a similar name see at conjugacy class and adjoint action.
The symmetric difference of two sets $ A $ and $ B $ (either pure sets or subsets of some fixed set), written $ A uplus B $ (and a host of other ways), may be defined using exclusive disjunction: $ A uplus B = { x ;|; x in A ;&8891;; x in B } $ .
You can also call this exclusive union, especially if you want to use it analogously to exclusive disjunction; then the exclusive union of $ n $ sets consists of those elements $ x $ that belong to exactly one of the $ n $ sets.
The term symmetric difference, however, is usually used as the addition in a Boolean ring and so interpreted as an associative operation; then the symmetric difference of $ n $ sets consists of those elements $ x $ that belong to an odd number of the $ n $ sets.
The empty set is the identity for this operation; it is the symmetric difference (or exclusive union, for that matter) of no sets.
In constructive mathematics, the symmetic difference cannot be proved associative and so becomes less useful (unless one restricts attention to sets with decidable equality, where it can be proved associative).
This is a problem in measure theory; see Cheng measurable space for one way to fix this.
Note that the union, symmetric difference, and (internal, or external up to natural isomorphism) disjoint union of a family of (pairwise) disjoint sets are all the same.
For a family that is not disjoint, however, the union and symmetric difference are different, the internal disjoint union does not make sense, and the external disjoint union is not isomorphic to either the union or the symmetric difference (at least not naturally, and in some cases not at all).
Given a subset $ A $ of a topological space $ X $ , a point $ x in A $ is an interior point of $ A $ it it is contained in the interior of $ A $ , hence if $ A $ is a neighborhood of $ x $ in $ X $ , i.e., if there is some open subset containing $ x $ that is included in $ A $ .
For $ H hookrightarrow G $ a subgroup inclusion, its index is the number $ {vert G: Hvert} $ of $ H $ - cosets in $ G $ , hence roughly is the number of copies of $ H $ that appear in $ G $ .
For $ H hookrightarrow G $ a subgroup, its index is the cardinality $ {vert G : Hvert} coloneqq {vert G/Hvert} $ of the set $ G/H $ of cosets.
If $ H $ is a subgroup of $ G $ , the coset projection $ - H: Gto G/H $ sends an element $ g $ of $ G $ to its orbit $ gH $ .
If $ s : G/Hto G $ is a section of the coset projection $ - H: Gto G/H $ , then $ G/H times H to G $ given by $ ( g H , h )mapsto s( g H ) h^{ - 1} $ is a bijection.
Its inverse is given by the set map $ Gto G/H times H $ given by
$ gmapsto ( g H , g^{ - 1} s( g H ) ) $ .
Note that the induced product projections $ Gto G/H $ conincides with the coset projection.
This argument can be internalized to a group object $ G $ and a subgroup object $ G $ in a category $ C $ .
In this case, the coset projection $ - H: Gto G/H $ is the coequalizer of the action on $ G $ by multiplication of $ H $ .
The coset projection need not have a section.
However, in case such sections exist, each section $ s $ of the coset projection, the above argument internalized yields an isomorphism $ G/H times H overset{simeq}rightarrow G , $ .
Even more generally, if $ H hookrightarrow K hookrightarrow G $ is a sequence of subgroup objects, then each section of the projection $ G/H to G/K $ yields an isomorphism $ G/K , times , K/H stackrel{simeq}{to} G/H , $ .
Returning to the case of ordinary groups, i.e. group objects internal to $ Set $ , where the external axiom of choice is assumed to hold, the coset projection, being a coequalizer and hence an epimorphism, has a section.
This gives the multiplicative property of the indices of a sequence $ H hookrightarrow K hookrightarrow G $ of subgroups $ {vert G : Kvert} dot {vert K : Hvert} = {vert G : Hvert} , $ .
The concept of index is meaningful especially for finite groups, i.e. groups internal to FinSet.
See, for example, its role in the classification of finite simple groups.
Multiplicativity of the index has the following corollary, which is known as Lagrange's theorem: If $ G $ is a finite group, then the index of any subgroup is the quotient $ {vert G : Hvert} = frac{{vert Gvert}}{vert Hvert} $ of the order (cardinality = number of elements) of $ G $ by that of $ H $ .
Given a set $ S $ , the power set of $ S $ is the set $ mathcal{P}S $ of all subsets of $ S $ .
Equivalently, it is One generally needs a specific axiom in the foundations of mathematics to ensure the existence of power sets.
In material set theory, this can be phrased as follows: If $ S $ is a set, then there exists a set $ mathcal{P} $ such that $ A in mathcal{P} $ if $ A subseteq S $ .
One can then use the axiom of separation (bounded separation is enough) to prove that $ mathcal{P} $ may be chosen so that the subsets of $ A $ are the only members of $ mathcal{P} $ ; the axiom of extensionality proves that this $ mathcal{P} $ is unique.
Alternatively, one could include a powerset structure, a primitive unary operator $ mathcal{P}(S) $ such that for all sets $ S $ , if for all sets $ A $ and sets $ B $ , $ B in A $ implies that $ B in S $ , then $ A in mathcal{P}(S) $ .
In structural set theory, we state rather that there exists a set $ mathcal{P} $ which indexes the subsets of $ A $ and prove uniqueness up to unique isomorphism.
In predicative mathematics, the existence of power sets (along with other "impredicative" axioms) is not accepted.
However we can still speak of a power set as a proper class, sometimes called a power class.
One can use power sets to construct function sets; the converse also works using excluded middle (or anything else that will guarantee the existence of the set of truth values).
In particular, power sets exist in any theory containing excluded middle and function sets; thus predicative theories which include function sets must also be constructive $ . {|S|} lt {|mathcal{P}S|} $ in the usual arithmetic of cardinal numbers.
The power set construction gives rise to two functors, the contravariant power set functor $ Set^op to Set $ and the covariant power set functor $ Set to Set $ .
The first sends a function $ fcolon Sto T $ to the preimage function $ f^colon P(T) to P(S) $ , whereas the second sends $ f $ to the _image_ function $ f_colon P(S) to P(T) $ . category: foundational axiom
One would like to embed an abstract group into a bigger group $ K $ in which every automorphism of $ G $ is obtained by restricting (to $ G $ ) an inner automorphism of $ K $ that fixes $ G $ as a subset of $ K $ .
The holomorph is the universal (smallest) solution to this problem.
Each group $ G $ embeds into the symmetric group $ Sym(G) $ on the underlying set of $ G $ by the left regular representation $ gmapsto lg $ where $ lg(h) = g h $ .
The image is isomorphic to $ G $ (that is, the left regular representation of a discrete group is faithful).
The normalizer of the image of $ G $ in $ Sym(G) $ is called the holomorph.
The holomorph occurs very naturally as the group of arrows of the 2 - group (groupoid internal to $ Groups $ ).
<div style="float:right;margin:0 10px 10px 0;"> <img src="https://ncatlab.org/nlab/files/OpenSubsetsOfSquareInsidePlane.png" width="200">
</div> Let $ (X, tauX) $ be a topological space, and let $ Y subset X $ be a subset of its underlying set.
Then the corresponding topological subspace_ has $ Y $ as its underlying set, and its open subsets are those subsets of $ Y $ which arise as restrictions of open subsets of $ X $ (i.e. intersections of open subsets of $ X $ with $ Y $ ): $ left( U_Y subset Y, , text{open} right) , Leftrightarrow, left( underset{UX in tauX}{exists} left( UY = UX cap Y right) right) , $ .
In other words, $ tau_Y $ is the smallest topology on $ Y $ such that the inclusion $ Y hookrightarrow X $ is continuous (the initial topology on that map).
The picture on the right shows two open subsets inside the square, regarded as a topological subspace of the plane $ mathbb{R}^2 $ : > graphics grabbed from Munkres
75
The pair $ (Y, tauY) $ is then said to be a topological subspace of $ (X, tauX) $ .
The induced topology is for that reason sometimes called the subspace topology on $ Y $ .
A continuous function that factors as a homeomorphism onto its image equipped with the subspace topology is called an embedding of topological spaces.
Such a map is referred to as a subspace inclusion.
A property of topological spaces is said to be hereditary if its satisfaction for a topological space $ X $ implies its satisfaction for all topological subspaces of $ X $ .
<div style="float:right;margin:0 10px 10px 0;"> <img src="https://ncatlab.org/nlab/files/OpenSubsetsOfSquareInsidePlane.png" width="200">
</div>
The image on the right shows open subsets in the closed square $ 0, 1^2 $ , regarded as a topological subspace of the Euclidean plane {UniversalProperty} Let $ U overset{i}{longrightarrow} X $ be an injective continuous function between topological spaces.
Then this is a subspace inclusion (Def. )
precisely if it satisfies the following universal property: $ array{ Z &overset{f}{longrightarrow}& U &{}_{mathllap{i circ f}}searrow& Bigdownarrow{}^{mathrlap{i}} && X } $ The elementary proof is spelled out, for instance, in Terilla 14, theorem (i) Of course this is just another way to speak of the initial topology.
The universal characterization of Prop. lends itself to formalization via axioms for cohesion: Let $ Set underoverset {underset{coDisc}{longrightarrow}} {overset{Gamma}{longleftarrow}} {bot} Top $ be the pair of adjoint functors given by sending a topological space $ X $ to its underlying set $ Gamma(X) $ , and by equipping a set $ S $ with the codiscrete topology making it a codiscrete space $ coDisc(X) $ .
Write $ sharp ;coloneqq; coDisc circ Gamma ;colon; Top longrightarrow Top $ for the induced modal operator on Top (sharp modality).
We write $ id overset{eta^{sharp}}{longrightarrow} sharp $ for the unit morphism of this adjunction.
Notice that this means that for any topological space $ Z $ , every function of underlying sets $ Z longrightarrow sharp X $ is continuous functions, hence that continuous functions into $ sharp X $ are in natural bijection to underlying functions of sets.
This is the statement of the adjunction hom - isomorphism: $ Hom_{Top}( Z, sharp X ) ;simeq; Hom_{Set}(Gamma(Z), Gamma(X)) , $ .
Let $ U overset{i}{longrightarrow} X $ be an injective continuous function between topological spaces.
Then this is a subspace inclusion (Def. )
precisely if its naturality square of the $ sharp $ - unit (Def. ) $ array{ U &overset{ eta^sharp_U }{longrightarrow}& sharp U {}^{mathllap{i}}Bigdownarrow && Bigdownarrow{}^{mathrlap{sharp i}} X &underset{eta^sharp_X}{longrightarrow}& sharp X } $ is a pullback square.
By the universal property of a pullback/fiber product and the nature of $ sharp $ , we have $ U simeq X times_{sharp X} sharp U $ precisely if continuous functions out of some topological space $ Z $ into $ U $ are in natural bijection with continuous functions $ Z to X $ whose underlying function $ Z to X to sharp X $ factors through the underlying function of $ i $ .
This implies the statement by Prop. .
The pullback square of the $ sharp $ - unit in Prop. should correspond (after generalizing from topological spaces to suitable topological ∞ - groupoids) to the categorical semantics of what in cohesive homotopy type theory is the statement that the characteristic function $ chi_U ;colon; X to Prop $ to the universe of propositions factors through the universe of sharp - modal types.
In this form topological subspace inclusions are characterized in Shulman 15, Remark (iii)1(iv) A subspace $ i: Y hookrightarrow X $ is closed if $ Y $ is closed as a subset of $ X $ (or if $ i $ is a closed map), and is open if $ Y $ is open as a subset of $ X $ (or if $ i $ is an open map).
Topological subspace inclusions (topological embedding) are precisely the regular monomorphisms in the category Top of all topological spaces.
For example, the equalizer of two maps $ f, g colon X stackrel{to}{to} Y $ in Top is computed as the equalizer at the underlying - set level, equipped with the subspace topology.
The pushout in Top of any (closed/open) subspace $ i colon A hookrightarrow B $ along any continuous function $ f colon A to C $ , $ array{ A & stackrel{i}{hookrightarrow} & B mathllap{f} downarrow & po & downarrow mathrlap{g} C & underset{j}{hookrightarrow} & D, } $ is a (closed/open) subspace $ j: C hookrightarrow D $ .
Since $ U = hom(1, - ): Top to Set $ is faithful, we have that monos are reflected by $ U $ ; also monos and pushouts are preserved by $ U $ since $ U $ has both a left adjoint and a right adjoint.
In $ Set $ , the pushout of a mono along any map is a mono, so we conclude $ j $ is monic in $ Top $ .
Furthermore, such a pushout diagram in $ Set $ is also a pullback, so that we have the Beck - Chevalley equality $ existsi circ f^ast = g^ast existsj colon P(C) to P(B) $ (where $ exists_i colon P(A) to P(B) $ is the direct image map between power sets, and $ f^ast: P(C) to P(A) $ is the inverse image map).
To prove that $ j $ is a subspace, let $ U subseteq C $ be any open set.
Then there exists open $ V subseteq B $ such that $ i^ast(V) = f^ast(U) $ because $ i $ is a subspace inclusion.
If $ chiU colon C to mathbf{2} $ and $ chiV colon B to mathbf{2} $ are the maps to Sierpinski space that classify these open sets, then by the universal property of the pushout, there exists a unique continuous map $ chiW colon D to mathbf{2} $ which extends the pair of maps $ chiU, chi_V $ .
It follows that $ j^{ - 1}(W) = U $ , so that $ j $ is a subspace inclusion.
If moreover $ i $ is an open inclusion, then for any open $ U subseteq C $ we have that $ j^ast(existsj(U)) = U $ (since $ j $ is monic) and (by Beck - Chevalley) $ g^ast(existsj(U)) = existsi(f^ast(U)) $ is open in $ B $ .
By the definition of the topology on $ D $ , it follows that $ existsj(U) $ is open, so that $ j $ is an open inclusion.
The same proof, replacing the word "open" with the word "closed" throughout, shows that the pushout of a closed inclusion $ i $ is a closed inclusion $ j $ .
A similar (but even simpler) line of argument establishes the following result.
Let $ kappa $ be an ordinal, viewed as a preorder category, and let $ F: kappa to Top $ be a functor that preserves directed colimits.
Then if $ F(i leq j) $ is a (closed/open) subspace inclusion for each morphism $ i leq j $ of $ kappa $ , then the canonical map $ F(0) to colim_{i in kappa} F(i) $ is also a (closed/open) inclusion.
There is also a notion of a Grothendieck topology induced along a functor from a Grothendieck topology on another category (actually the input can be a somewhat more general coverage, then the topology induced along the identity functor will serve as a sort of a completion).
(this will be explained later).
A topology may be induced by more than a function other than a subset inclusion, or indeed by a family of functions out of $ Y $ (not necessarily all with the same target).
However, the term 'induced topology' is often (usually?) restricted to subspaces; the general concept is called a weak topology.
(This construction can be done in any topological concrete category; in this generality it is often called an initial structure for a source.)
The dual construction (involving functions to $ Y $ ) is a strong topology (or final structure for a sink); an example is the quotient topology on a quotient space.
>
This entry is about the signature of a permutation.
For other notions of signature see there.
For $ Aut({1, cdots , n } ) simeq Sn $ the symmetric group on $ n in mathbb{N} $ elements, the signature_ is the unique group homomorphism $ sign : Sn to mathbb{Z}2 = {1, - 1 } $ that sends each transposition $ s{i, i+1} : {1, cdots, n } to {1, cdots, n } $ , which interchanges the $ i $ th element with its neighbour and leaves the other elements fixed, to the nontrivial element $ ( - 1) in mathbb{Z}2 $ .
Permutations in the kernel of $ sign $ are called even permutations, and the rest are called odd permutations.
The signature is well - defined.
One way of seeing this is invoking a standard group presentation of $ Sn $ where generators $ sigmai $ for $ i = 1 $ to $ n - 1 $ (representing $ s_{i, i+1} $ ) are subject to relations $ sigma{i}^2 = 1, qquad (sigmai sigma{i+1})^3 = 1, qquad sigmai sigmaj = sigmaj sigma_i ; ({|i - j|} gt 1), $ and checking that the sign applied to both sides of a relation equation gives the same result.
Another is by invoking a tautological representation of $ Sn $ on a polynomial algebra $ mathbb{Z}x1, ldots, x_n $ , $ Sn stackrel{cong}{to} Set{core}({x1, ldots, xn } , {x1, ldots, xn } ) to CRing{core}(mathbb{Z}x1, ldots, xn, mathbb{Z}x1, ldots, x_n) $ (where core refers to the groupoid of invertible morphisms) and recognizing that for the special polynomial $ D coloneqq prod{i lt j} (xi - x_j) $ we have, for each permutation $ tau $ , either $ tau cdot D = D $ or $ tau cdot D = - D $ .
(The polynomial $ Delta coloneqq D^2 $ , which is invariant under the action, is called the discriminant.)
There are various means for computing the signature (also called sign) of a permutation.
The definition itself suggests one method: if we linearly order the set $ {x1, ldots, xn } $ by $ x1 lt ldots lt xn $ , then we can exhibit a permutation $ tau $ by a string diagram and simply count the number of crossings $ I(tau) $ ; then we have $ sign(tau) = ( - 1)^{I(tau)} $ .
Each crossing corresponds to a pair of elements $ xi lt xj $ such that $ tau(xi) gt tau(xj) $ , called an inversion.
Another method which does not depend on choosing a total order is to exhibit a permutation through its cycle decomposition.
Each cycle of period $ k $ contributes a sign $ ( - 1)^{k - 1} $ , and the overall sign is the product of these contributions taken over all the cycles.
Thus the signature is given by the parity of the number of cycles of even length.
This cycle description can actually be used to give an independent definition of the signature.
It is manifestly well - defined and invariant on conjugacy classes.
To check that it defines a homomorphism to $ {1, - 1 } $ , it suffices to check that multiplication by a transposition changes the parity of the number of even - length cycles by one.
This is easy if we note that transposing two elements belonging to different cycles merges two cycles into one, whereas transposing two elements belonging to the same cycle splits one cycle into two.
For $ p $ a prime number, a group is $ p $ - primary if each of its elements $ g $ has a prime power order $ p^{n(g)} $ .
(Also called primary group a $ p $ - group, but NO relation to n - group.)
The fundamental theorem of finite abelian groups stats that every finite abelian group is a direct sum of its $ p $ - primary subgroups.
These are often called its $ p $ - primary parts or $ p $ - primary components.
See also at Adams spectral sequence and for instance at stable homotopy groups of spheres.
Every finite $ p $ - primary group $ G $ has a nontrivial center $ Z(G) $ .
For a proof, see class equation.
Since the center $ Z(G) $ is a normal subgroup of $ G $ , we may define by induction (with the help of this proposition here) a series of inclusions of normal subgroups $ Z^k(G) subseteq G $ where $ Z^0(G) $ is the trivial subgroup and $ Z^k(G) $ is the inverse image of the center $ Z(G/Z^{k - 1}(G)) $ along the canonical homomorphism $ G to G/Z^{k - 1}(G) $ .
The resulting series $ Z^0(G) subseteq ldots subseteq Z^{k - 1}(G) subseteq Z^k(G) subseteq ldots $ is called the upper central series of $ G $ , and Proposition shows that in the case of a finite $ p $ - group, this series consists of strict inclusions that eventually terminate in the full subgroup $ G $ .
A group with that property is a nilpotent group.
In particular it is a solvable group.
A subset $ Asubseteq X $ of a topological space $ X $ is called meager (alias first category, often meagre outside the USA) if it is a countable union of nowhere dense subsets of $ X $ .
>
This page consider the very general concept of embeddings.
For the special cases traditionally considered see at embedding of topological spaces or embedding of smooth manifolds.
An embedding is, generally, a morphism which in some sense is an isomorphism onto its image For this to make sense in a given category $ C $ , we not only need a good notion of image.
Note that it is not enough to have the image of $ fcolon X to Y $ as a subobject $ im f $ of $ Y $ ; we also need to be able to interpret $ f $ as a morphism from $ X $ to $ im f $ , because it is this morphism that we are asking to be an isomorphism.
One general abstract way to define an embedding morphism is to say that this is equivalently a regular monomorphism.
If the ambient category has finite limits and colimits, then this is equivalently an effective monomorphism.
In terms of this we recover a formalization of the above idea, that an embedding is an iso onto its image :
For a morphism $ f : X to Y $ in $ C $ the definition of image as an equalizer says that the image of $ f $ is $ im f := limleftarrow ( Y stackrel{to}{to} Y coprodX Y) , $ .
In particular we have a factorization of $ f $ as $ f : X stackrel{tilde f}{to} im f hookrightarrow Y , , $ where the morphism on the right is a monomorphism.
The morphism $ f $ being an effective monomorphism means that $ tilde f $ is an isomorphism, hence that $ f $ is an "isomomorphism onto its image".
Assume that the dependent type theory has identity types, dependent identity types, and uniqueness quantifiers.
Then a family of elements $ x:A vdash f(x):B $ is an embedding if there is a family of elements $ x:A, y:A, q:f(x) =B f(y) vdash eta(x, y, q):exists! p:x =A y.apf(x, y, p) ={f(x) =_B f(y)} q $ which states that for all identities $ q:f(x) =B f(y) $ there is a unique identity $ p:x =A y $ up to identity such that $ apf(x, y, p) ={f(x) =_B f(y)} q $ .
Equivalently, if the dependent type theory also has existential quantifiers, then $ x:A vdash f(x):B $ is an embedding if there is a family of elements $ y:B, z:exists x:A.f(x) =B y vdash p(y, z):exists! x:A.f(x) =B y $ which states that for all $ y:B $ , if there exists an element $ x:A $ such that $ f(x) =_B y $ , then that element is unique up to identity.
A morphism $ U to X $ of topological spaces is a regular monomorphism precisely if this is an injection such that the topology on $ U $ is the induced topology.
This is an embedding of topological spaces.
An inner product space ("scalar product", i.e. with values in scalars) is a vector space $ V $ equipped with a (conjugate) - symmetric bilinear or sesquilinear form: a linear map from the tensor product $ V otimes V $ of $ V $ with itself, or of $ V $ with its dual module $ bar{V} otimes V $ to the ground ring $ k $ .
One often studies positive - definite inner product spaces; for these, see Hilbert space.
Here we do not assume positivity (positive semidefiniteness) or definiteness (nondegeneracy).
See also bilinear form.
The group of automorphisms of an inner product space is the orthogonal group of an inner product space.
Let $ V $ be a vector space over the field (or more generally a ring) $ k $ .
Suppose that $ k $ is equipped with an involution $ r mapsto bar{r} $ , called conjugation; in many examples, this will simply be the identity function, but not always.
An inner product on $ V $ is a function $ langle { - }, { - } rangle: V times V to k $ that is (1 - - 3) sesquilinear (or bilinear when the involution is the identity) and (4) conjugate - symmetric (or symmetric when the involution is the identity).
That is: (i) $ langle 0, x rangle = 0 $ and $ langle x, 0 rangle = 0 $ ; (ii) $ langle x + y, z rangle = langle x, z rangle + langle y, z rangle $ and $ langle x, y + z rangle = langle x, y rangle + langle x, z rangle $ ; (iii) $ langle c x, y rangle = bar{c} langle x, y rangle $ and $ langle x, c y rangle = langle x, y rangle c $ ; (iv) $ langle x, y rangle = overline{langle y, x rangle} $ .
Here we use the physicist's convention that the inner product is antilinear (= conjugate - linear) in the first variable rather than in the second, rather than the mathematician's convention, which is the reverse.
The physicist's convention fits in a little better with $ 2 $ - Hilbert spaces and is often used in a generalization for Hilbert modules.
Note that we use the same ring as values of the inner product as for scalars.
Notice that $ langle x, c y rangle = langle x, y rangle c $ is written with $ c $ on the right for the case that we deal with noncommutative division ring.
Are the two conventions really equivalent when $ k $ is noncommutative?
&8212;Toby
(The axiom list above is rather redundant.
First of all, (1) follows from (3) by setting $ c = 0 $ ; besides that, (1 - - 3) come in pairs, only one of which is needed, since each half follows from the other using (4).
It is even possible to derive (3) from (2) under some circumstances.)
An inner product space is simply a vector space equipped with an inner product.
We define a function $ {|{ - }|^2}colon V to k $ by $ {|x|^2} = langle x, x rangle $ ; this is called the norm of $ x $ .
As the notation suggests, it is common to take the norm of $ x $ to be the square root of this expression in contexts where that makes sense, but for us $ {|{ - }|^2} $ is an atomic symbol.
The norm of $ x $ is real in that it equals its own conjugate, by (4).
{definite} Notice that, by (1), $ langle 0, y rangle = 0 $ for all $ y $ .
In fact, the subset $ { x ;|; forall y, ; langle x, y rangle = 0 } $ is a linear subspace of $ V $ .
Of course, we also have $ {|0|^2} = 0 $ , but $ { x ;|; {|x|^2} = 0 } $ may not be a subspace.
These observations motivate some possible conditions on the inner product: (In constructive mathematics, we usually want an inequality relation relative to which the vector - space operations and the inner product are strongly extensional, to make sense of the conditions with $ ne $ in them.
We can also use contrapositives to put $ ne $ in the other conditions, which makes them stronger if the inequality relation is tight.)
An inner product is definite iff
it's both semidefinite and nondegenerate.
Semidefinite inner products behave very much like definite ones; you can mod out by the elements with norm $ 0 $ to get a quotient space with a definite inner product.
In a similar way, every inner product space has a nondegenerate quotient.
Now suppose that $ k $ is equipped with a partial order.
(Note that the complex numbers are standardly so equipped, with $ a leq b $ iff $ b - a $ is a nonnegative real.)
Then we can consider other conditions on the inner product: In this case, we have these theorems: Negative (semi)definite inner products behave very much like positive (semi)definite ones; you can turn one into the other by multiplying all inner products by $ - 1 $ .
The study of positive definite inner product spaces (hence essentially of all semidefinite inner product spaces over partially ordered fields) is essentially the study of Hilbert spaces.
(For Hilbert spaces, one usually uses a topological field, typically $ mathbb{C} $ , and requires a completeness condition, but this does not effect the algebraic properties much.)
The study of indefinite inner product spaces is very different; see the English Wikipedia article on Krein spaces for some of it.
All of this definiteness terminology may now be applied to an operator $ T $ on $ V $ , since $ (x, y) mapsto langle{x, T y}rangle $ is another inner product (on $ dom T $ , if necessary).
See positive operator.
Discussion in terms of self - dual objects in suitable symmetric monoidal categories: A finitely complete category is a category $ C $ which admits all finite limits, that is all limits for any diagrams $ F: J to C $ with $ J $ a finite category.
Finitely complete categories are also called lex categories.
They are also called (at least by Johnstone in the Elephant) cartesian categories, although this term more often means a cartesian monoidal category.
Small finitely complete categories form a 2 - category, Lex.
There are several well known reductions of this concept to classes of special limits.
For example, a category is finitely complete if and only if: An appropriate notion of morphism between finitely complete categories $ C $ , $ D $ is a left exact functor, or a functor that preserves finite limits (also called a lex functor, a cartesian functor, or a finitely continuous functor).
A functor preserves finite limits if and only if: Since these conditions frequently come up individually, it may be worthwhile listing them separately: $ F(c) stackrel{F(pi1)}{leftarrow} F(c times d) stackrel{F(pi2)}{to} F(d) $ exhibits $ F(c times d) $ as a product of $ F(c) $ and $ F(d) $ , where $ pi1: c times d to c $ and $ pi2: c times d to d $ are the product projections in $ C $ ; $ F(i): F(e) to F(c) $ is the equalizer of $ F(f), F(g): F(c) stackrel{to}{to} F(d) $ , whenever $ i: e to c $ is the equalizer of $ f, g: c stackrel{to}{to} d $ in $ C $ .
In any finitely complete category, the kernel pair of the identity morphism $ id $ on an object $ X $ is the diagonal morphism $ (id, id) $ of $ X $ and has a coequalizer isomorphic to $ X $ itself.
Section A(i)2 in Representation theory is concerned with the study of algebraic structures via their representations.
This concerns notably groups, directly or in their incarnation as group algebras, Hopf algebras or Lie algebras, and usually concerns linear representations, hence modules of these structures.
But more generally representation theory also studies representations/modules/actions of generalizations of such structures, such as coalgebras via their comodules etc.
See also at geometric representation theory.
{InHomotopyTypeTheory} The fundamental concepts of representation theory have a particular natural formulation in homotopy theory and in fact in homotopy type theory, which also refines it from the study of representations of groups to that of ∞ - representations of ∞ - groups.
This includes both discrete ∞ - groups as well as geometric homotopy types such as smooth ∞ - groups, the higher analog of Lie groups.
The key observation to this translation is that (i) an ∞ - group $ G $ is equivalently given by its delooping $ mathbf{B}G $ regarded with its canonical point (see at looping and delooping), hence the universal $ G $ - principal ∞ - bundle $ array{ G &longrightarrow& ast && downarrow && mathbf{B}G } $ (i) an ∞ - action $ rho $ of $ G $ on any geometric homotopy type $ V $ is equivalently given by a homotopy fiber sequence of the form $ array{ V &stackrel{}{longrightarrow}& V//_rho G && downarrow && mathbf{B}G } , , $ hence by a $ V $ - fiber ∞ - bundle over $ mathbf{B}G $ which is the $ rho $ - associated ∞ - bundle to the universal $ G $ - principal ∞ - bundle (see at ∞ - action for more on this).
Under this identification, the representation theory of $ G $ is equivalently More in detail, this yields the following identifications: {References} Lecture notes:
Textbook accounts for finite groups: and more generally for compact Lie groups: Discussion via string diagrams/Penrose notation: > (aimed at Lie theory and gauge theory)
Further references: The relation to number theory and the Langlands program is discussed in tableofcontents In set theory, there are many ways to say that given the relation or correspondence $ R $ , $ R(x, y) $ holds of elements $ x in A $ and $ y in B $ .
In allegorical set theories like SEAR, it is a foundational concept.
In categorical set theories like ETCS with elements, we say that $ R(x, y) $ holds of elements $ x in A $ and $ y in B $ if the ordered pair $ (x, y) $ is in the image of the function $ (p1, p2):R to A times B $ .
In material set theories like ZFC, we say that $ R(x, y) $ holds of elements $ x in A $ and $ y in B $ if the ordered pair $ (x, y) $ is in $ R $ .
In set theory, a one - to - one correspondence is a relation or correspondence $ R $ between sets $ A $ and $ B $ for which for every element $ x in A $ , there is a unique element $ y in B $ such that $ R(x, y) $ holds, and for every element $ y in B $ , there is a unique element $ x in A $ such that $ R(x, y) $ holds.
Equivalently, it is an anafunction $ R $ between sets $ A $ and $ B $ such that for every element $ y in B $ , there is a unique element $ x in A $ such that $ R(x, y) $ holds.
In type theory, given types $ A $ and $ B $ , a one - to - one correspondence is a correspondence $ x:A, y:B vdash R(x, y) $ for which for every element $ x:A $ , the dependent type $ sum{y:B} R(x, y) $ is a contractible type, and for every element $ y:B $ , the dependent type $ sum{x:A} R(x, y) $ is a contractible type.
Equivalently, it is an anafunction $ x:A, y:B vdash R(x, y) $ such that for every element $ y:B $ , the dependent type $ sum_{x:A} R(x, y) $ is a contractible type.
By the principle of unique choice, given every one - to - one correspondence, there is a bijection $ f:A cong B $ .
However, in the absence of the principle of unique choice, bijections and one - to - one correspondences are not necessarily the same; this is the same phenomena as the phenomena between functions and anafunctions.
However, frequently in material set theories, functions are defined to be anafunctions, and so bijections are similarly defined to be one - to - one correspondences.
Something similar occurs in dependent type theory, where by the principle of unique choice, given every one - to - one correspondence, there is a function with contractible fibers $ x:A vdash f(x):B $ , which becomes a bijection in the context of axiom K or uniqueness of identity proofs.
However, in contrast to material set theory, in dependent type theory, there is always a distinction between a function $ x:A vdash f(x):B $ and an anafunction $ x:A, y:B vdash R(x, y) $ , and so there is always a distinction between a function with contractible fibers and a one - to - one correspondence.
Let $ R $ be a discrete integral domain.
We say that an element $ rin R $ is a unit if it is invertible.
A non - unit is called irreducible if it can not be represented as a product of two non - units.
Note that then, $ 0 $ is never irreducible, because it is a product of two non - units under the form $ 0 = 0.0 $ .
It is often included in the definition of an irreducible element that it must be non - zero
but this is in fact redudant.
An integral domain $ R $ is a unique factorization domain (UFD for short) if every non - zero non - unit has a factorization $ u = r1 cdots rn $ (where $ n ge 1 $ ) as product of irreducibles and this decomposition is unique up to renumbering and rescaling the irreducibles by units.
Put differently: $ R $ is a UFD precisely when the multiplicative monoid of nonzero principal ideals of $ R $ (which is isomorphic to the quotient monoid $ Can(R)/R^times $ , where $ Can(R) coloneqq R backslash {0 } $ denotes the multiplicative subset of cancellative elements in $ R $ and $ R^times $ denotes the group of units in $ R $ ) is a commutative monoid freely generated by irreducible principal ideals.
It follows that if $ K $ is the field of fractions of $ R $ , then the quotient group $ K^times/R^times $ is an abelian group that is freely generated by the set of cosets $ f R^times $ with $ f $ ranging over irreducible elements.
As a side remark, we observe that in this circumstance the exact sequence $ 0 to R^times to K^times to K^times/R^times to 0 $ splits and there is an isomorphism $ K^times cong R^times oplus (K^times/R^times) $ of abelian groups.
Let $ R $ be an integral domain.
Then, $ R $ is a UFD iff every non - zero prime ideal contains a non - zero non - unit prime element.
The inverse operation to multiplication.
Given a Heyting field $ F $ , let us define the type of all terms in $ F $ apart from 0: $ F_{0} coloneqq {a in F vert a 0 } $ The division function is a binary function $ frac{( - )}{( - )}:F times F_{0} to F $ defined as $ frac{x}{y} coloneqq x cdot frac{1}{y} $ where $ frac{1}{y} $ is the reciprocal function.
An $ n times n $ - matrix $ U in Mat(n, mathbb{C}) $ with entries in the complex numbers (for $ n $ a natural number) is unitary if the following equivalent conditions hold $ U^dagger ;=; U^{ - 1} , $ .
hence equivalently: $ U cdot U^dagger ;=; mathrm{I} $ For fixed $ n $ , the unitary matrices under matrix product form a Lie group: the unitary group $ mathrm{U}(n) $ (or other notations).
For $ N $ a module (over some ring $ R $ ) and $ S hookrightarrow N $ a submodule, then the corresponding quotient module $ N/S $ is the mdoule where all elements in $ N $ that differ by n element in $ S $ are identified.
If the ring $ R $ is a field then $ R $ - modules are called vector spaces and quotient modules are called quotient vector spaces.
Thoughout let $ R $ be some ring.
Write $ R $ Mod for the category of modules over $ R $ .
Write $ U:R Mod to $ Set for the forgetful functor that sends a module to its underlying set.
For $ i : K hookrightarrow N $ a submodule, the quotient module $ frac{N}{K} $ is the quotient group of the underlying groups, equipped with the $ R $ - action induced by that on $ N $ .
The quotient module is equivalently the cokernel of the inclusion in $ R $ Mod $ frac{N}{K} simeq coker(i) , $ .
The quotient module is equivalently the quotient object of the congruence $ N oplus K to N oplus N $ given by projection on the first factor and by addition in $ N $ .
>
This entry is about the notion in order theory.
For the related concept in topology see at topological interval, and for concept in homotopy theory see at interval object.
In the general context of posets, an interval is an under category, over category, or under - over category.
They are closed under betweenness: if two points belong to an interval and a third point is between them, then that third point also belongs to the interval.
Given a poset $ P $ and an element $ x $ of $ P $ , the upwards unbounded interval $ x, infty $ (also $ x, infty) $ , $ x, infty_P $ , etc) is the subset $ {x, infty} = { y : P ;|; x leq y } ; $ the downwards unbounded interval $ { - infty}, x $ (also $ ( - infty, x $ , $ { - infty}, x_P $ , etc) is the subset $ { - infty}, x = { y : P ;|; y leq x } ; $ and given an element $ y $ of $ P $ , the bounded interval $ x, y $ (also $ x, y_P $ ) is the subset $ x, y = { z : P ;|; x leq z leq y } $ .
Thinking of $ P $ as a category and subsets of $ P $ as subcategories, $ x, infty $ is the coslice category $ (x/P) $ , $ { - infty}, x $ is the slice category $ (P/x) $ , and $ x, y $ is the bislice category $ (y/P/x) $ .
An interval with distinct top and bottom element in a total order is also called a linear interval.
(Sometimes this is called a strict linear interval and just "linear interval" then refers to the situation where top and bottom may coincide.)
Besides the closed intervals above, we also have the open intervals as well as the half - open intervals These are important in analysis, and more generally whenever the quasiorder $ lt $ is at least as important as the partial order $ leq $ .
The entire poset $ P $ is also considered an unbounded interval in itself.
Intervals of real numbers are important in analysis and topology.
They may be succinctly characterized as the connected subspaces of the real line.
The bounded closed intervals in the real line are the original compact spaces.
The interval in the reals has a universal characterization: it is the terminal coalgebra of the endofunctor on the category of all intervales that glues an interval end - to - end to itself.
The unit interval $ 0, 1 $ is primary in homotopy theory; specifically in topological homotopy theory a left homotopy from a continuous function $ f $ to a continuous function $ g $ is a continuous function $ h colon A times I to B $ out of the product topological space with the topological interval $ I = 0, 1 $ such that $ h(x, 0) = f(x) $ and $ h(x, 1) = g(x) $ .
More generally this is the concept of left homotopy for an interval object in a suitable (model) category.
The usual integral in ordinary calculus is done over an interval in the real line, a compact interval for a 'proper' integral, or any interval for an 'improper' integral.
The theory of Lebesgue measure removes this restriction and allows integrals over any measurable subset of the real line.
Still, the Lebesgue measure on intervals (even compact intervals) generates all of the rest.
To integrate a $ 1 $ - form on the real line requires orienting an interval; the standard orientation is from $ x $ to $ y $ in $ x, y $ .
If $ x gt y $ , then $ x, y $ (which by the definition above would be empty)
may also be interpreted as $ y, x $ with the reverse orientation.
This also matches the traditional notation for the integral.
The classifying topos for linear intervals is the category sSet of simplicial sets.
See the section For intervals at classifying topos.
{RelationToSimplices} Let $ mathbb{I} $ be the category of finite linear intervals.
There is an equivalence of categories $ widehat{( - )} : Delta^{op} stackrel{simeq}{to} mathbb{I} $ from the opposite category of the simplex category to $ mathbb{I} $ .
Here $ widehat{n} coloneqq Hom_{Delta}(n, 1) simeq n+1 $ and the inverse is $ n mapsto Hom_{mathbb{I}}(n, 1) , $ .
See also at Simplex category - - Duality with intervals.
Recall that the incidence algebra $ I(P) $ of a poset $ P $ (relative to some commutative ring $ R $ ) is an associative unital algebra containing all functions $ f : P times P to R $ such that $ x nleq y $ implies $ f(x, y) = 0 $ .
For any pair of elements related by the order $ x leq y $ , we can define an element $ epsilon_{x, y} $ of the incidence algebra by: $ epsilon_{x, y}(u, v) = 1 & u = x, w = y 0 & text{otherwise} $ and the collection of such functions $ epsilon_{x, y} $ form a basis of $ I(P) $ as an $ R $ - module.
So, the dimension of the incidence algebra $ I(P) $ is equal to the total number of (non - empty) intervals in $ P $ .
Information about the number of intervals in a finite poset is also encoded in its zeta polynomial.
In homotopy theory, "cellular" models for the intervals play a central role.
See interval object.
The geometry (for instance differential geometry) of intervals, for instance in the real line, are often relevant.
See for instance Geometric spaces and their homotopy types at cohesive homotopy type theory.
A differential form is a geometrical object on a manifold that can be integrated.
A differential form $ omega $ is a section of the exterior algebra $ Lambda^ T^ X $ of a cotangent bundle, which makes sense in many contexts (e.g. manifolds, algebraic varieties, analytic spaces, ...).
What we're actually describing here are the exterior differential forms; for more general concepts, see absolute differential form and cogerm differential form.
Given a differentiable manifold $ X $ , or even a generalized smooth space $ X $ for which this definition makes sense, a differential form on $ X $ is a section of the exterior algebra of the cotangent bundle over $ X $ ; sometimes one refers to an exterior differential form to be more precise.
One often requires differential forms to be smooth, or at least continuous, but we will state this explicitly when we want it.
A differential $ p $ - form on $ X $ is a section of the $ p $ th exterior power of the cotangent bundle; the natural number $ p geq 0 $ is the rank of the form.
A general differential form is a $ p $ - indexed sequence of differential $ p $ - forms of which all but finitely many are zero; on a finite - dimensional manifold, this latter condition is automatic.
The space $ C^inftyOmega^(X) $ of smooth forms on $ X $ may also be defined as the universal differential envelope of the space $ C^inftyOmega^0(X) $ of smooth functions on $ X $ (which are the same as the smooth $ 0 $ - forms as defined above); more concretely: It is generated by the smooth functions and three operations: subject to these identities: in which $ f $ is a smooth function and $ eta $ is an arbitrary smooth form.
(Note that one often drops the ' $ wedge $ ' after a $ 0 $ - form; thus, $ f eta = f wedge eta $ .
There is hardly any ambiguity if one drops the ' $ wedge $ ' entirely, but it's traditional.)
Although not directly stated, it can be proved that addition makes $ C^inftyOmega^(X) $ into an abelian group; in fact, it is a module of the commutative ring of smooth functions on $ X $ .
This is further a graded module, graded by the natural numbers, with the elements of grade $ p $ being the $ p $ - forms defined earlier; the space of these is $ C^inftyOmega^p(X) $ .
If $ omega $ is a $ p $ - form and $ eta $ is a $ q $ - form, we have: The law $ mathrm{d}mathrm{d}eta = 0 $ holds for any form $ eta $ , but the other laws become more complicated; if $ omega $ is a $ p $ - form and $ eta $ is a $ q $ - form, then we get That is, $ C^inftyOmega^(X) $ is a skew - commutative algebra over the ring of smooth functions, equipped with a derivation $ mathrm{d} $ of degree $ 1 $ .
In fact, the description above in terms of generators and relations makes it the free skew - commutative algebra over that ring equipped with such a derivation.
(Or if it doesn't, then it's because I left something out of that description.)
More general forms (in $ Omega^(X) $ ) can be recovered as sums of terms, each of which is the wedge product of a function and a smooth form.
(This can also be seen as a special case of a vector - valued form as below.)
One can still define the exterior derivative of a $ C^1 $ (once continuously differentiable) form; in general, the differential of a $ C^k $ form is a $ C^{k - 1} $ form.
If $ X $ is not a smooth manifold but only $ C^k $ for some $ 1 leq k lt infty $ , then one has to take more care here, but the definition of the skew - commutative algebra of $ C^k $ differential forms can still be made to work.
Given local coordinates $ (x^1, ldots, x^n) $ on a patch $ U $ in an $ n $ - dimensional manifold $ X $ , any differential form $ eta $ on $ U $ can be expressed uniquely as a sum of $ 2^n $ terms $ eta = sumI etaI wedge mathrm{d}x^I , $ where $ I $ runs over increasing lists of indices from $ (1, ldots, n) $ , each $ eta_I $ is a function on $ U $ (continuous, smooth, etc according as $ eta $ is), and $ mathrm{d}x^I = mathrm{d}x^{I1} wedge cdots wedge mathrm{d}x^{Ip} $ (for $ p $ the length of the list $ I $ ) is simply an abbreviation.
For a $ p $ - form, there are $ left(n atop pright) $ terms that appear.
Recall that a differential form on $ X $ is a section of the exterior algebra of the cotangent bundle over $ X $ ; call this bundle $ Lambda $ .
Then given any vector bundle $ V $ over $ X $ , a $ V $ - valued form on $ X $ is a section of the vector bundle $ V otimes Lambda $ .
The wedge product of a $ V $ - valued form and a $ V' $ - valued form is a $ (V otimes V') $ - valued form, but if there is a commonly used multiplication map $ V otimes V' to W $ , then we may think of their wedge product as a $ W $ - valued form.
Of particular importance are $ L $ - valued forms when $ L $ is a line bundle; these are also called $ L $ - twisted forms.
(Compare the notion of twisted form in a more general context.)
In local coordinates, a twisted form looks just like an ordinary form, once you choose a nonzero vector in $ L $ as a basis.
Therefore, they can seem sneaky and confusing sometimes when you realise that they do not behave in the same way!
Let $ Psi $ be the pseudoscalar bundle, obtained as the bundle associated to the frame bundle by the character $ rho(A)=sgn(det(A)) $ .
That is, a section of $ Psi $ (a pseudoscalar field) is given locally by a simple scalar field (a real - valued function) for each orientation of a local patch, with opposite orientations giving oppositely - signed scalars.
A $ Psi $ - twisted form is called pseudoform.
On an $ n $ - dimensional manifold $ X $ , the bundle $ Lambda^n(X)=Lambda^n(T^M) $ is itself a line bundle, which is associated to the frame bundle by the character $ Amapsto det(A)^{ - 1} $ ; a $ p $ - form twisted by this line bundle is called a __densitised form__.
Sometimes an $ n $ - form is itself called a __density__.
As we will see under integration below, it is really an $ n $ - pseudoform (a section of the bundle $ Lambda^notimesPsi $ , which comes from the character $ Amapsto |det(A)|^{ - 1} $ ) that should be called a density, but that is not the traditional terminology.
Given any real number $ w $ , the bundle $ |Lambda|^w $ associated to the character $ Amapsto |det A|^{ - w} $ is called the line bundle of $ w $ - weighted scalars (also called $ w $ - densities); a form twisted by this line bundle is a $ w $ - weighted form.
Note that $ |Lambda|^0=1 $ is the trivial bundle, so a $ 0 $ - weighted form is just an ordinary form.
Also, an $ n $ - pseudoform turns out to be equivalent to a $ 1 $ - weighted scalar: $ Lambda^n otimes Psi simeq |Lambda|^1 $ .
Since $ PsiotimesPsi=1 $ is the trivial bundle, we have $ Lambda^n simeq |Lambda|^1 otimesPsi $ , and thus a densitised form is equivalent to a $ 1 $ - weighted pseudoform: $ Lambda^k otimes Lambda^n simeq Lambda^k otimes Psi otimes |Lambda|^1 $ The bundle $ Lambda^notimesPsisimeq|Lambda|^1 $ of $ n $ - pseudoforms is the absolute value of the bundle of $ n $ - forms (that is of densitised $ 0 $ - forms), so we may take the absolute value of one of either and get one of the latter.
Similarly, the bundle of $ 0 $ - forms is the absolute value of the bundle $ Psi $ of pseudo - $ 0 $ - forms; that is, the trivial bundle is the absolute value of the pseudoscalar bundle.
One way to exhibit this statement nicely is: A differential $ n $ - form on $ X $ is a smooth $ n $ - functor $ Pn(X) to mathbf{B}^n mathbb{R} $ from the path n - groupoid of $ X $ to the $ n $ - fold delooping of the additive Lie group of real numbers.
Urs, do you know where the need for orientation comes in here?
I don't follow it in enough detail to see, although I intend to read Moerdijk - - Reyes. - - - Toby Eric: I'm probably confused, but if $ sigman $ is a morphism in $ Pn(X) $ , then (unless $ X $ is a directed space), the opposite $ sigman^{ - 1} $ is also in $ Pn(X) $ and I think $ omega(sigman) = - omega(sigman^{ - 1}) $ .
Toby:
Between Eric's comment here and Urs's at latest changes, I'm happy to remove this query box.
Eric: I think it is a good question.
Maybe we should keep the query box here until the answer is incorporated in the page.
Urs Schreiber: here is my reply, that I originally posted at latest changes.
I'll try to eventually work this into the main text of the entry The orientation of the diffential form corresponds to the inherent orientation of k - morphisms: as we identify the differential form with a smooth functor on the path n - groupoid, that path n - groupoid necessarily has oriented $ k $ - volumes as its k - morphisms, simply because these $ k $ - morphisms need to come with information about their (higher categorical) source and target.
To get pseudo - differential forms that may be integrated also over non - oriented and possibly non - orientable manifolds one needs to consider parallel transport functors not with coefficients in just $ mathbf{B}^n mathbb{R} $ coming from the crossed complex $ (mathbb{R} to {} to cdots to {}) $ but the more refined crossed complex $ (mathbb{R} to {*} to cdots to mathbb{Z}2) $ where the $ mathbb{Z}2 $ - factor acts by sign reversal on $ mathbb{R} $ (one can also use $ U(1) $ instead of $ mathbb{R} $ , this way $ Pn( - ), mathbf{B}^n U(1) $ becomes the Deligne complex and knows not just about differential forms but about $ U(1) $ $ n - 1 $ - gerbes with connection even).
A little bit of discussion of this unoriented case is currently at orientifold.
There for the case $ n=2 $ . Note that an $ n $ - morphism in $ Pn(X) $ is an oriented $ n $ - dimensional submanifold of $ X $ .
Such a functor (as described in more detail at connection on a bundle) assigns a real number to each parametrised $ n $ - dimensional cube of $ X $ , that is a subspace by a smooth map $ Sigmacolon 0, 1^n to X $ .
If the differential form that this $ n $ - functor defines is denoted $ omega in Omega^n(X) $ , then this real number is denoted by the integral $ int{0, 1^n} Sigma^ omega , $ .
This integral in turn encodes the $ n $ - functoriality of the $ n $ - functor: it effectively says that $ int_{0, 1^n} Sigma^ omega = sumk omega(Ck) , $ .
Since one can let $ N $ increase arbitrarily in this prescription - - $ N to infty $ - - it follows that the value of the functor on $ Sigma $ is already determined by all its values on all "infinitesimal $ n $ - cubes" in some sense.
The notion of differential form is the one that makes this precise: a differential form is a rule for assigning to each "infinitesimal $ n $ - cube" a number.
There are in turn different ways to make that last statement precise: $ omegacolon X^{D^n} times D^n to mathbb{R} $ (where $ mathbb{R} $ is now the synthetic differential version of the real numbers) subject to three constraints.
(These constraints can be seen as the infinitesimal analog of the $ n $ - functoriality discussed above).
This is described in detail in section 4 of For more on this see differential forms in synthetic differential geometry.
While differential forms are usually restricted to the linear case, there are also more general kinds of "differential forms" which can be integrated.
See for instance absolute differential form and cogerm differential form.
Given manifolds $ X $ and $ Y $ and a continuously differentiable map $ fcolon X to Y $ , any differential form $ eta $ on $ Y $ defines a pullback form $ f^(eta) $ on $ X $ .
See at pullback of differential forms.
Thus, the operation that maps $ X $ to $ Omega^(X) $ extends to a contravariant functor $ Omega^ $ .
Perhaps confusingly, forms are traditionally known in physics as 'covariant' concepts, because of how the components transform under a change of coordinates.
(Ultimately, this confusion goes back to that between active and passive coordinate transformations.)
Note that twisted and (more general) vector - valued forms cannot be pulled back so easily.
One needs some extra structure on $ f $ to do so; see the discussion of integration of $ p $ - pseudoforms at integration of differential forms for an example.
Let $ X $ be an $ n $ - dimensional manifold, and let $ omega $ be an $ n $ - pseudoform on $ X $ .
At least when $ X $ is paracompact and Hausdorff, we may turn $ omega $ into a measure on $ X $ and thereby find its integral.
Conversely, any absolutely continuous Radon measure on $ X $ arises in this way from a unique $ n $ - pseudoform $ omega $ .
If we wish to integrate untwisted (or differently twisted or vector - valued) forms and/or forms of smaller rank, then we may do so on submanifolds of $ X $ equipped with some appropriate structure.
In particular, if $ X $ itself is equipped with an orientation, then $ n $ - pseudoforms on $ X $ are the same as (untwisted) $ n $ - forms, and so we can integrate those on $ X $ .
See integration of differential forms for the general case.
Zoran Škoda: Should maybe this entry have a discussion on heuristics behind the usual trick in supersymmetry which asserts that the inner hom for supermanifolds, gives the statement that the algebra of smooth differential forms on $ M $ is the space of functions on the odd tangent bundle $ Pi T M $ ?
I am not the most competent to do this succinctly enough...
Toby: Possibly that should go at differential forms on supermanifolds?
Zoran Škoda:
By no means.
Ordinary differential forms on ORDINARY manifolds are the same as functions on odd tangent bundle.
I did not want to say anything about the generalization of differential forms on supermanifolds.
So it is NOT a different notion, but a different way to define it.
If going to toposes hence synthetic framework is not separated why would be separated the equality which involves a parity trick...
Toby:
Ah, I see; your $ M $ above need not be super, and it still works.
Then yes, that should be mentioned here too.
There is a cohomology theory of smooth differential forms; we have a chain complex $ cdots stackrel{mathrm{d}}to C^inftyOmega^2(X) stackrel{mathrm{d}}to C^inftyOmega^1(X) stackrel{mathrm{d}}to C^inftyOmega^0(X) stackrel{mathrm{d}}to 0 ; $ the chain cohomology of this complex is the de Rham cohomology of $ X $ .
As smooth differential forms are the cochains in de Rham cohomolgy, the theory of integration of forms allows us to interpret relatively compact oriented submanifolds as chains on $ X $ , giving us a homology theory.
Combining these, we have Stokes's theorem $ int{partial{R}} omega = intR mathrm{d}omega , $ where $ partial{R} $ , which may be interpreted as the boundary of $ R $ , is also called the codifferential as it is dual to $ mathrm{d} $ .
The concept of differential forms (and their exterior algebra), at least on affine spaces/Euclidean spaces originates in Textbook accounts: A basic introduction with an eye towards applications in physics is in section (ii)1 of An introductory wiki - format textbook is published as half of web.
The equivalence between differential forms and smooth functors on the path groupoid in low degree is discussed in Much fun discussion between Eric Forgy, Toby Bartels, and John Baez, about whether integration of forms or pseudoforms is most fundamental (and about whether twisted forms in general are useful and interesting geometric objects or the bastard spawn of hell) may be found in this giant Usenet thread.
More specifically: Let $ G $ be a group.
For the following this is often assumed to be (though is not necessarily) an abelian group.
Hence we write here the group operation with a plus - sign $ + : G times G to G , $ .
For $ mathbb{N} $ the natural numbers, there is a function $ ( - )cdot ( - ) : mathbb{N} times G to G $ which takes a group element $ g $ to $ n cdot g coloneqq underbrace{g + g + cdots + g}_{n ; summands} , $ .
A group $ G $ is called divisible if for every natural number $ n $ (hence for every integer) we have that for every element $ g in G $ there is an element $ h in G $ such that $ g = n cdot h , $ .
In other words, if for every $ n $ the 'multiply by $ n $ ' map $ G stackrel{n}{to} G $ is a surjection.
For $ p $ a prime number a group is $ p $ - divisible if the above formula holds for all $ n $ of the form $ p^k $ for $ k in mathbb{N} $ .
There is also an abstract notion of $ p $ - divisible group in terms of group schemes.
Let $ A $ be an abelian group.
Assuming the axiom of choice, the following are equivalent: (i) $ A $ is divisible (i) $ A $ is injective object in the the category Ab of abelian groups (i) the hom functor $ Hom_{Ab}( - , A) : Ab^{op} to Ab $ is exact.
This is for instance in (Tsit - YuenMoRi, Proposition (iii)19 (Tsit - YuenMoRi)).
It follows for instance from using Baer's criterion.
The torsion - free and divisible abelian groups are precisely the rational vector spaces, i.e. if $ A $ is torsion - free and divisible, then it carries a unique vector space structure.
The direct sum of divisible groups is itself divisible.
Every quotient group of a divisible group is itself divisible.
The additive group of rational number $ mathbb{Q} $ is divisible.
Hence also that underlying the real numbers $ mathbb{R} $ and the complex numbers.
Hence: The underlying abelian group of any $ mathbb{Q} $ - vector space is divisible.
Also, by prop.
, The quotient groups $ mathbb{Q}/mathbb{Z} $ and $ mathbb{R}/mathbb{Z} $ are divisible (the latter is also written $ U(1) $ (for unitary group) or $ S^1 $ (for circle group)).
What is additionally interesting about example is that it provides an injective cogenerator for the category Ab of abelian groups.
Similarly, $ mathbb{R}/mathbb{Z} $ is an injective cogenerator.
The following groups are not divisible: In the most general sense, a bundle over an object $ B $ in a category $ mathcal{C} $ is simply an object $ E $ of $ mathcal{C} $ equipped with a morphism in $ mathcal{C} $ from $ E $ to $ B $ : $ array { E downarrow^{mathrlap{p}} B } $ One often refers to such a bundle simply as $ E $ , even though $ B $ is really part of the data.
For $ x in B $ a generalized element of $ B $ , the fiber $ E_x $ of the bundle over $ x $ is the pullback $ x^ E $ .
Given two bundles $ E1 $ and $ E2 $ over $ B $ , then a morphism of bundles over $ B $ is a morphism $ E1 to E2 $ which makes this diagram commute: $ array{ E1 && longrightarrow && E2 & {}{mathllap{p1}}searrow && swarrow{mathrlap{p2}} && B } , $ .
This way bundles over $ B $ form a category, also called the slice category $ mathcal{C}{/B} $ of $ mathcal{C} $ over $ B $ .
One generally considers bundles with extra properties or structure: The category of bundles over a given object $ B $ is the over category $ mathcal{C}/B $ .
The collection of all bundles in a given category $ mathcal{C} $ therefore arranges itself into the codomain fibration $ cod : I, mathcal{C} to mathcal{C} $ .
As such, the descent for bundles may be expressed as monadic descent with respect to the codomain bifibration.
This does in general not work inside one of the more restrictive subcategories of bundles with extra structure and property, as the push - forward operation typically does not respect these extra conditions.
For more on this see monadic descent of bundles.
A useful collection of introductory notes to fiber bundles, vector bundles and fiber bundles with connection is at The concept of isomorphism generalizes the concept of bijection from the category Set of sets to general categories.
An isomorphism is an invertible morphism, hence a morphism with an inverse morphism.
Two objects of a category are said to be isomorphic if there exists an isomorphism between them.
This means that they "are the same for all practical purposes" as long as one does not violate the principle of equivalence.
But beware that two objects may be isomorphic by more than one isomorphism.
In particular a single object may be isomorphic to itself by nontrivial isomorphisms other than the identity morphism.
Frequently the particular choice of isomorphism matters.
Every isomorphism is in particular an epimorphism and a monomorphism, but the converse need not hold.
Common jargon includes "is a mono" or "is monic" for "is a monomorphism", and "is an epi" or "is epic" for "is an epimorphism", and "is an iso" for "is an isomorphism".
Henri Poincaré wrote in Poincaré 1908 about isomorphisms: > "It is scarcely credible, as Mach said, how much a well - chosen word can economize thought.
I do not know whether or not I have said somewhere that mathematics is the art of giving the same name to different things.
We must so understand it.
It is appropriate that things different in substance, but alike in form, should be put into the same mold, so to speak.
When our language is well chosen, it is astonishing to see how all the demonstrations made upon some known fact immediately become applicable to many new facts.
Nothing has to be changed, not even the words, since the names are the same in the new cases.
There is an example, which comes at once to my mind; it is quaternions, upon which, however, I will not dwell.
>
A word well chosen very often causes the disappearance of exceptions to rules as announced in their former forms; it was for this purpose that the terms 'negative quantities', 'imaginary quantities', 'infinite points', have been invented.
And let us not forget that these exceptions are pernicious, for they conceal laws.
Very well then, one of those marks by which we recognize the pregnancy of a result is in that it permits a happy innovation in our language.
The mere fact is oftentimes without interest; it has been noted many times, but has rendered no service to science; it becomes of value only on that day when some happily advised thinker perceives a relationship, which he indicates and symbolizes by a word.
>
The physicists also do it just the same way.
They invented the term 'energy', a word of very great fertility, because through the elimination of exceptions it established a law; because it gave the same name to things different in substance, but alike in form.
>
Among the words which have had this happy result, I will mention the 'group' and the 'invariant'.
They make us perceive the gist of many mathematical demonstrations; they make us realize how often mathematicians of the past must have run across groups without recognizing them and how, believing these groups to be isolated things, they have found them to be in close relationship without knowing why.
Today we would say that they were looking right in the face of isomorphic groups.
We feel now that in a group the substance interests us but very little; it is the form alone which matters, and so, when we once know well a single group, then we know through it all the isomorphic groups; thanks to the words 'groups' and 'isomorphism', which sum in a few syllables this subtle law and make it at once familiar to us all, we take our step at once and in so doing economize all effort of thought."
An isomorphism, or iso for short, is an invertible morphism, i.e. a morphism with a 2 - sided inverse.
A morphism could be called isic (following the more common 'monic' and 'epic') if it is an isomorphism, but it's more common to simply call it invertible.
Two objects $ x $ and $ y $ are isomorphic if there exists an isomorphism from $ x $ to $ y $ (or equivalently, from $ y $ to $ x $ ).
An automorphism is an isomorphism from one object to itself.
It is immediate that isomorphisms satisfy the two - out - of - three property.
But they also satisfy two - out - of - six property satisfied by the weak equivalences in any homotopical category.
Note that the inverse morphism of an isomorphism is an isomorphism, as is any identity morphism or composite of isomorphisms.
Thus, being isomorphic is an equivalence relation on objects.
The equivalence classes form the fundamental 0 - groupoid of the category in question.
Every isomorphism is both a split monomorphism (and thus about any other kind of monomorphism) and a split epimorphism (and thus about any other kind of epimorphism).
In a balanced category, every morphism that is both a monomorphism and an epimorphism is invertible, but this does not hold in general.
However, any monic regular epimorphism (or dually, any epic regular monomorphism) must be an isomorphism.
A groupoid is precisely a category in which every morphism is an isomorphism.
More generally, the core of any category $ C $ is the subcategory consisting of all objects but only the isomorphisms; it is a kind of underlying groupoid of $ C $ .
In a similar way, the automorphisms of any given object $ x $ form a group, the automorphism group of $ x $ .
In higher categories, isomorphisms generalise to equivalences, which we expect to have only weak inverses.
In the context of homotopy type theory, for every morphism $ f : homA(a, b) $ the type "f is an isomorphism" is a proposition.
Therefore, for any $ a, b:A $ the type $ a cong b $ is a set.
Suppose given $ g:homA(b, a) $ and $ eta:1a = g circ f $ and $ epsilon : f circ g = 1b $ , and similarly $ g', eta' $ , and $ epsilon' $ .
We must show $ (g, eta, epsilon)=(g', eta', epsilon') $ .
But since all hom - sets are sets, their identity types are mere propositions, so it suffices to show $ g=g' $ .
For this we have $ g' = 1{a} circ g'= (g circ f) circ g' = g circ (f circ g') = g circ 1{b}= g $ By definition of groupoid.
A representation/action $ V times G longrightarrow V $ is trivial if it is given by the projection out of the product onto $ V $ .
Let $ G $ be a finite group and $ H overset{iota}{hookrightarrow} G $ a subgroup - inclusion.
Then the induced representation in Rep(G) of the 1 - dimensional trivial representation $ mathbf{1} in Rep(H) $ is the permutation representation $ kG/H $ of the coset G - set $ G/H $ : $ mathrm{ind}H^Gbig( mathbf{1}big) ;simeq; kG/H , $ .
This follows directly as a special case of the general formula for induced representations of finite groups (this Example).
Given an index set I and a matrix $ A = (A{i j}){i, j in I} $ , a principal submatrix of $ A $ is a matrix of the form $ (A{i j}){i, j in I'} $ for $ I' subset I $ some subset.
In physics: In mathematics: category: disambiguation A maximal ideal (in say a commutative ring $ R $ ) is an ideal $ M $ which is maximal among proper ideals.
(This is a second - order definition, as it quantifies over subsets of $ R $ .)
Equivalently, an ideal $ M subseteq R $ is maximal if the quotient ring $ R/M $ is a field.
This suggests a first - order definition: an ideal $ M $ is maximal if $ forall x in R. neg (x in M) Rightarrow exists y in R. x y = 1 $ .
Assuming the axiom of choice then: Let $ R $ be a commutative ring and let $ I subset R $ be a proper ideal.
Then $ R $ contains a maximal ideal $ mathfrak{m} $ containing $ I $ , i.e $ . I subset mathfrak{m} $ .
(See also at prime ideal theorem.)
Write $ PropIdl(R){subset} $ for the set of proper ideals of $ R $ , partially ordered by inclusion.
We claim that every chain in $ PropIdl(R){subset} $ has an upper bound (def.).
This then implies the statement by Zorn's lemma (equivalent to the axiom of choice).
To show the claim, assume that $ mathcal{C} subset PropIdl(R){subset} $ is a chain.
We have to produce an $ I in PropIdl(R) $ such that for all $ c in C $ then $ c subset I $ .
We claim that such $ I $ is provided by the union: $ I coloneqq underset{J in mathcal{C}}{cup} J , $ .
It is clear that if this is indeed a proper ideal, then it is an upper bound of the chain.
To see first of all that this $ I $ is an ideal, consider $ x1, x2 in I $ .
There are thus $ J1, J2 in mathcal{C} $ with $ x1 in J1 $ and $ x2 in J2 $ .
Since a chain is total order by definition, either $ J1 subset J2 $ or $ J2 subset J1 $ .
We may assume the former without restriction, otherwise rename $ 1 leftrightarrow 2 $ .
Therefore now $ x1, x2 in J2 $ and so we may add them there and find that $ x1 + x2 in J2 subset I $ .
Similarly if $ r in R $ then $ r xi in J2 subset I $ .
Finally to see that this idea $ I $ is indeed proper.
But since all the $ Ji $ are proper, neither of them contains $ 1 in R $ , and hence $ I $ does not contain $ 1 in R $ .
In classical mathematics then: Every maximal ideal is a prime ideal.
Assuming AC and EM, then Maximal ideals in the spectrum of a commutative ring $ Spec(R) $ correspond precisely to the closed points in the Zariski topology on $ Spec(R) $ (this prop.).
Closed points are at the heart of the definition of schemes.
A scheme $ X $ is a sheaf with respect to the Zariski topology that admits a covering by open embeddings of affine schemes, where "covering" means that every closed point $ p: Spec(F) to X $ ( $ F $ a field) factors through one of the embeddings.
For $ k $ a field and $ V $ a free $ k $ - vector space, a basis for $ V $ is a basis of a free module for $ V $ regarded as a free module over $ k $ .
In functional analysis, a basis in this sense is called a Hamel basis.
The basis theorem asserts that, with the axiom of choice, every vector space admits a basis, hence that every module over a field is a free module.
In representation theory: Specifically in representation theory of the symmetric group: A semigroup is like a monoid where there might not be an identity element.
The term "semigroup" is standard, but semi - monoid would be more systematic.
A semigroup is, equivalently, Some semigroups happen to be monoids; even then, a semigroup homomorphism might not be a monoid homomorphism (because it might not preserve the identity element).
Nevertheless, semigroup isomorphisms must be monoid isomorphisms.
Thus, the identity element of a monoid forms a property - like structure on the underlying semigroup.
This should be contrasted with the phenomenon that a semigroup homomorphism between two semigroups that happens to be groups does, in fact, happen to be a group homomorphism, since in this special case one can show a semigroup homomorphism must preserve the identity and inverses.
As a monoid is a category with one object, so a semigroup is a semicategory with one object.
Any small category $ mathcal{C} $ can be thought of as a semigroup by defining $ S = text{Mor}(mathcal{C})cup {0 } $ and taking $ fg = f circ g $ for any composable morphisms $ f, g $ , and $ fg = 0 $ otherwise.
Then the semigroup $ (S, *) $ fully describes $ mathcal{C} $ .
This type of semigroup is a weakly reductive semigroup.
Generalizing this, any category can be thought of as a semigroup which isn't necessarily defined on a set.
Some mathematicians consider semigroups to be a case of centipede mathematics.
Category theorists sometimes look with scorn on semigroups, because unlike a monoid, a semigroup is not an example of a category.
However, a semigroup can be promoted to a monoid by adjoining a new element and decreeing it to be the identity.
This gives a fully faithful functor from the category of semigroups to the category of monoids.
So, a semigroup can actually be seen as a monoid with extra property.
Describe this property.
On the other hand, analysts run across semigroups often in the wild, and don't always want to add formal identities just to turn them into monoids.
Another variant with strong links with category theory is that of inverse semigroups, which Charles Ehresmann showed were closely related to ordered groupoids.
Inverse semigroups naturally occur when considering partial symmetries of an object.
We can internalize the concept of semigroup in any monoidal category (or even multicategory) $ V $ to get a semigroup object in $ V $ .
Semicategories and semigroups are mentioned for instance Discussion in the context of Lie theory: A vector space is finite - dimensional if it admits a finite basis.
The category FinVect of finite - dimensional vector spaces is of course the full subcategory of Vect whose objects are finite - dimensional.
{CompactClosure} A vector space $ V $ is finite - dimensional precisely if the hom - functor $ hom(V, - ): Vect to Set $ preserves filtered colimits.
Every vector space $ W $ is the filtered colimit of the diagram of finite - dimensional subspaces $ W' subseteq W $ and inclusions between them; applying this to $ W = V $ , the condition that $ hom(V, - ) $ preserves filtered colimits implies that the canonical comparison map $ colim{fd; V' subseteq V} hom(V, V') to hom(V, V) $ is an isomorphism, so some element $ f $ in the colimit represented by $ f: V to V' $ gets mapped to $ 1V $ , i.e., $ i circ f = 1V $ for some inclusion $ i: V' hookrightarrow V $ .
This implies $ i $ is an isomorphism, so that $ V $ is finite - dimensional.
In the converse direction, observe that $ hom(V, - ) $ has a right adjoint (and in particular preserves filtered colimits) if $ V $ is finite - dimensional.
To see this, first notice that the dual vector space $ V^ast $ of functionals $ f: V to k $ to the ground field is a dual object to $ V $ in the monoidal category sense, so that there is a counit $ eva colon V^ast otimes V to k $ taking $ f otimes v mapsto f(v) $ .
The unit is uniquely determined from this counit and can be described using any basis $ ei $ of $ V $ and dual basis $ fj $ as the map $ k to V otimes V^ast $ taking $ 1 mapsto sumi ei otimes fi $ .
We thus have an adjunction $ ( - otimesk V) ; dashv ( - otimes V^ast) $ , which is mated to an adjunction $ hom(V, - ) dashv hom(V^ast, - ) $ by familiar hom - tensor adjunctions; thus $ hom(V, - ) $ has a right adjoint.
This means that Finite - dimensional vector spaces are exactly the compact objects of Vect in the sense of locally presentable categories, but also the compact = dualizable objects in the sense of monoidal category theory.
In particular the category FinVect is a compact closed category.
Simple functions are (almost) the most basic notion of measurable function in measure theory.
Given a measure, it's easy to define the integral of a simple function, and we extend this to more general functions by continuity.
Let $ X $ be a measurable space.
We may want $ X $ to be equipped with some more data; if $ X $ is a measure space, then this is plenty of data.
However, for the most basic definitions, it's enough if $ X $ is simply a measurable space.
This is the domain of our simple functions.
Another necessary datum is the simple functions' codomain $ K $ , which we will eventually want to be at least a Banach space over the real numbers.
(In the simplest example, $ K $ is $ mathbb{R} $ itself, or perhaps the space $ mathbb{C} $ of complex numbers.)
We take $ K $ to be a measurable space using its Borel sets.
A measurable function from $ X $ to $ K $ is simple if its range is finite.
Since a simple function $ f $ is measurable and a singleton is Borel, each fibre of $ f $ is a measurable set in $ X $ ; the function $ f $ is given by the (finitely many) nonempty fibres and their (singleton) images.
This suggests another way to look at simple functions: A simple function from $ X $ to $ K $ is a formal $ K $ - linear combination of measurable subsets of $ X $ .
Here we identify a measurable set $ A $ with its characteristic function $ chiA $ , so the formal linear combination $ sumi ci Ai $ is identified with the function $ sumi ci chi{Ai} $ , which is measurable and whose range is contained in the finite set of sums of the $ ci $ .
(If there are $ n $ terms in the linear combination, then there are at most $ 2^n $ such sums.)
However, the na&239;ve notion of equality of linear combinations is finer than equality of the corresponding functions, so we must combine Definition with a definition of equality: Two simple functions from $ X $ to $ K $ , in the sense of Definition , are equal if their corresponding functions from $ X $ to $ K $ are equal as functions.
Then we have a canonical bijection between the set of simple functions as in Definition and the set of equivalence classes of simple functions as in Definition .
Arguably, even this is not really the correct notion of equality, since functions may be equal for the purpose of integration without being literally equal.
If $ X $ is equipped with a $ sigma $ - ideal of null sets (or a $ delta $ - filter of full sets), then we may consider a yet coarser notion of equality: Two simple functions, in the sense of either Definition or Definition , are almost equal if they (or their corresponding functions) are equal almost everywhere.
Sometimes, we wish to restrict attention to those simple functions which we expect to have a finite integral.
If $ X $ is equipped with an ideal of bounded sets (which in a measure space are sets with finite measure), then we may do this: A simple function of bounded support is a simple function in the sense of Definition such that the fibre over every non - zero number is bounded, or equivalently (in the sense of Definition ) a formal linear combination of bounded measurable sets.
In some approaches to measure theory, one starts with a $ delta $ - ring of measurable sets, which may be reinterpreted as the bounded sets in the generated $ sigma $ - algebra of relatively measurable sets, and then the simple functions will automatically have bounded support.
Finally, there is one more useful restriction (and slight generalisation) of simple functions, applicable when $ K $ is ordered: A positive simple function is a simple function in the sense of Definition whose range is contained in the positive cone $ K^+ $ of $ K $ , or equivalently (in the sense of Definition ) a formal $ K^+ $ - linear combination of measurable sets.
An extended positive simple function (note the red herring) takes values in the extended positive cone $ bar{K}^+ $ , or equivalently is a $ bar{K}^+ $ - linear combination.
Let $ X $ be equipped with a measure $ mu $ , so $ (X, mu) $ is a measure space.
(In particular, $ X $ has the structure necessary for all of the definitions above, including both Definitions and .)
If $ f $ is a simple function from $ X $ to $ K $ , then we wish to define the integral of $ f $ .
In general, this is a little tricky, but it's easy if $ f $ either is positive or has bounded support.
It is easiest to write down the definition if we think of simple functions using Definition .
Then we have: The integral of the simple function $ f $ , represented by the linear combination $ sumi ci Ai $ , is $ sumi ci mu(Ai) $ .
The integral of a positive simple function always exists (but may be infinite).
It is finite if $ mu $ is a finite measure, and it is positive (possibly $ 0 $ or $ infty $ ) if $ mu $ is a positive measure.
Also, if $ mu $ is positive, then the integral of an extended positive simple function always exists.
(However, the integral of an extended positive simple function with respect to a finite positive measure need not be finite.)
The integral of a simple function with bounded support always exists and is finite (being a finite linear combination of finite numbers).
Two (positive or with bounded support) simple functions $ f $ and $ g $ are almost equal (with respect to $ mu $ ) if and only if the integral of $ f - g $ is zero.
The $ L^1 $ - norm of a simple function is the integral of its pointwise norm (which is a positive simple function to $ mathbb{R} $ ) with respect to the absolute value of the measure $ mu $ (which is a positive measure): $ {|f|}1 coloneqq int {|f(x)|} {|mu(mathrm{d}x)|} $ .
In this context, we usually start with a positive measure $ mu $ ; in that case, of course, there is no need to bother taking the absolute value of $ mu $ .
The simple functions of bounded support form a normed vector space $ Simpc $ under the $ L^1 $ - norm, if we consider them up to almost equality.
If we don't use almost equality, then we get in general only a seminorm, but if we pass to a quotient space with a norm, then Proposition tells us that we are now using almost equality (and shows that Definition is well defined when applied to Definition ).
The completion of the normed vector space $ Simpc $ (under the $ L^1 $ - norm) is the Banach space $ L^1 $ of absolutely integrable functions (an example of a Lebesgue space).
Taking the integral of a simple function of bounded support is a continuous linear functional on $ Simpc $ , so it extends to all of $ L^1 $ .
In this way, we may define the integral of any absolutely integrable function.
There might be some technical requirements for this to be true.
I'll try to check on that.
The term 'bounded' has several meaning in different branches of mathematics.
For a general axiomatic approach to boundedness, see bornological set.
Here we list definitions in various fields.
Let $ E $ be a metric space.
A subset $ B subseteq E $ is bounded if there is some real number $ r $ such that $ d(x, y) lt r $ for all $ x, y in B $ .
This generalises immediately to pseudometric spaces, quasimetric spaces, extended metric spaces, and most generally to Lawvere metric spaces.
We can also generalise to gauge spaces: Let $ E $ be a gauge space.
A subset $ B subseteq E $ is bounded if there is some real number $ r $ such that $ d(x, y) lt r $ for all $ x, y in B $ and all gauging distances $ d $ .
This generalises immediately to quasigauge spaces.
The family of all bounded sets of a quasigauge space (and hence of the more particular kinds of spaces above) defines a bornology on its underlying set.
Let $ E $ be a LCTVS.
A subset $ B subseteq E $ is bounded if whenever $ U subseteq E $ is a neighbourhood of $ 0 $ then there is some real number $ r $ such that $ B subseteq r U $ .
The family of all bounded sets of a LCTVS defines a bornology on its underlying set.
Some authors do not require an integral domain to be commutative.
However, on the nLab we require our integral domains to be commutative.
Let $ R $ be a commutative ring, let $ mathrm{Reg}(R) $ be the monoid of regular elements in $ R $ , let $ neg mathrm{Reg}(R) $ be the complement of $ mathrm{Reg}(R) $ , the set of zero divisors in $ R $ , and let $ I{neg mathrm{Reg}(R)} $ be the two - sided ideal generated by $ neg mathrm{Reg}(R) $ .
A commutative ring is non - trivial if $ 0 neq 1 $ .
An integral domain is a non - trivial commutative ring $ R $ such that every element in $ I{neg mathrm{Reg}(R)} $ is equal to zero, or that the quotient ring $ R/I{neg mathrm{Reg}(R)} $ is isomorphic to $ R $ .
Since every element of the ideal generated by the set of zero divisors is equal to zero, and the integral domain is a non - trivial ring, which means that there is at least one zero divisor, it follows that zero is a zero divisor and if $ a cdot b = 0 $ , then $ a = 0 $ or $ b = 0 $ .
It then follows that every integral domain is a reduced ring.
The ring of fractions of every integral domain is a field, the field of fractions.
The ring of formal power series of an integral domain is a local integral domain.
in constructive mathematics, there are different inequivalent ways to define an integral domain.
The above definition is sometimes called a ring without zero divisors.
Stronger notions include: A Heyting integral domain is an integral domain which has a tight apartness relation and where every element apart from zero is regular.
The ring of fractions of a Heyting integral domain is a Heyting field.
A discrete integral domain is a Heyting integral domain with decidable equality, or a Heyting integral domain where every element is either zero or regular.
The ring of fractions of a discrete integral domain is a discrete field.
Rings without zero divisors and discrete integral domains are both definable in coherent logic.
However, Heyting integral domains can only be defined in first - order logic.
Sometimes, one may want the trivial ring to be an integral domain, resulting in the notion of possibly trivial integral domain.
In LombardiQuitté2010, the authors define an integral domain to be a possibly trivial integral domain.
In principle, one could just as easily consider a commutative rig or commutative semiring $ R $ .
In that case, however, only the definition involving the cancellative property extends to rigs and semirings.
Furthermore, we should add the additional requirement that addition in $ R $ is cancellable (that is, addition by any element is injective), to make the analogue of the previous paragraph correct.
Since these could also be done for general domains to turn them into what could be called domain rigs and domain semirings, these could be called commutative domain rigs or commutative domain semirings.
| commutative ring | reduced ring | integral domain | - - - - - - - - - - - - - - - - - - - - - | - - - - - - - - - - - - - - - - - | - - - - - - - - - - - - - - - - - | | local ring | reduced local ring | local integral domain | | Artinian ring | semisimple ring | field |
| Weil ring | field | field | {Definition} Torsion and torsion - free classes of objects in an abelian category were introduced axiomatically as a torsion theory (or torsion pair) in (Dickson 1963).
Beware that there are other, completely independent, concepts referred to as torsion.
See there for more.
The torsion subgroup of an abelian group $ G in $ Grp is the subgroup of all those elements $ g , in, G $ , which have finite order, i.e. those for which some power is the neutral element $ g in G ;text{is torsion} ;;;;;;Leftrightarrow;;;;;; underset{n in mathbb{N}}{exists} ;;; g^n ;coloneqq; underset{ n; factors }{ underbrace{ g cdot g cdots g } } , =, mathrm{e} , $ .
A group is Notice that for abelian groups $ A in $ AbGrp the group operation is often written additively, namely as " $ + $ " and the neutral element is written as zero, whence this reads: $ a in A ;text{is torsion} ;;;;;Leftrightarrow;;;;; underset{n in mathbb{N}}{exists} ;;; n cdot a ;coloneqq; underset{ n; summands }{ underbrace{ a + a cdots + a } } , =, 0 , $ .
The situation with monoids is very similar to the situation with groups.
The torsion subgroup of a commutative monoid $ M in $ Mon is the submonoid of all those elements $ m , in, M $ for which some power is the neutral element $ m in M ;text{is torsion} ;;;;;;Leftrightarrow;;;;;; underset{n in mathbb{N}}{exists} ;;; m^n ;coloneqq; underset{ n; factors }{ underbrace{ m cdot m cdots m } } , =, mathrm{e} , $ .
Every such submonoid is a group, which is why the set of all such elements is called a torsion subgroup.
A monoid is Notice that for commutative monoids $ C in $ CMon, where the monoid operation is traditionally written as addition $ + $ and the neutral element is written as zero, this reads: $ c in C ;text{is torsion} ;;;;;Leftrightarrow;;;;; underset{n in mathbb{N}}{exists} ;;; n cdot c ;coloneqq; underset{ n; summands }{ underbrace{ c + c cdots + c } } , =, 0 , $ .
Given a ring $ R $ , an element $ m $ in an $ R $ - module $ M $ is a torsion element if there is a nonzero element $ r $ in $ R $ such that $ r m=0 $ .
In constructive mathematics, given a ring $ R $ with a tight apartness relation $ $ , an element $ m $ in an $ R $ - module $ M $ is a torsion element if there is a element $ r $ in $ R $ such that $ r 0 $ and $ r m=0 $ .
A torsion module is a module whose elements are all torsion.
A torsion - free module is a module whose elements are not torsion, other than $ 0 $ .
For $ A $ an abelian group, its torsion subgroup is isomorphic to the value of the degree - 1 Tor functor $ Tor^mathbb{Z}1(mathbb{Q}/mathbb{Z}, A) $ .
See at Tor - relation to torsion subgroups for more.
An abelian group is torsion - free precisely if regarded as a $ mathbb{Z} $ - module it is a flat module.
This is a special case of a more general result for modules over a principal ideal domain.
See also flat module - Examples for more.
However, it is unclear whether this result holds in constructive mathematics, since the $ mathbb{Z} $ is not a principal ideal domain unless excluded middle holds.
{ExamplesAndApplications} linebreak Every finite group is pure torsion, hence is its own maximal torsion subgroup.
linebreak Given an abelian group $ A $ which is pure torsion (e.g. a finite abelian group, by Ex. ), its tensor product with the additive group of rational numbers is the trivial abelian group: $ A , text{torsion} ;;; Rightarrow ;;; A otimes{mathbb{Z}} mathbb{Q} ;simeq; 0 ;;; in ; AbGrp , $ .
Because, for $ a in A $ with $ underset{ n;summands }{underbrace{a + a + cdots + a}} = 0 $ and for $ p, q in mathbb{Z} subset mathbb{Q} $ with $ q neq 0 $ we have, by the definition of tensor product of abelian groups: $ a otimes frac{p}{q} & ;=; a otimes underset{n; summands}{ underbrace{ Big( frac{p}{n cdot q} + frac{p}{n cdot q} + cdot + frac{p}{n cdot q} Big) }} & ;=; underset{n;summands}{ underbrace{ Big(a otimes frac{p}{n cdot q}Big) + cdots + Big(a otimes frac{p}{n cdot q}Big) }} & ;=; underset{ n ; summands }{ underbrace{ ( a + cdots + a ) }} otimes frac{p}{n cdot q} & ;=; 0 otimes frac{p}{n cdot q} & ;=; 0 , $ .
In rational homotopy theory one considers the higher homotopy groups $ pin(X) $ of topological spaces $ X $ tensored over $ mathbb{Q} $ : the resulting groups $ pin(X) otimes{mathbb{Z}} mathbb{Q} $ are then necessarily torsion - free - - in this sense rational homotopy theory studies spaces "up to torsion".
linebreak By the Serre finiteness theorem, the homotopy groups of spheres are finite groups, and hence pure torsion by Ex. , except in the degree of the dimension of the sphere and, for even - dimensional spheres, twice its dimension minus one: $ pikbig( S^n big) ;; simeq ; left{ {ll} mathbb{Z} & k = n mathbb{Z} oplus text{torsion} & k = 2n - 1 ;text{and}; n;text{even} text{torsion} & text{otherwise} right $ .
linebreak The torsion elements of an elliptic curve as a group are important in number theory and arithmetic geometry.
See torsion points of an elliptic curve.
On axiomatization of torsion theory in abelian categories: The graph of a function $ f : X to Y $ is the subset that $ f $ "carves out" of the cartesian product $ X times Y $ .
The traditional standard definition of a graph of a function is this: The graph $ graph(f) $ of a function $ f: X to Y $ is that subset $ graph(f) hookrightarrow X times Y $ of the cartesian product $ X times Y $ defined by the property that $ (a, b) in X times Y $ belongs to the graph of $ f $ if and only if $ f(a) = b $ : $ graph(f) = {(a, b) in X times Y | f(a) = b } , $ .
This can be understood as a special case of a graph of a functor by the following observation For $ f : X to Y $ a function, define a function $ chif : X times Y to {0, 1 } $ by regarding a set as a 0 - category and a 0 - category as a ( - 1) - category - enriched category and then setting $ chif : X times Y stackrel{=}{to} X^{op} times Y stackrel{f^{op} times Id}{to} Y^{op} times Y stackrel{Hom}{to} {0, 1 } , $ .
Then $ chif $ is the characteristic function of $ graph(f) $ in that the diagram $ array{ graph(f) &to& {} downarrow && downarrow X times Y &stackrel{chi_f}{to}& {0, 1 } } $ is a pullback diagram.
In other words this means that in the context of ( - 1) - category - enriched category theory the graph of a function $ f $ , regarded as an enriched functor is the category of elements of the corresponding profunctor.
More on this at graph of a functor.
It is easy to identify the properties of those subsets of $ X times Y $ that are the graphs of functions, and $ f = g $ if they have the same graph (given $ X $ and $ Y $ ).
Consequently, it is common, especially (but not only) in material set theory, to define a function from $ X $ to $ Y $ as such a subset, that is to identify a function with its graph.
On the other hand, from a more categorial foundation, as discussed above, it's common to define a subset to be a characteristic function!
More generally, we can say that the graph of a binary relation from $ X $ to $ Y $ is a subset of $ X times Y $ ; $ (a, b) $ belongs to the graph if and only if $ a $ is related to $ b $ .
(Note that every subset of $ X times Y $ defines a unique relation; such a subset is the graph of a function if and only if the relation is both functional and entire.)
Notice that with a function $ f : X to Y $ regarded as a profunctor $ X times Y to ( - 1)Cat $ as described above, a relation $ R subset X times Y $ corresponds to a general such profunctor.
More precisely we have a pullback square $ array{ R &to& {} downarrow && downarrow X times Y &stackrel{chiR}{to}& {0, 1 } } $ where So in this sense the ordinary notion of relation as a subset does really define the graph of the relation, while the relation itself is more naturally understood as the corresponding 0 - profunctor/characteristic function $ chif $ .
The graph of a binary relation from $ X $ to $ X $ is related to the notion of graph from graph theory; more precisely, such relations correspond to directed loop graphs (in the sense defined at graph) with vertex set $ X $ , and either can be defined as a subset of $ X^2 $ .
In a similar way, spans from $ X $ to $ X $ correspond to directed pseudographs with vertex set $ X $ .
For the case of a relation from $ X $ to $ Y $ without $ X = Y $ , see under the cograph below.
The graph of a relation of arbitrary arity is similarly a subset of an arbitrary cartesian product; see relation theory for more on this.
{cograph} Bill Lawvere has also considered the cograph of a function, which is dually a quotient set of the disjoint union $ X uplus Y $ ; $ a $ is identified with $ b $ if $ f(a) = b $ (and additional identifications may follow).
However it may make more sense to define the cograph to be a quotient poset of (the discrete poset) $ X uplus Y $ ; we declare $ a lt b $ if $ f(a) = b $ (and no additional relationships follow).
By regarding again a set as a 0 - category, the latter notion of cograph is a special case of the notion of cograph of a functor, as follows: A function $ f : X to Y $ determines a functor $ bar f : I to Set $ from the interval category $ I = mathbf{2} = {a to b } $ to Set by setting $ bar f(a) = X $ , $ bar f(b) = Y $ and $ bar f(a to b) = f $ .
Then let $ cograph(f) $ be the corresponding category of elements, given by the 2 - pullback $ array{ cograph(f) &to& {} downarrow && downarrow I &stackrel{bar f}{to}& Set } $ which is computed by the strict pullback $ array{ cograph(f) &to& Set_{} downarrow && downarrow I &stackrel{bar f}{to}& Set } , $ .
The cograph of $ f $ in the sense of Lawvere is the set of connected components of this category, i.e
$ . pi0(cograph(f)) $ .
The notion of cograph of a function may be even more related to the sense of graph in graph theory; although the identifications are not done there, the cograph draws a picture in which any relation (or multispan) of any arity becomes a directed graph (or directed multigraph) whose vertex set is the disjoint union of the relation's domains.
When the vertex set is broken up into a disjoint union in this way, graph theorists study this as multipartite graphs; in particular, directed bipartite graphs with vertex set broken up as $ X + Y $ correspond precisely to binary relations from $ X $ to $ Y $ .
The notion of graph of a function is a special case of the notion graph of a functor obtained for functors between 0 - categories.
Accordingly, the notion of cograph of a function is a special case of the notion of cograph of a functor.
In a category associativity is the condition that the two ways to use binary composition of morphisms to compose a sequence of three morphisms are equal $ h circ (g circ f) = (h circ g) circ f phantom{AAAA} $ <center> <img src="https://ncatlab.org/nlab/files/AssociativityDiagram.png" width="300"> </center> $ array{ c2 &overset{ phantom{AA}gphantom{AA} }{longrightarrow}& c3 {}^{mathllap{f}}Biguparrow & searrow^{mathrlap{h circ g}} & Bigdownarrow{}^{mathrlap{h}} c1 &underset{ (h circ g) circ f }{longrightarrow}& c4 } ;;;;=;;;; array{ c2 &overset{ phantom{AA}gphantom{AA} }{longrightarrow}& c3 {}^{mathllap{f}}Biguparrow & {}^{mathllap{ g circ f }}nearrow & Bigdownarrow{}^{mathrlap{h}} c1 &underset{ h circ (g circ f) }{longrightarrow}& c4 } $ If the category has a single object it is the delooping $ mathcal{B} A $ a monoid $ A $ , and then this condition is the associativity condition on the binary operation of monoids such as groups, rings, algebras, etc.
More generally, in higher category theory, associativity of composition of morphisms in an n - category means that the different ways to use binary composition for composing collections of k - morphisms form a contractible infinity - groupoid.
This is a coherence law.
For instance the associativity law in an A - infinity algebra is the special case of associativity in a 1 - object A - infinity - category.
The coherence law of associativity is stated in For $ a $ a dualizable object in a symmetric monoidal category $ C $ (or more generally an object in a traced monoidal category), there is a natural notion of the trace of an endomorphism $ f:a to a $ , which reproduces the ordinary notion of trace of a linear map of finite dimensional vector spaces in linear algebra for the case that $ C = Vect $ .
The idea of the trace operation is easily seen in string diagram notation: essentially one takes the endomorphism $ a stackrel{f}{to} a $ , "bends it around" using the duality and the symmetry and connects its output to its input $ . array{ 1 ;;;downarrow^{tr(f)} 1 } ;;; := ;;; array{ & 1 & downarrow a^* &otimes& a downarrow^{mathrlap{Id{a^}}} && ;;downarrow^f a^ &otimes& a & downarrow^{mathrlap{b{a^*, a}}} a &otimes& a^* & downarrow & 1 } $ This definition makes sense in any braided monoidal category, but often in non - symmetric cases one wants instead a slightly modified version which requires the extra structure of a balancing.
The trace of the identity $ 1a:a to a $ is called the dimension or Euler characteristic of $ a $ .
See trace of a category.
See trace in a bicategory.
Let $ V in C $ be a dualizable object, and $ W $ any object.
From an endomorphism $ f $ of $ V otimes W $ , one can produce an endomorphism $ trV(f) $ of $ W $ , by applying the duality data of $ V $ .
In terms of string diagrams, this is "bending along" the strand representing $ V $ .
TO DO:
Draw the diagram just described.
Suppose $ V $ , $ W $ are finite - dimensional vector spaces over a field, with dimensions $ m $ and $ n $ , respectively.
For any space $ A $ let $ L(A) $ denote the space of linear operators on $ A $ .
The partial trace over $ W $ , Tr $ {W} $ , is a mapping $ T in L(V otimes W) mapsto Tr{W}(T) in L(V) $ .
Let $ e{1}, ldots, e{m} $ and $ f{1}, ldots, f{n} $ be bases for $ V $ and $ W $ respectively.
Then $ T $ has a matrix representation $ {a{k l, i j} } $ where $ 1 le k, i le m $ and $ 1 le l, j le n $ relative to the basis of the space $ V otimes W $ given by $ e{k} otimes f{l} $ .
Consider the sum $ b{k, i} = sum{j=1}^{n}a{k j, i j} $ for $ k, i $ over $ 1, ldots, m $ .
This gives the matrix $ b{k, i} $ .
The associated linear operator on $ V $ is independent of the choice of bases and is defined as the partial trace.
Consider a quantum system, $ rho $ , in the presence of an environment, $ rho{env} $ .
Consider what is known in quantum information theory as the CNOT gate: $ U={|00rangle}{langle 00|} + {|01rangle}{langle 01|} + {|11rangle}{langle 10|} + {|10rangle}{langle 11|} $ .
Suppose our system has the simple state $ {|1rangle}{langle 1|} $ and the environment has the simple state $ {|0rangle}{langle 0|} $ .
Then $ rho otimes rho{env} = {|10rangle}{langle 10|} $ .
In the quantum operation formalism we have $ T(rho) = frac{1}{2}Tr{env}U(rho otimes rho{env})U^{dagger} = frac{1}{2}Tr{env}({|10rangle}{langle 10|} + {|11rangle}{langle 11|}) = frac{{|1rangle}{langle 1|}{langle 0|0rangle} + {|1rangle}{langle 1|}{langle 1|1rangle}}{2} = {|1rangle}{langle 1|} $ where we inserted the normalization factor $ frac{1}{2} $ .
The categorical notion of trace in a monoidal category is due to national Conference on Geometric Topology (Warsaw, 1978), pages 81{102, Warsaw, 1980.
PWN. and Surveys include Generalization of this to indexed monoidal categories is in and to bicategories in Further developments are in {BenZviNadler13} For the notion of partial trace, particularly its application to quantum mechanics, see: A group is nilpotent if it can be built up by central extensions from abelian groups.
A central series for a group is a witness to its nilpotency.
More generally, we may speak about $ mathcal{A} $ - nilpotent $ pi $ - groups, for any class $ mathcal{A} $ of abelian groups and any group $ pi $ acting on our groups.
A group $ G $ is equivalently an Ab - nilpotent $ G $ - group for its adjoint action.
The class of nilpotent groups is defined inductively by the following clauses: (i) The trivial group $ 1 $ is nilpotent.
(ii) If $ 1to G' to G to G''to 1 $ is a central extension (so that in particular, $ G' $ is abelian) and $ G'' $ is nilpotent, then $ G $ is nilpotent.
Phrased in this way, nilpotency is an inductive predicate on the class of groups.
If we regard the same clauses as defining an inductive family indexed over the class of groups, then we obtain the definition of a central series.
The set of central series for a group $ G $ is defined inductively by the following clauses: (i) The trivial group $ 1 $ has a specified central series, called the "trivial" one.
(ii) From any central extension $ 1to G' to G to G''to 1 $ and any central series of $ G'' $ , we obtain a central series of $ G $ , called an "extension" of the given one.
Thus, central series are "witnesses" to nilpotency: a group is nilpotent if and only if it has some central series.
If we "expand out" the inductive definition of central series, and use the isomorphism theorems, we see that it consists of a sequence of central extensions $ 1 to G1 to G to G/G1 to 1 $ $ 1 to G2/G1 to G/G1 to G/G2 to 1 $ $ 1 to G3/G2 to G/G2 to G/G3 to 1 $ $ dots $ $ 1 to G/G{n - 1} to G/G{n - 1} to 1 to 1 $ and therefore a sequence of normal subgroups $ 1 = G0 trianglelefteq G1 trianglelefteq G2 trianglelefteq dots trianglelefteq G{n - 1} trianglelefteq Gn = G $ such that each $ Gi/G{i - 1} $ is central in $ G/G{i - 1} $ .
This is the "usual" definition of central series.
Every central series has a length, defined recursively by saying that the length of the trivial central series is $ 0 $ and the length of an extension is one more than the length of the original.
The nilpotency class of a nilpotent group is the minimum length of all of its central series.
Proofs about nilpotent groups are often most naturally phrased using induction over the inductive definition of nilpotency.
However, probably due to widespread ignorance about inductive definitions, it is common to find them phrased instead using ordinary natural - number induction over the nilpotency class.
If we interpret the same defining clauses of nilpotent groups and central series coinductively rather than inductively, we obtain notions that might be called co - nilpotent groups and central streams ("stream" being the standard name for the coinductive counterpart of a list).
Explicitly, a central stream is a descending countable sequence of normal subgroups, such that each successive quotient is central in the corresponding quotient of the whole group, that may or may not ever terminate with the trivial group.
In fact, every group admits some central stream and hence is co - nilpotent.
Two canonical central streams associated to any group are its lower central series and its upper central series (for now see Wikipedia).
Despite the names, these two central streams are actually central series (i.e. they terminate at the trivial group) if and only if the group is nilpotent.
The following generalization of nilpotent groups is sometimes useful.
Let $ mathcal{A} $ be any class of abelian groups containing $ 0 $ , and let $ pi $ be any group.
By a $ pi $ - group we mean a group with an action of $ pi $ (through group automorphisms, of course).
The class of $ mathcal{A} $ - nilpotent $ pi $ - groups is defined inductively by the following clauses: (i) The trivial group $ 1 $ is $ mathcal{A} $ - nilpotent.
(ii) If $ 1to G' to G to G''to 1 $ is a central extension of $ pi $ - groups (i.e. a central extension whose maps are $ pi $ - equivariant), and $ G'' $ is $ mathcal{A} $ - nilpotent while $ G'in mathcal{A} $ and $ pi $ acts trivially on $ G' $ , then $ G $ is $ mathcal{A} $ - nilpotent.
A group $ G $ is nilpotent in the original sense if and only if it is an $ Ab $ - nilpotent $ G $ - group with its adjoint action.
If $ pi $ is nontrivial and/or $ mathcal{A} $ is strictly smaller than $ Ab $ , then the notion of $ mathcal{A} $ - nilpotency can be nontrivial even for abelian groups (whereas every abelian group is obviously nilpotent in the ordinary sense).
Every nilpotent group is an example of a solvable group (indeed, the groups in the lower central series of any group can be term - wise included into its derived series).
The Sylow p - subgroups of any nilpotent group are normal.
The direct product of these subgroups in such a group is its torsion subgroup.
Generally: Specifically: In measure theory, measure spaces are used in the general theory of measure and integration, somewhat analogous to the role played by topological spaces in the study of continuity.
For the general theory of measure spaces, we first need a measurable space $ (X, Sigma) $ , that is a set equipped with a collection $ Sigma $ of measurable sets complete under certain operations.
Then this becomes a measure space $ (X, Sigma, mu) $ by throwing in a function $ mu $ from $ Sigma $ to a space of values (such as the real line) that gets along with the set - theoretic operations that $ Sigma $ has.
If $ E $ is a measurable set, then $ mu(E) $ is called the measure of $ E $ with respect to $ mu $ .
The original notation for an integral (going back to Gottfried Leibniz) was inta^b f(x) , mathrm{d}x (where $ f(x) $ would be replaced by some formula in the variable $ x $ ).
In modern measure theory, we can now understand this as the integral of the measurable function $ f $ on the interval $ a, b $ relative to Lebesgue measure.
If we wish to generalise from Lebesgue measure to an arbitrary measure $ mu $ and generalise from $ a, b $ to an arbitrary measurable set $ S $ , then we can write int{xin{S}} f(x) , mu(mathrm{d}x) instead.
Now, if $ f $ is not given by a formula but rather explicitly named, then there is no need for the dummy variable $ x $ , so we should write intS f , mu .
However, it has been more common to keep the symbol ' $ mathrm{d} $ ' and write intS f , mathrm{d}mu .
(Note that ' $ mathrm{d} $ ' can be read as 'with respect to' in both (eq:Leibniz) and (eq:excessive), although meaning different things; in the former case, it indicates the dummy variable, while in the latter case, it indicates the measure.)
This notation then leads to replacing (eq:full) with int{xin{S}} f(x) , mathrm{d}mu(x) .
This last notation, however, hides the fact that integrating a function with respect to a measure is a way of multiplying a function by a measure to get a new measure; the integral of $ f $ on $ S $ with respect to $ mu $ is simply the measure of $ S $ with respect to $ f mu $ , as can be seen in (eq:simple).
Compare also notation for Radon - Nikodym derivatives.
It is also possible to take the entire expression ' $ mathrm{d}mu $ ' as the name of the measure, writing $ mathrm{d}mu(A) $ even where the common notation is $ mu(A) $ .
In that case, the common expression (eq:excessive) is literally the same as (what would otherwise be) (eq:simple), although (eq:switched) is not quite the same as (what would otherwise be) (eq:full).
We will use (eq:simple) below (although other forms may well be found on other pages).
See Usenet discussion, and contrast (eq:switched) with the Stieltjes integral.
(The point is that it is $ mathrm{d}x $ , not just $ x $ , that gives us the relevant measure in (eq:Leibniz).)
The notation (eq:simple) has also been used in an introductory graduate - level course by John Baez.
There is also some variation in notation as to whether to use a roman ' $ mathrm{d} $ ' or an italic ' $ mathit{d} $ '; roman is more common in England and italic in America.
But of course, that variation should not cause any difficulties!
A measure space is a measurable space equipped with a measure.
There are many different kinds of measures; we start with the most specific and then consider generalisations.
The motivating example is Lebesgue measure on the unit interval.
Let $ (X, Sigma) $ be a measurable space.
A probability measure on $ X $ (due to Andrey Kolmogorov) is a function $ mu $ from the collection $ Sigma $ of measurable sets to the unit interval $ 0, 1 $ such that: (i) The measure of the entire space is one: $ mu(X) = 1 $ ; (ii) Countable additivity: $ mu(bigcup{i = 1}^{infty} Si) = sum{i=1}^{infty} mu(Si) $ whenever the $ Si $ are mutually disjoint.
(Part of the latter condition is the requirement that the sum on the right - hand side must converge.)
It is sometimes stated (but in fact follows from the above) that: The first of these conditions will follow for all of the generalised notions of measure below, but the second usually will not.
Related query discussion is archived here.
From now on, we drop the condition $ mu(X)=1 $ ; the next step is to generalize the target of $ mu $ , as follows: We define an infinite measure by replacing the domain of $ mu $ by an ideal $ Sigma' $ of $ Sigma $ such that the following saturation condition is satisfied: if $ {Si } {iin I} $ is a disjoint family of elements of $ Sigma' $ and $ sum{iin I}|mu|(Si) $ exists (and is finite), then $ bigcup{iin I}SiinSigma' $ .
The countable additivity condition should now be modified to require $ bigcup{iin I}SiinSigma' $ .
An infinite measure $ mu $ is semifinite if for any $ SinSigmasetminusSigma' $ there is $ TinSigma' $ such that $ Tsubset S $ and $ mu(T)gt0 $ .
The Radon - Nikodym theorem shows that semifinite complex - valued measures that are absolutely continuous with respect to some fixed localizable measure form a free module over the algebra of complex - valued measurable functions (not necessarily bounded).
Some further terms: Remarks: Another possibility is to generalize the source of $ mu $ ; instead of using a $ sigma $ - algebra on $ X $ , we could use a $ sigma $ - ring or even a $ delta $ - ring.
These versions are mostly more about changing the definition of measurable space, so refer there for details of the definitions; however, we note that (3), when $ Sigma $ is a $ delta $ - ring, should state that the left - hand side exists (that is, the union is measurable) if the right - hand side converges.
Generalizing $ Sigma $ in this way is complementary to generalizing the target above; in particular it may allow one to avoid dealing with $ infty $ .
For example, while Lebesgue measure is only a positive measure on a $ sigma $ - algebra, it is a finite positive measure on the $ delta $ - ring of bounded measurable sets.
Indeed, every signed measure gives rise to finite measure on its $ delta $ - ring of finitely measurable sets (as defined below); conversely, every $ sigma $ - finite measure can be recovered from this by imposing (3) in all cases.
Yet another possibility is to drop countable additivity, replacing it with finite additivity.
The result is a finitely additive measure, sometimes called a charge to avoid the red herring principle; in contrast, the usual sort of measure may be called countably additive.
For a charge, one could replace $ Sigma $ with an algebra (or even a ring) of sets; again see measurable space for these definitions.
Finally, an extended measure takes values in the set $ - infty, infty $ of extended real numbers.
Here we have the problem that, even when considering finite additivity, we might have to add $ infty $ and $ - infty $ .
While we might simply require that this never happens (so that at least one of $ mu(S) $ and $ mu(T) $ must be finite if they have opposite signs and $ S cap T = empty $ ), this does not include some examples that we want (and in fact it would follow that $ infty $ and $ - infty $ cannot both be values of $ mu $ after all).
To deal with this, we define an extended measure to be a formal difference $ mu^+ - mu^ - $ of positive measures; $ mu(S) = mu^+(S) - mu^ - (S) $ whenever this is not of the form $ infty - infty $ and is otherwise undefined.
Note that the set of extended measures on $ X $ is a quotient set of the set of pairs of positive measures; we say that $ mu = nu $ if $ mu(S) = nu(S) $ whenever either side is defined, that is if $ mu $ and $ nu $ are the same as partial functions from $ Sigma $ to $ - infty, infty $ .
Any extended measure restricts to an infinite signed measure, taking $ Sigma'subsetSigma $ to be the set of elements of $ Sigma $ with a finite measure.
Vice versa, an infinite signed measure $ mu $ canonically extends to an extended measure: we can define $ mu+ $ and $ mu - $ as usual and then take the formal difference $ mu+ - mu - $ .
In Henry Cheng's constructive theory of measure, the definition of measurable space becomes more complicated; the main point is that a single measurable set $ S $ is replaced by a complemented pair $ (S, T) $ .
Once that is understood, very little needs to be changed to define a measure space.
In the requirements (1 - - 3), the constants $ empty $ and $ X $ and the operation $ union $ are interpreted by formal de Morgan duality, as explained at Cheng measurable space.
The convergence requirement in (3) should be interpreted in the strong sense of located convergence and is no longer trivial for positive measures.
We must add a further requirement to enforce the idea that $ mu(S, T) $ is the measure of $ S $ alone, as follows: In general, a measurable set is any set $ S $ such that $ (S, T) $ is a complemented pair for some set $ T $ ; the term 'measurable set' in the classical theory should be interpreted as either 'mesurable set' or 'complemented pair' in the constructive theory, depending on context.
Usually both interpretations will actually work, but often only the first set of the pair will matter, thanks to the axiom above.
We will mention other occasional fine points in the constructive theory when they occur; the main outline does not change.
I need to check Bishop & Bridges to see if there are any other changes, but I don't think so; that is, I went through the following, and it all seems correct as it is. - - - Toby In measure theory, a measure on a $ sigma $ - frame or more generally a $ sigma $ - complete distributive lattice $ (L, leq, bot, vee, top, wedge, Vee) $ is a valuation $ mu:L to 0, infty $ such that the elements are mutually disjoint and the probability valuation is denumerably/countably additive $ forall sin L^mathbb{N}. forall m in mathbb{N}. forall n in mathbb{N}. (m neq n) wedge (s(m) wedge s(n) = bot) $ $ forall sin L^mathbb{N}. mu(Vee{n:mathbb{N}} s(n)) = sum{n:mathbb{N}} mu(s(n)) $ Given a measure space $ (X, Sigma, mu) $ , a $ mu $ - null $ Sigma $ - measurable set is a measurable set $ N $ such that $ mu(S) = 0 $
whenever $ S subseteq N $ is measurable; a $ mu $ - null set is any subset of a null measurable set.
In a positive measure space, we don't have to bother with $ S $ ; $ N $ will be a null measurable set as long as $ mu(N) = 0 $ .
A $ mu $ - full $ Sigma $ - measurable set is a measurable set $ F $ such that $ mu(S) = mu(S cap F) $ for every measurable set $ S $ ; a $ mu $ - full set is any superset of a full measurable set.
In a probability measure space, we don't have to bother with $ S $ ; $ F $ will be a full measurable set as long as $ mu(F) = 1 $ .
Classically, a full set is precisely the complement of a null set, but this doesn't hold in the constructive theory.
A property of elements of $ X $ holds $ mu $ - almost everywhere if the set of values where it holds is full.
A measure is complete if every full set is measurable.
We may form the completion of a measure space by accepting as a measurable set the intersection of any set and a full set; these $ mu $ - measurable sets will automatically form a $ sigma $ - algebra (or whatever $ Sigma $ originally was).
Classically, a measure is complete if and only if every null set is measurable and a set is $ mu $ - measurable if and only if it is the symmetric difference between a measurable set and a null set.
A finitely $ mu $ - measurable set is a measurable set $ M $ such that $ mu(S) $ is finite whenever $ S subseteq M $ is measurable; a $ sigma $ - finitely $ mu $ - measurable set is any union of countably many finitely measurable sets.
Again, we don't have to bother with $ S $ in a positive measure space.
Note that a measure space is ( $ sigma $ ) - finite if and only if every measurable set is ( $ sigma $ ) - finitely measurable.
The finitely measurable sets form a $ delta $ - ring, and the $ sigma $ - finitely measurable sets form a $ sigma $ - ring.
Recall that a $ Sigma $ - measurable function from $ (X, Sigma) $ to some other measurable space is any function $ f $ such that the preimage under $ f $ of a measurable set is always measurable (or something more complicated in the constructive theory).
Now that we have a measure space, let a $ mu $ - measurable function be a partial function $ f $ from $ X $ to some other measurable space such that the domain of $ f $ is full and the preimage under $ f $ of a measurable set is always $ mu $ - measurable (that is measurable in the completion of $ mu $ ), and let two such functions be $ mu $ - equivalent if their equaliser is a full set.
We are really interested in the quotient set under this equivalence and so identify equivalent $ mu $ - measurable functions.
Classically, every $ mu $ - measurable function is equivalent to some (total) $ Sigma $ - measurable function, so the definition is simpler in that case; however, partial functions still come up naturally in the classical theory, so it can be convenient to allow them rather than (as is usually done in a rigorous treatment) systematically replacing them with total functions.
A $ mu $ - integrable function is a $ mu $ - measurable function $ f $ such that the integral $ intS f , mu $ (as defined below) exists for every measurable set $ S $ ; it is enough to check $ S = X $ .
Equivalently, we may say that it is a $ mu $ - measurable function $ f $ such that the extended measure $ f mu $ (also defined below) is actually a finite measure.
(In any case, we get a finite measure $ f mu $ if $ f $ is integrable.)
In the following, 'measurable' will mean $ mu $ - measurable.
That is, we assume that $ mu $ is complete and identify $ mu $ - equivalent functions.
We will also assume that $ mu $ is a positive measure until I make sure of what must be done to generalise.
Given a measure $ mu $ , a measurable set $ S $ , and a measurable function $ f $ , we will define the integral $ intS f , mu $ (see above for variations in notation) in stages, from the simplest form of $ f $ to the most arbitrary.
Each measurable subset $ S subseteq X $ induces a measurable characteristic function $ chiScolon X to mathbb{R}+ $ where $ chiS(x) = 1 $ if $ x in S $ , $ chiS(x) = 0 $ if $ x in neg{S} $ .
(In the constructive theory, where $ S $ is a complemented pair, $ chiS $ is a partial function with a full domain, so $ chiS f $ is still a measurable function as defined above.)
In general, we have $ intS f , mu = intX chiS f , mu , $ so from now on we will assume that we are integrating over all of $ X $ (and drop the subscript).
A positive simple function is a finite $ mathbb{R}+ $ - linear combination of measurable characteristic functions; the first form of integral that we define is $ int sum{1 leq i leq n} ai chi{Si} , mu = sum{1 leq i leq n} ai mu(Si) $ .
The integral is extended to all measurable functions $ fcolon X to 0, infty $ by the rule $ int f , mu = sup { int s , mu ;|; 0 leq s leq f, s; simple } $ if this supremum converges.
Classically, the integral either converges or diverges to infinity, so $ int f , mu $ exists in some sense in any case; the possibilities are more complicated constructively.
For any measurable function $ fcolon X to - infty, infty $ , define $ f+ $ and $ f{ - } $ by $ f+(x) = max{f(x), 0 } , qquad f{ - }(x) = max{ - f(x), 0 } $ so that $ f = f+ - f{ - } $ , $ {|f|} = f+ + f{ - } $ .
Then the final definition is $ int f , mu = int f{+} , mu - int f{ - } , mu $ if both integrals on the right converge.
Classically, the other possibilities are $ infty $ , $ - infty $ , and $ infty - infty $ ; not much can be done with the latter.
A measurable function $ f $ is integrable with respect to $ mu $ if this integral converges.
It can be proved that all of the definitions above are consistent; that is, if the final definition is applied to a simple function, then it agrees with the original definition.
If $ f $ takes values in the field $ mathbb{C} $ of complex numbers or in some more general Banach space $ V $ , then we can still ask whether $ {|f|} $ is integrable.
If it is, then we say that $ f $ is absolutely integrable.
We can then define the integral of $ f $ ; we always have $ {|int f , mu|} leq int {|f|} , mu $ .
This integral is easy to define if $ V $ has a basis; for example, a measurable complex - valued function $ fcolon X to mathbb{C} $ is integrable iff both its real and imaginary parts are integrable, and we have $ int f , mu = int Re{f} , mu + mathrm{i} int Im{f} , mu $ .
I need to check HAF for more details here in the general case.
In particular, something can be integrable without being absolutely integrable (although not if it's complex - valued, of course) or indeed even without being valued in a (pseudo)normed space.
The vector space of $ V $ - valued integrable functions is itself a Banach space, using the norm $ {|f|1} coloneqq int {|f|} , mu $ .
Note that we must use the notion of measurable function as an equivalence class of functions to get a Banach space here; otherwise we have only a pre - Banach space (that is, a complete pseudonormed vector space).
This Banach space is called a Lebesgue space and is denoted $ L^1(mu, V) $ , $ L^1(X, V) $ , or just $ L^1 $ , depending on context.
The default value of $ V $ is usually either $ mathbb{R} $ or $ mathbb{C} $ , depending on the author.
More general Lebesgue spaces of the form $ L^p $ also exist; $ f $ is in $ L^p $ precisely when $ {|f|^p} $ is integrable, and we use $ {|f|p} coloneqq root p {int {|f|^p} , mu} $ as the norm.
(At least, this is so for $ p in {{0, infty}} $ ; see Lebesgue space for generalizations to other values of $ p $ .)
Note that $ (f mu) (S) = int chiS f , mu $ makes $ f mu $ into a $ V $ - valued measure whenever $ f $ is an integrable $ V $ - valued function.
When $ f $ is $ - infty, infty $ - valued and $ mu $ is a signed measure, then $ f $ is an extended measure which is finite iff $ f $ is integrable.
We have $ (f g) mu = f (g mu) $ .
Thus integration can be seen as a way of multiplying a function by a measure to get another measure.
The Radon - Nikodym derivative is about reversing this (dividing two measures to get a function).
Other topics: absolute continuity, etc. (Refer to &lt;http://tobybartels.name/notes/Radon>.)
Every commutative von Neumann algebra is isomorphic to the Lebesgue space $ L^infty(X, mu) $ where $ mu $ is some measure (which is irrelevant) on a localisable measurable space, and this extends to a duality between localisable measurable spaces and commutative von Neumann algebras.
This is similar to the correspondence between commutative $ C^* $ - algebras and locally compact Hausdorff spaces, which is the central approach to noncommutative geometry.
It is useful to exploit the intuition that the theory of (noncommutative) von Neumann algebras is a noncommutative analogue of classical measure theory.
See the references at measure theory.
For measures on $ sigma $ - frames, see Discussion via Boolean toposes is in category: analysis For a finite set $ X $ , a cyclic permutation on $ X $ is a permutation $ sigma colon X to X $ such that the induced group homomorphism $ mathbb{Z} to Aut(X) $ from the integers to the automorphism group (i.e. the symmetric group) of $ X $ , sending $ n in mathbb{Z} $ to $ sigma^n $ , defines a transitive action.
One may visualize the elements of $ X $ as points arranged on a circle spaced equally apart, with $ sigma(x) $ the next - door neighbor of $ x $ in the counterclockwise direction, hence the name.
See also rotation permutation.
See also: A tree is a connected graph without cycles.
Some notions of tree (such as planar tree) consider extra structure or properties as well, but the baseline notion is tree as acyclic connected graph.
Trees are fundamental combinatorial objects which appear in a wide variety of guises.
Some are given below.
Recall that an undirected graph $ G $ consists of a set $ V $ of vertices and a set $ E $ of unordered pairs of vertices.
A path in $ G $ is a finite sequence of vertices $ x0, ldots, xn $ such that each pair $ xi x{i+1} $ belongs to $ E $ .
If $ xn = x0 $ , then the path is called a cycle.
A graph is connected if it is nonempty and if for every distinct pair of vertices $ x, y $ , there is a path for which $ x0 = x $ and $ xn = y $ .
A graph is acyclic if the only cycles are paths $ x0, ldots, x{n - 1}, xn, x{n - 1}, ldots, x0 $ where steps are retraced; an acyclic graph is also called a forest.
A tree is a connected forest.
Each forest is a disjoint sum (a coproduct in the category of graphs) of trees.
Removal of a vertex of a tree (and any edges incident to it) results in a forest.
Not all authors include nonemptiness as part of the notion of connectedness.
See connected space for commentary on this.
Forests on the other hand may be empty.
A topological tree is a 1 - dimensional CW - complex which is contractible, i.e., homotopy equivalent to a point.
In this language, a topological graph is simply a 1 - dimensional CW - complex; more precisely, we mean a CW - presentation and not merely a space that can be so presented.
A topological forest is then a 1 - dimensional CW - complex with vanishing first homology group with integral coefficients, and a tree is a connected forest.
For finite graphs $ G $ as CW - complexes, one has the useful Euler formula: $ h0 - h1 = c0 - c1 $ where $ ci $ is the number of $ i $ - cells and $ hi $ is the rank of the homology group $ Hi(G; mathbb{Z}) $ .
This gives a useful criterion for a graph to be a tree: that it be connected ( $ h0 = 1 $ ) and that the number of vertices $ c0 $ be 1 greater than the number of edges $ c1 $ .
A rooted tree is a directed graph (or quiver) $ G $ such that the free category generated by $ G $ has a terminal object, called the root of $ G $ .
(Thus for every vertex $ x $ in $ G $ there is exactly one directed path from $ x $ to the root.
It follows easily that the free category is a poset.
There is no significant change in content if "terminal" here is replaced by "initial"; we can distinguish the conventions by a tree directed towards the root rather than away from the root.)
A rooted forest is a coproduct of rooted trees, and again we have the fundamental fact that there is a natural equivalence of categories $ Tree overset{to}{leftarrow} Forest $ which in one direction is the functor which sends a tree to the forest which results by excising the root and all edges incident to it, and in the other sends a forest to the tree gotten by adjoining a new root and joining the roots of the forest to that new root by new edges.
This equivalence can be exploited to relate the exponential generating function for finite rooted trees to the Lambert W - function (q.v.).
A tree in the form of an undirected graph together with a chosen vertex can be regarded as a rooted tree in digraph form (with root the chosen vertex), by orienting all edges in the direction of paths going to the root.
The category of rooted trees has very nice categorical properties not shared by the category of unrooted trees; see the following section.
In order theory, a tree is described by a partial order with the added property that it is downward well ordered.
Let $ S $ be a partially ordered set, then $ S $ is a tree when for each $ x in S $ the downward closure or history $ x^ - = { y mid y leq x } $ is a well ordered subset of $ S $ .
If instead of a well - order we find that $ x^ - $ is only totally ordered (meaning that points in the tree do not have a distinguished successor) we say that $ S $ is prefix ordered.
Let $ mathbb{N} $ be the totally ordered set of natural numbers $ 0 leq 1 leq 2 leq ldots $ , viewed as a category.
A rooted forest is a presheaf on $ mathbb{N} $ , i.e., a functor $ F: mathbb{N}^{op} to Set $ to "the" category of sets.
A rooted tree is a forest for which $ F(0) $ is terminal (a point).
In this case, we get from a tree as functor $ F $ to a tree as digraph by passing to the category of elements $ El(F) $ .
The vertices of the digraph are the elements, and the edges are those morphisms of $ El(F) $ which map to morphisms $ i + 1 to i $ in $ mathbb{N}^{op} $ .
Notice that $ mathbb{N}^{op} $ is itself (the free category on) a tree as digraph, one that is terminal in the category of forests.
In the other direction, starting with a tree as digraph, we define a functor $ F colon mathbb{N}^{op} to Set $ by letting $ F(n) $ be the set of vertices $ v $ such that the path from $ v $ to the root has $ n $ edges.
The map $ F(n+1) to F(n) $ moves a vertex $ v in F(n+1) $ to the vertex that is one step closer to the root (along the unique path from $ v $ to the root).
The functor description makes it clear that the category of forests is a (presheaf) topos, indeed a Grothendieck topos; therefore the category of trees, which is equivalent, is also a topos.
If we replace $ Set $ here by the category of totally ordered sets $ Tos $ , then we may define a planar forest as a functor $ F: mathbb{N}^{op} to Tos $ The category of trees as described in the section immediately above can be described universally in 2 - universal terms, as the 2 - terminal coalgebra for the endofunctor on $ Cat $ (locally small categories) which takes a category to its small - coproduct cocompletion.
See terminal coalgebra for an extended discussion.
Let $ mathbf{F} $ denote the free (strict) monoidal category generated by $ n $ - ary operations $ thetan: x^n to x $ , one for each arity $ n geq 0 $ .
A (finite) planar forest with ( $ n $ ) live leaves is a morphism $ phi: x^n to x^m $ in $ mathbf{F} $ ; a (finite) planar tree with ( $ n $ ) live leaves is a morphism $ phi: x^n to x $ .
The previous description is more a theorem than definition, but it points to the recursive construction of trees based on the fundamental equivalence between forests and trees: $ f1 otimes ldots otimes fk colon x^{n1 + ldots + nk} = x^{n1} otimes ldots otimes x^{nk} to x otimes ldots otimes x = x^k $ whose set of live leaves is the disjoint union of sets of live leaves of
the $ fj $ $ . f1 otimes ldots otimes fk colon x^{n1 + ldots + nk} = x^{n1} otimes ldots otimes x^{nk} to x otimes ldots otimes x = x^k $ there is a tree $ thetan circ (f1 otimes ldots otimes fk) colon x^{n1 + ldots + nk} to x $ with the same set of live leaves.
In more straightforward combinatorial language: if a finite planar tree is a functor $ F colon n^{op} to Deltaa $ from a finite ordinal to the augmented simplex category, and a **leaf** is an element without predecessors in the poset of elements of $ F $ , then we can consider as extra structure some subset of the leaves whose elements are designated as **live**.
The principle is that one is permitted to graft roots of trees onto live leaves, but not onto dead ones.
(Dead leaves arise by plugging in the constant = $ 0 $ - ary operation $ theta0 colon I = x^0 to x $ .)
Fancier versions of this basic recursive construction may involve "colored trees", "cherry trees", and so on, and figure prominently in the theory of operads, especially in the construction of free operads.
In fact, this type of recursivity is at the root (pun perhaps intended) of the cumulative hierarchy conception of sets in a material set theory like ZFC set theory: all sets are collections of sets $ {x1, ldots, xn } $ , and all sets are formed in this way.
In order to found this conception on trees in a way that accepts the axiom of foundation, one must restrict to well - founded trees.
A tree (pictured as a free category on a digraph, i.e., as a certain poset $ P $ ) is well - founded if every object of $ P^{op} $ is bounded above by a maximal element, or equivalently if there are no infinite chains $ x0 lt x1 lt ldots $ in $ P^{op} $ starting from the root $ x0 $ .
(Chains starting from the root are also called **branches**.)
See well - founded relation for other formulations of this definition (including those suitable for constructive mathematics; see pure set for details on this construction of the cumulative hierarchy, including using arbitrary trees for ill - founded sets.
The category of well - founded trees admits a (2 - )universal description, as an initial algebra for a certain endofunctor on Cat.
See well - founded forest for details.
To be continued... Very nice!
Is there a similar story worth telling for possibly infinite trees, corecursion, etc.
Toby:
Well - founded trees (and pure sets) may be defined recursively; ill - founded trees (and pure sets) may be defined corecursively; there is stuff about this at pure set.
(Note that even a well - founded tree may be infinite, as long as some vertex has infinitely many branches out of it.)
A rooted tree can be defined as a relational structure and as such serves as a useful model in the context of modal logics.
In this form it consists of a set of nodes, vertices or whatever your preferred terminology is, and a binary relation, $ S $ , on $ T $ .
These are to satisfy the following: This last property, of course, implies that $ S $ is irreflexive.
A new way of thinking about (rooted, usually assumed finite) trees has been introduced by Joachim Kock.
A tree $ T $ consists of a set $ T0 $ of edges, a set $ T1 $ of nodes, and a set $ T2 $ of input flags, all assumed finite, together with functions $ T0 stackrel{s}{leftarrow} T2 stackrel{p}{to} T1 stackrel{t}{to} T0 $ such that Some commentary is in order.
The subscript $ 0 $ for edges and $ 1 $ for nodes is consonant with standard usage in string diagrams, where edges are labeled by $ 0 $ - cells in a monoidal category and nodes by $ 1 $ - cells.
Each node is pictured as having a multiplicity of (and possibly zero) input edges and exactly one outgoing edge; the map $ t: T1 to T0 $ maps a node to its outgoing edge.
Only the root edge is not an input edge of any node, i.e., the unique inhabitant of the complement of $ im(s) $ is what we call the root $ r $ .
Now: the input "function" $ T1 to T0 $ is actually a multivalued function, taking a node to the set of its input edges, and is therefore represented as a relation or span from $ T0 $ to $ T1 $ .
The domain of this relation $ T2 $ is the set of ordered pairs $ (e, v) $ where $ e in T0 $ is an input edge of $ v in T1 $ ; this may be called a "flag" (thinking of a general flag as a chain of incidence relations, here a 1 - step chain with $ e $ input - incident to $ v $ ).
To each tree $ T $ described in this form, there is an associated polynomial endofunctor $ pT: Set/T0 to Set/T0 $ controlled by the data $ T0 stackrel{s}{leftarrow} T2 stackrel{p}{to} T1 stackrel{t}{to} T0 $ and defined by the composition $ Set/T0 stackrel{s^ast}{to} Set/T2 stackrel{Pip}{to} Set/T1 stackrel{Sigmat}{to} Set/T0 $ where as usual $ Sigmaf dashv f^ast dashv Pif $ .
Notice that the functors on display preserve pullbacks, so $ pT $ preserves pullbacks.
There is a double category whose $ 0 $ - cells are sets $ I $ , whose horizontal $ 1 $ - cells are polynomial endofunctors $ p: Set/I to Set/J $ , whose vertical $ 1 $ - cells are pullback functors $ f^ast: Set/I to Set/I' $ induced by functions $ f: I' to I $ , and whose $ 2 $ - cells are cartesian natural transformations of the form $ array{ Set/I & stackrel{p}{to} & Set/J mathllap{f^ast} downarrow & swArrow & downarrow mathrlap{g^ast} Set/I' & underset{p'}{to} & Set/J' } $ The category consisting of horizontal arrows and 2 - cells between them is called the category of polynomial endofunctors, $ PolyEnd $ .
Kock defines a category of trees where objects are trees $ T $ and whose morphisms are morphisms between the corresponding endofunctors $ pT $ as objects in $ PolyEnd $ .
As Kock shows, this description of trees is well - adapted to the usual sorts of combinatorics that emerge in the study of operads, such as free operads.
In the category Set a 'pullback' is a subset of the cartesian product of two sets.
Given a diagram of sets and functions like this: A arrd, "f"' & & B arld, "g" & C the 'pullback' of this diagram is the subset $ X subseteq A times B $ consisting of pairs $ (a, b) $ such that the equation $ f(a) = g(b) $ holds.
A pullback is therefore the categorical semantics of an equation.
This construction comes up, for example, when $ A $ and $ B $ are fiber bundles over $ C $ : then $ X $ as defined above is the product of $ A $ and $ B $ in the category of fiber bundles over $ C $ .
For this reason, a pullback is sometimes called a fibered product (or fiber product or fibre product).
In this case, the fiber of $ A timesC B $ over a (generalized) element $ x $ of $ C $ is the ordinary product of the fibers of $ A $ and $ B $ over $ x $ .
In other words, the fiber product is the product taken fiber - wise.
Of course, the fiber of $ A $ at the generalized element $ xcolon I to C $ is itself a fibre product $ I timesC A $ ; the terminology depends on your point of view.
Note that there are maps $ pAcolon X to A $ , $ pBcolon X to B $ sending any $ (a, b) in X $ to $ a $ and $ b $ , respectively.
These maps make this square commute: & X arld, "pA"' arrd, "pB" A arrd, "f"' & & B arld, "g" & C In fact, the pullback is the universal solution to finding a commutative square like this.
In other words, given any commutative square & Y arld, "qA"' arrd, "qB" A arrd, "f"' & & B arld, "g" & C there is a unique function $ hcolon Y to X $ such that $ pA h = qA $ and $ pB h = qB, $ .
Since this universal property expresses the concept of pullback purely arrow - theoretically, we can formulate it in any category.
It is, in fact, a simple special case of a limit.
A pullback is a limit of a diagram like this: a arrd, "f"' & & b arld, "g" & c Such a diagram is also called a pullback diagram or a cospan.
If the limit exists, we obtain a commutative square & x arld, "pa"' arrd, "pb" a arrd, "f"' & & b arld, "g" & c and the object $ x $ is also called the pullback.
It is well defined up to unique isomorphism.
It has the universal property already described above in the special case of the category $ Set $ .
The last commutative square above is called a pullback square.
The concept of pullback is dual to the concept of pushout: that is, a pullback in $ C $ is the same as a pushout in the opposite category $ C^{op} $ .
Let $ mathcal{C} $ be a category, with $ fcolon ato c $ and $ gcolon bto c $ coterminal arrows in $ mathcal{C} $ as below a arrd, "f"' & & b arld, "g" & c A pullback of $ f $ and $ g $ consists of an object $ x $ together with arrows $ pacolon xto a $ and $ pbcolon xto b $ such that the following diagram commutes universally & x arld, "pa"' arrd, "pb" a arrd, "f"' & & b arld, "g" & c This means that for any other object $ x' $ with arrows $ p'acolon x'to a $ and $ p'bcolon x'to b $ such that & x' arld, "p'a"' arrd, "p'b" a arrd, "f"' & & b arld, "g" & c commutes, there exists a unique arrow $ ucolon x'to x $ such that & x' arld, "p'a"' arrd, "p'b" ard, "u", dotted a & x arl, "pa"' arr, "pb" & b commutes.
In type theory a pullback $ P $ in P arr ard & A ard, "f" B arr, "g"' & C is given by the dependent sum over the dependent equality type $ P = sum{acolon A} sum{bcolon B} (f(a) = g(b)) , $ .
If products exist in $ C $ , then the pullback a timesc b arr ard & a ard, "f" b arr, "g"' & c is equivalently the equalizer a timesc b arr & a times b arr, shift left, "fp1" arr, shift right, "gp2"' & c of the two morphisms induced by $ f $ and $ g $ out of the product of $ a $ with $ b $ .
As a consequence of the above, any category with binary products and equalizers has pullbacks.
Conversely any category with binary products and pullbacks has equalizers: the equalizer of $ f, g:A to B $ is the pullback of $ (1, f) maps A to A times B $ and $ (1, g) maps A to A times B $ .
Pullbacks preserve monomorphisms and isomorphisms: If a arr ard, "f^ast g"' & b ard, "g" c arr, "f"' & d is a pullback square in some category then: (i) if $ g $ is a monomorphism then $ f^ast g $ is a monomorphism; (i) if $ g $ is an isomorphism then $ f^ast g $ is an isomorphism.
On the other hand that $ f^ast g $ is a monomorphism does not imply that $ g $ is a monomorphism.
In any category consider a diagram of the form a arr ard & b arr ard & c ard d arr & e arr & f
There are three commuting squares: the two inner ones and the outer one.
Suppose the right - hand inner square is a pullback, then: The square on the left is a pullback if and only if the outer square is.
Pasting a morphism $ x to a $ with the outer square gives rise to a commuting square over the (composite) bottom and right edges of the diagram.
The square over the cospan in the left - hand inner square arising from $ x to a $ includes a morphism into $ b $ , which if $ b $ is a pullback induces the same commuting square over $ d to e to f $ and $ c to d $ .
So one square is universal iff
the other is.
The converse implication does not hold: it may happen that the outer and the left square are pullbacks, but not the right square.
For instance let $ icolon a to b $ be a split monomorphism with retract $ pcolon b to a $ and consider a arr, "=" ard, "="' & a arr, "=" ard, "i" & a ard, "=" a arr, "i"' & b arr, "p"' & a Then the left square and the outer rectangle are pullbacks but the right square cannot be a pullback unless $ i $ was already an isomorphism.
On the other hand, in the (∞, 1) - category of ∞ - groupoids, there is a sort of "partial converse"; see homotopy pullbackHomotopyFiberCharacterization.
The saturation of the class of pullbacks is the class of limits over categories $ C $ whose groupoid reflection $ Pi1(C) $ is trivial and such that $ C $ is L - finite.
{PullbackFunctor} If $ fcolon X to Y $ is a morphism in a category $ C $ with pullbacks, there is an induced pullback functor $ f^*colon C/Y to C/X $ , sometimes also called base change.
Textbook account: See also: In view of more general finite limits and L - finite limits: In general, let $ U = (Ui){i: I} $ and $ V = (Vj){j: J} $ be two families of objects of some category $ C $ .
We say that $ V $ is a refinement of $ U $ if there is a function $ f: J to I $ of indices and a morphism $ Vj to U{f(j)} $ for each $ j in J $ .
A common special case is the concept of refinement of open covers, example below.
We state a list of examples, beginning with general cases and then consecutively making them more specific.
Very often we do this in the slice category $ C/X $ for some object $ X $ .
If you spell this out, then you have families $ (Ui to X)i $ and $ (Vj to X)j $ of morphisms to $ X $ ; $ V $ is a refinement of $ U $ if there are a function $ f: J to I $ and a commutative diagram array{ Vj &&to&& U{f(j)} & searrow && swarrow && X } for each $ j $ .
More specifically, apply this to the poset of subobjects of $ X $ .
Then you have families $ (Ui hookrightarrow X)i $ and $ (Vj hookrightarrow X)j $ of subobjects of $ X $ ; $ V $ is a refinement of $ U $ if there are a function $ f: J to I $ and a commutative diagram (eq:slice) for each $ j $ .
Yet more specifically, apply this to the lattice of subsets of some set $ X $ .
Then you have families $ (Ui subseteq X)i $ and $ (Vj subseteq X)j $ of subsets of $ X $ ; $ V $ is a refinement of $ U $ if there is a function $ f: J to I $ such that each $ Vj $ is contained in $ U{f(j)} $ .
Yet more specifically, let the families of subsets be indexed by themselves.
Then have collections $ U subseteq mathcal{P}X $ and $ V subseteq mathcal{P}X $ of subsets of $ X $ ; $ V $ is a refinement of $ U $ if for each $ j $ there is an $ i $ such that $ Vj $ is contained in $ Ui $ .
Actually, this definition is slightly weaker than the previous one in the absence of the axiom of choice.
Perhaps in that case the general definition should say that for each $ j $ there is an $ i $ and a morphism $ Vj to Ui $ .
Special cases of example include refinement of filters and refinement of open covers of topological spaces.
Let $ (X, tau) $ be a topological space, and let $ {Ui subset X } {i in I} $ be a set of open subsets which covers $ X $ in that $ underset{i in I}{cup} Ui ;= ;X $ .
Then a refinement of this open cover is a set of open subsets $ {Vj subset X } {j in J} $ which is still an open cover in itself and such that for each $ j in J $ there exists
an $ i in I $ with $ Vj subset Ui $ .
On the other hand, you might want to generalise the case of open covers to covers or covering sieves on a site.
In that case, the general definition still applies; you have covering families $ (Ui to X)i $ and $ (Vj to X)j $ of some object $ X $ ; $ V $ is a refinement of $ U $ if there are a map $ f: J to I $ and a commutative diagram (eq:slice) for each $ j $ .
Refinement of open covers is a concept appearing in the definition of Given a set $ S $ and an equivalence relation $ equiv $ on $ S $ , the quotient set of $ S $ by $ equiv $ is the set $ S/{equiv} $ whose elements are the elements of $ S $ but where two elements are now considered equal if in $ S $ they were merely equivalent.
If changing the definition of equality like this is not allowed in your foundations of mathematics, then you can still define $ S/{equiv} $ as a subset of the power set of $ S $ as follows: A in S/{equiv} ;Leftrightarrow; exists (x: S), ; A = {y: S ;mid; x equiv y } If you don't have (extensional) power sets either, then you'll have to use setoids (in which case, perhaps you'd do better to change your terminology as described there).
Alternatively, don't worry about any of this and just include the existence of quotient objects in Set as an axiom (the axiom of quotient sets, which you have if you assume that $ Set $ is a pretopos or a Grothendieck topos as given by Giraud's axioms).
There are actually two possible axiom of quotient sets, depending on what definition of relation one uses.
In any case, the element of $ S/{equiv} $ that comes from the element $ x $ of $ S $ may be denoted $ x{equiv} $ , or simply $ x $ if $ {equiv} $ is understood, or simply $ x $ if there will be no confusion as to which set it is an element of.
This $ x $ is called the equivalence class of $ x $ with respect to $ equiv $ ; the term 'class' here is an old word for 'set' (in the sense of 'subset') and refers to the definition (eq:setdef) above, where $ x $ is literally the set $ A $ .
Let $ S $ be a set and let $ equiv $ be an equivalence relation on $ S $ .
Let us define a quotient set algebra of $ S $ and $ equiv $ to be a set $ A $ with a function $ iota S to A $ such that for all $ a in S $ and $ b in S $ , $ (a equiv b) $ implies $ (iota(a) = iota(b)) $ .
A quotient set algebra homomorphism of $ S $ and $ equiv $ is a function $ f: A to B $ between two quotient set algebras $ A $ and $ B $ such that for all $ a in S $ , $ f(iotaA(a)) = iotaB(a) $ .
The category of quotient set algebras of $ S $ and $ equiv $ is the category $ QSA(S, equiv) $ whose objects
$ Ob(QSA(S, equiv)) $ are quotient set algebras of $ S $ and $ equiv $ and whose morphisms $ Mor(A, B) $ for $ A in Ob(QSA(S, equiv)) $ and $ B in Ob(QSA(S, equiv)) $ are quotient set algebra homomorphisms of $ S $ and $ equiv $ .
The quotient set of $ S $ and $ equiv $ , denoted $ S/equiv $ , is defined as the initial object in the category of quotient set algebras of $ S $ and $ equiv $ .
Let $ (T, equiv) $ be a symmetric proset.
The quotient set $ T/equiv $ is a higher inductive type inductively generated by the following: $ a colon T , ; b colon T ;;; vdash ;;; eq{T/equiv}(a, b) , colon, (a equiv b) ;to; (iota(a) ={T/equiv} iota(b)) $ $ a:T/equiv, b:T/equiv vdash tau(a, b): isProp(a ={T/equiv} b) $ The axiom of quotient sets in type theory says that every symmetric proset is a set.
Quotient sets in Set generalise to quotient objects in other categories.
In particular, an exact category is a regular category in which every congruence on every object has an effective quotient object.
See the references at quotient type.
category: foundational axiom A maximal subgroup of a given group $ G $ is a subgroup which is not all of $ G $ and not contained in any other subgroup of $ G $ .
Hence a maximal subgroup is a maximal element of the lattice of subgroups after removing the trivial subgroup $ G subset G $ itself.
More concisely it is a coatom of $ G $ 's subgroup lattice.
See also The tensor product of two vector spaces is a new vector space with the property that bilinear maps out of the Cartesian product of the two spaces are equivalently linear maps out of the tensor product.
The tensor product of vector spaces is just the special case of the tensor product of modules over some ring $ R $ for the case that this ring happens to be a field.
The tensor product of vector spaces makes the category Vect of all vector spaces into a monoidal category, in fact a distributive monoidal category.
Given two vector spaces over some field $ k $ , $ V1, V2 in Vectk $ , their tensor product of vector spaces is the vector space denoted $ V1 otimesk V2 in Vect $ whose elements are equivalence classes of formal linear combinations of tuples $ (v1, v2) $ with $ vi in Vi $ , for the equivalence relation given by $ (k v1 , v2) ;sim; k( v1 , v2) ;sim; (v1, k v2) $ $ (v1 + v'1 , v2) ; sim ; (v1, v2) + (v'1, v2) $ $ (v1 , v2 + v'2) ; sim ; (v1, v2) + (v1, v'2) $ More abstractly this means that the tensor product of vector spaces is the vector space characterized by the fact that (i) it receives a bilinear map $ V1 times V2 longrightarrow V1 otimes V2 $ (out of the Cartesian product of the underlying sets) (i) any other bilinear map of the form $ V1 times V2 longrightarrow V3 $ factors through the above bilinear map via a unique linear map $ array{ V1 times V2 &overset{bilinear}{longrightarrow}& V3 downarrow & nearrow{mathrlap{exists ! , linear}} V1 otimesk V2 } $ A topological subspace $ A $ is a neighborhood retract of a topological space $ X $ if there is a neighborhood $ Usupset A $ in $ X $ such that $ A $ is a retract of $ U $ .
A metrisable topological space $ Y $ is an absolute neighborhood retract if for any embedding $ Ysubset Z $ as a closed subspace in a metrisable topological space $ Z $ , $ Y $ is a neighborhood retract of $ Z $ .
A pair $ (X, A) $ where $ A $ is a closed subspace of $ X $ is an NDR - pair or a closed Borsuk pair if there is a function $ u:Xto I=0, 1 $ and a homotopy $ H:Xtimes Ito X $ such that $ H(x, 0)=x $ , for all $ xin X $ , $ H(a, t)=a $ for all $ ain A $ , $ H(x, 1)in A $ for all $ xin X $ such that $ u(x)lt 1 $ and $ u^{ - 1}(0)subset A $ .
(See deformation retract.)
The canonical inclusion $ i:Ahookrightarrow X $ corresponding to any NDR - pair $ (X, A) $ is a Hurewicz cofibration.
Textbook accounts A Noetherian (or often, as below, noetherian) ring (or rng) is one where it is possible to do induction over its ideals, because the ordering of ideals by reverse inclusion is well - founded.
Every ring $ R $ has a canonical $ R $ - $ R $ - bimodule structure, with left action $ alphaL:R times R to R $ and right action $ alphaR:R times R to R $ defined as the multiplicative binary operation on $ R $ and biaction $ alpha:R times R times R to R $ defined as the ternary product on $ R $ : $ alphaL(a, b) coloneqq a cdot b $ $ alphaR(a, b) coloneqq a cdot b $ $ alpha(a, b, c) coloneqq a cdot b cdot c $ Let $ mathrm{TwoSidedIdeals}(R) $ be the category of two - sided ideals in $ R $ , whose objects are two - sided ideals $ I $ in $ R $ , sub - $ R $ - $ R $ - bimodules of $ R $ with respect to the canonical bimodule structure on $ R $ , and whose morphisms are $ R $ - $ R $ - bimodule monomorphisms.
An ascending chain of two - sided ideals in $ R $ is a direct sequence of two - sided ideals in $ R $ , a sequence of two - sided ideals $ A:mathbb{N} to mathrm{TwoSidedIdeals}(R) $ with the following dependent sequence of $ R $ - $ R $ - bimodule monomorphisms: for natural number $ n in mathbb{N} $ , a dependent $ R $ - $ R $ - bimodule monomorphism $ in:A{n} hookrightarrow A{n+1} $ .
A ring $ R $ is Noetherian if it satisfies the ascending chain condition on its two - sided ideals: for every ascending chain of two - sided ideals $ (A, in) $ in $ R $ , there exists a natural number $ m in mathbb{N} $ such that for all natural numbers $ n geq m $ , the $ R $ - $ R $ - bimodule monomorphism $ in:A{n} hookrightarrow A{n+1} $ is an $ R $ - $ R $ - bimodule isomorphism.
Let $ mathrm{LeftIdeals}(R) $ be the category of left ideals in $ R $ , whose objects are left ideals $ I $ in $ R $ , sub - left - $ R $ - modules of $ R $ with respect to the canonical left module structure $ ( - )cdot( - ):R times R to R $ on $ R $ , and whose morphisms are left $ R $ - module monomorphisms.
An ascending chain of left ideals in $ R $ is a direct sequence of left ideals in $ R $ , a sequence of left ideals $ A:mathbb{N} to mathrm{LeftIdeals}(R) $ with the following dependent sequence of left $ R $ - module monomorphisms: for natural number $ n in mathbb{N} $ , a dependent left $ R $ - module monomorphism $ in:A{n} hookrightarrow A{n+1} $ .
A ring $ R $ is left Noetherian if it satisfies the ascending chain condition on its left ideals: for every ascending chain of left ideals $ (A, in) $ in $ R $ , there exists a natural number $ m in mathbb{N} $ such that for all natural numbers $ n geq m $ , the left $ R $ - module monomorphism $ in:A{n} hookrightarrow A{n+1} $ is an left $ R $ - module isomorphism.
Let $ mathrm{RightIdeals}(R) $ be the category of right ideals in $ R $ , whose objects are right ideals $ I $ in $ R $ , sub - right - $ R $ - modules of $ R $ with respect to the canonical right module structure $ ( - )cdot( - ):R times R to R $ on $ R $ , and whose morphisms are right $ R $ - module monomorphisms.
An ascending chain of right ideals in $ R $ is a direct sequence of right ideals in $ R $ , a sequence of right ideals $ A:mathbb{N} to mathrm{RightIdeals}(R) $ with the following dependent sequence of right $ R $ - module monomorphisms: for natural number $ n in mathbb{N} $ , a dependent right $ R $ - module monomorphism $ in:A{n} hookrightarrow A{n+1} $ .
A ring $ R $ is right Noetherian if it satisfies the ascending chain condition on its right ideals: for every ascending chain of right ideals $ (A, in) $ in $ R $ , there exists a natural number $ m in mathbb{N} $ such that for all natural numbers $ n geq m $ , the right $ R $ - module monomorphism $ in:A{n} hookrightarrow A{n+1} $ is an right $ R $ - module isomorphism.
Every field is a noetherian ring.
Every principal ideal domain is a noetherian ring.
For $ R $ a Noetherian ring (e.g. a field by example ) then (i) the polynomial algebra $ RX1, cdots, Xn $ (i) the formal power series algebra $ R X1, cdots, Xn $ over R in a finite number $ n $ of coordinates are Noetherian.
Spectra of noetherian rings are glued together to define locally noetherian schemes.
One of the best - known properties is the Hilbert basis theorem.
Let $ R $ be a (unital) ring.
If $ R $ is left Noetherian, then so is the polynomial algebra $ Rx $ .
(Similarly if "right" is substituted for "left".)
(We adapt the proof from Wikipedia.)
Suppose $ I $ is a left ideal of $ Rx $ that is not finitely generated.
Using the axiom of dependent choice, there is a sequence of polynomials $ fn in I $ such that the left ideals $ In coloneqq (f0, ldots, f{n - 1}) $ form a strictly increasing chain and $ fn in I setminus In $ is chosen to have degree as small as possible.
Putting $ dn coloneqq deg(fn) $ , we have $ d0 leq d1 leq ldots $ .
Let $ an $ be the leading coefficient of $ fn $ .
The left ideal $ (a0, a1, ldots) $ of $ R $ is finitely generated; say $ (a0, ldots, a{k - 1}) $ generates.
Thus we may write $ ak = sum{i=0}^{k - 1} ri ai $ The polynomial $ g = sum{i=0}^{k - 1} ri x^{dk - di} fi $ belongs to $ Ik $ , so $ fk - g $ belongs to $ I setminus Ik $ .
Also $ g $ has degree $ dk $ or less, and therefore so does $ fk - g $ .
But notice that the coefficient of $ x^{dk} $ in $ fk - g $ is zero, by (eq:kill).
So in fact $ fk - g $ has degree less than $ dk $ , contradicting how $ fk $ was chosen.
For a unital ring $ R $ the following are equivalent: (i) $ R $ is left Noetherian (i)
Any small direct sum of injective left $ R $ - modules is injective.
(i) $ operatorname{Ext}^kR(A, cdot) $ commutes with small direct sums for any finitely generated $ A $ .
Direct sums here can be replaced by filtered colimits $ . 1 Rightarrow 2 $ : assume that $ R $ is Noetherian and $ Ialpha $ are injective modules.
In order to verify that $ I := bigoplusalpha Ialpha $ is injective it is enough to show that for any ideal $ mathfrak{j} $ any morphism of left modules $ f : mathfrak{j} to I $ factors through $ mathfrak{j} to R $ .
Since $ R $ is Notherian, $ mathfrak{j} $ is finitely generated, so the image of $ f $ lies in a finite sum $ I{alpha1} oplus dots oplus I{alphan} $ .
Thus an extension to $ R $ exists by the injectivity of each $ I{alphak} $ $ . 2 Rightarrow 1 $ : if $ R $ is not left Noetherian then there is a sequence of left ideals $ mathfrak{j}1 subsetneq mathfrak{j}2 subsetneq dots $ .
Take $ mathfrak{j} := bigcupk mathfrak{j}k $ .
The obvious map $ j to prodk (mathfrak{j} / mathfrak{j}k) $ factors through $ bigoplusk (mathfrak{j} / mathfrak{j}k) $ , since any element lies in all but finitely many $ mathfrak{j}k $ .
Now take any injective $ Ik $ with $ 0 to mathfrak{j} / mathfrak{j}k to Ik $ .
The map $ mathfrak{j} to bigoplusk Ik $ cannot extend to the whole $ R $ , since otherwise its image would be contained in a sum of finitely many $ Ik $ .
Therefore, $ bigoplusk Ik $ is not injective $ . 2 Rightarrow 3 $ : $ operatorname{Ext}^kR(A, bigoplusalpha Xalpha) $ can be computed by taking an injective resolution of $ bigoplusalpha Xalpha $ .
Since direct sums of injective modules are assumed to be injective, we can take a direct sum of injective resolutions of each $ Xalpha $ .
It remains to note that Hom out of a finitely generated module commutes with arbitrary direct sums $ . 3 Rightarrow 2 $ :
Follows from the fact that $ I $ is injective iff $ operatorname{Ext}^1R(R / mathfrak{i}, I) = 0 $ for any ideal $ mathfrak{i} $ .
A dual condition is artinian: an artinian ring is a ring satisfying the descending chain condition on ideals.
The symmetry is severely broken if one considers unital rings: for example every unital artinian ring is noetherian; artinian rings are intuitively much smaller than generic noetherian rings.
{Idea} {InPointSetTopology} In point - set topology, the (un - reduced) suspension $ mathrm{S} X $ of an inhabited topological space $ X $ is the quotient space of the cylinder space $ X times - 1, 1 $ (the product space with a closed interval) by the relation which identifies all the points at either end: mathrm{S}X ;coloneqq; frac{ X , times, - 1, , +1 }{ left( {c} X times { - 1 } mathrlap{, , } X times {+1 } right) } , .
{Illustration} The following graphics gives an artistic impression of the suspension of a (non - empty) space $ X $ , indicated in gray: <center> <img src="https://ncatlab.org/nlab/files/Suspension - unreduced - 23010(v)jpg" width="420"> </center> > (adapted from Muro 2010)
In particular, the suspension of an $ n $ - sphere is homeomorphic to the $ (n+1) $ - sphere $ S^{n+1} ;underset{mathrm{homeo}}{simeq}; mathrm{S}(S^n) , , $ namely the union of (in terms of the above graphics): (i) a north pole " $ nth $ " (i) a south pole " $ sth $ " (i) the meridians " $ mer(x) $ " through all points $ x in S^{n} $ on the equator.
Hence, by induction, the $ (n+1) $ - sphere is homeomorphic to the $ n+1 $ - fold suspension of the 0 - sphere: $ S^{n+1} ;underset{mathrm{homeo}}{simeq}; mathrm{S}^{n+1}(S^0) , $ . {InHomotopyTheory} Regarded in the classical homotopy category, the suspension construction (eq:PointSetFormula) on a CW - complex $ X $ is a canonical model for the suspension object of the homotopy type represented by $ X $ - - - namely the homotopy pushout of the terminal map $ X to ast $ along itself) - - - and as such plays a key role in homotopy theory and stable homotopy theory.
This also explains the usual definition of the suspension of the empty space as the 0 - sphere $ mathrm{S}(varnothing) ;=; S^0 , , $ since the latter does model the homotopy pushout of $ varnothing to ast $ along itself (which is just a 1 - categorytheoretic pushout and hence the coproduct of the point space with itself).
For more on this see at suspension object.
More precisely, what appears in most of algebraic topology and stable homotopy theory is the reduced suspension of pointed topological spaces $ (X, x0) $ (and eventually their suspension spectra): $ Sigma X , coloneqq, mathrm{S}X / {x0 } , , $ where in addition the copy of the interval over the given basepoint is identified with a single point.
For CW - complexes the reduced suspension is weakly homotopy equivalent to the ordinary suspension.
In this context of (stable) homotopy theory, the suspension construction is part of the canonical point - set model for cofiber sequences induced from any mapping cone construction: <center> <img src="http://ncatlab.org/nlab/files/mappingcone.jpg" width="660" >
</center> > (from Muro 2010)
Let $ X $ be a space (such as a topological space, or something more interesting like a generalized smooth space).
Let $ I $ be the unit interval $ 0, 1 $ in the real line; let $ 2 $ be the $ 2 $ - point discrete space $ {bot, top } $ .
Let $ X times I times 2 $ be the cartesian product of $ X $ , $ 2 $ , and $ I $ ; let $ X + (X times 2 times I) + 2 $ be the disjoint union of $ X $ , $ X times I times 2 $ and $ 2 $ .
We will suppress reference to the inclusion maps into $ X + (X times I) + 2 $ ; it will be clear from context how to parse an element of the latter.
The suspension $ S X $ of $ X $ is the quotient space of $ X + (X times I times 2) + 2 $ by the equivalence relation $ sim $ generated by: This generalises immediately to an operation called the join $ X star Y $ of two spaces $ X $ and $ Y $ ; this is the quotient space of $ X + (X times I times Y) + Y $ by the equivalence relation generated by: (Compare join of simplicial sets and join of topological spaces, the same operation in another guise.)
Then we have $ S X = X star 2 $ .
It is somewhat simpler to define $ S X $ as the quotient space of $ (X times I) + 2 $ by the equivalence relation generated by: This works to define a topological space, but it does not directly give the smooth structure that matches the picture above.
If $ X $ has a point $ p $ , hence if it is inhabited, then we can define $ S X $ as the quotient space of $ X times I $ by the equivalence relation generated by:
This is probably the most common definition seen, but it only works for $ X $ an inhabited space (and even then gives only the topological structure).
To make the suspension of a pointed space $ (X, p) $ again a pointed space one may further collapse in $ S X $ the set $ {p } times I $ to the point.
The result then is called the reduced suspension of $ (X, p) $ and is denoted $ Sigma X coloneqq S X / {p } times I simeq X times I / left( X times {0, 1 } cup {p } times I right) , $ .
It's easy to extend the suspension operation $ S $ to a functor from Top to itself.
For CW - complexes suspension and reduced suspension agree, up to weak homotopy equivalence.
In the pointed case (reduced suspension): suspensions are H - cogroup objects The suspension of the $ n $ - cube is the $ (n+1) $ - cube, probably best visualised as a diamond.
This gives a recursive definition of cube, starting with the $ 0 $ - cube as the point, which is not the suspension of anything.
Note that this not only gives us the topological structure of the cube, but also (by working in an appropriate category of smooth spaces throughout) the correct smooth structure on the cube as a manifold with corners.
You can probably even get the correct metric on the cube (normalised to have diagonals of length $ 1 $ ) automatically by using a more complicated quotienting process.
Up to homeomorphism, the suspension of the $ n $ - sphere is the $ (n+1) $ - sphere, and the reduced suspension is $ Sigma S^n simeq S^{n+1} , $ .
See at one - point compactification - - Examples - - Spheres for details.
Notice that the $ n $ - sphere is (topologically) the boundary of the $ (n+1) $ - cube.
The coincidence that 'sphere' and 'suspension' both begin with 's' has not been ignored; we can write $ S^n cong S^n(2) $ , where $ S^n $ on the left is the $ n $ - sphere and $ S^n $ on the right is the $ n $ - fold composite of the suspension functor.
(Actually, you should start with the $ ( - 1) $ - sphere as the empty space, which is not the suspension of anything; then the $ 0 $ - sphere is $ S empty = 2 $ .)
However, this does not give the correct smooth structure on the sphere, unless perhaps there is some more sophisticated definition that fixes this (but then that would break the cube).
It might be more appropriate to say that the suspension of the $ n $ - globe is the $ (n+1) $ - globe.
Up to topological structure, the suspension of the $ n $ - simplex is the $ (n+1) $ - simplex, but now this is not very useful.
To study simplices, you should use the cone functor instead, which is $ Lambda X = X star 1 $ , where $ 1 $ is the point.
{References} >
For discussion of reduced suspension see there.
For more general discussion of homotopy pushouts see also there.
Most introductions to homotopy theory discuss suspension, in one form or other, see there.
Textbook accounts with the basics definition: A textbook which knows that the suspension of the empty set is the 0 - sphere (although even it regards this as an exception): Discussion of the suspension type as a higher inductive type in homotopy type theory:
On the free loop space of a suspension: On the question on what is the Eckman - Hilton dual to $ Xstar Y $ : The above graphics is taken from In a monoid, an element $ x $ is irreducible if it is neither invertible nor the product of two non - invertible elements.
Without bias, we can say that $ x $ is irreducible if, whenever it is written as a product of a finite list of elements, at least one element in the list is invertible.
In a commutative ring, an element is irreducible if it is neither invertible nor the product of two non - invertible elements, with respect to the multiplication operation on the commutative ring.
Cellular homology is a very efficient tool for computing the ordinary homology groups of topological spaces which are CW complexes, based on the relative singular homology of their cell complex - decomposition and using degree - computations.
Hence cellular homology uses the combinatorial structure of a CW - complex to define, first a chain complex of celluar chains and then the corresponding chain homology.
The resulting cellular homology of a CW - complex is isomorphic to its singular homology, hence to its ordinary homology as a topological space, and hence provides an efficient method for computing the latter.
For definiteness and to fix notation which we need in the following, we recall the definition of CW - complex.
The actual definition of cellular homology is below.
For $ n in mathbb{N} $ write Write furthermore $ S^{ - 1} coloneqq emptyset $ for the empty topological space and think of $ S^{ - 1} to D^0 simeq * $ as the boundary inclusion of the ( - 1) - sphere into the 0 - disk, which is the point.
A CW complex of dimension $ ( - 1) $ is the empty topological space.
By induction, for $ n in mathbb{N} $ a CW complex of dimension $ n $ is a topological space $ X{n} $ obtained from (i) a $ CW $ - complex $ X{n - 1} $ of dimension $ n - 1 $ ; (i) an index set $ Cell(X)n in Set $ ; (i) a set of continuous maps (the attaching maps) $ { fi colon S^{n - 1} to X{n - 1} } {i in Cell(X)n} $ as the pushout $ Xn simeq coprod{j in Cell(X)n} D^n coprod{j in Cell(X)n S^{n - 1}} Xn $ $ array{ coprod{j in Cell(X){n}} S^{n - 1} &stackrel{(fj)}{to}& X{n - 1} downarrow && downarrow coprod{j in Cell(X){n}} D^{n} &to& X{n} } , $ .
By this construction an $ n $ - dimensional CW - complex is canonical a filtered topological space with filter inclusion maps $ emptyset hookrightarrow X0 hookrightarrow X1 hookrightarrow cdots hookrightarrow X{n - 1} hookrightarrow Xn $ the right vertical morphisms in these pushout diagrams.
A general CW complex $ X $ is a topological space given as the sequential colimit over a tower diagram each of whose morphisms is such a filter inclusion $ emptyset hookrightarrow X0 hookrightarrow X1 hookrightarrow cdots hookrightarrow X , $ .
For the following a CW - complex is all this data: the chosen filtering with the chosen attaching maps.
{CellularHomology} We define "ordinary" cellular homology with coefficients in the group $ mathbb{Z} $ of integers.
The analogous definition for other coefficients is immediate.
For $ X $ a CW - complex, def. , its $ Hn^{CW}(X) coloneqq Hn(Xn, X{n - 1}) , , $ $ partial^{CW}n colon H{n+1}(X{n+1}, Xn) stackrel{partialn}{to} Hn(Xn) stackrel{in}{to} Hn(Xn, X{n - 1}) , , $ where $ partialn $ is the boundary map of the singular chain complex and where $ in $ is the morphism on relative homology induced from the canonical inclusion of pairs $ (Xn, emptyset) to (Xn, X{n - 1}) $ .
The composition $ partial^{CW}{n} circ partial^{CW}{n+1} $ of two differentials in def. is indeed zero, hence $ H^{CW}bullet(X) $ is indeed a chain complex.
On representative singular chains the morphism $ in $ acts as the identity and hence $ partial^{CW}{n} circ partial^{CW}{n+1} $ acts as the double singular boundary, $ partial{n} circ partial{n+1} = 0 $ .
By the discussion at Relative homology - Relation to reduced homology of quotient spaces the relative homology group $ Hn(Xn, X{n - 1}) $ is isomorphic to the the reduced homology $ tilde Hn(Xn/X{n - 1}) $ of $ Xn/X{n - 1} $ .
This implies in particular that For every $ n in mathbb{N} $ we have an isomorphism $ H^{CW}n(X) coloneqq Hn(Xn, X{n - 1}) simeq mathbb{Z}(Cell(X)n) $ that the group of cellular $ n $ - chains with the free abelian group whose set of basis elements is the set of $ n $ - disks attached to $ X{n - 1} $ to yield $ Xn $ .
This is discussed at Relative homology - Homology of CW - complexes.
Thus, each cellular differential $ partial^{CW}n $ can be described as a matrix $ M $ with integer entries $ M{i j} $ .
Here an index $ j $ refers to the attaching map $ fj colon S^n to Xn $ for the $ j^{th} $ disk $ D^{n+1} $ .
The integer entry $ M{i j} $ corresponds to a map $ mathbb{Z} cong H{n+1}(D^{n+1}, S^n) to Hn(S^n) to Hn(D^n, S^{n - 1}) cong Hn(S^n) cong mathbb{Z} $ and is computed as the degree of a continuous function $ S^n stackrel{fj}{to} Xn to Xn/(Xn - D^n) cong D^n/S^{n - 1} cong S^n $ where the inclusion $ Xn - D^n hookrightarrow Xn $ corresponds to the attaching map for the $ i^{th} $ disk $ D^n $ .
For $ X $ a CW - complex, its cellular homology $ H^{CW}bullet(X) $ agrees with its singular homology $ Hbullet(X) $ : $ H^{CW}bullet(X) simeq Hbullet(X) , $ .
This appears for instance as (Hatcher, theorem (ii)35).
A proof is below as the proof of cor. .
{RelationToSpectralSequenceOfFilteredSingularComplex} The structure of a CW - complex on a topological space $ X $ , def.
naturally induces on its singular simplicial complex $ Cbullet(X) $ the structure of a filtered chain complex: For $ X0 hookrightarrow X1 hookrightarrow cdots hookrightarrow X $ a CW complex, and $ p in mathbb{N} $ , write $ Fp Cbullet(X) coloneqq Cbullet(Xp) $ for the singular chain complex of $ Xp hookrightarrow X $ .
The given topological subspace inclusions $ Xp hookrightarrow X{p+1} $ induce chain map inclusions $ Fp Cbullet(X) hookrightarrow F{p+1} Cbullet(X) $ and these equip the singular chain complex $ Cbullet(X) $ of $ X $ with the structure of a bounded filtered chain complex $ 0 hookrightarrow F0 Cbullet(X) hookrightarrow F1 Cbullet(X) hookrightarrow F2 Cbullet(X) hookrightarrow cdots hookrightarrow Finfty Cbullet(X) coloneqq Cbullet(X) , $ .
(If $ X $ is of finite dimension $ dim X $ then this is a bounded filtration.)
Write $ {E^r{p, q}(X) } $ for the spectral sequence of a filtered complex corresponding to this filtering.
We identify various of the pages of this spectral sequences with structures in singular homology theory.
(...)
This now directly implies the isomorphism between the cellular homology and the singular homology of a CW - complex $ X $ : $ H^{CW}bullet(X) simeq Hbullet(X) $
By the third item of prop.
the $ (r = 2) $ - page of the spectral sequence $ {E^r{p, q}(X) } $ is concentrated in the $ (q = 0) $ - row.
This implies that all differentials for $ r gt 2 $ vanish, since their domain and codomain groups necessarily have different values of $ q $ .
Accordingly we have $ E^infty{p, q}(X) simeq E^2{p, q}(X) $ for all $ p, q $ .
By the third and fourth item of prop.
this is equivalently $ Gp H{p}(X) simeq H^{CW}p(X) , $ .
Finally observe that $ Gp Hp(X) simeq Hp(X) $ by the definition of the filtering on the homology as $ Fp Hp(X) coloneq image(Hp(Xp) to Hp(X)) $ and by standard properties of singular homology of CW complexes discusses at CW complex - - singular homology.
There are convenient software implementations for large - scale computations of cellular homology: one may use LinBox, CHomP or Perseus.
A standard textbook account is from p. 139 on in Lecture notes include Formulation in homotopy type theory: The notion of an idempotent morphism in a category generalizes the notion of projector in the context of linear algebra: it is an endomorphism $ e colon X to X $ of some object $ X $ that "squares to itself" in that the composition of $ e $ with itself is again $ e $ : $ e circ e = e , $ .
Accordingly, given any idempotent $ e colon X to X $ it is of interest to ask what subobject $ A stackrel{i}{hookrightarrow} X $ of $ X $ it is the projector onto, in that there is a projection $ X stackrel{p}{to} A $ such that the idempotent is the composite of this projection followed by including $ A $ back into $ X $ : $ e colon X stackrel{p}{to} A stackrel{i}{hookrightarrow} X , $ .
As opposed to the case of linear algebra, in general such a factorization into a projection onto a subobject $ A $ need not actually exists for an idempotent $ e $ in a generic category.
If it exists, one says that $ e $ is a split idempotent.
Accordingly, one is interested in those categories for which every idempotent is split.
These are called idempotent complete categories or Cauchy complete categories.
If a category is not yet idempotent complete it can be completed to one that is: its Karoubi envelope or Cauchy completion.
An endomorphism $ ecolon B to B $ in a category is an idempotent if the composition with itself equals itself $ e circ e = e , $ .
A splitting of an idempotent $ e $ consists of morphisms $ scolon A to B $ and $ rcolon B to A $ such that $ r circ s = 1A $ and $ s circ r = e $ .
In this case $ A $ is a retract of $ B $ , and we call $ e $ a split idempotent.
Of course, we can simply consider the idempotent elements of any monoid.
Given an abelian monoid $ R $ , the idempotent elements form a submonoid $ Idem(R) $ .
Given a commutative ring $ R $ , the idempotent elements of $ R $ form a Boolean algebra $ Idem(R) $ with these operations: This is important in measure theory; if $ R $ is the ring $ L^infty(X, mathcal{M}, mathcal{N}) $ of essentially bounded real - valued measurable functions on some measurable space $ (X, mathcal{M}) $ modulo an ideal $ mathcal{N} $ of null sets, then $ Idem(R) $ is the Boolean algebra of characteristic functions of measurable sets modulo null sets, which is isomorphic to the Boolean algebra $ mathcal{M}/mathcal{N} $ of measurable sets modulo null sets itself.
If $ R $ is a commutative $ * $ - ring, then we may restrict to the self - adjoint idempotent elements to get the Boolean algebra $ Proj(R) $ .
In measure theory, if $ R $ is the complex - valued version of $ L^infty(X, mathcal{M}, mathcal{N}) $ , then $ Proj(R) $ will still reconstruct $ mathcal{M}/mathcal{N} $ .
In operator algebra theory, the self - adjoint idempotent elements of an operator algebra are called projection operators, which is the origin of the notation $ Proj $ .
(Sometimes one requires projection operators to be proper: to have norm $ 1 $ ; the only projection operator that is not proper is $ 0 $ .)
The projection operators of a commutative $ W^star $ - algebra give the link between operator algebra theory and measure theory; in fact, the categories of commutative $ W^star $ - algebras and of localisable measurable spaces (or measurable locales) are dual, and $ W^star $ - algebra theory in general may be thought of as noncommutative measure theory.
In noncommutative measure theory, the projection operators are still important, but they no longer form a Boolean algebra.
Given a category $ mathcal{C} $ one may ask for the universal category obtained from $ mathcal{C} $ subject to the constraint that all idempotents are turned into split idempotents.
This is called the Karoubi envelope of $ mathcal{C} $ .
More generally, in enriched category theory it is called the Cauchy completion of $ mathcal{C} $ .
Formalization in homotopy type theory:
In the context of algebraic topology, a continuous map $ f colon X longrightarrow Y $ between two topological spaces $ X, Y $ , is said to be null homotopic if it is homotopic to a constant map $ g $ .
This is considered in particular in the context of pointed topological spaces with base point - preserving maps between them, hence for $ g $ the map constant on the base point of $ Y $ (which is the zero morphism in this context).
In the context of homological algebra, a null homotopy is a chain homotopy from (or to) the zero map.
Generally in abstract homotopy theory, a null homotopy in an pointed (infinity, 1) - category is a 2 - morphism to (or from) a zero morphism.
This general concept subsumes the previous two cases via the (infinity, 1) - categories presented by the classical model structure on pointed topological spaces or a model structure on chain complexes, respectively.
Textbook accounts: A skewfield (also spelled skew - field), or reciprocal ring is a unital ring where each non - zero element has a two - sided inverse (but zero does not), or equivalently, an associative unital $ mathbb{Z} $ - reciprocal algebra where the multiplicative identity element $ 1 $ is not zero.
A division ring is a unital ring where each non - zero element has a left inverse and a right inverse, or equivalently, an associative unital $ mathbb{Z} $ - division algebra where the multiplicative identity element $ 1 $ is not zero.
However in all associative unital division algebras, left and right inverses are the same, for the same reason that associative unital quasigroups and associative unital invertible magmas are both groups.
As a result, division rings are the same as skewfields.
A commutative skewfield is called a field, but sometimes in specialized works on skewfields one often says simply field for skewfield.
In constructive mathematics and internally, the same issues appear for skewfields as for fields, and may be dealt with in the same way.
Linear algebra is often understood in the generality of division rings, namely the usual notions of linear basis, dimension, linear map, matrix of a linear map with respect to two bases and so on, and even Gauss elimination procedure, hold without changes for left or right vector spaces over a division rings.
The most famous noncommutative example is the skewfield of quaternions.
The Frobenius theorem states that apart from the fields of real and complex numbers and quaternions, there are no associative finite - dimensional division algebras over the real numbers; and even if one includes nonassociative finite - dimensional division algebras one obtains only one more example (the octonions).
See at normed division algebra for more on this.
{Idea} A compact Hausdorff space or compactum, for short, is a topological space which is both a Hausdorff space as well as a compact space.
This is precisely the kind of topological space in which every limit of a sequence or more generally of a net that should exist does exist (this prop.)
and does so uniquely (this prop).
One may consider the analogous condition for convergence spaces, or for locales (see also at Hausdorff locale and compact locale).
Even though these are all different contexts, the resulting notion of compactum is (at least assuming the axiom of choice) always the same.
Interestingly, there is even an algebraic definition, not one that uses only finitary operations, but one which uses a monad.
If you know what a compact space is and what a Hausdorff space is, then you know what a compact Hausdorff space is, so let's be fancy.
(Full justifications will be provided in section on compacta as algebras.)
Given a set $ S $ , let $ beta S $ be the set of ultrafilters on $ S $ .
Note that $ beta $ is an endofunctor on Set; every function $ f: S to T $ induces a function $ beta f: beta S to beta T $ using the usual application of functions to filters.
In fact, $ beta $ is a monad; it comes with a natural (in $ S $ ) unit $ etaS: S to beta S $ , which maps a point $ x $ to the principal ultrafilter that $ x $ generates, and multiplication $ muS: beta beta S to beta S $ , which maps an ultrafilter $ U $ on ultrafilters to the ultrafilter of sets whose principal ultrafilters of ultrafilters belong to $ U $ .
That is, Then a compactum is simply an algebra for this monad; that is, a set $ X $ together with a function $ lim: beta X to X $ , such that It is then a theorem that this $ lim $ generates a convergence on $ S $ that is compact, Hausdorff, and topological.
The converse, that every compact Hausdorff topological convergence is of this form, is equivalent to the ultrafilter principle.
Every compact Hausdorff space is regular and sober and so defines a compact regular locale.
Again, the axiom of choice gives us a converse: every compact regular locale is spatial and so comes from a compactum.
>
Probably this is also equivalent to the ultrafilter principle, but I need to check.
Note that every compact Hausdorff space (topological or localic) is not only regular but also normal.
See compact Hausdorff spaces are normal.
Throughout this section, $ CH $ will be used to denote the category of compact Hausdorff spaces (compacta).
Let $ Bool $ be the category of Boolean algebras.
The functor $ hom( - , mathbf{2}): Bool^{op} to Set $ has a left adjoint $ P: Set to Bool^{op} $ given by power sets, and we define the ultrafilter monad to be the composite $ beta coloneqq hom(P - , mathbf{2}) $ .
For a set $ S $ , topologize $ beta S $ by declaring a basic open set to be one of the form $ hat{A} coloneqq {F in beta S: A in F } $ for $ A $ a subset of $ S $ .
Notice $ hat{emptyset} $ is empty.
Indeed, $ widehat{( - )} $ defines a Boolean algebra map $ P(S) to P(beta S) $ so that in particular $ widehat{A cap B} = hat{A} cap hat{B} $ , which immediately implies that the $ hat{A} $ form a basis of a topology.
In fact, $ widehat{( - )} $ is the component at $ P(S) $ of the counit of the adjunction $ P dashv hom( - , mathbf{2}) $ , as a morphism in $ Bool^{op} $ .
If $ f: S to T $ is a function, the commutativity of the naturality square $ array{ P(T) & stackrel{widehat{( - )}}{to} & P(beta T) mathllap{P(f)} downarrow & & downarrow mathrlap{P(beta f)} P(S) & overset{widehat{( - )}}{to} & P(beta S) } $ implies that if $ U = hat{B} in P(beta T) $ is a basic (cl)open, then so is $ (beta f)^{ - 1}(U) = P(beta f)(hat{B}) = widehat{f^{ - 1}(B)} $ .
It then follows that $ beta f $ is continuous.
These results show that the monad $ beta: Set to Set $ lifts through the forgetful functor $ U: Top to Set $ .
The unit of the monad $ beta $ is given componentwise by functions $ prinX: X to beta X $ where $ prinX $ takes $ x in X $ to the principal ultrafilter $ prinX(x) = {A in P(X): x in A } $ .
It is evident that $ prinX $ is injective.
The injection $ prinX: X to beta X $ exhibits $ X $ as a dense subset of $ beta X $ .
If $ hat{A} $ is a basic open neighborhood containing an ultrafilter $ F $ , then $ A $ is nonempty and hence contains some $ x in X $ , which is to say $ A in prinX(x) $ or that $ prinX(x) in hat{A} $ $ . beta S $ is Hausdorff.
Let $ F, G $ be distinct ultrafilters, so there is $ A subseteq S $ with $ A in F $ and $ neg A in G $ .
Then $ hat{A} $ and $ widehat{neg A} $ are disjoint neighborhoods which contain $ F $ and $ G $ respectively $ . beta S $ is compact.
It is enough to show that if $ mathcal{O} $ is a collection of opens such that the union of any finite subcollection is a proper subset, then the union of $ mathcal{O} $ is also proper.
If $ mathcal{O} $ covers $ U $ , it admits a refinement by basic clopens also covering $ U $ , and thus we may assume WLOG that $ mathcal{O} $ consists of basic clopens $ hat{A} $ .
If every finite union of elements of $ mathcal{O} $ is a proper subset of $ beta S $ , then every finite intersection $ widehat{neg A1} cap ldots cap widehat{neg An} $ is nonempty, so that the $ neg A $ generate a filter, which is contained in some ultrafilter $ F $ .
This $ F $ lies outside the union of all the $ hat{A} $ 's. Let $ X $ be a topological space, and $ F $ an ultrafilter on the underlying set $ U X $ .
We say $ F $ converges to a point $ x $ (in symbols, $ F rightsquigarrow x $ ) if the neighborhood filter $ N_x $ of $ x $ is contained in $ F $ .
Convergence defines a relation $ xi $ from $ beta(U X) $ to $ U X $ .
If $ X $ is Hausdorff, then the relation $ xi $ is well - defined, or functional (i.e., there is at most one point to which a given ultrafilter $ F $ converges).
If $ x neq y $ , then there are disjoint neighborhoods $ U $ , $ V $ of $ x $ and $ y $ .
We cannot have both $ U in F $ and $ V in F $ (otherwise $ emptyset = U cap V $ would be an element of $ F $ ), so at most one of the neighborhood filters $ Nx, Ny $ can be contained in $ F $ .
If $ X $ is compact, then the relation $ xi $ is total (i.e., there exists a point to which a given ultrafilter $ F $ converges).
If not, then for each $ x in X $ there is an open neighborhood $ Ux $ that does not belong to $ F $ .
Then $ neg Ux in F $ .
Some finite number of neighborhoods $ U{x1}, ldots, U{xn} $ covers $ X $ .
Then $ neg U{x1} cap ldots cap neg U{xn} = emptyset in F $ , which is a contradiction.
If $ X $ is compact Hausdorff, then the function $ xi: beta(U X) to X $ is continuous.
Let $ U $ be an open neighborhood of $ x in X $ ; we must show that $ xi^{ - 1}(U) $ contains an open neighborhood of any of its points (i.e., ultrafilters $ F $ such that $ F rightsquigarrow x $ ).
Since $ X $ is $ T3 $ (Hausdorff regular), we may choose a neighborhood $ V in Nx $ whose closure $ bar{V} $ is contained in $ U $ .
Then $ hat{V} $ is an open neighborhood of $ F $ in $ beta(U X) $ , and we claim $ hat{V} subseteq xi^{ - 1}(U) $ .
For this, we must check that if $ G in hat{V} $ and $ G rightsquigarrow y $ , then $ y in U $ .
But if $ y in neg U subseteq neg bar{V} $ , then $ neg bar{V} in Ny $ , whence $ G rightsquigarrow y $ implies $ neg bar{V} in G $ .
This contradicts $ G in hat{V} $ , i.e., contradicts $ V in G $ , since $ V cap neg bar{V} = emptyset $ .
If $ S $ is a set and $ X $ is a compact Hausdorff space, then any function $ f: S to X $ can be extended (along $ prinS: S to beta S $ ) to a continuous function $ hat{f}: beta S to X $ .
We define $ hat{f} $ to be the composite $ beta S stackrel{beta(f)}{to} beta (U X) stackrel{xi}{to} X $ where $ beta(f) $ is continuous by Remark and $ xi $ is continuous by Proposition .
It remains to check that the following diagram is commutative: $ array{ S & stackrel{f}{to} & U X & & mathllap{prinS} downarrow & & mathllap{prin{U X}} downarrow & searrow mathrlap{1{U X}} & beta S & underset{beta (f)}{to} & beta (U X) & underset{xi}{to} & U X. } $ The square commutes by naturality of $ prin $ , and commutativity of the triangle simply says that the ultrafilter $ prin{U X}(x) $ converges to $ x $ , or that $ Nx subseteq prin(x) $ , which reduces to the tautology that $ x in V $ for every neighborhood $ V in Nx $ .
For any set $ S $ , the function $ prinS: S to beta S $ is universal among functions from $ S $ to compact Hausdorff spaces.
Hence the functor $ F: Set to CH $ that takes $ S $ to the compact Hausdorff space $ beta S $ is left adjoint to the forgetful functor $ CH to Set $ .
Proposition shows that for any function $ f: S to U X $ to a compact Hausdorff space, there exists continuous $ g: beta S to X $ such that $ g circ prinS = f $ .
All that remains is to establish uniqueness of such $ g $ .
But if two maps $ g, g': beta S to X $ to a Hausdorff space $ X $ agree on a dense subspace, in this case the subspace $ prinS : S hookrightarrow beta S $ by Proposition , then they must be equal.
Indeed, the pullback of the closed diagonal defines a closed subspace $ D $ of $ beta S $ , $ array{ D & to & X downarrow & & downarrow mathrlap{deltaX} beta S & underset{langle g, g' rangle}{to} & X times X, } $ and $ D $ contains a dense subspace $ S $ , therefore $ D = beta S $ ; i.e., the equalizer of $ g $ and $ g' $ is all of $ beta S $ , hence these two maps are equal.
We recall hypotheses of Beck's precise monadicity theorem: a functor $ U: C to D $ is monadic if and only if (i) $ U $ has a left adjoint, (i) $ U $ reflects isomorphisms: a morphism $ f: X to Y $ of $ C $ is an isomorphism if $ U f: U X to U Y $ is an isomorphism in $ D $ , (i) $ D $ has, and $ U $ preserves, coequalizers of parallel pairs that are $ U $ - split.
(We say $ X stackrel{overset{f}{to}}{underset{g}{to}} Y $ is $ U $ - split if there is a coequalizer $ U X stackrel{overset{U f}{to}}{underset{U g}{to}} U Y stackrel{h}{to} Z $ that is split in $ D $ : there exists $ i: Z to U Y $ and $ j: U Y to U X $ such that $ U h circ i = 1Z $ , $ U g circ j = i circ h $ , and $ U f circ j = 1{U Y} $ .)
In the case where $ D = Set $ , we have the following useful lemma: Suppose given a coequalizer in $ Set $ $ X stackrel{overset{f}{to}}{underset{g}{to}} Y stackrel{h}{to} Z $ split by $ i: Z to Y $ , $ j: Y to X $ (so that $ f j = 1Y $ , $ h i = 1Z $ , $ g j = i h $ ).
Let $ R hookrightarrow Y times Y $ be the image of $ langle f, g rangle : X to Y times Y $ , and let $ langle p1, p2 rangle : E to Y times Y $ be the equivalence relation given by the kernel pair $ (p1, p2) $ of $ h $ .
Then $ E = R cdot R^{op} $ , the relational composite given by taking the image of the span composite $ R timesY R^{op} to Y times Y $ .
Clearly $ R subseteq E $ since $ h f = h g $ , and we have $ R^{op} subseteq E^{op} = E $ and $ R cdot R^{op} subseteq E cdot E subseteq E $ by symmetry and transitivity of $ E $ .
In the other direction, suppose $ (y1, y3) in E $ , so that $ h(y1) = h(y3) $ .
Put $ x = j(y1) $ and $ x' = j(y3) $ (so that $ f(x) = y1 $ and $ f(x') = y3 $ ), and put $ y2 = g(x) $ .
Clearly then $ (y1, y2) in R $ .
Moreover, $ y2 = g(x) = g j(y1) = i h(y1) = i h(y3) = g j(y3) = g(x') $ so that $ (y3, y2) in R $ , or $ (y2, y3) in R^{op} $ .
Hence $ (y1, y3) in R cdot R^{op} $ , and we have shown $ E subseteq R cdot R^{op} $ .
The forgetful functor $ U: CH to Set $ is monadic.
By theorem , $ U $ has a left adjoint.
Since bijective continuous maps between compact Hausdorff spaces are homeomorphisms, we have that $ U $ reflects isomorphisms.
Finally, suppose $ (f, g) $ is a $ U $ - split pair of morphisms $ X to Y $ in $ CH $ ; let $ h: Y to Z $ be their coequalizer in $ Top $ , given by a suitable quotient space.
Being a quotient of a compact space, $ Z $ is compact.
Since $ CH $ is a full subcategory of $ Top $ , the map $ h $ is a coequalizer in $ CH $ once we prove the following claim: Furthermore, since the forgetful functor $ Top to Set $ has a right adjoint (given by taking indiscrete topologies on sets), the underlying function of $ h $ (again denoted $ h $ ) is the coequalizer of $ (U f, U g) $ in $ Set $ , so that $ U $ would preserve the claimed coequalizer.
In other words, to complete the proof, it suffices to verify the claim.
Letting $ p0, p1: E stackrel{to}{to} Y $ be the kernel pair of $ h $ in $ Top $ , to show $ Z = Y/E $ is Hausdorff, it suffices to prove that the equivalence relation $ langle p0, p1 rangle : E to Y times Y $ in $ Top $ is closed.
Let $ R hookrightarrow Y times Y $ be the image of $ langle f, g rangle: X to Y times Y $ .
By lemma , the subset $ E $ of $ U Y times U Y $ coincides with the subset $ R cdot R^{op} subseteq U Y times U Y $ .
Now $ R $ is the image of the compact space $ X $ under the continuous map $ langle f, g rangle $ , so $ R $ is a closed subset of $ Y times Y $ .
Similarly $ R^{op} $ is a closed subset of $ Y times Y $ .
Under their subspace topologies, their fiber product $ R timesY R^{op} $ is compact, and so its image $ R cdot R^{op} $ under the (continuous) span composite $ R timesY R^{op} to Y times Y $ is also closed.
This completes the proof.
Every Hausdorff space, hence every compactum, satisfies the separation axiom $ T0 $ .
As is usual with separation axioms, we can also look for a non - $ T0 $ version.
A priori, this is a compact preregular space; however, since every such space is regular, we can speak instead of a compact regular space.
In the absence of the axiom of choice, and especially in constructive mathematics, the best definition of compactum seems to be a compact regular locale.
That is, it is the category of compact regular locales that has all of the nice properties, forming a nice category of spaces, and that has the desired examples, such as the unit interval.
(See the discussion at Tychonoff theorem for an example of how the category of compact Hausdorff topological spaces might fail to be nice; see Frank Waaldijk's PhD thesis (pdf) for a thorough discussion of what is needed to make the unit interval a compact Hausdorff topological space.)
The monadic definition, in particular, falls quite flat without some form of the axiom of choice; even excluded middle and COSHEP are powerless here.
In fact, it is quite consistent to assume that every ultrafilter is principal (a strong denial of the ultrafilter principle), in which case $ beta $ is the identity monad.
Then a compactum would be just a set if that were the definition used.
On the other hand, it is the monadic definition that gives an algebraic category with a nice relationship to Set.
Without the ultrafilter principle, there is no reason to think that the set - of - points functor from compact regular locales to sets is even continuous.
{StoneCechCompactification} By general nonsense, every $ beta S $ , regarded as a free $ beta $ - algebra, is a compactum, and the functor $ beta: Set to Comp $ is left adjoint to the forgetful functor $ Comp to Set $ .
Assuming the ultrafilter principle, this functor extends to a functor $ beta: Top to Comp $ (identifying a set with its discrete space) that is left adjoint to the forgetful functor $ Comp to Top $ .
This is the Stone–Čech compactification functor (N.B.: for many authors, Stone - - &268;ech compactification refers to the restriction of this functor to Tychonoff spaces $ X $ , which are precisely those spaces where the unit $ X to beta X $ is an embedding so that we have a compactification in the technical sense).
A classical construction of the Stone - - &268;ech compactification starts with the unit interval $ I =0, 1 $ and proceeds to the codensity monad induced from the functor $ hom( - , I) colon Top^{op} to Set $ .
The monad is given on objects by $ X mapsto I^{hom(X, I)} $ ; this lands in compact Hausdorff spaces under the ultrafilter principle.
Let $ bar{X} $ be the closure of the image of the unit $ uX: X to I^{hom(X, I)} $ ; this $ bar{X} $ is compact Hausdorff.
If $ X $ is a Tychonoff space, then the unit $ uX: X to I^{hom(X, I)} $ is a subspace embedding, so that $ I $ is a cogenerator in the category of Tychonoff spaces.
(In particular, $ uC $ is an embedding if $ C $ is compact Hausdorff, so $ I $ is also a cogenerator in the category of compact Hausdorff spaces.)
The proof is essentially Urysohn's lemma; see also related discussion at Tychonoff space and at uniform space (noting that compact Hausdorff spaces are uniform spaces for a unique uniformity).
The natural map $ iX: X to bar{X} $ is universal among maps from $ X $ to compact Hausdorff spaces, thus giving a left adjoint $ Top to Comp $ to the (fully faithful) forgetful functor $ U: Comp to Top $ .
Let $ f: X to C $ be a map, where $ C $ is a compact Hausdorff space.
Since $ I $ is a cogenerator in the category of compact Hausdorff spaces, the unit for the codensity monad $ MI $ , $ uC: C to I^{hom(C, I)}, $ is a continuous injection (and hence a closed subspace embedding, since $ C $ is compact Hausdorff).
Let $ hat{f} = MI(f) $ , and consider the pullback square $ array{ hat{f}^{ - 1}(C) & to & I^{hom(X, I)} mathllap{pi} downarrow & & downarrow mathrlap{hat{f}} C & underset{uC}{to} & I^{hom(C, I)}. } $ From an evident naturality square for the unit $ u $ , we have a map $ h: X to hat{f}^{ - 1}(C) $ , i.e., the map $ uX: X to I^{hom(X, I)} $ factors through the closed subspace $ hat{f}^{ - 1}(C) hookrightarrow I^{hom(X, I)} $ .
Therefore $ h $ factors as $ X stackrel{iX}{to} bar{X} subseteq hat{f}^{ - 1}(C) $ and since $ pi circ h = f $ , we conclude that $ f $ factors through $ iX $ .
And moreover, there is at most one $ k: bar{X} to C $ such that $ k circ iX = f $ , because $ iX $ maps $ X $ onto a dense subspace of $ bar{X} $ , and dense subspaces are epic in the category of Hausdorff spaces.
This completes the proof.
We have a similar Stone - - &268;ech compactification functor $ Loc to Comp $ ; we do not need the ultrafilter principle here if $ Comp $ is defined in terms of locales.
The category $ Comp $ of compact Hausdorff spaces and continuous maps is From the first two properties, it follows that $ Comp $ is a pretopos, meaning that $ Comp $ enjoys the same finitary exactness properties that hold in a topos; in particular, first - order intuitionistic logic may be enacted within $ Comp $ .
In (Marra - Reggio 18), the authors give a characterization of $ Comp $ up to equivalence as the unique non - trivial pretopos which is well - pointed, filtral and admits all set - indexed copowers of its terminal object.
They contrast this result with Lawvere’s characterisation of the category of sets in ETCS, noting that the main divergence concerns > the existence of infinite “discrete” objects.
While the third axiom of ETCS postulates the existence of a natural numbers object, we prescribe filtrality which forbids the existence of infinite discrete objects.
(Marra - Reggio 18, p. 2)
In the context of ultracategories, $ Comp $ is equivalent to $ Fun{RUlt}(ast, Set) $ , the category of right ultrafunctors between the terminal ultracategory and $ Set $ (Lurie, p. 4).
The infinitary pretopos of condensed sets is the completion of the pretopos of compact Hausdorff spaces.
linebreak A topological space is a k - space (Def. )
iff
it is a colimit as formed in Top (according to this Prop.) of a diagram of compact Hausdorff spaces.
(Escardo, Lawson & Simpson 2004, Lem.
(iii)2 (v))
Such colimits of compact Hausdorff spaces are also equivalently quotient topological spaces of locally compact Hausdorff spaces, see there.
Relation to compactly generated topological spaces: A strong epimorphism in a category $ C $ is an epimorphism which is left orthogonal to any monomorphism in $ C $ .
A monomorphism in an (∞, 1) - category is a ( - 1) - truncated morphism in an (∞, 1) - category $ C $ .
Therefore it makes sense to define an strong epimorphism in an $ (infty, 1) $ - category to be a morphism that is part of the left half of an orthogonal factorization system in an (∞, 1) - category whose right half is that of $ ( - 1) $ - truncated morphisms.
If $ C $ is an (∞, 1) - topos then it has an n - connected/n - truncated factorization system for all $ n $ .
The $ ( - 1) $ - connected morphisms are also called effective epimorphisms.
Therefore in an $ (infty, 1) $ - topos strong epimorphisms again coincide with effective epimorphisms.
Strong epimorphisms were introduced in: Textbook accounts: A subset $ Asubseteq X $ of a topological space $ X $ is called nowhere dense (alias rare) if the interior of its closure is empty: $ Int(Cl(A)) = emptyset $ .
The quotient of a ring by an ideal.
Given a ring $ R $ and a two - sided ideal $ I $ with canonical $ R $ - $ R $ - bimodule monomorphism $ i:I hookrightarrow R $ , the quotient of $ R $ by $ I $ is the initial two - sided $ R $ - algebra $ R/I $ with canonical ring homomorphism $ h:R to R/I $ such that
for every element $ a in I $ , $ h(i(a)) = 0 $ : for any other $ R $ - algebra $ S $ with canonical ring homomorphism $ k:R to S $ such that for every element $ a in I $ , $ k(i(a)) = 0S $ , there is a unique ring homomorphism $ l:R/I to S $ such that $ l circ h = k $ .
Given a ring $ R $ and a left ideal $ I $ with canonical left $ R $ - module monomorphism $ i:I hookrightarrow R $ , the quotient of $ R $ by $ I $ is the initial left $ R $ - algebra $ R/I $ with canonical ring homomorphism $ h:R to R/I $ such that for every element $ a in I $ , $ h(i(a)) = 0 $ : for any other $ R $ - algebra $ S $ with canonical ring homomorphism $ k:R to S $ such that for every element $ a in I $ , $ k(i(a)) = 0S $ , there is a unique ring homomorphism $ l:R/I to S $ such that $ l circ h = k $ .
Given a ring $ R $ and a right ideal $ I $ with canonical right $ R $ - module monomorphism $ i:I hookrightarrow R $ , the quotient of $ R $ by $ I $ is the initial right $ R $ - algebra $ R/I $ with canonical ring homomorphism $ h:R to R/I $ such that for every element $ a in I $ , $ h(i(a)) = 0 $ : for any other $ R $ - algebra $ S $ with canonical ring homomorphism $ k:R to S $ such that for every element $ a in I $ , $ k(i(a)) = 0S $ , there is a unique ring homomorphism $ l:R/I to S $ such that $ l circ h = k $ .
See also The kernel of a morphism is that part of its domain which is sent to zero.
There are various definitions of the notion of kernel, depending on the properties and structures available in the ambient category.
We list a few definitions and discuss (in parts) when they are equivalent.
In a category with an initial object $ 0 $ and pullbacks, the kernel $ ker(f) $ of a morphism $ f: A to B $ is the pullback $ ker(f) to A $ along $ f $ of the unique morphism $ 0 to B $ $ array{ ker(f) &to& 0 {}^{mathllap{p}}downarrow && downarrow A &stackrel{f}{to}& B } , $ .
More explicitly, this characterizes the object $ ker(f) $ as the object (unique up to unique isomorphism) that satisfies the following universal property: for every object $ C $ and every morphism $ h : C to A $ such that $ fcirc h = 0 $ is the zero morphism, there is a unique morphism $ phi : C to ker(f) $ such that $ h = pcirc phi $ .
In a category with zero morphisms (meaning: enriched over the category of pointed sets), the kernel $ ker(f) $ of a morphism $ f : c to d $ is, if it exists, the equalizer of $ f $ and the zero morphism $ 0{c, d} $ .
In any category enriched over pointed sets, the kernel of a morphism $ f:cto d $ is the universal morphism $ k:ato c $ such that $ f circ k $ is the basepoint.
It is a weighted limit in the sense of enriched category theory.
This applies in particular in any (pre) - additive category.
This is a special case of the construction of generalized kernels in enriched categories.
Let $ Ab $ be the category of abelian groups.
It is a category with kernels.
In every $ Ab $ - enriched category $ A $ , for every morphism $ f: Xto Y $ in $ A $ there is a subfunctor $ ker f : A^{op}to Ab $ of the representable functor $ hom( - , X) $ , defined on objects by $ (ker f)(Z) = ker(hom(Z, X)to hom(Z, Y)), $ where $ ker $ on the right - hand side is the kernel n the category of abelian groups.
If the category is in fact preabelian, $ ker f $ is also representable with representing object $ Ker f $ .
One has to be careful with $ Coker f $ which does not represent the functor naive $ coker f $ defined as
$ (coker f)(Z) = coker(hom(Z, X)to hom(Z, Y)) $ in $ Ab $ , which is often not representable at all, even in the simple example of the category of abelian groups.
Instead, as a colimit construction, one should corepresent another functor, namely, the covariant functor $ Zmapsto ker(hom(Y, Z) to hom(X, Z)) $ (which is a quotient of the corepresentable functor $ hom(X, - ) $ ).
In short, $ Coker f $ is defined by the double dualization using the kernel in $ Ab $ : $ Coker f = (Ker f^{op})^{op} $ .
This is a particular case of the dualization involved in defining any colimit from its corresponding limit.
The kernel of a morphism in an (∞, 1) - category with $ infty $ - categorical zero object is the homotopy pullback as in the pullback definition above: the homotopy fiber.
See also stable (∞, 1) - category.
In some fields, the term 'kernel' refers to an equivalence relation that category theorists would see as a kernel pair.
This is especially important in fields such as monoid theory where both notions exist but are not equivalent (while in group theory they are equivalent).
In ring theory, even when one assumes that rings have units preserved by ring homomorphisms, the traditional notion of kernel (an ideal) exists in the category of non - unital rings (and is not itself a unital ring in general).
A purely category - theoretic theory of unital rings can be recovered either by using the kernel pair instead or (to fit better the usual language) moving to a category of modules.
In universal algebra, this may be handled in the framework of Mal'cev varieties.
Kashiwara - Schapira, following the terminology of EGA, uses kernel as a synonym of equalizer (and co - kernel of co - equalizer).
Let $ C $ be a category with pullbacks and zero object.
In $ C $ , the kernel of a kernel is 0.
By the <a href="http://nlab.mathforge.org/nlab/show/pullbackPasting">pasting law for pullbacks</a> we have that the total square $ array{ ker ker f &to& ker f &to& 0 downarrow && downarrow && downarrow 0 &to& c &stackrel{f}{to}& d } $ is a pullback.
Since $ 0 to c $ is a monomorphism and the pullback of a monomorphism along itself is the domain of the monomorphis, we have $ ker ker f simeq 0 $ .
This statement crucially fails to be true in higher category theory.
There, the kernel of a kernel is the based loop space object of $ d $ .
For this reason where one has short exact sequences in 1 - category theory, there are instead long fiber sequences in higher category theory.
In a category $ C $ with pullbacks and pushouts and zero object, kernel and cokernel form a pair of adjoint functors on the arrow categories $ (coker dashv ker) : Arr(C) stackrel{overset{coker}{leftarrow}}{underset{ker}{to}} Arr(C) , $ .
We check the hom - isomorphism of a pair of adjoint functors.
An element in the hom - set $ ArrC(g, ker f) $ is a diagram $ array{ c &to& ker(f) &to& 0 {}^{mathllap{g}}downarrow && downarrow && downarrow d &to& a &stackrel{f}{to}& b } , $ .
By the universal property of the pullback, this is the same as a diagram $ array{ c &to& &to& 0 {}^{mathllap{g}}downarrow && && downarrow d &to& a &stackrel{f}{to}& b } , $ .
By the dual reasoning, an element in $ ArrC(coker g, f) $ is a diagram $ array{ c &stackrel{g}{to}& d &to& a downarrow && downarrow && downarrow^{mathrlap{f}} 0 &to& coker g &to& b } , $ .
By the universal property of the pushout this is equivalently a diagram $ array{ c &stackrel{g}{to}& d &to& a downarrow && && downarrow^{mathrlap{f}} 0 &to& &to& b } , $ .
(This also follows from the general theory of generalized kernels.)
In the category Ab of abelian groups, the kernel of a group homomorphism $ f : A to B $ is the subgroup of $ A $ on the set $ f^{ - 1}(0) $ of elements of $ A $ that are sent to the zero - element of $ B $ .
More generally, for $ R $ any ring, this is true in $ R $ Mod: the kernel of a morphism of modules is the preimage of the zero - element at the level of the underlying sets, equipped with the unique sub - module structure on that set.
The notion of cofibration is dual to that of fibration.
See there for more details.
A cofibration is a member of a distinguished class of cofibrations in one of the several setups in homotopy theory:
In traditional topology, one usually means a Hurewicz cofibration.
In category theory and descent theory, Grothendieck however introduced a notion of cofibered category or cofibration, whose definition is categorically dual to that of a fibered category and based on the generalization of the universal property of coCartesian squares; however it does not correspond to the extension property in topology, but to a lifting property, like for fibrations.
For that reason, Gray suggested (and this is to some extent adopted in $ n $ lab) to call such categories opfibrations.
In the quasicategorical setup, the generalizations of fibered categories are called Cartesian fibrations, and the generalizations of op/co - fibered categories are called coCartesian fibrations.
In the $ 1 $ - categorical setup, the coCartesian arrows in op/co - fibrations are indeed the ones which complete coCartesian squares in the special and most important case of domain opfibrations.
{Examples} Cofibrations are usually defined in such a way that they are stable at least under the following operations in the category under consideration (Please mind the precise definitions of the category you are using.
Also compare the stability properties of the dual notion fibration.)
Given a metric space $ (X, d) $ , the metric topology on $ X $ is the structure of a topological space $ mathcal{T} $ on $ X $ which is generated from the topological base of $ mathcal{T} $ given by the open balls $ B(x, r) coloneqq {y in X ;|; d(x, y) lt r } $ for all $ x in X $ and $ r in (0, infty) subset mathbb{R} $ .
A topological space whose topology is the metric topology for some metric space structure on its underlying set is called a metrizable topological space.
For $ f : X to Y $ a smooth function, a critical point is a point $ x in X $ at which the derivative $ d f : T X to T Y $ has rank strictly less than the dimension of $ Y $ .
The collection of all critical points is also called the critical locus of $ f $ .
The $ f $ - image of a critical point is known as a critical value.
A point in $ Y $ that is not a critical value is known as a regular value.
A formalization of this in cohesive geometry is at cohesive (infinity, 1) - topos - - infinitesimal cohesion - - critical locus.
see *fixed point A collection of integers is called coprime or relatively prime if the only common prime factor is 1, equivalently if their greatest common divisor is (i) See also: Given a function $ f $ of $ n $ variables, and given $ n $ functions $ {gi } $ of one variable, then the total derivative of the composite function
$ t mapsto f(g1(t), cdots, gn(t)) $ is (if it exists) simply its derivative with respect to $ t $ , but understood as a linear combinationof the partial derivatives of $ f $ , via the chain rule: $ frac{d f}{d t} = sumi frac{partial f}{partial gi} , frac{d gi}{d t} , $ .
This has various evident generalizations.
One is the horizontal derivative in variational calculus, see at variational bicomplex.
Given a group $ G $ and a subgroup $ H $ , then their coset object is the quotient $ G/H $ , hence the set of equivalence classes of elements of $ G $ where two are regarded as equivalent if they differ by right multiplication with an element in $ H $ .
If $ G $ is a topological group, then the quotient is a topological space and usually called the coset space.
This is in particular a homogeneous space, see there for more.
In a category $ C $ , for $ G $ a group object and $ H hookrightarrow G $ a subgroup object, the left/right object of cosets is the object of orbits of $ G $ under left/right multiplication by $ H $ .
Explicitly, the left coset space $ G/H $ coequalizes the parallel morphisms $ H times G underoverset{mu}{projG}rightrightarrows G $ where $ mu $ is (the inclusion $ Htimes G hookrightarrow Gtimes G $ composed with) the group multiplication.
Simiarly, the right coset space $ Hbackslash G $ coequalizes the parallel morphisms $ G times H underoverset{projG}{mu}rightrightarrows G $ Specializing the above definition to the case where $ C $ is the well - pointed topos $ Set $ , given an element $ g $ of $ G $ , its orbit $ g H $ is an element of $ G/H $ and is called a left coset.
Using comprehension, we can write $ G/H = {g H | g in G } $ Similarly there is a coset on the right $ H backslash G $ .
If $ H hookrightarrow G $ is an inclusion of Lie groups then the quotient $ G/H $ is also called a Klein geometry.
{ForInfinityGroups} More generally, given an (∞, 1) - topos $ mathbf{H} $ and a homomorphism of ∞ - group objects $ H to G $ , hence equivalently a morphism of their deloopings $ mathbf{B}H to mathbf{B}G $ , then the homotopy quotient $ G/H $ is given by the homotopy fiber of this map $ array{ G/H &longrightarrow& mathbf{B}H && downarrow && mathbf{B}G } , $ .
See at ∞ - action for more on this definition.
See at higher Klein geometry and higher Cartan geometry for the corresponding concepts of higher geometry.
The coset inherits the structure of a group if $ H $ is a normal subgroup.
Unless $ G $ is abelian, considering both left and right coset spaces provide different information.
{QuotientMaps} For $ X $ a smooth manifold and $ G $ a compact Lie group equipped with a free smooth action on $ X $ , then the quotient projection $ X longrightarrow X/G $ is a $ G $ - principal bundle (hence in particular a Serre fibration).
This is originally due to (Gleason 50).
See e.g. (Cohen, theorem (i)3)
For $ G $ a Lie group and $ H subset G $ a compact subgroup, then the coset quotient projection $ G longrightarrow G/H $ is an $ H $ - principal bundle (hence in particular a Serre fibration).
This is originally due to (Samelson 41).
For $ G $ a compact Lie group and $ K subset H subset G $ closed subgroups, then the projection map $ p ;colon; G/K longrightarrow G/H $ is a locally trivial $ H/K $ - fiber bundle (hence in particular a Serre fibration).
Observe that the projection map in question is equivalently $ G timesH (H/K) longrightarrow G/H , , $ (where on the left we form the Cartesian product and then divide out the diagonal action by $ H $ ).
This exhibits it as the $ H/K $ - fiber bundle associated to the $ H $ - principal bundle of corollary .
Let $ G $ be a topological group and $ H subset G $ a subgroup.
Sufficient conditions for the coset space coprojection $ G overset{q}{to} G/H $ to admit local sections, in that there is an open cover $ underset{i in I}{sqcup}Ui to G/H $ and a continuous section $ sigma{mathcal{U}} $ of the pullback of $ q $ to the cover, $ array{ && G{vert mathcal{U}} &longrightarrow& G & {}^{mathllap{ exists sigma }} nearrow & bigdownarrow &{}^{{}{(pb)}}& bigdownarrow mathllap{ exists ; } underset{i in I}{sqcup} Ui &=& underset{i in I}{sqcup} Ui &longrightarrow& G/H mathrlap{, , } } $ include the following: and $ H $ is a compact Lie group (in particular for $ H $ a closed subgroup if $ G $ itself is a compact Lie group, since closed subspaces of compact Hausdorff spaces are equivalently compact subspaces).
(Gleason 50, Thm. (iv)1) or: (i) locally compact; (i) separable metric space; (i) of finite dimension of a separable metric space (e.g. if $ G $ is a Lie group) and $ H subset G $ is a closed subgroup.
(Mostert 53, Theorem 3)
In geometric homotopy theory (in an (∞, 1) - topos), for $ H longrightarrow G $ any homomorphisms of ∞ - group objects, then the natural projection $ G longrightarrow G/H $ , generally realizes $ G $ as an $ H $ - principal ∞ - bundle over $ G/H $ .
This is exhibited by a homotopy pullback of the form $ array{ G & longrightarrow & downarrow && downarrow G/H &longrightarrow& mathbf{B}H } , $ . where $ mathbf{B}H $ is the delooping groupoid of $ H $ .
This also equivalently exhibits the ∞ - action of $ H $ on $ G $ (see there for more).
By the pasting law for homotopy pullbacks then we get the homotopy pullback $ array{ G/H & longrightarrow &mathbf{B}H downarrow && downarrow } $ which exhibits the coset as the homotopy fiber of $ mathbf{B}H to mathbf{B}G $ .
The n - spheres are coset spaces of orthogonal groups: $ S^n simeq O(n+1)/O(n) , $ .
The odd - dimensional spheres are also coset spaces of unitary groups: $ S^{2n+1} simeq U(n+1)/U(n) $ Regarding the first statement: Fix a unit vector in $ mathbb{R}^{n+1} $ .
Then its orbit under the defining $ O(n+1) $ - action on $ mathbb{R}^{n+1} $ is clearly the canonical embedding $ S^n hookrightarrow mathbb{R}^{n+1} $ .
But precisely the subgroup of $ O(n+1) $ that consists of rotations around the axis formed by that unit vector stabilizes it, and that subgroup is isomorphic to $ O(n) $ , hence $ S^n simeq O(n+1)/O(n) $ .
The second statement follows by the same kind of reasoning: Clearly $ U(n+1) $ acts transitively on the unit sphere $ S^{2n+1} $ in $ mathbb{C}^{n+1} $ .
It remains to see that its stabilizer subgroup of any point on this sphere is $ U(n) $ .
If we take the point with coordinates $ (1, 0, 0, cdots, 0) $ and regard elements of $ U(n+1) $ as matrices, then the stabilizer subgroup consists of matrices of the block diagonal form $ left( array{ 1 & vec 0 vec 0 & A } right) $ where $ A in U(n) $ .
There are also various exceptional realizations of spheres as coset spaces.
For instance: linebreak {QuotientMapsOfCosetSpaces} Consider $ K hookrightarrow H hookrightarrow G $ two consecutive group inclusions with their induced coset quotient projections $ array{ H/K & longrightarrow& G/K && downarrow && G/H } , $ .
When $ G/K to G/H $ is a Serre fibration, for instance in the situation of prop.
(so that this is indeed a homotopy fiber sequence with respect to the classical model structure on topological spaces) then it induces the corresponding long exact sequence of homotopy groups $ cdots to pi_{n+1}(G/H) longrightarrow pin(H/K) longrightarrow pin(G/K) longrightarrow pi_n(G/H) longrightarrow pi_{n - 1}(H/K) to cdots , $ .
Consider a sequence of inclusions of orthogonal groups of the form $ O(n) hookrightarrow O(n+1) hookrightarrow O(n+k) , $ .
Then by example we have that $ O(n+1)/O(n) simeq S^n $ is the n - sphere and by corollary the quotient map is a Serre fibration.
Hence there is a long exact sequence of homotopy groups of the form $ cdots to pi_q(S^n) longrightarrow piq(O(n+k)/O(n)) longrightarrow piq(O(n+k)/O(n+1)) longrightarrow pi_{q - 1}(S^n) to cdots , $ .
Now for $ q lt n $ then $ pi_q(S^n) = 0 $ and hence in this range we have isomorphisms $ pi_{bullet lt n}(O(n+k)/O(n)) stackrel{simeq}{longrightarrow} pi_{bullet lt n}(O(n+k)/O(n+1)) , $ .
On coset spaces with the same rational cohomology as a product of n - spheres: For $ R hookrightarrow A $ an associative algebra over a ring $ R $ equipped with the structure of an augmented algebra $ epsilon colon A to R $ , the augmentation ideal is the kernel of $ epsilon $ .
Specifically for $ G $ a group, and $ RG $ its group algebra over a ring $ R $ , the augmentation ideal is the ideal in $ RG $ which consists of those formal linear combinations over $ R $ of elements in $ G $ whose sum of coefficients vanishes in $ R $ .
Let $ G $ be a discrete group and $ R $ a ring.
Write $ RG $ for the group algebra of $ G $ over $ R $ .
Write $ epsilon colon mathbb{Z}G to mathbb{Z} $ for the homomorphism of abelian groups which forms the sum of $ R $ - coefficients of the formal linear combinations that constitute the group ring $ epsilon colon r mapsto sum{g in G} rg , $ .
This is called the augmentation map.
Its kernel $ ker(epsilon) hookrightarrow mathbb{Z}G $ is the augmentation ideal of $ mathbb{Z}G $ .
(It is often denoted by $ I(G) $ .
The augmentation ideal is indeed a left and right ideal in $ RG $ .
The $ R $ - module underlying the augmentation ideal of a group algebra is a free module, free on the set of elements $ { g - e | g in G, ; g neq e } $ in $ RG $ .
(For the case $ R= mathbb{Z} $ )
As a $ mathbb{Z}G $ - module, considered with the same generators, the relations are generated by those of the form $ g1(g2 - e)= (g1g2 - e) - (g_1 - e) $ .
>
This entry is about the notion of skeleton in category theory.
For the notion of (co)skeletal simplicial sets see at simplicial skeleton.
{Definition} A strict category is called skeletal if objects that are isomorphic are necessarily equal, hence if all its isomorphisms are automorphisms.
(If in addition all isomorphisms are in fact identity morphisms, then one speaks of a gaunt category.)
A skeleton of a category $ C $ is defined to be a skeletal subcategory of $ C $ whose inclusion functor exhibits it as equivalent to $ C $ .
A weak skeleton of $ C $ is any skeletal category which is weakly equivalent to $ C $ .
In the absence of the axiom of choice, it is more appropriate to define a skeleton of $ C $ to be a weak skeleton as defined above.
In this section, we work in set - level foundations to construct skeleta of categories and more general objects.
If the axiom of choice holds, then every category $ C $ has a skeleton (in the strongest sense).
Simply choose one object in each isomorphism class and one isomorphism to that object from each other object in that class.
In more detail, generate the full subcategory $ sk(C) $ containing just the chosen objects.
Denote by $ incolon sk(C)to C $ the inclusion.
We exhibit a weak inverse of $ in $ as a functor $ - ':xmapsto x' $ constructed as follows.
For every object $ x $ one has chosen already the unique object $ x' $ in $ sk(X) $ isomorphic to $ x $ , but one also needs to make a choice of isomorphism $ i_xcolon xto x' $ for every $ x $ .
This enables to conjugate between $ C(x, y) $ and $ C(x', y') $ by $ (xstackrel{f}to y)mapsto (x'stackrel{ix^{ - 1}}to xstackrel{f}to ystackrel{iy}to y') $ .
The rule for morphisms $ - ': fmapsto f' := iycirc fcirc i{x}^{ - 1} $ is clearly functorial.
Let us show that $ - ' $ is a weak inverse of $ in $ .
In one direction, given $ yin sk(C) $ we compute $ (in{y})' = y $ (strict equality); in another direction, given $ xin C $ , notice that $ i^{ - 1}{in{x'}}:in{x'}cong x $ for $ xin C $ is an isomorphism.
It suffices to show that these isomorphisms for all $ xin C $ together form a natural isomorphism $ i^{ - 1}{in}:in{ - '}to id_C $ ; the naturality diagram is commutative precisely because of the conjugation formula for the functor $ - ' $ for morphisms.
This completes the proof that $ - ' $ is indeed a weak inverse of $ in $ .
In fact, the statement that every (possibly small) category has a skeleton is equivalent to the axiom of choice if "subcategory" and "equivalence" have their naive ('strong') meanings.
For given a surjection $ p:Ato B $ in $ Set $ , make $ A $ into a category with a unique isomorphism $ acong a' $ iff $ p(a)=p(a') $ ; then a skeleton of $ A $ supplies a splitting of $ p $ .
Even with the more general notion of weak or ana - equivalence of categories, some amount of choice is required to show that every category has a skeleton.
It would be interesting to know the precise strength of the statement "every category is weakly equivalent to a skeletal one."
In the presence of choice we can thusly turn the process of taking the skeleton of a category into an endo - pseudofunctor on $ mathfrak{Cat} $ , the $ 2 $ - category of categories.
For each category $ mathcal{C} $ let $ skmathcal{C} $ denote a skeleton of $ mathcal{C} $ and let $ Emathcal{C}:skmathcal{C}simeqmathcal{C}:Emathcal{C}^{sim1} $ denote the skeletal equivalence at $ mathcal{C} $ , with $ epsilon^{sk}mathcal{C}:Emathcal{C}circ E^{sim1}mathcal{C}Rightarrow1mathcal{C} $ the skeletal transformation at $ mathcal{C} $ .
We define an endo - pseudofunctor $ sk:mathfrak{Cat}tomathfrak{Cat} $ as follows: (i) $ sk(mathcal{C})=sk_mathcal{C}, $ (i) $ sk(F:mathcal{C}tomathcal{D})=E^{sim1}mathcal{D}circ Fcirc Emathcal{C}:skmathcal{C}tomathcal{C}tomathcal{D}to skmathcal{D}, $ (i) $ sk(alpha:FRightarrow G)=icircalphacirc i^{ - 1}:sk(F)Rightarrow sk(G), $ where $ icircalphacirc i^{ - 1}:sk(F)Rightarrow sk(G) $ is defined by $ (icircalphacirc i^{ - 1})X=i{G(X)}circalphaXcirc i{F(X)}^{ - 1}:F(X)'to F(X)to G(X)to G(X)' $ .
(i) For each category $ mathcal{C} $ , the unitor $ iota^{sk}mathcal{C}:1{sk(mathcal{C})}Rightarrow sk(1_mathcal{C}) $ is defined by $ iota^{sk}mathcal{C}=1{1_{sk(mathcal{C})}}, $ since $ sk(1mathcal{C})=E^{sim1}mathcal{C}circ1mathcal{C}circ Emathcal{C}=E^{sim1}mathcal{C}circ Emathcal{C}=1_{sk(mathcal{C})} $ .
(i) For each pair of composable functors $ F:mathcal{C}tomathcal{D} $ , $ G:mathcal{B}tomathcal{C} $ , the associator $ alpha^{sk}_{F, G}:sk(F)circ sk(G)Rightarrow sk(Fcirc G) $ is defined by $ alpha^{sk}{F, G}=1{E^{sim1}mathcal{D}circ F}starepsilon^{sk}mathcal{C}star1{Gcirc Emathcal{B}}:E^{sim1}mathcal{D}circ Fcirc Emathcal{C}circ Emathcal{C}^{sim1}circ Gcirc Emathcal{B}Rightarrow E^{sim1}mathcal{D}circ Fcirc Gcirc Emathcal{B} $ .
Using the above definition, we can canonically define the skeleton of an indexed category.
Let $ psi:mathcal{B}^{op}tomathfrak{Cat} $ be an indexed category.
We define the indexed skeleton of $ psi $ , denoted $ sk(psi):mathcal{B}^{op}tomathfrak{Cat}, $ to be the indexed category given by postcomposing $ psi $ with $ sk $ , so $ sk(psi)=skcircpsi $ .
That is, for each $ Iinmathcal{B} $ we take a skeleton $ sk(psi(I)) $ of the category $ psi(I) $ indexed by $ I $ with equivalence $ EI:psi(I)simeq sk(psi(I)):EI^{sim1} $ , we extend functors using the equivalences at various skeletons, and we extend natural transformations using skeletal isomorphisms in the codomain categories (although $ mathcal{B}^{op} $ has only identity $ 2 $ - cells since it's a promoted $ 1 $ - category, so the action on $ 2 $ - cells is trivial).
Using the above definition and the Grothendieck construction, we can define the skeleton of a fibration using the skeleton of an indexed category.
Let $ p:mathcal{E}tomathcal{B} $ be a fibration.
We define the fibered skeleton of $ p $ , denoted $ sk(p):sk^p_mathcal{E}tomathcal{B} $ to be the Grothendieck completion of the indexed skeleton of the indexing by $ p $ .
That is, $ sk(p) $ is the fibration obtained by turning $ p $ into an indexed category using the Grothendieck construction, taking the indexed skeleton of this indexed category, then turning the resulting skeletal indexed category back into a fibration (via the Grothendieck construction again).
We refer to the total category $ sk^pmathcal{E} $ in the resulting fibration as the $ p $ - skeleton of $ mathcal{E} $ , which is different than $ skmathcal{E} $ since we have only skeletalized the fiber categories of our original fibration and not the total category of the original fibration.
In general, we will have that $ skmathcal{E}ncong sk^pmathcal{E}, $ although they are trivially equivalent.
As an example of this construction in action, we can pass from the monomorphism fibration on a category with pullbacks to the subobject fibration by taking the fibered skeleton.
For details, see the subobject fibration section of codomain fibration.
In this section we collect some properties of skeleta in set - level foundations.
Of course, two categories can be equivalent even if one is skeletal and the other is not.
Thus, the notion of skeletal category violates the principle of equivalence.
(It doesn't make sense to ask whether a particular category, skeletal or not, "violates the principle of equivalence".)
Without any choice, we have the following theorems.
Any thin category (i.e. any preordered set) has a weak skeleton.
In this case, we can take the objects of the skeleton of $ C $ to be the isomorphism classes of $ C $ .
If $ C $ is thin, then we can define a partial ordering on its set of isomorphism classes, making them into a skeleton of $ C $ .
Any two skeletons (in the strong sense) of a category are isomorphic.
Let $ mathcal{C} $ be a category, with $ sk (mathcal{C}) $ and $ sk (mathcal{C})' $ two skeletons of $ mathcal{C} $ , and for each object $ Yinmathcal{C} $ denote by $ XY $ and $ XY' $ respectively the unique objects in $ sk (mathcal{C}) $ and $ sk (mathcal{C})' $ which are isomorphic to Y, and denote their respective isomorphisms by $ iY:Yto XY $ and $ iY':Yto XY' $ .
We define a functor $ F:sk (mathcal{C})to sk (mathcal{C})' $ by $ F(XY)=XY', $ $ F(f:XYto XZ)=iZ'circ iZ^{ - 1}circ fcirc iYcirc iY'^{ - 1}:XY'to Yto XYto XZto Zto XZ' $ .
We then have $ F(1{XY})=iY'circ iY^{ - 1}circ 1{XY}circ iYcirc iY'^{ - 1}=iY'circ iY^{ - 1}circ iYcirc iY'^{ - 1}=iY'circ1Ycirc iY'^{ - 1}=iY'circ iY'^{ - 1}=1{XY'}=1{F(X_Y)}, $ $ F(f:XBto XC)circ F(g:XAto XB)=iC'circ iC^{ - 1}circ fcirc iBcirc iB'^{ - 1}circ iB'circ iB^{ - 1}circ gcirc iAcirc iA'^{ - 1} $ $ =iC'circ iC^{ - 1}circ fcirc iBcirc 1{B}circ iB^{ - 1}circ gcirc iAcirc iA'^{ - 1}=iC'circ iC^{ - 1}circ fcirc iBcirc iB^{ - 1}circ gcirc iAcirc i_A'^{ - 1} $ $ =iC'circ iC^{ - 1}circ fcirc1{XB}circ gcirc iAcirc iA'^{ - 1}=iC'circ iC^{ - 1}circ fcirc gcirc iAcirc iA'^{ - 1}=F(fcirc g), $ so $ F $ is a functor.
The inverse $ F^{ - 1}: sk (mathcal{C})'to sk (mathcal{C}) $ is defined in the obvious way, and is functorial by similar computations.
Notice that the axiom of choice fails in general when one considers internal categories.
Hence not every internal category has a skeleton.
A necessary condition for an internal category $ X1 rightrightarrows X0 $ to have a skeleton is the existence quotient $ X0/X1 $ - the object of orbits under the action of the core of $ X $ .
If the quotient map $ X0 to X0/X_1 $ has a section, then one could consider $ X $ to have a skeleton, but this condition isn't sufficient for the induced inclusion functor to be a weak equivalence of internal categories when this makes sense (i.e. if the category is internal to a site).
David Roberts: The claim above about the necessity of the existence of the quotient needs to be checked.
Define a coskeleton of a category $ C $ to be a skeletal category $ S $ with a surjective equivalence $ Cto S $ .
In Categories, Allegories it is shown that the following are equivalent.
(i) The axiom of choice holds.
(i)
Any two ana - equivalent categories are strongly equivalent.
I removed 'non - ana', since I don't think that 'strongly equivalent' would ever be used in an 'ana - ' sense.
- - - Toby Addendum:
Actually, I don't know why I asked whether you meant weakly or strongly here, since obviously one can prove that two ana - equivalent categories are weakly equivalent!
It seems that the discussion above used the terms 'equivalence' and 'ana - equivalence' where equivalence of categories uses 'strong equivalence' and 'weak equivalence' or 'ana - equivalence'; so I just changed it.
And then I added another entry, which maybe you should remove if Freyd & Scedrov don't actually address it.
On the other hand, if they really talk about weak equivalence instead of ana - equivalence (although if they define it in elementary terms, it's hard to tell the difference), maybe there's no need to say 'ana - ' at all on this page.
(i)
Any two weakly equivalent categories are strongly equivalent.
(i) Every small category has a weak skeleton.
(i) Every small category has a coskeleton.
(i)
Any two weak skeletons of a given small category are isomorphic.
(i)
Any two coskeletons of a given small category are isomorphic.
For convenience we add: (i) Given an inhabited family $ {Si } I $ of equinumerous sets there exists $ 0 in I $ and a family of isomorphisms of the permutation groups $ {Aut(S0) to Aut(Si) } _I $ .
(i) Given a family $ {Si } I $ of inhabited equinumerous sets, there exists a family $ (xi)I $ such that $ xi in Si $ for all $ i in I $ .
It is well - known that objects defined by universal properties in a category, such as limits and colimits, are not unique on the nose, but only unique up to unique canonical isomorphism.
It can be tempting to suppose that in a skeletal category, where any two isomorphic objects are equal, such objects will in fact be unique on the nose.
However, under the most appropriate definition of "unique, " this is not true (in general), because of the presence of automorphisms.
More explicitly, consider the notion of cartesian product in a category.
Although we colloquially speak of "a product" of objects $ A $ and $ B $ as being the object $ Atimes B $ , strictly speaking a product consists of the object $ Atimes B $ together with the projections $ Atimes Bto A $ and $ Atimes Bto B $ which exhibit its universal property.
Thus, even if the category in question is skeletal, so that there can be only one object $ Atimes B $ that is a product of $ A $ and $ B $ , in general this object can still "be the product of $ A $ and $ B $ " in many different ways.
For example, given any projections $ Atimes Bto A $ and $ Atimes Bto B $ that exhibit $ Atimes B $ as a product of $ A $ and $ B $ , we can compose them both with any automorphism of $ Atimes B $ to get a new, different, pair of projections that also exhibit $ Atimes B $ as a product of $ A $ and $ B $ .
In fact, the universal property of a product implies that any two pairs of projections are related by an automorphism of $ Atimes B $ , so this example is generic.
Thus, even in a skeletal category, we cannot speak of "the" product of $ A $ and $ B $ , except in the same generalized sense that makes sense in any category.
A formal way to say this is that the "category of products of $ A $ and $ B $ , " while still equivalent to the trivial category, as it is in any category with products, will not be isomorphic to the trivial category even when the ambient category is skeletal.
(It is true in a few cases, though, that skeletality implies uniqueness on the nose.
For instance, a terminal object can have no nonidentity automorphisms, so in a skeletal category, a terminal object (if one exists) really is unique on the nose.)
All the discussion above pertains to set - level foundations.
In intensional type theory such as homotopy type theory, additional care is needed.
A first guess is to define a precategory $ C $ to be skeletal if for any objects $ a, b $ there is a function $ Vert acong bVert to (a=b) $ , i.e. if $ a $ and $ b $ are merely isomorphic then they are equal.
(Here $ Vert - Vert $ denotes the propositional truncation.)
However, if the type $ ob(C) $ of objects is not a set, then $ a=b $ is not a proposition, and so under this definition a category could "be skeletal" in more than one way.
Arguably a better definition is to say that a precategory $ C $ is skeletal if for any objects $ a, b $ the canonical function $ (a=b) to Vert acong bVert $ is an equivalence.
Since $ Vert acong bVert $ is always a proposition, this entails that $ a=b $ is also a proposition.
Thus, this implies that $ ob(C) $ is a set, i.e. that $ C $ is a strict category.
Note the analogy between this condition and the notion of univalent category: the only difference is the propositional truncation.
It follows that if a precategory is both skeletal and univalent, then $ acong b $ is always a proposition (since it is equivalent to its propositional truncation), and thus the category is gaunt.
Indeed, the gaunt categories are precisely those that are both skeletal and univalent.
Unlike in set - level foundations, in intensional type theory not every precategory (and not even every univalent category) has a skeleton.
Indeed, if the axiom sets cover fails, then there can be univalent categories that are not weakly equivalent to any strict category.
For this reason, the notion of skeleton tends to be less useful outside of set - level foundations, although particular concrete examples may turn out to be skeletal.
All of the above examples are in fact gaunt: not only are any two isomorphic objects equal, but any isomorphism is an identity morphism.
{PosetsAsSkeletaOfProsets} In terms of (n, r) - category - theory one may essentially identify preordered sets with thin categories or (0, 1) - categories.
Under this identification, the passage of skeleta of categories corresponds to choosing an equivalent partial order inside a preorder.
For more details (and more precise statements, see at relation between preorders and (0, 1) - categories.
See also: The fundamental groupoid of a space $ X $ is a groupoid whose objects are the points of $ X $ and whose morphisms are paths in $ X $ , identified up to endpoint - preserving homotopy.
In parts of the literature the fundamental groupoid, and more generally the fundamental ∞ - groupoid, is called the Poincar&233; groupoid.
The fundamental groupoid $ Pi1(X) $ of a topological space $ X $ is the groupoid whose set of objects is $ X $ and whose morphisms from $ x $ to $ y $ are the equivalence classes of homotopy of homotopy relative to $ partial I $ $ gamma $ of continuous maps $ gamma : 0, 1 to X $ whose endpoints map to $ x $ and $ y $ (which the homotopies are required to fix).
Composition is by concatenation (and reparametrization) of representative maps.
Under the homotopy - equivalence relation this becomes an associative and unital composition with respect to which every morphism has an inverse; hence $ Pi1(X) $ is a groupoid.
The use of the fundamental groupoid of a manifold for describing the monodromy principle on the extension of local morphisms is discussed in the paper by Brown/Mucuk listed below.
For any $ x $ in $ X $ the first homotopy group $ pi1(X, x) $ of $ X $ based at $ x $ arises as the automorphism group of $ x $ in $ Pi1(X) $ : $ pi1(X, x) = Aut{Pi_1(X)}(x) , $ .
So the fundamental groupoid gets rid of the choice of basepoint for the fundamental group, and this is valuable for some applications.
The set of connected components of $ Pi1(X) $ is precisely the set $ Pi0(X) $ of path - components of $ X $ .
(This is not to be confused with the set of connected components of $ X $ , sometimes denoted by the same symbol.
Of course they are the same when $ X $ is locally path - connected.)
The fundamental groupoid $ Pi_1(X) $ can be made into a topological groupoid (i.e. a groupoid internal to Top) when $ X $ is path - connected, locally path - connected and semi - locally simply connected.
This is a special case of (Brown 06, (x)(v)8).
This construction is closely linked with the construction of a universal covering space for a path - connected pointed space.
The object space of this groupoid is just the space $ X $ .
When $ X $ is not semi - locally simply connected, the set of arrows of the fundamental groupoid inherits the quotient topology from the path space such that the fibres of $ (s, t):Mor(Pi1(X)) to Xtimes X $ are not discrete, which is an obstruction to the above - mentioned source fibre's being a covering space.
However the composition is no longer continuous.
When $ X $ is not locally path - connected, $ Pi0(X) $ also inherits a non - discrete topology (the quotient topology of $ X $ by the relation of path connections).
In circumstances like these more sophisticated methods are appropriate, such as shape theory.
This is also related to the fundamental group of a topos, which is in general a progroup or a localic group rather than an ordinary group.
An improvement on the fundamental group and the total fundamental groupoid relevant to the van Kampen theorem for computing the fundamental group or groupoid is to use $ Pi1(X, A) $ , defined for a set $ A $ to be the full subgroupoid of $ Pi1(X) $ on the set $ Acap X $ , thus giving a set of base points which can be chosen according to the geometry at hand.
Thus if $ X $ is the union of two open sets $ U, V $ with intersection $ W $ then we can take $ A $ large enough to meet each path - component of $ U, V, W $ ; note that by the above definition we can write $ Pi1(U, A) $ , etc.
If $ X $ has an action of a group $ G $ then $ G $ acts on $ Pi1(X, A) $ if $ A $ is a union of orbits of the action.
Thus $ Pi_1(X, A) $ can represent some symmetry of a given situation.
The notion of $ Pi_1(X, A) $ was introduced in 1967 by Ronnie Brown to give a version of the Seifert - van Kampen Theorem which allowed the determination of the fundamental group of a connected space which is the union of connected subspaces with nonconnected intersection, such as the circle, a space which is, after all, THE basic example in topology.
Grothendieck writes in his 1984 Esquisse d'un Programme (English translation): " .., people still obstinately persist, when calculating with fundamental groups, in fixing a single base point, instead of cleverly choosing a whole packet of points which is invariant under the symmetries of the situation, which thus get lost on the way.
In certain situations (such as descent theorems for fundamental groups `a la van Kampen) it is much more elegant, even indispensable for understanding something, to work with fundamental groupoids with respect to a suitable packet of base points, ..".
Notice that $ Pi1(X, X) $ recovers the full fundamental groupoid, while $ Pi1(X, {x } ) $ is simply the fundamental group $ pi_1(X, x) $ .
Basically, $ Pi1(X, A) $ allows for the computation of homotopy 1 - types; the theory was developed in Elements of Modern Topology (1968), now available as Topology and Groupoids_ (2006).
These accounts show the use of the algebra of groupoids in 1 - dimensional homotopy theory, for example for covering spaces, and, in the later edition, for orbit spaces.
Another text in English which covers this notion is by Philip Higgins, see below.
See fundamental ∞ - groupoid.
See simplicial fundamental groupoid.
Review and Exposition: > (about groupoids in topology, notably fundamental groupoids - - not about topological groupoids) See also: Math.
Soc_.
(3) 17 (1967) 385 - 40(i) topological groupoid, Proc.
Edinburgh Math.
Soc. 19 (1975) 237 - 24(iv) groupoid, Cah.
Top.
G'eom.
Diff.
Cat. 36 (1995) 345 - 36(ix) Relations with group theory:
Discussion from the point of view of Galois theory is in Discussion of the fundamental groupoid (for good topological spaces and for noetherian schemes) as the costack (via the Seifert - van Kampen theorem) characterized as being 2 - terminal is in A recent paper in the area of dynamical systems which uses fundamental groupoids on many base points is: Given a sequence $ X_bullet = left( X_0 overset{f_0}{longrightarrow} X_1 overset{f_1}{longrightarrow} X_2 overset{f_2}{longrightarrow} cdots right) $ of (pointed) topological spaces, then its mapping telescope is the result of forming the (reduced) mapping cylinder $ Cyl(f_n) $ for each $ n $ and then attaching all these cylinders to each other in the canonical way.
At least if all the $ f_n $ are inclusions, this is the sequential attachment of ever "larger" cylinders, whence the name "telescope".
The mapping telescope is a representation for the homotopy colimit over $ X_bullet $ .
It is used for instance for discussion of lim^1 and Milnor sequences (and that's maybe the origin of the concept?).
For $ X_bullet = left( X_0 overset{f_0}{longrightarrow} X_1 overset{f_1}{longrightarrow} X_2 overset{f_2}{longrightarrow} cdots right) $ a sequence in Top, its mapping telescope is the quotient topological space of the disjoint union of product topological spaces $ Tel(X_bullet) coloneqq left( underset{n in mathbb{N}}{sqcup} left( X_n times n, n+1 right) right)/_sim $ where the equivalence relation quotiented out is $ (xn, n) sim (f(xn), n+1) $ for all $ nin mathbb{N} $ and $ xn in Xn $ .
Analogously for $ X_bullet $ a sequence of pointed topological spaces then use reduced cylinders to set $ Tel(X_bullet) coloneqq left( underset{n in mathbb{N}}{sqcup} left( Xn wedge n, n+1+ right) right)/_sim , $ .
For $ Xbullet $ the sequence of stages of a (pointed) CW - complex $ X = underset{longleftarrow}{lim}n X_n $ , then the canonical map $ Tel(X_bullet) longrightarrow X $ from the mapping telescope, def. , is a weak homotopy equivalence.
Write in the following $ Tel(X) $ for $ Tel(Xbullet) $ and write $ Tel(Xn) $ for the mapping telescop of the substages of the finite stage $ X_n $ of $ X $ .
It is intuitively clear that each of the projections at finite stage $ Tel(Xn) longrightarrow Xn $ is a homotopy equivalence, hence a weak homotopy equivalence.
A concrete construction of a homotopy inverse is given for instance in (Switzer 75, proof of prop.
(vii)53).
Moreover, since spheres are compact, so that elements of homotopy groups $ piq(Tel(X)) $ are represented at some finite stage
$ piq(Tel(X_n)) $ it follows that $ underset{longrightarrow}{lim}n piq(Tel(X_n)) overset{simeq}{longrightarrow} pi_q(Tel(X)) $ are isomorphisms for all $ qin mathbb{N} $ and all choices of basepoints (not shown).
Together these two facts imply that in the following commuting square, three morphisms are isomorphisms, as shown $ . array{ underset{longleftarrow}{lim}n piq(Tel(X_n)) &overset{simeq}{longrightarrow}& pi_q(Tel(X)) {}^{mathllap{simeq}}downarrow && downarrow underset{longleftarrow}{lim}n piq(X_n) &underset{simeq}{longrightarrow}& pi_q(X) } , $ .
Therefore also the remaining morphism is an isomorphism (two - out - of - three).
Since this holds for all $ q $ and all basepoints, it is a weak homotopy equivalence.
A (binary) relation $ sim $ on a set $ A $ is symmetric if any two elements that are related in one order are also related in the other order: $ forall (x, y: A), ; x sim y ;Rightarrow; y sim x $ In the language of the $ 2 $ - poset - with - duals Rel of sets and relations, a relation $ R: A to A $ is symmetric if it is contained in its reverse: $ R subseteq R^{op} $ In that case, this containment is in fact an equality.
A set with a symmetric relation is the same as a loop digraph $ (V, E, s:E to V, t:E to V) $ with a function $ sym:E to E $ such that A point $ P $ of a topological space $ X $ is isolated if it is a neighbourhood of itself, in other words if the singleton subset $ {P } $ is open.
More generally, a point $ P $ of a subset $ A $ of a space $ X $ is isolated in $ A $ if it is isolated when viewed as a point in the subspace $ A $ with the subspace topology.
More explicitly, for some neighbourhood $ U $ of $ P $ (in $ X $ ), $ U cap A = {P } $ .
The antithetical concept is that of an accumulation point.
Every function on $ X $ is continuous at $ P $ if $ P $ is isolated.
The projective plane $ mathbb{R}P^2 $ over the real numbers.
Given a topological space (or locale) $ X $ , a subspace $ A $ of $ X $ is dense if its closure is all of $ X $ : $ cl(A)=X $ .
Since $ cl(A) $ is the set of all points $ x $ such that every open neighborhood of $ x $ intersects $ A $ , this can equivalently be written as "every open neighborhood of every point intersects $ A $ ", or equivalently "every inhabited open set intersects $ A $ ", i.e $ . Acap U $ is inhabited for all inhabited open sets $ U $ .
Contraposing this, we obtain another equivalent definition "the only open subset not intersecting $ A $ is the empty set", or "if $ Acap U=emptyset $ for some open set $ U $ , then $ U=emptyset $ ".
This is the definition usually given when $ X $ is a locale: a nucleus $ j $ is dense if $ j(0)=0 $ (since $ j(0) $ is the union of all opens whose "intersection with $ j $ " is $ 0 $ ).
In the category of Hausdorff topological spaces (with continuous functions between them), the inclusion of a dense subspace $ A overset{;;i;;}{hookrightarrow} X $ is an epimorphism.
We have to show that for $ (f, g) $ any pair of parallel morphisms out of $ X $ $ A overset{;;i;;}{hookrightarrow} X underoverset {;;g;;} {;;f;;} {rightrightarrows} Y $ into a Hausdorff space $ Y $ , the equality $ f circ i = g circ i $ implies $ f = g $ .
With classical logic we may equivalently show the contrapositive: That $ f neq g $ implies $ f circ i neq g circ i $ .
So assume that $ f neq g $ .
This means that there exists $ y in Y $ with $ f(y) neq g(y) $ .
But since $ Y $ is Hausdorff, there exist disjoint open neighbourhoods $ O{f(y)}, ;O{g(y)} subset Y $ , i.e $ . f(x) in O{f(x)} $ and $ g(x) in O{g(x)} $ with $ O{f(x)} cap O{g(x)} = varnothing $ .
But their preimages must intersect at least in $ x in f^{ - 1}big( O{f(x)} big) cap g^{ - 1}big( O{g(x)} big) $ .
Since this intersection is an open subset (as preimages of open subsets are open by definition of continuous functions, and since finite intersections of open subsets are open by the definition of topological spaces) there exists a point $ a in A $ with $ i(a) in f^{ - 1}big( O{f(x)} big) cap g^{ - 1}big( O{g(x)} big) $ (by definition of dense subset).
But since then $ f(i(a)) in O{f(x)} $ and $ g(i(a)) in O{g(x)} $ while $ O{f(x)} $ is disjoint from $ O{g(x)} $ , it follows that $ f(i(a)) neq g(i(a)) $ .
This means that $ f circ i neq g circ i $ .
In constructive mathematics, the law of contraposition is not an equivalence, so we obtain two inequivalent notions of density: Of course, strong density implies weak density, since emptiness is non - inhabitation (whereas inhabitation is stronger than non - emptiness).
The two notions of density are related dually to the corresponding notions of closed subspace: $ A $ is strongly dense iff
its weak closure is all of $ X $ , and weakly dense iff its strong closure is all of $ X $ .
Note that the usual notion of density for sublocales $ j(0)=0 $ is an analogue of weak density, and could be called such.
There is also a notion of strong density for sublocales.
Since strong density refers to inhabited sets, one might expect strong density for sublocales to refer to positive elements, and thus only be sensible for overt locales; but in fact it can be reformulated to make sense in all cases.
A nucleus $ j $ on a locale $ X $ is strongly dense if $ j(hat{P})=hat{P} $ for any truth value $ P $ , where $ hat{P} = bigvee { X mid P } $ .
With classical logic, every truth value is either $ top $ or $ bot $ , and we have $ hat{top}=X $ (and any nucleus satisfies $ j(X)=X $ ) while $ hat{bot}=0 $ .
Thus classically strong and weak density coincide.
To see that this is really a notion of strong density, we prove: If $ i:Asubseteq X $ is a sublocale such that $ A $ and $ X $ are both overt, then $ A $ is strongly dense if and only if for any positive open $ Uin O(X) $ , the intersection $ Acap U = i^U in O(A) $ is also positive.
First suppose $ A $ is strongly dense, and let $ Uin O(X) $ be positive.
Let $ P $ be the truth value of the statement " $ i^U in O(A) $ is positive".
We want to show that $ P $ is true, for which it suffices to show that $ hat{P} = bigvee { X mid P } $ is positive, since then its covering $ { X mid P } $ would be inhabited and thus $ P $ would be true.
And since $ U $ is positive, it suffices to show $ U subseteq hat{P} $ .
Now since $ A $ is strongly dense, $ jA(hat{P}) = hat{P} $ , which is to say that $ hat{P} = i(i^hat{P}) $ .
By adjointness, therefore, to show $ U subseteq hat{P} $ it suffices to show $ i^U subseteq i^hat{P} = bigvee { A mid P } $ .
Now since $ A $ is overt, $ i^U $ can be covered by positive opens, so it suffices to show that for any positive $ Vsubseteq i^U $ we have $ Vsubseteq bigvee { A mid P } $ .
But if $ Vsubseteq i^U $ is positive, then $ i^U $ is also positive, i.e $ . P $ is true, and thus $ bigvee { A mid P } = A $ , which contains $ V $ .
Now suppose conversely that for any positive $ Uin O(X) $ , $ i^U $ is also positive, and let $ P $ be any truth value; we must show $ i_ i^hat{P} subseteq hat{P} $ .
Since $ X $ is overt, $ i_ i^hat{P} $ can be covered by positive opens, so it suffices to show that for any positive $ Usubseteq i_ i^hat{P} $ we have $ Usubseteq hat{P} $ .
But by adjointness, $ Usubseteq i_ i^hat{P} $ is equivalent to $ i^U subseteq i^hat{P} $ , and by assumption $ i^U $ is also positive.
Thus, $ i^hat{P} = bigvee { A mid P } $ is positive, which means that $ P $ is true, and hence $ hat{P} = X $ and so $ Usubseteq hat{P} $ .
Since spatial locales are overt, and their positivity predicate coincides with inhabitedness, we have in particular:
If $ i:Asubseteq X $ is a subspace of a topological space, then $ A $ is strongly dense as a topological subspace if and only if it is strongly dense as a sublocale.
Strong density for sublocales gives rise to a corresponding notion of weakly closed sublocale.
It is also the specialization of the notion of fiberwise dense sublocale to the case of locale maps $ Xto 1 $ .
Strongly dense sublocales are discussed in A priori a locally compact topological group is a topological group $ G $ whose underlying topological space is locally compact.
Typically it is also assumed that $ G $ is Hausdorff.
(Notice that if not, then $ G/overline{{1 } } $ is Hausdorff.).
One often says just "locally compact group".
We take here locally compact groups $ G $ to be also Hausdorff.
Locally compact topological groups are the standard object of study in classical abstract harmonic analysis.
The crucial properties of locally compact groups is that they posses a left (right) Haar measure $ rho $ and that $ L^1(rho) $ has a structure of a Banach $ * $ - algebra.
A left (right) Haar measure on a locally compact topological group is a nonzero Radon measure which is invariant under the left (right) multiplications by elements in the group.
A topological subgroup $ H $ of a locally compact topological group $ G $ is itself locally compact (in induced topology) iff
it is closed in $ G $ .
Again taking locally compact groups $ G $ to be Hausdorff, such are complete both with respect to their left uniformity and their right uniformity.
For if $ {xalpha } $ is a Cauchy net in $ G $ and $ U $ is a compact neighborhood of the identity $ e $ , then there is $ alpha $ so large that $ xbeta xalpha^{ - 1} in U $ for all $ beta geq alpha $ .
Those elements converge to a point $ x in U $ since $ U $ is compact, and the original net converges to $ x cdot xalpha $ .
A similar argument is used for the right uniformity.
See at Pontrjagin duality.
Kazhdan's property (T) See also: A (binary) relation $ sim $ on a set $ A $ is reflexive if every element of $ A $ is related to itself: $ forall (x: A), ; x sim x $ In the language of the $ 2 $ - poset Rel of sets and relations, a relation $ R: A to A $ is reflexive if it contains the identity relation on $ A $ : $ idA subseteq R $ A set with a reflexive relation is the same as a loop digraph $ (V, E, s:E to V, t:E to V) $ with function $ refl:V to E $ such that Under the Dold - Kan correspondence, ∞ - groupoids with strict abelian group structure (modeled by Kan complexes that are simplicial abelian groups) are identified with non - negatively graded chain complexes of abelian groups $ Nbullet : SimpAb stackrel{simeq}{to} Ch+ , $ .
The homology groups of a chain complex of abelian groups are the image under this identification of the homotopy groups of the corresponding ∞ - groupoids.
More details on this are at chain homology and cohomology.
So at least for the case of chain complexes of abelian groups we have the slogan Of course historically the development of concepts was precisely the opposite: chain homology is an old fundamental concept in homological algebra that is simpler to deal with than simplicial homotopy groups.
The computational simplification for chain complexes is what makes the Dold - Kan correspondence useful after all.
Conceptually, however, it can be useful to understand homology as a special kind of homotopy.
This is maybe most vivid in the dual picture: cohomology derives its name from that fact that chain homology and cohomology are dual concepts.
But later generalizations of cohomology to generalized (Eilenberg - Steenrod) cohomology and further to nonabelian cohomology showed that the restricted notion of homology is an insufficient dual model for cohomology: what cohomology is really dual to is the more general concept of homotopy.
More on this is at cohomotopy and Eckmann - Hilton duality.
The category of abelian groups is in particular an abelian category.
We can define chain complexes and their homology in any abelian category $ C $ .
Let $ C $ be an abelian category and let $ Vbullet = ( cdots to V{n+1} stackrel{deltan}{to} Vn stackrel{delta{n - 1}}{to} V{n - 1} to cdots ) $ be a chain complex in $ C $ .
For each integer $ n in mathbb{N} $ this induces the following diagram of kernels, cokernels and images $ array{ && im deltan &&to&& ker delta{n - 1} & nearrow && searrow && swarrow V{n+1} &&stackrel{deltan}{to}&& Vn &&stackrel{delta{n - 1}}{to}&& V{n - 1} & && swarrow && searrow && nearrow && coker deltan &&stackrel{}{to}&& im delta{n - 1} } $ the homology $ Hn(V) $ of $ V $ in degree $ n $ is the object $ im(ker delta{n - 1} to Vn to coker delta{n}) & simeq coker(im deltan to ker delta{n - 1}) & simeq coker(V{n+1} to ker delta{n - 1}) & simeq ker(coker deltan to im delta{n - 1}) & simeq ker(coker deltan to V{n - 1}) $ In the special case that $ C $ is the category of abelian groups, or of vector spaces, this definition reduces to the more familiar simpler statement: the $ n $ - th homology group of the chain complex $ Vbullet $ is the quotient group $ Hn(V) = ker(partialn) / im(partial{n+1}) , $ .
By the Brown representability theorem every spectrum $ A $ induces a generalized (Eilenberg - Steenrod) cohomology theory, and dually a generalized homology theory.
For $ X $ a topological space and $ A $ a spectrum, the generalized homology of spectrum of $ X $ with coefficients in $ A $ is $ X wedge A := Sigma^infty(X)wedge A , , $ where on the right we have the smash product of spectra with the suspension spectrum of $ X $ and on the left we abbreviate this to the (∞, 1) - tensoring of Spec over Top.
The corresponding homology groups are the homotopy groups of this spectrum: $ En(X, A) := pin(X wedge A) := Sigma^n mathbb{S}, X wedge A , $ . where $ mathbb{S} $ is the sphere spectrum.
For more see generalized homology.
The relation between homology, cohomology and homotopy: The ingredients of homology and cohomology: An orthogonal matrix is a square matrix $ A $ whose transpose matrix equals its inverse matrix $ A^T = A^{ - 1} $ , hence such that $ A^T A = 1 $ under matrix multiplication.
Orthogonal matrices form a subgroup of the general linear group, namely the orthogonal group.
For a generalization see J - orthogonal matrix.
Every real matrix $ A $ can be factorized $ A = Q R $ where $ Q $ is orthogonal and $ R $ is a (say, upper) triangular matrix (wikipedia/QR decomposition which is a special case of Iwasawa decomposition for semisimple Lie groups).
This is consequence of Gram - Schmidt orthogonalization.
Similarly, every complex matrix can be factorized into a unitary and a complex upper triangular (complex) matrix.
Over the reals, the Cayley transform is a diffeomorphism between the linear space skewsymmetric matrices and an open subset of the Lie group of orthogonal matrices ( $ A $ such that $ I+A $ is invertible) - a chart which is often having an advantage over using the exponential map.
A free module over some ring $ R $ is freely generated on a set of basis elements.
Under the interpretation of modules as generalized vector bundles a free module corresponds to a trivial bundle.
Let $ C $ be a monoidal category, and $ Alg(C) $ the category of monoids in $ C $ ; and for $ A in Alg(C) $ let $ A $ Mod $ (C) $ be the category of $ A $ - modules in $ C $ .
There is the evident forgetful functor $ U : A Mod(C) to C $ that sends each module $ (N, rho) $ to its underlying object $ N in C $ .
The left adjoint $ C to A Mod(C) $ is the corresponding free construction.
The modules in the image of this functor are free modules.
Let $ R $ be a ring.
We discuss free modules over $ R $ .
For $ R in $ Ring a ring and $ S in $ Set, the free $ R $ - module on $ S $ is isomorphic to the $ {vert Svert} $ - fold direct sum of $ R $ with itself $ R^{(S)}simeq oplus{s in S} R , $ .
Let $ R $ be a commutative ring, and let $ R{X } $ denote the free $ R $ - module on a set $ X $ .
The free $ R $ - module functor is strong monoidal with respect to the Cartesian monoidal structure on sets, and the tensor product of $ R $ - modules.
In other words, the free module construction turns set - theoretic products into tensor products.
Thus, it preserves algebraic objects (such as monoid objects, Hopf monoid objects, etc.) and their homomorphisms.
In particular, if $ M $ is a monoid in the category of sets (and hence a bimonoid with the canonical comonoid structure) then $ R{M } $ is a bimonoid object in $ R mathsf{Mod} $ , which is precisely a $ K $ - bialgebra.
A group $ G $ in the category of sets is a Hopf monoid, and hence $ R{G } $ is a Hopf algebra - - - this is precisely the group algebra of $ G $ . {SubmodulesOfFreeModules} Let $ R $ be a commutative ring.
Assuming the axiom of choice, the following are equivalent (i) every submodule of a free $ R $ - module is itself free; (i) every ideal in $ R $ is a free $ R $ - module; (i) $ R $ is a principal ideal domain.
(See also Rotman, pages 650 - 65(i))
Condition (i) immediately implies condition (ii), since ideals of $ R $ are the same as submodules of $ R $ seen as an $ R $ - module.
Now assume condition (ii) holds, and suppose $ x in R $ is any nonzero element.
Let $ lambdax $ denote multiplication by $ x $ (as an $ R $ - module map).
We have a sequence of surjective $ R $ - module maps $ R stackrel{lambdax}{to} (x) cong oplusJ R stackrel{nabla}{to} R $ (where $ nabla $ is the codiagonal map); by the Yoneda lemma, the composite map $ R to R $ is of the form $ lambdar $ , where $ r in R $ is the value of the composite at $ 1 in R $ .
Since $ lambdar $ is surjective, we have $ lambdar(s) = r s = 1 $ for some $ s $ , so that $ r $ is invertible.
Hence $ lambdar $ is invertible, and this implies $ lambdax $ is monic.
Therefore $ R $ is a domain.
From that, we infer that if $ f $ and $ g $ belong to a basis of an ideal $ I $ , then $ 0 neq f g in Rcdot f cap R cdot g $ whence $ f $ and $ g $ are not linearly independent, so $ f = g $ and $ I $ as an $ R $ - module is generated by a single element, i.e., $ R $ is a principal ideal domain.
That condition (iii) implies condition (i) is proved here.
Assuming the axiom of choice, over a ring $ R $ which is a principal ideal domain, every module has a projective resolution of length (i) See at projective resolution - - Resolutions of length 1 for more.
Assuming the axiom of choice, if $ R = k $ is a field then every $ R $ - module is free: it is $ k $ - vector space and by the basis theorem every such has a basis.
Textbooks:
A pushout is an ubiquitous construction in category theory providing a colimit for the diagram $ bulletleftarrowbulletrightarrowbullet $ .
It is dual to the notion of a pullback.
In the category Set a 'pushout' is a quotient of the disjoint union of two sets.
Given a diagram of sets and functions like this: & C arld, "f"' arrd, "g" A & & B the 'pushout' of this diagram is the set $ X $ obtained by taking the disjoint union $ A + B $ and identifying $ a in A $ with $ b in B $ if there exists $ x in C $ such that $ f(x) = a $ and $ g(x) = b $ (and all identifications that follow to keep equality an equivalence relation).
This construction comes up, for example, when $ C $ is the intersection of the sets $ A $ and $ B $ , and $ f $ and $ g $ are the obvious inclusions.
Then the pushout is just the union of $ A $ and $ B $ .
Note that there are maps $ iA : A to X $ , $ iB : B to X $ such that $ iA(a) = a $ and $ iB(b) = b $ respectively.
These maps make this square commute: & C arld, "f"' arrd, "g" A arrd, "iA"' & & B arld, "iB" & X In fact, the pushout is the universal solution to finding a commutative square like this.
In other words, given any commutative square & C arrowld, "f"' arrowrd, "g" & A arrowrd, "jA"' & & B arrowld, "jB" & Y & there is a unique function $ h: X to Y $ such that $ h iA = jA $ and $ h iB = jB $ .
Since this universal property expresses the concept of pushout purely arrow - theoretically, we can formulate it in any category.
It is, in fact, a simple special case of a colimit.
A pushout is a colimit of a diagram like this: & c arrowld, "f"' arrowrd, "g" & a & & b Such a diagram is called a span.
If the colimit exists, we obtain a commutative square & c arrowld, "f"' arrowrd, "g" & a arrowrd, "ia"' & & b arrowld, "ib" & chi & and the object $ x $ is also called the pushout.
It has the universal property already described above in the special case of the category $ Set $ .
Other terms: $ x $ is a cofibred coproduct of $ a $ and $ b $ , or (especially in algebraic categories when $ f $ and $ g $ are monomorphisms) a free product of $ a $ and $ b $ with $ c $ amalgamated, or more simply an amalgamation (or amalgam) of $ a $ and $ b $ .
The concept of pushout is a special case of the notion of wide pushout (compare wide pullback), where one takes the colimit of a diagram which consists of a set of arrows $ {fi: c to ai } {i in I} $ .
Thus an ordinary pushout is the case where $ I $ has cardinality $ 2 $ .
Note that the concept of pushout is dual to the concept of pullback: that is, a pushout in $ C $ is the same as a pullback in $ C^{op} $ .
See pullback for more details.
If coproducts exist in some category, then the pushout a arr, "f" ard, "g"' & b ard c arr & b underset{a}{sqcup} c is equivalently the coequalizer a arr, "i1 circ f", shift left arr, "i2 circ g"', shift right & b sqcup c arrowr & - 35pt b underset{a}{sqcup} c of the two morphisms induced by $ f $ and $ g $ into the coproduct of $ b $ with $ c $ .
Pushouts preserve epimorphisms and isomorphisms:
If a arrowr, "f" arrowd, "g"' & b arrowd, "fast g" c arrowr & d is a pushout square in some category then: (i) if $ g $ is a epimorphism then $ fast g $ is an epimorphism; (i) if $ g $ is an isomorphism then $ fast g $ is an isomorphism.
Consider a commuting diagram of the following shape in any category: x arrowr arrowd & y arrowr arrowd & z arrowd u arrowr & v arrowr & w
If the left square is a pushout, then the total rectangle is a pushout if and only if the right square is a pushout.
See the proof of the dual property for pullbacks.
The converse implication does not hold: it may happen that the outer and the right square are pushouts, but not the left square.
See the proof of the dual proposition for pullbacks.
Suppose that $ (mathrm{T}, mathcal{C}) $ is either Suppose that {O{0, 1}} arrowr arrowd, "m"' & {O{1, 1}} arrowd, "h" {O{0, 0}} arrowr & {O{1, 0}} is a commutative diagram in $ mathcal{C} $ such that Then See at quasitopos this lemma.
Note that the result for quasitoposes immediately implies the result for toposes, since all monomorphisms $ i: A to B $ in a topos are regular ( $ i $ being the equalizer of the arrows $ chii, t circ !: B to Omega $ in & 1 arrowd, "t" B arrowru, "!" arrowr, "chii"' & Omega where $ chii $ is the classifying map of $ i $ ) and therefore strong. ...
Textbook accounts: A space (such as a topological space) is second - countable if, in a certain sense, there is only a countable amount of information globally in its topology.
(Change 'globally' to 'locally' to get a first - countable space.)
A topological space is second - countable if it has a base for its topology consisting of a countable set of subsets.
A locale is second - countable if there is a countable set $ B $ of open subspaces (elements of the frame of opens) such that every open $ G $ is a join of some subset of $ B $ .
That is, we have $ G = bigvee { Ucolon B ;|; U subseteq G } $ .
The weight of a space is the minimum of the cardinalities of the possible bases $ B $ .
We are implicitly using the axiom of choice here, to suppose that this set of cardinalities (which really is a small set because bounded above by the number of open subspaces, and inhabited by this number as well) has a minimum.
But without Choice, we can still consider this collection of cardinalities.
Then a second - countable space is simply one with a countable weight.
Let $ n in mathbb{N} $ .
Consider the Euclidean space $ mathbb{R}^n $ with its Euclidean metric topology.
Then $ mathbb{R}^n $ is second countable.
A countable set of base open subsets is given by the open balls $ B^circx(epsilon) $ of rational radius $ epsilon in mathbb{Q}{geq 0} subset mathbb{R}{geq 0} $ and centered at points with rational coordinates: $ x in mathbb{Q}^n subset mathbb{R}^n $ .
A compact metric space is second - countable.
A separable metric space, e.g., a Polish space, is second - countable.
It is not true that separable first - countable spaces are second - countable; a counterexample is the real line equipped with the half - open or lower limit topology that has as basis the collection of half - open intervals $ a, b) $ .
A Hausdorff locally Euclidean space is second - countable precisely it is paracompact and has a countable set of connected components.
In this case it is called a topological manifold.
See at topological space this prop..
A countable coproduct (disjoint union space) of second - countable spaces is second - countable.
Countable products (product topological spaces) of second - countable spaces are second - countable.
Subspaces of second - countable spaces are second - countable.
If $ X $ is second - countable and there is an open surjection $ f colon X to Y $ , then $ Y $ is second - countable.
For second - countable T3 spaces $ X, Y $ , if $ X $ is locally compact, then the mapping space $ Y^X $ with the compact - open topology is second - countable.
Cf.
Urysohn metrization theorem and Polish space.
I (Todd Trimble) am uncertain to what extent the $ T3 $ assumption can be removed.
A simple group is a group $ G $ with exactly two quotient groups: the trivial quotient group $ {1 } cong G/G $ and the group $ G cong G/{1 } $ itself.
Equivalently, a simple group is a group possessing exactly two normal subgroups: the trivial subgroup $ {1 } $ and the group $ G $ itself.
One can also say that a normal subgroup is trivial iff
it is not $ G $ , or trivial iff proper (compare the definition in constructive mathematics below).
Note that the trivial group does not itself count as simple, on the grounds that it has only one quotient group (or only one normal subgroup).
It may be possible to find authors that use "at most" in place of "exactly", thereby allowing the trivial group to be simple.
(Compare too simple to be simple.)
In constructive mathematics, we consider a group $ G $ equipped with a tight apartness $ ne $ such that the group operations are strongly extensional and use the theory of antisubgroups (which classically are the complements of subgroups).
Then $ G $ is simple if, given any normal antisubgroup $ N $ of $ G $ , $ N $ is trivial iff
it is proper.
Explicitly, this says $ N $ owns every nonidentity element (every $ x $ such that $ x ne 1 $ ) iff $ N $ is inhabited (with some $ x $ such that necessarily $ x ne 1 $ ).
Replacing 'iff' with 'if' here would allow the trival group to be simple.
Simple groups are most commonly encountered in the theory of finite groups.
Every finite group $ G $ admits a composition series, i.e., a finite filtration of subgroups $ 1 = G0 subseteq G1 subseteq ldots subseteq Gn = G $ where each inclusion $ Gi subseteq G{i+1} $ is a normal subgroup and the quotient $ G{i+1}/Gi $ (called a composition factor) is simple.
The condition of simplicity means that that the filtration cannot be further refined by addition of strict inclusions of normal subgroups.
Furthermore, the Jordan - Hölder theorem ensures that any two composition series have the same length and the same composition factors (up to permutation).
Thus finite simple groups are in some sense the primitive building blocks of finite groups generally.
The massive program of classifying all finite simple groups was announced as completed by Daniel Gorenstein in 1983, although some doubts remained because there were some gaps in proofs.
Most if not all the gaps are considered by experts in the area to have been filled, but there remain some notable skeptics, including for example Jean - Pierre Serre, who said in an interview >
Whenever I asked the specialists, they replied something like: "Oh no, it is not a gap; it is just something which has not been written, but there is an incomplete unpublished 800 - page manuscript on it."
For me, it was just the same as a "gap, " and I could not understand why it was not acknowledged as such.
(Source) and possibly also John H. Conway, although according to Joe Shipman, >
A few months ago I was discussing the COFSG with John Conway and he was still pessimistic.
(Meaning of course that he was confident the classification was correct, "optimistic" in his case means there are previously undiscovered finite simple groups, because they're beautiful and interesting objects and it would be disappointing to have no more.)
See classification of finite simple groups.
Let $ Salpha $ be a directed system of simple groups and monomorphisms between them.
Then $ colimalpha Salpha $ is also simple.
Suppose $ N $ is a normal subgroup of $ colimalpha Salpha $ with a non - identity element.
Then $ Nalpha = N cap Salpha $ is normal in $ Salpha $ (if $ x in Salpha $ and $ y in N cap Salpha $ , then clearly $ x y x^{ - 1} $ belongs to both $ N $ and $ Salpha $ ).
As soon as $ alpha $ is large enough that $ Salpha $ contains a non - identity element of $ N $ , it follows from simplicity of $ Salpha $ that $ Nalpha = Salpha $ .
By directedness, this shows $ Nalpha = Salpha $ for all $ alpha $ , and since for any $ s in S $ there is $ alpha $ such that $ s in Salpha $ , we conclude $ s in Salpha = Nalpha subseteq N $ , i.e., $ N $ contains any $ s in S $ .
There are simple groups of any infinite cardinality $ kappa $ ; take for example the smallest normal subgroup of the automorphism group $ Aut(kappa) $ containing all 3 - cycles (this is the infinite version of the alternating group).
To see that $ Alt(kappa) $ is simple, it is enough to observe that it is a directed colimit of $ Alt(X) $ where $ X $ ranges over finite subsets of $ kappa $ of cardinality at least $ 5 $ ; then simplicity of $ An $ for integers $ n geq 0 $ , coupled with Proposition , yields the desired result.
A rather deeper set of examples is afforded by the following result, which follows from a theorem named after Baer, Ulam, and Schreier.
For an infinite set $ X $ , every proper normal subgroup of the permutation group $ Sym(X) $ is contained in a maximal such normal subgroup $ NX $ , consisting of all permutations that move fewer than $ {|X|} $ many elements of $ X $ , where $ {|X|} $ is the cardinality of $ X $ .
It follows that the quotient group $ QX = Sym(X)/NX $ is simple, and we have the following corollary.
Every group embeds into a simple group.
For finite groups $ G $ (WLOG, of cardinality at least $ 3 $ ), we have the Cayley embedding $ G hookrightarrow Sym(G) $ into the permutation group of the underlying set, and there is an embedding $ Sym(G) hookrightarrow Alt(G + 2) $ which carries an even permutation on $ G $ to the obvious even permutation on $ G + 2 $ that fixes the elements $ a, b $ of $ 2 $ , and an odd permutation $ pi $ on $ G $ to the even permutation $ pi (a; b) $ .
Hence $ G $ embeds in a simple group $ Alt(G + 2) $ .
An infinite group $ G $ embeds in $ Q_G $ via the Cayley embedding $ G hookrightarrow Sym(G) to Sym(G)/NG = QG $ noting that for any non - identity $ g in G $ , the permutation $ Cayley(g) = (h mapsto g h) $ has no fixed points, hence does not belong to $ NG $ , so that $ G to QG $ is indeed monic.
Among the infinite simple groups, there are curious examples called "Tarski monsters" for primes $ p $ , infinite groups with the property that every subgroup is either trivial, of prime order $ p $ , or the entire group.
Their existence (for all primes $ p gt 10^{75} $ , according to Wikipedia) was established only in 1979, by Olshanskii.
It may be shown that all such groups must be simple, and generated by two elements, and also that for each prime $ p gt 10^{75} $ there are continuum many monsters for $ p $ that are distinct up to isomorphism.
An endomorphism of an object $ x $ in a category $ C $ is a morphism $ f : x to x $ .
An endomorphism that is also an isomorphism is called an automorphism.
Given an object $ x $ , the endomorphisms of $ x $ form a monoid under composition, the endomorphism monoid of $ x $ : $ EndC(x) = HomC(x, x) , $ which may be written $ End(x) $ if the category $ C $ is understood.
Up to equivalence, every monoid is an endomorphism monoid; see delooping.
An endomorphism monoid is a special case of a monoid structure on an end construction.
Let $ d:Dto C $ be a diagram in $ C $ , where $ C $ is a monoidal category (in the case above the monoidal structure is the cartesian product and $ d $ is a constant diagram from the initial category).
One defines $ End(d) $ as an object in $ C $ , equipped with a natural transformation $ a: End(d) otimes d to d $ which is universal in the sense that for all objects $ Z in C $ , and any natural transformation $ f: Z otimes d to d $ there exists a unique morphism $ g: Z to End(d) $ such $ a circ (g otimes d) = f: Z otimes d to d $ .
If the universal object $ (End(d), a) $ exists then there is a unique structure of an internal monoid $ mu: End(d) otimes End(d) to End(d) $ , such that the map $ a: End(d) otimes d to d $ is an action.
In a cartesian monoidal category $ C $ , if an endomorphism monoid $ End(c) $ for an object $ c: 1 to C $ exists and is commutative, then $ c $ is a subterminal object.
Let $ k: c to End(c) $ correspond to first projection $ pi1: c times c to c $ .
Then the composition $ c times c stackrel{k times k}{to} End(c) times End(c) stackrel{comp}{to} End(c) $ (where $ comp $ denotes internal composition) may be computed to be $ k pi1 $ , corresponding to first projection $ pi1: c times c times c to c $ .
Thus, assuming commutativity of $ End(c) $ and letting $ sigma $ generally denote a symmetry map, consideration of the diagram $ array{ c times c & stackrel{k times k}{to} & End(c) times End(c) & stackrel{comp}{to} & End(c) mathllap{sigma} downarrow & & mathllap{sigma} downarrow & & downarrow mathrlap{id} c times c & stackrel{k times k}{to} & End(c) times End(c) & stackrel{comp}{to} & End(c) } $ leads to the conclusion that $ k pi1 = k pi1 sigma $ , or $ pi1 = pi2: c times c times c to c $ .
We easily conclude $ pi1 = pi2: c times c to c $ , which forces equality $ f = g $ for any two maps $ f, g: d to c $ , so that the unique map $ !: c to 1 $ is a monomorphism.
A finite abelian group is a group which is both finite and abelian.
As any finite group, a finite abelian group is pure torsion.
If a finite abelian group $ A $ has order $ {vert A vert} = p $ a prime number, then it is the cyclic group $ mathbb{Z}p $ .
If $ A $ is a finite abelian group and $ p in mathbb{N} $ is a prime number that divides the order $ {vert A vert} $ , then equivalently This is Cauchy's theorem restricted to abelian groups.
We prodeed by induction on the order of $ A $ .
For $ {vert A vert} = 2 $ we have that $ A = mathbb{Z}2 $ is the unique group of order 2 and the statement holds for $ p =2 $ .
Assume then that the statement has been show for groups of order $ lt n $ and let $ {vert A vert} = n $ .
If $ A $ has no non - trivial proper subgroup then $ n $ must be prime and $ A = mathbb{Z}n $ a cyclic group and the statement follows.
If $ A $ does have a non - trivial proper subgroup $ H hookrightarrow A $ then $ p $ divides either $ {vert H vert} $ or $ vert A/Hvert $ .
In the first case by induction assumption $ H $ has an element of order $ p $ which is therefore also an element of $ G $ of order $ p $ .
In the second case there is by induction assumption an element $ a in A $ such that $ a + H in A/H $ has order $ p $ .
Since the order of $ a + H in A/H $ divides the order of $ a in A $ it follows that $ a $ has order $ k p $ for some $ k in mathbb{N} $ .
Then $ k a $ has order $ p $ .
Every finite abelian group is the direct sum of cyclic groups of prime power order (its p - primary groups).
See for instance (Sullivan).
A new proof of the fundamental theorem of finite abelian groups was given in reviewed in By a multifunctor one may mean: (i) a "functor of several variables", i.e., the categorification of the notion of a multifunction) (i) a morphism of multicategories.
There are at least two ways to generalize the notion of a functor to the case where its domain may an n - tuple of categories: (i) jointly functorial maps (i) separately functorial maps which we discuss in turn.
In all of the following, {JointlyFunctorialMaps} A jointly functorial map from $ C1, cdots, Cn $ to $ D $ consists of: (i) a multifunction on objects $ F , colon, big( {|C1|}, ldots, {vert Cnvert} big) longrightarrow {|D|} $ (ii) For all n - tuples of morphisms $ fi , in, Ci(ai, bi), ;;;; 1 leq i leq n $ a morphism of the form $ F(f1, ldots, fn) , colon, F(a1, ldots, an) to F(b1, ldots, bn) $ in $ D $ .
such that: (i) identity morphisms are preserved, in that $ F(id{a1}, ldots, id{an}) ;=; id{F(a1, ldots, an)} $ (iv) composition is respected, in thay $ F(f1 circ g1, ldots, fn circ gn) ;=; F(f1, ldots, fn) circ F(g1, ldots, gn) , $ .
Such a jointly functorial map is the same as an ordinary functor out of the product category of the $ n $ - tuple of domain categories: $ C1 times cdots times Cn longrightarrow D , $ .
In the case $ n = 1 $ this is an ordinary functor, while for $ n = 2 $ this is a "bifunctor".
And if one understands multifunctions of zero arguments as functions out of the empty product of domain categories, which is the terminal category, then for $ n = 0 $ this is just a choice of object of $ D $ .
{SeparatelyFunctorialMaps} On the other hand, rather than requiring an "action" on morphisms from each domain category simultaneously, one may want to require an action of each domain category separately, which we could call separately functorial.
I.e., a separately functorial map $ big(C1, ldots, Cnbig) to D $ consists of: (i) A multifunction of objects $ F colon big( {|C1|}, ldots, {vert Cnvert} big) longrightarrow D $ (ii) Such that for each domain category $ Ci $ , and objects $ a1, ldotswidehat{ai}, ldots, an $ , the map $ F(a1, ldots, widehat {ai}, ldots, an) colon Ci to D $ extends to a functor from $ Ci $ to $ D $ .
This definition is instead equivalent to an ordinary functor out of the funny tensor product of the domain categories $ C1 Box cdots Box Cn longrightarrow D , $ .
For $ n = 0 $ and $ n = 1 $ this definition coincides with that of jointly functorial maps above, bu for $ n geq 2 $ arguments it is different.
For more see also at funny tensor product - - Separate functoriality On "functors of several variables": A forgetful functor from a category of actions/representations to the underlying sets/spaces is often called a fiber functor, notably in the context of Tannaka duality and Galois theory.
The archetypical example which gives rise to the term is the following.
If one has the category $ Et(X) $ of covering spaces of a (nice enough) topological space $ X $ , then after picking any point $ x in X $ the operation of forming the fibre over that point gives a functor $ fibx colon Et(X)to Set $ to the category Set of sets.
The natural automorphisms of this functor form the (algebraic) fundamental group, $ pi1(X) $ .
The main theorem of the Galois - Poincaré theory of covering spaces can be viewed as stating that this sets up an equivalence of categories between that category of covering spaces and the category of $ pi1 $ - sets.
This equivalence is compatible with the chosen fibre functor and the further forgetful functor from $ pi1 - Sets $ to $ Sets $ .
Extracting from this situation, that forgetful functor is thought of as being a fibre functor as well.
Any category of G - sets, for $ G $ a group, gives a monoidal category, and the forgetful functor is a monoidal functor; of course, the category of G - sets corresponds to the category of permutation representations of $ G $ , and generalising this basic example leads to the following idea.
The forgetful strict monoidal functor from a monoidal category to some standard monoidal category, usually the category Vect of vector spaces over a field is called the fiber functor in some contexts, especially in Tannaka reconstruction in which the symmetry object is reconstructed from the (object of) endomorphisms of the fiber functor.
In mixed Tannaka duality, a single fiber functor does not suffice for reconstruction, but rather a family of fiber functors to different bases.
Historically, the notion was used extensively, starting in the 1960s by Grothendieck and his collaborators.
The terminology is from the Grothendieck Galois theory: namely Grothendieck reconstructs the (profinite) fundamental group in algebraic geometry from a fiber functor: the fundamental group acts on a covering by deck transformations and by monodromy transformation for bundles over the covering, algebraic analogues of such a picture can thus be used to define a fundamental group, not by using some idea of loops which are often hard to define in abstract setups, but by a form of Tannakian reconstruction.
Grothendieck also introduced the idea of using many "base points" that is, many fibre functors, thus giving an abstract analogue of the fundamental groupoid of a space.
Please do not confuse the terminology with the case of a functor which is a Grothendieck fibration (i.e. a fibered category); nor with a fiber ("preimage" of a sort) of a functor.
These are related ideas but are best kept separate.
The free group on a given set $ S $ is the free object on $ S $ in the category of groups.
The elements of $ S $ are called the generators of this group.
In dependent type theory, the free group on a type $ A $ is the 0 - truncation of the underlying type of free infinity - group of $ A $ , $ mathrm{FreeGroup}(A) coloneqq mathrm{UTFIG}(A)0 $ .
This is because in any dependent type theory with uniqueness of identity proofs, where every type is 0 - truncated, the underlying type of the free infinity - group of $ A $ is the free group of $ A $ .
In addition, one could construct the free group directly from the traditional axioms of a group, as detailed below: Formation rules for free groups: $ frac{Gamma vdash A ; mathrm{type}}{Gamma vdash mathrm{FreeGroup}(A) ; mathrm{type}} $ Introduction rules for free groups: $ frac{Gamma vdash A ; mathrm{type}}{Gamma vdash eta:A to mathrm{FreeGroup}(A) ; mathrm{type}} quad frac{Gamma vdash A ; mathrm{type}}{Gamma vdash mu:mathrm{FreeGroup}(A) times mathrm{FreeGroup}(A) to mathrm{FreeGroup}(A)} $ $ frac{Gamma vdash A ; mathrm{type}}{Gamma vdash epsilon:mathrm{FreeGroup}(A)} quad frac{Gamma vdash A ; mathrm{type}}{Gamma vdash iota:mathrm{FreeGroup}(A) to mathrm{FreeGroup}(A)} $ $ frac{Gamma vdash A ; mathrm{type} quad Gamma vdash x:mathrm{FreeGroup}(A) quad Gamma vdash y:mathrm{FreeGroup}(A) quad Gamma vdash z:mathrm{FreeGroup}(A)}{Gamma vdash alpha(x, y, z):mathrm{Id}{mathrm{FreeGroup}(A)}(mu(x, mu(y, z)), mu(mu(x, y), z))} $ $ frac{Gamma vdash A ; mathrm{type} quad Gamma vdash x:mathrm{FreeGroup}(A)}{Gamma vdash lambdaepsilon(x):mathrm{Id}{mathrm{FreeGroup}(A)}(mu(epsilon, x), x)} quad frac{Gamma vdash A ; mathrm{type} quad Gamma vdash x:mathrm{FreeGroup}(A)}{Gamma vdash rhoepsilon(x):mathrm{Id}{mathrm{FreeGroup}(A)}(mu(x, epsilon), x)} $ $ frac{Gamma vdash A ; mathrm{type} quad Gamma vdash x:mathrm{FreeGroup}(A)}{Gamma vdash lambdaiota(x):mathrm{Id}{mathrm{FreeGroup}(A)}mu(iota(x), x), epsilon)} quad frac{Gamma vdash A ; mathrm{type} quad Gamma vdash x:mathrm{FreeGroup}(A)}{Gammavdash rhoiota(x):mathrm{Id}{mathrm{FreeGroup}(A)}(mu(x, iota(x)), epsilon)} $ $ frac{Gamma vdash A ; mathrm{type}}{Gamma vdash tau:mathrm{isSet}(mathrm{FreeGroup}(A))} $ Every subgroup of a free group is itself a free group.
This is the Nielsen - Schreier theorem.
Discussion of free groups in homotopy type theory: >
This entry is about the generating functions in the sense of algebraic combinatorics.
For another notion see generating function in classical mechanics.
A generating function is an element of
$ R!z! $ , the rig of formal power series over the rig $ R $ (which is often taken to be the natural numbers or the rational numbers), used for purposes of combinatorics.
A general element takes the form f(z) = sum{n=0}^{infty}fn z^n.
If $ R $ is taken to be the real numbers or the complex numbers (or any subrig), then we can ask whether the power series has a radius of convergence $ r ge 0 $
and if there's an analytic continuation; if so, then we also say that the continuation is the generating function.
When $ R = mathbb{N}, $ we can think of the coefficients on $ z^n $ as counting the number of ways to put a particular structure on the finite set $ n $ .
(You get structure types if you take this literally.)
Multiplying generating functions in the same variable gives left(sum{n=0}^{infty}fn z^nright)left(sum{n=0}^{infty}gn z^nright) = sum{n=0}^{infty}sum{k=0}^n fk g{n - k} z^n, which effectively says to split up the set into two parts, put the $ f $ structure on the first part and the $ g $ structure on the second part.
Ordinary generating functions (OGFs) describe structures on totally ordered sets, while exponential generating functions (EGFs) apply to unordered sets (whose elements may be distinguished by having different labels).
For example, the generating function for being an unordered finite set is e^z = 1 + z + frac{z^2}{2!} + frac{z^3}{3!}
+ cdots , while the generating function for being a finite ordered set is frac{1}{1 - z} = 1 + z + z^2 + z^3 + cdots .
If we assume that the zeroth term is $ 1 $ , then multiplying generating functions in different variables gives left(sum{n=0}^{infty}fn x^nright)left(sum{n=0}^{infty}gn z^nright) = 1 + (f1 x + g1 z)
+ (f2 x^2 + f1 g1 x z + g2 z^2) + cdots If we take the product of countably many generating functions $ f^i(xi) $ and then set $ xi = pi^{ - s}, $ where $ pi $ is the $ i $ th prime, then we get 1^{ - s} + f^11 2^{ - s} + f^21 3^{ - s} + f^12 4^{ - s} + f^31 5^{ - s} + f^11 f^21 6^{ - s} + cdots + prod{i} f^i{ei} (pi^{ei})^{ - s} + cdots, which is called the Dirichlet generating function for the family $ f^i $ .
The product of two Dirichlet generating functions gives left(sum{n=1}^{infty}fn n^{ - s}right)left(sum{n=1}^{infty}gn n^{ - s}right) = sum{n=1}^{infty} sum{d|n} fd g{n/d} n^{ - s}, which effectively says to factor the term into two dimensions, apply $ f $ to the first and $ g $ to the second.
Sometimes we take the exponents on $ z $ to be in a rig other than the natural numbers.
For example, we might set $ z^a cdot z^b = z^{max(a, b)} $ and $ (z^a)^b = z^{a+b}; $ such a system lets us talk about the cost of operations done in parallel (max) or sequentially (+).
Similarly, we could take the exponents to be binary strings when considering instantaneous codes, or finite field elements when considering structures on a finite collection of objects.
The OGF $ T(z) $ for binary trees (rooted in the plane, counted by number of internal nodes) satisfies $ T(z) = 1 + z T(z)^2 $ , which can be solved as $ T(z) = frac{1 - sqrt{1 - 4z}}{2z} $ .
The coefficient of $ z^n $ in $ T(z) $ is the $ n $ th Catalan number $ binom{2n}{n}/(n+1) $ .
Fixed - point free involutions on a set have the EGF $ e^{z^2/2} $ , while arbitrary involutions have EGF $ e^{z+z^2/2} $ , and partitions have EGF $ e^{e^z - 1} $ .
