{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "22703266",
   "metadata": {},
   "source": [
    "AKA T1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e33ef05f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f751a309",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_comments(text):\n",
    "    # Split the text into lines\n",
    "    lines = text.split('\\n')\n",
    "    # Filter out lines that don't start with \"%\"\n",
    "    filtered_lines = [line for line in lines if not line.strip().startswith('%') and not line.strip().startswith(\"#\") and not line.strip().startswith(\"*\") and not line.strip().startswith(\"+--\") and not line.strip().startswith(\"=--\") and not line.strip().startswith('{:')]\n",
    "    # Join the filtered lines back together\n",
    "    cleaned_text = '\\n'.join(filtered_lines)\n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d5472ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_links(text):\n",
    "    text = re.sub(r'\\[\\[![^\\]]+\\]\\]', '', text)\n",
    "    text = re.sub(r'\\[([^\\]]+)\\]\\([^\\)]+\\)', r'\\1', text)\n",
    "    start_indices = [match.start() for match in re.finditer(r'\\[\\[', text)]\n",
    "    \n",
    "    for index in start_indices:\n",
    "        if text[index - 1] == '!':\n",
    "            close_index = text.find(']', index)\n",
    "            text = text.replace(text[index - 1:close_index + 3], (close_index + 3 - index)*'#')\n",
    "        else:\n",
    "            next_pipe = text.find('|', index)\n",
    "            close_index = text.find(']', index)\n",
    "            if next_pipe != -1:\n",
    "                if next_pipe - close_index < 0:\n",
    "                    text = text.replace(text[index:next_pipe + 1], (next_pipe - index + 1)*'#')\n",
    "    text = text.replace('#', '')\n",
    "    text = text.replace('[', '')\n",
    "    text = text.replace(']', '')\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "90e5fc27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_simples(text):\n",
    "    text = text.replace(\"$$\", \"$\")\n",
    "    text = text.replace(\"\\\\begin{equation}\", \"$\")\n",
    "    text = text.replace(\"\\\\end{equation}\", \" $ .\")\n",
    "    text = text.replace(\"\\\\begin{equation*}\", \" $ \")\n",
    "    text = text.replace(\"\\\\end{equation*}\", \" $ .\")\n",
    "    text = text.replace(\"\\\\begin{align*}\", \" $\")\n",
    "    text = text.replace(\"\\\\end{align*}\", \" $ .\")\n",
    "    text = text.replace(\"\\\\begin{align}\", \" $\")\n",
    "    text = text.replace(\"\\\\end{align}\", \" $ .\")\n",
    "    text = text.replace(\"\\\\[\", \"$\")\n",
    "    text = text.replace(\"\\\\]\", \"$\")\n",
    "    text = text.replace(\"\\\\(\", \"$\")\n",
    "    text = text.replace(\"\\\\)\", \"$\")\n",
    "    text = text.replace(\".$\", \"$.\")\n",
    "    text = text.replace(\"$\", \" $ \")\n",
    "    text = text.replace(\"-\", \" - \")\n",
    "    text = text.replace(\"%\", \"\")\n",
    "    text = text.replace(\"\\\\item\", \"\")\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a4fd6ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_figures_and_exercises(text):\n",
    "    pattern = r\"\\\\begin\\{figure\\}[\\s\\S]*?\\\\end\\{figure\\}\"\n",
    "    # Use the sub() function to remove all matches of the pattern\n",
    "    text = re.sub(pattern, \"\", text, flags=re.DOTALL)\n",
    "    pattern2 = r\"\\\\begin\\{exercises\\}[\\s\\S].*?\\\\end\\{exercises\\}\"\n",
    "    # Use the sub() function to remove all matches of the pattern\n",
    "    text = re.sub(pattern2, \"\", text,flags=re.DOTALL)\n",
    "    pattern3 = r\"\\\\begin\\{minipage\\}[\\s\\S].*?\\\\end\\{minipage\\}\"\n",
    "    # Use the sub() function to remove all matches of the pattern\n",
    "    text = re.sub(pattern3, \"\", text,flags=re.DOTALL)\n",
    "    pattern3 = r\"\\\\begin\\{center\\}[\\s\\S].*?\\\\end\\{center\\}\"\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "92bb43fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_environments(text):\n",
    "    pattern = r'\\\\begin\\{[^\\}]+\\}'\n",
    "    # Substitute the pattern with an empty string\n",
    "    cleaned_text = re.sub(pattern, '', text)\n",
    "    pattern2 = r'\\\\end\\{[^\\}]+\\}'\n",
    "    # Substitute the pattern with an empty string\n",
    "    cleaned_text = re.sub(pattern2, '', cleaned_text)\n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5319ad95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_emphasis(text):\n",
    "    text = re.sub(r\"\\\\demph\\{([^{}]*)\\}\", r\"\\1\", text)\n",
    "    text = re.sub(r\"\\\\emph\\{([^{}]*)\\}\", r\"\\1\", text)\n",
    "    text = re.sub(r\"\\\\definend\\{([^{}]*)\\}\", r\"\\1\", text)\n",
    "    text = re.sub(r\"\\\\textit\\{([^{}]*)\\}\", r\"\\1\", text)\n",
    "    text = re.sub(r\"\\\\textbf\\{([^{}]*)\\}\", r\"\\1\", text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "41d6b7f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_formatting(text):\n",
    "    text = re.sub(r'~\\\\[^}]+}', ' $ X $ ', text)\n",
    "    text = re.sub(r'\\\\nearby[^\\}]+\\}', ' $ X $ ', text)\n",
    "\n",
    "    text = re.sub(r\"\\\\chapter\\{.*?\\}\", \"\", text)\n",
    "    text = re.sub(r\"\\\\section\\{.*?\\}\", \"\", text)\n",
    "    text = re.sub(r\"\\\\subsection\\{.*?\\}\", \"\", text)\n",
    "    text = re.sub(r\"\\\\subsectionoptional\\{.*?\\}\", \"\", text)\n",
    "    text = re.sub(r\"\\\\label\\{.*?\\}\", \"\", text)\n",
    "    text = re.sub(r\"\\\\ntn\\{.*?\\}\", \"\", text)\n",
    "    text = re.sub(r\"\\\\index\\{.*?\\}\", \"\", text)\n",
    "    text = re.sub(r\"\\\\ref\\{.*?\\}\", \"\", text)\n",
    "    text = re.sub(r\"\\\\bref\\{.*?\\}\", \"\", text)\n",
    "    text = re.sub(r\"\\\\eqref\\{.*?\\}\", \"\", text)\n",
    "    text = re.sub(r\"\\\\cite\\{.*?\\}\", \"\", text)\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2d6e61fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_w_spaces(text):\n",
    "    text = text.replace(\"\\\\\\\\\", \" \\\\\")\n",
    "    text = text.replace(\"\\{\", \"{\")\n",
    "    text = text.replace(\"\\}\", \" } \") \n",
    "    text = text.replace(\",\", \", \")\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "49fb7730",
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_fix(text):\n",
    "    text = text.replace(\"1.\", \"(i)\")\n",
    "    text = text.replace(\"2.\", \"(ii)\")\n",
    "    text = text.replace(\"3.\", \"(iii)\")\n",
    "    text = text.replace(\"4.\", \"(iv)\")\n",
    "    text = text.replace(\"5.\", \"(v)\")\n",
    "    text = text.replace(\"6.\", \"(vi)\")\n",
    "    text = text.replace(\"7.\", \"(vii)\")\n",
    "    text = text.replace(\"8.\", \"(viii)\")\n",
    "    text = text.replace(\"9.\", \"(ix)\")\n",
    "    text = text.replace(\"10.\", \"(x)\")\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "e7544a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_sweep(text):\n",
    "    words = [word.replace(\"\\\\\", \"\") for word in text.split() if not word.startswith(\"Helvetica\")]\n",
    "    text = \" \".join(words)\n",
    "    text = text.replace('~', \" \")\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "adf30156",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_everything(text):\n",
    "    text1 = remove_comments(text)\n",
    "    text2 = clean_links(text1)\n",
    "    text3 = remove_figures_and_exercises(text2)\n",
    "    text4 = remove_simples(text3)\n",
    "    text5 = remove_environments(text4)\n",
    "    text6 = remove_emphasis(text5)\n",
    "    text7 = remove_formatting(text6)\n",
    "    text8 = prep_w_spaces(text7)\n",
    "    text9 = list_fix(text8)\n",
    "    text10 = final_sweep(text9)\n",
    "    return text10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1aef711b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.detextor(doc)>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "from spacy_conll import init_parser\n",
    "\n",
    "nlp = init_parser(\"en_core_web_sm\", \"spacy\")\n",
    "from spacy.language import Language\n",
    "@Language.component(\"detextor\")\n",
    "def detextor(doc):\n",
    "    dollar_indices = [index for index, token in enumerate(doc) if token.text == \"$\"]\n",
    "    while len(dollar_indices) > 1:\n",
    "        with doc.retokenize() as retokenizer:\n",
    "            retokenizer.merge(doc[dollar_indices[0]:dollar_indices[1] + 1])\n",
    "        dollar_indices = [index for index, token in enumerate(doc) if token.text == \"$\"]\n",
    "    return doc\n",
    "# nlp.remove_pipe(\"detextor\") \n",
    "# you might need to add the above line back in if you run this block more than once\n",
    "nlp.add_pipe(\"detextor\", after=\"tagger\")           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f6883eea",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'remove'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [17]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m full_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/Users/lucyhorowitz/Documents/GitHub/definition-extraction/textbooks/bct/tex\u001b[39m\u001b[38;5;124m\"\u001b[39m, filename)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/Users/lucyhorowitz/Documents/GitHub/definition-extraction/textbooks/bct/bct_clean.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m----> 8\u001b[0m     f\u001b[38;5;241m.\u001b[39mwrite(\u001b[43mclean_everything\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfull_path\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "Input \u001b[0;32mIn [15]\u001b[0m, in \u001b[0;36mclean_everything\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m      2\u001b[0m text \u001b[38;5;241m=\u001b[39m clean_links(text)\n\u001b[1;32m      3\u001b[0m text \u001b[38;5;241m=\u001b[39m remove_figures_and_exercises(text)\n\u001b[0;32m----> 4\u001b[0m text \u001b[38;5;241m=\u001b[39m \u001b[43mremove_comments\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m text \u001b[38;5;241m=\u001b[39m remove_simples(text)\n\u001b[1;32m      6\u001b[0m text \u001b[38;5;241m=\u001b[39m remove_environments(text)\n",
      "Input \u001b[0;32mIn [4]\u001b[0m, in \u001b[0;36mremove_comments\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Join the filtered lines back together\u001b[39;00m\n\u001b[1;32m      7\u001b[0m cleaned_text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(filtered_lines)\n\u001b[0;32m----> 8\u001b[0m cleaned_text \u001b[38;5;241m=\u001b[39m \u001b[43mtext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mremove\u001b[49m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m:toc\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m}\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cleaned_text\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'remove'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Loop through every file name in the folder\n",
    "for filename in os.listdir(\"/Users/lucyhorowitz/Documents/GitHub/definition-extraction/textbooks/bct/tex\"):\n",
    "    # Construct the full path to the file\n",
    "    full_path = os.path.join(\"/Users/lucyhorowitz/Documents/GitHub/definition-extraction/textbooks/bct/tex\", filename)\n",
    "    with open(\"/Users/lucyhorowitz/Documents/GitHub/definition-extraction/textbooks/bct/bct_clean.txt\",\"a\") as f:\n",
    "        f.write(clean_everything(open(full_path).read()) + '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "a4b99cc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1211881"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean = open(\"/Users/lucyhorowitz/Documents/GitHub/definition-extraction/textbooks/nlab/nlab_clean.txt\",\"a\")\n",
    "clean.write(clean_everything(open(\"/Users/lucyhorowitz/Documents/GitHub/definition-extraction/textbooks/nlab/nlab_mathgloss.txt\",\"r\").read()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "7d982281",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n"
     ]
    }
   ],
   "source": [
    "text = open(\"/Users/lucyhorowitz/Documents/GitHub/definition-extraction/textbooks/nlab/nlab_clean.txt\",\"r\").readlines()\n",
    "sent_lengths = []\n",
    "with open(\"/Users/lucyhorowitz/Documents/GitHub/definition-extraction/textbooks/nlab/nlab.conllu\", \"a\") as f:\n",
    "        j = 1\n",
    "        i=1\n",
    "        for line in text:\n",
    "            text2 = clean_everything(line)\n",
    "            doc = nlp(text2)\n",
    "            print(i)\n",
    "            for sent in doc.sents:\n",
    "                doc2 = nlp(sent.text)\n",
    "                conll = doc2._.conll_str\n",
    "                sent_lengths.append(len(doc2))\n",
    "                f.write(\"# sent_id = \" + str(j) + \"\\n\")\n",
    "                f.write(\"# text = \" + sent.text + \"\\n\")\n",
    "                f.write(conll + \"\\n\")\n",
    "                j = j + 1\n",
    "            i = i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "a4d1fa26",
   "metadata": {},
   "outputs": [],
   "source": [
    "sents = open(\"textbooks/nlab/nlab_sents.txt\",\"a\")\n",
    "with open(\"textbooks/nlab/nlab.conllu\",\"r\") as a:\n",
    "    for line in a.readlines():\n",
    "        if \"# text = \" in line:\n",
    "            sents.write(line[9:])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "7e1998ff7f8aa20ada591c520b972326324e5ea05489af9e422744c7c09f6dad"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
