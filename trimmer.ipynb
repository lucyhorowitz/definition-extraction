{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "22703266",
   "metadata": {},
   "source": [
    "AKA T1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e33ef05f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f751a309",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_comments(text):\n",
    "    # Split the text into lines\n",
    "    lines = text.split('\\n')\n",
    "    # Filter out lines that don't start with \"%\"\n",
    "    filtered_lines = [line for line in lines if not line.strip().startswith('%')]\n",
    "    # Join the filtered lines back together\n",
    "    cleaned_text = '\\n'.join(filtered_lines)\n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "90e5fc27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_simples(text):\n",
    "    text = text.replace(\"$$\", \"$\")\n",
    "    text = text.replace(\"\\\\begin{equation}\", \"$\")\n",
    "    text = text.replace(\"\\\\end{equation}\", \"$\")\n",
    "    text = text.replace(\"\\\\begin{equation*}\", \"$\")\n",
    "    text = text.replace(\"\\\\end{equation*}\", \"$\")\n",
    "    text = text.replace(\"\\\\[\", \"$\")\n",
    "    text = text.replace(\"\\\\]\", \"$\")\n",
    "    text = text.replace(\"\\\\(\", \"$\")\n",
    "    text = text.replace(\"\\\\)\", \"$\")\n",
    "    text = text.replace(\".$\", \"$.\")\n",
    "    text = text.replace(\"$\", \" $ \")\n",
    "    text = text.replace(\"-\", \" - \")\n",
    "    text = text.replace(\"%\", \"\")\n",
    "    text = text.replace(\"\\\\item\", \"\")\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "9a4fd6ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_figures_and_exercises(text):\n",
    "    pattern = r\"\\\\begin\\{figure\\}(.*?)\\\\end\\{figure\\}\"\n",
    "    # Use the sub() function to remove all matches of the pattern\n",
    "    new_text = re.sub(pattern, \"\", text, flags=re.DOTALL)\n",
    "    pattern2 = r\"\\\\begin\\{exercises\\}[^\\}]+\\\\end\\{exercises\\}\"\n",
    "    # Use the sub() function to remove all matches of the pattern\n",
    "    new_text = re.sub(pattern2, \"\", new_text,flags=re.DOTALL)\n",
    "    return new_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "d1b75dc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Some text before the figure.\n",
      "\begin{figure}\n",
      "    Figure content to be removed.\n",
      "\\end{figure}\n",
      "Some text after the figure.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def remove_figure_content(text):\n",
    "    # Define the regular expression pattern\n",
    "    pattern = r'\\\\begin\\{figure\\}.*?\\\\end\\{figure\\}'\n",
    "    \n",
    "    # Replace all occurrences of the pattern with an empty string\n",
    "    clean_text = re.sub(pattern, '', text, flags=re.DOTALL)\n",
    "    \n",
    "    return clean_text\n",
    "\n",
    "# Example usage:\n",
    "text = \"\"\"\n",
    "Some text before the figure.\n",
    "\\begin{figure}\n",
    "    Figure content to be removed.\n",
    "\\end{figure}\n",
    "Some text after the figure.\n",
    "\"\"\"\n",
    "\n",
    "cleaned_text = remove_figure_content(text)\n",
    "print(cleaned_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "92bb43fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_environments(text):\n",
    "    \n",
    "    pattern = r'\\\\begin\\{[^\\}]+\\}'\n",
    "    # Substitute the pattern with an empty string\n",
    "    cleaned_text = re.sub(pattern, '', text)\n",
    "    pattern2 = r'\\\\end\\{[^\\}]+\\}'\n",
    "    # Substitute the pattern with an empty string\n",
    "    cleaned_text = re.sub(pattern2, '', cleaned_text)\n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5319ad95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_emphasis(text):\n",
    "    text = re.sub(r\"\\\\demph\\{([^{}]*)\\}\", r\"\\1\", text)\n",
    "    text = re.sub(r\"\\\\emph\\{([^{}]*)\\}\", r\"\\1\", text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "41d6b7f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_formatting(text):\n",
    "    text = re.sub(r'~\\\\[^}]+}', ' $ X $ ', text)\n",
    "    text = re.sub(r'\\\\nearby[^\\}]+\\}', ' $ X $ ', text)\n",
    "\n",
    "    text = re.sub(r\"\\\\chapter\\{.*?\\}\", \"\", text)\n",
    "    text = re.sub(r\"\\\\section\\{.*?\\}\", \"\", text)\n",
    "    text = re.sub(r\"\\\\subsection\\{.*?\\}\", \"\", text)\n",
    "    text = re.sub(r\"\\\\label\\{.*?\\}\", \"\", text)\n",
    "    text = re.sub(r\"\\\\ntn\\{.*?\\}\", \"\", text)\n",
    "    text = re.sub(r\"\\\\index\\{.*?\\}\", \"\", text)\n",
    "    text = re.sub(r\"\\\\ref\\{.*?\\}\", \"\", text)\n",
    "    text = re.sub(r\"\\\\bref\\{.*?\\}\", \"\", text)\n",
    "    text = re.sub(r\"\\\\eqref\\{.*?\\}\", \"\", text)\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2d6e61fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_w_spaces(text):\n",
    "    text = text.replace(\"\\\\\\\\\", \" \\\\\")\n",
    "    text = text.replace(\"\\{\", \"{\")\n",
    "    text = text.replace(\"\\}\", \" } \") \n",
    "    text = text.replace(\",\", \", \")\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "49fb7730",
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_fix(text):\n",
    "    text = text.replace(\"1.\", \"(i)\")\n",
    "    text = text.replace(\"2.\", \"(ii)\")\n",
    "    text = text.replace(\"3.\", \"(iii)\")\n",
    "    text = text.replace(\"4.\", \"(iv)\")\n",
    "    text = text.replace(\"5.\", \"(v)\")\n",
    "    text = text.replace(\"6.\", \"(vi)\")\n",
    "    text = text.replace(\"7.\", \"(vii)\")\n",
    "    text = text.replace(\"8.\", \"(viii)\")\n",
    "    text = text.replace(\"9.\", \"(ix)\")\n",
    "    text = text.replace(\"10.\", \"(x)\")\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e7544a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_sweep(text):\n",
    "    words = [word.replace(\"\\\\\", \"\") for word in text.split() if not word.startswith(\"Helvetica\")]\n",
    "    text = \" \".join(words)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "adf30156",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_everything(text):\n",
    "    text = remove_comments(text)\n",
    "    text = remove_simples(text)\n",
    "    text = remove_figures_and_exercises(text)\n",
    "    text = remove_environments(text)\n",
    "    text = remove_emphasis(text)\n",
    "    text = remove_formatting(text)\n",
    "    text = prep_w_spaces(text)\n",
    "    text = list_fix(text)\n",
    "    text = final_sweep(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "1aef711b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.detextor(doc)>"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "from spacy_conll import init_parser\n",
    "\n",
    "nlp = init_parser(\"en_core_web_sm\", \"spacy\")\n",
    "from spacy.language import Language\n",
    "@Language.component(\"detextor\")\n",
    "def detextor(doc):\n",
    "    dollar_indices = [index for index, token in enumerate(doc) if token.text == \"$\"]\n",
    "    while len(dollar_indices) > 1:\n",
    "        with doc.retokenize() as retokenizer:\n",
    "            retokenizer.merge(doc[dollar_indices[0]:dollar_indices[1] + 1])\n",
    "        dollar_indices = [index for index, token in enumerate(doc) if token.text == \"$\"]\n",
    "    return doc\n",
    "# nlp.remove_pipe(\"detextor\") \n",
    "# you might need to add the above line back in if you run this block more than once\n",
    "nlp.add_pipe(\"detextor\", after=\"tagger\")           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "f6883eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "adj = open(\"/Users/lucyhorowitz/Documents/GitHub/definition-extraction/textbooks/bct/adj.tex\",\"r\").read()\n",
    "arl = open(\"/Users/lucyhorowitz/Documents/GitHub/definition-extraction/textbooks/bct/arl.tex\",\"r\").read()\n",
    "cfnt = open(\"/Users/lucyhorowitz/Documents/GitHub/definition-extraction/textbooks/bct/cfnt.tex\",\"r\").read()\n",
    "gaft = open(\"/Users/lucyhorowitz/Documents/GitHub/definition-extraction/textbooks/bct/gaft.tex\",\"r\").read()\n",
    "intro = open(\"/Users/lucyhorowitz/Documents/GitHub/definition-extraction/textbooks/bct/intro.tex\",\"r\").read()\n",
    "lims = open(\"/Users/lucyhorowitz/Documents/GitHub/definition-extraction/textbooks/bct/lims.tex\",\"r\").read()\n",
    "rep = open(\"/Users/lucyhorowitz/Documents/GitHub/definition-extraction/textbooks/bct/rep.tex\",\"r\").read()\n",
    "sets = open(\"/Users/lucyhorowitz/Documents/GitHub/definition-extraction/textbooks/bct/sets.tex\",\"r\").read()\n",
    "\n",
    "tex = [adj, arl, cfnt, gaft, intro, lims, rep, sets]\n",
    "\n",
    "with open(\"textbooks/bct/all_clean.txt\",\"a\") as a:\n",
    "    for thing in tex:\n",
    "        a.write(clean_everything(thing))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "7d982281",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = open(\"/Users/lucyhorowitz/Documents/GitHub/definition-extraction/textbooks/bct/all_clean.txt\",\"r\").read()\n",
    "sent_lengths = []\n",
    "with open(\"textbooks/bct/bct.conllu\", \"a\") as f:\n",
    "        text = clean_everything(text)\n",
    "        doc = nlp(text)\n",
    "        j = 1\n",
    "        for sent in doc.sents:\n",
    "            doc2 = nlp(sent.text)\n",
    "            conll = doc2._.conll_str\n",
    "            sent_lengths.append(len(doc2))\n",
    "            f.write(\"# sent_id = \" + str(j) + \"\\n\")\n",
    "            f.write(\"# text = \" + sent.text + \"\\n\")\n",
    "            f.write(conll + \"\\n\")\n",
    "            j = j + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "a4d1fa26",
   "metadata": {},
   "outputs": [],
   "source": [
    "sents = open(\"textbooks/bct/bct_sents.txt\",\"a\")\n",
    "with open(\"textbooks/bct/bct.conllu\",\"r\") as a:\n",
    "    for line in a.readlines():\n",
    "        if \"# text = \" in line:\n",
    "            sents.write(line[9:])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "7e1998ff7f8aa20ada591c520b972326324e5ea05489af9e422744c7c09f6dad"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
