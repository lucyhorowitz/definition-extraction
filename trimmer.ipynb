{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "22703266",
   "metadata": {},
   "source": [
    "AKA T1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e33ef05f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "90e5fc27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_simples(text):\n",
    "    text = text.replace(\"$$\", \"$\")\n",
    "    text = text.replace(\"\\\\begin{equation}\", \"$\")\n",
    "    text = text.replace(\"\\\\end{equation}\", \"$\")\n",
    "    text = text.replace(\"\\\\[\", \"$\")\n",
    "    text = text.replace(\"\\\\]\", \"$\")\n",
    "    text = text.replace(\".$\", \"$.\")\n",
    "    text = text.replace(\"$\", \" $ \")\n",
    "    text = text.replace(\"-\", \" - \")\n",
    "    text = text.replace(\"%\", \"\")\n",
    "    text = text.replace(\"\\\\item\", \"\")\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9a4fd6ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_figures(text):\n",
    "    pattern = r\"\\\\begin\\{figure\\}(.*?)\\\\end\\{figure\\}\"\n",
    "\n",
    "    # Use the sub() function to remove all matches of the pattern\n",
    "    new_text = re.sub(pattern, \"\", text)\n",
    "    return new_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "92bb43fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_environments(text):\n",
    "    \n",
    "    pattern = r'\\\\begin\\{[^\\}]+\\}'\n",
    "    # Substitute the pattern with an empty string\n",
    "    cleaned_text = re.sub(pattern, '', text)\n",
    "    pattern2 = r'\\\\end\\{[^\\}]+\\}'\n",
    "    # Substitute the pattern with an empty string\n",
    "    cleaned_text = re.sub(pattern2, '', cleaned_text)\n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5319ad95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_emphasis(text):\n",
    "    text = re.sub(r\"\\\\demph\\{([^{}]*)\\}\", r\"\\1\", text)\n",
    "    text = re.sub(r\"\\\\emph\\{([^{}]*)\\}\", r\"\\1\", text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "41d6b7f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_formatting(text):\n",
    "    pattern = r'~\\\\[^}]+}'\n",
    "    text = re.sub(pattern, ' $ X $ ', text)\n",
    "\n",
    "    text = re.sub(r\"\\\\chapter\\{.*?\\}\", \"\", text)\n",
    "    text = re.sub(r\"\\\\section\\{.*?\\}\", \"\", text)\n",
    "    text = re.sub(r\"\\\\subsection\\{.*?\\}\", \"\", text)\n",
    "    text = re.sub(r\"\\\\label\\{.*?\\}\", \"\", text)\n",
    "    text = re.sub(r\"\\\\ntn\\{.*?\\}\", \"\", text)\n",
    "    text = re.sub(r\"\\\\index\\{.*?\\}\", \"\", text)\n",
    "    text = re.sub(r\"\\\\ref\\{.*?\\}\", \"\", text)\n",
    "    text = re.sub(r\"\\\\bref\\{.*?\\}\", \"\", text)\n",
    "    text = re.sub(r\"\\\\eqref\\{.*?\\}\", \"\", text)\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2d6e61fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_w_spaces(text):\n",
    "    text = text.replace(\"\\\\\\\\\", \" \\\\\")\n",
    "    text = text.replace(\"\\{\", \"{\")\n",
    "    text = text.replace(\"\\}\", \" } \") \n",
    "    text = text.replace(\",\", \", \")\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "49fb7730",
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_fix(text):\n",
    "    text = text.replace(\"1.\", \"(i)\")\n",
    "    text = text.replace(\"2.\", \"(ii)\")\n",
    "    text = text.replace(\"3.\", \"(iii)\")\n",
    "    text = text.replace(\"4.\", \"(iv)\")\n",
    "    text = text.replace(\"5.\", \"(v)\")\n",
    "    text = text.replace(\"6.\", \"(vi)\")\n",
    "    text = text.replace(\"7.\", \"(vii)\")\n",
    "    text = text.replace(\"8.\", \"(viii)\")\n",
    "    text = text.replace(\"9.\", \"(ix)\")\n",
    "    text = text.replace(\"10.\", \"(x)\")\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e7544a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_sweep(text):\n",
    "    words = [word.replace(\"\\\\\", \"\") for word in text.split() if not word.startswith(\"Helvetica\")]\n",
    "    text = \" \".join(words)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "adf30156",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_everything(text):\n",
    "    text = remove_simples(text)\n",
    "    text = remove_environments(text)\n",
    "    text = remove_emphasis(text)\n",
    "    text = remove_formatting(text)\n",
    "    text = prep_w_spaces(text)\n",
    "    text = list_fix(text)\n",
    "    text = final_sweep(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1aef711b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.detextor(doc)>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "from spacy_conll import init_parser\n",
    "\n",
    "nlp = init_parser(\"en_core_web_sm\", \"spacy\")\n",
    "from spacy.language import Language\n",
    "@Language.component(\"detextor\")\n",
    "def detextor(doc):\n",
    "    dollar_indices = [index for index, token in enumerate(doc) if token.text == \"$\"]\n",
    "    while len(dollar_indices) > 1:\n",
    "        with doc.retokenize() as retokenizer:\n",
    "            retokenizer.merge(doc[dollar_indices[0]:dollar_indices[1] + 1])\n",
    "        dollar_indices = [index for index, token in enumerate(doc) if token.text == \"$\"]\n",
    "    return doc\n",
    "# nlp.remove_pipe(\"detextor\") \n",
    "# you might need to add the above line back in if you run this block more than once\n",
    "nlp.add_pipe(\"detextor\", after=\"tagger\")           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f6883eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = open(\"/Users/lucyhorowitz/Documents/GitHub/definition-extraction/textbooks/bct/sets.tex\",\"r\").read()\n",
    "\n",
    "with open(\"textbooks/bct/sets.txt\",\"w\") as a:\n",
    "    a.write(clean_everything(text))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7d982281",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = open(\"/Users/lucyhorowitz/Documents/GitHub/definition-extraction/textbooks/bct/sets.txt\",\"r\").read()\n",
    "sent_lengths = []\n",
    "with open(\"textbooks/bct/sets.conllu\", \"a\") as f:\n",
    "        text = clean_everything(text)\n",
    "        doc = nlp(text)\n",
    "        j = 1\n",
    "        for sent in doc.sents:\n",
    "            doc2 = nlp(sent.text)\n",
    "            conll = doc2._.conll_str\n",
    "            sent_lengths.append(len(doc2))\n",
    "            f.write(\"# sent_id = \" + str(j) + \"\\n\")\n",
    "            f.write(\"# text = \" + sent.text + \"\\n\")\n",
    "            f.write(conll + \"\\n\")\n",
    "            j = j + 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "7e1998ff7f8aa20ada591c520b972326324e5ea05489af9e422744c7c09f6dad"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
